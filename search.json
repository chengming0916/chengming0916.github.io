[{"title":"Git代码提交规范","url":"/2024/12/19/Git/Git%E4%BB%A3%E7%A0%81%E6%8F%90%E4%BA%A4%E8%A7%84%E8%8C%83/","content":"消息格式每个提交消息都由一个标题、一个正文和一个页脚组成。而标题又具有特殊格式，包括修改类型、影响范围和内容主题：\n修改类型(影响范围): 标题&lt;--空行--&gt;[正文]&lt;--空行--&gt;[页脚]\n\n标题是强制性的，但标题的范围是可选的。\n修改类型每个类型值都表示了不同的含义，类型值必须是以下的其中一个：\n\nfeat：提交新功能\nfix：修复了bug\ndocs：只修改了文档\nstyle：调整代码格式，未修改代码逻辑（比如修改空格、格式化、缺少分号等）\nrefactor：代码重构，既没修复bug也没有添加新功能\nperf：性能优化，提高性能的代码更改\ntest：添加或修改代码测试\nchore：对构建流程或辅助工具和依赖库（如文档生成等）的更改\n\n代码回滚代码回滚比较特殊，如果本次提交是为了恢复到之前的某个提交，那提交消息应该以revert:开头，后跟要恢复到的那个提交的标题。然后在消息正文中，应该写上This reverts commit &lt;hash&gt;，其中&lt;hash&gt;是要还原的那个提交的SHA值。\n影响范围范围不是固定值，它可以是你提交代码实际影响到的任何内容。例如$location、$browser、$compile、$rootScope、ngHref、ngClick、ngView等，唯一需要注意的是它必须足够简短。\n当修改影响多个范围时，也可以使用*。\n标题标题是对变更的简明描述：\n\n使用祈使句，现在时态：是“change”不是“changed”也不是“changes”\n不要大写首字母\n结尾不要使用句号\n\n正文正文是对标题的补充，但它不是必须的。和标题一样，它也要求使用祈使句且现在时态，正文应该包含更详细的信息，如代码修改的动机，与修改前的代码对比等。\n页脚任何Breaking Changes（破坏性变更，不向下兼容）都应该在页脚中进行说明，它经常也用来引用本次提交解决的GitHub Issue。\nBreaking Changes应该以“BREAKING CHANGE:”开头，然后紧跟一个空格或两个换行符，其他要求与前面一致。\n分支功能描述master: 长期分支，用于对外版本发布，所有版本出自此版本库。此分支不允许直接提交代码，只从bugfix分支和develop分支合并。\ndevelop: 长期分支，用于日常代码开发，与master分支 保持同步，当新功能开发完成后线合并到此分支，经过测试后再合并到master分支。\nbugfix: 临时分支，当出现bug时基于master分支新建bugfix/bug-1,bug分支可根据bug编号命名。bug测试完毕合并进入develop分支和master分支\nfeature: 临时分支，开发新功能时从develop分支新建feature/feature-1,feature分支可根据功能命名。新特性开发完成合并进入develop分支并删除feature分支。\nrelease: 临时分支，需要发布版本时从master分支新建release/release-1.0.0,release分支根据版本号命名。\nrelease分支禁止再合并功能，只提交bug修改，版本发布完成后合并进入master和develop，并再对应的提交上打版本Tag。\n提交规范参考格式\n&lt;type&gt;: &lt;subject&gt;&lt;BLANK LINE&gt; 空行&lt;body&gt;&lt;BLANK LINE&gt; 空行&lt;footer&gt;\n\n\ntype:  本次commit的类型，如bugfix,docs,style等\n\nfeat: 添加新特性\n\nfix: 修复bug\n\ndocs: 修改文档\n\nstyle: 修改格式缩进,不改变代码逻辑\n\nrefactor: 代码重构,没有添加新下功能或者修复bug\n\nperf: 增加代码进行性能测试\n\ntest: 增加测试用例\n\nchore:  改变构建流程或者增加依赖库、工具等\n\nscope: 本次commit波及范围\n\nsubject: 简明扼要阐述本次commit的主旨\n\n使用祈使句\n首字母不要大写\n结尾无需添加标点\n\n\nbody: 详细描述本次commit,如需换行则使用|\n\nfooter: 描述下与之关联的 issue 或 breadk change\n\n\n标题行： 50个字符以内，描述主要变更内容\n主体内容: 更详细下说明文本，建议72个字符以内。需要描述信息包括：\n\n为什么这个变更是必须的，它可能是用来修复一个bug，增加一个feature,提升性能、可靠性、稳定性等\n如何解决这个问题，具体描述解决问题的步骤\n是否存在副作用、风险\n\n如果需要的话可以添加一个连接到issue或其他文档\n示例\ndocs(README): README添加代码提交规范添加代码规范，提升提交日志的可读性和功能#123 #没有关联的issue可以省略----------------------feat: 增加XXX功能增加XXX功能，实现XXX效果#21\n","categories":["Git"],"tags":["Git"]},{"title":"Git解决中文乱码","url":"/2017/03/11/Git/Git%E8%A7%A3%E5%86%B3%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81/","content":"解决路径显示数字问题\n命令及现象\n\ngit status # 当提交文件中有中文目录时，目录会显示为数字\n\n\n原因\n在默认设置下中文名不能正常显示，而是显示为八进制的字符编码。\n\n解决办法\n修改git配置文件core.quotepath 为false\n# --global 表示全局配置git config --global core.quotepath false\n\n\n\n终端输出中文为乱码\n命令及现象\ngit log # 当log中有中文日志时，日志显示为乱码\n\n原因\ngit commit  默认的编码是UTF-8 ,cmd默认的编码是GB-2312,字符集不同显示为乱码。\n\n解决办法\n# 设置GUI编码为UTF-8git config --global gui.encoding utf-8# 设置提交日志编码为UTF-8git config --global i18n.commitencoding  utf-8\n\n\n\n配置文件配置文件默认存放路径\nC:\\Users\\[用户名]\\.gitconfig # 全局配置文件存放路径，修改此文件效果等价git config --global[存储库根目录]\\.git\\config    # 当前存储库配置文件，只影响当前存储库，效果等价于在此存储库执行 git config\n\n# 全局设置[gui]      encoding = utf-8 [core]\tquotePath = false[i18n]      commitencoding = utf-8  \n\n\n\n","categories":["Git"],"tags":["环境配置"]},{"title":"Git配置","url":"/2019/04/12/Git/Git%E9%85%8D%E7%BD%AE/","content":"配置用户信息#配置用户名和邮箱git config --global user.name git config --global user.email\n\n配置编码#中文路径和文件名乱码git config --global core.quotePath false#修改commit编码方式git config --global i18n.commitEncoding utf-8git config --global i18n.logOutputEncoding\n\n配置内网域名证书git config --global http.&quot;内网域名&quot;.sslCAInfo &quot;证书所在路径&quot;# 示例git config --global http.&quot;https://example.io&quot;.sslCAInfo ~/.certs/selfsigned-root-ca.crt","categories":["Git"]},{"title":"Git子库","url":"/2020/04/29/Git/submodule/","content":"原文链接:Git应用详解第十讲：Git子库：submodule与subtree\n一个中大型项目往往会依赖几个模块，git提供了子库的概念。可以将这些子模块存放在不同的仓库中，通过submodule或subtree实现仓库的嵌套。本讲为Git应用详解的倒数第二讲，胜利离我们不远了！\n一、submodulesubmodule：子模块的意思，表示将一个版本库作为子库引入到另一个版本库中：\n\n1.引入子库需要使用如下命令：\ngit submodule add 子库地址 保存目录比如：\ngit submodule add git@github.com:AhuntSun/git_child.git mymodule\n\n执行上述命令会将地址对应的远程仓库作为子库，保存到当前版本库的mymodule目录下：\n\n随后查看当前版本库的状态：\n\n可以发现新增了两个文件。查看其中的.gitmodules文件：\n\n可以看到当前文件的路径和子模块的url，随后将这两个新增文件添加、提交并推送。在当前仓库git_parent对应的远程仓库中多出了两个文件：\n\n其中mymodule文件夹上的3bd7f76 对应的是子仓库git_child中的最新提交：\n\n点击mymodule文件夹，会自动跳转到子仓库中：\n\n通过上述分析，可以得出结论：两个仓库已经关联起来了，并且仓库git_child为仓库git_parent的子仓库；\n2.同步子库变化当被依赖的子版本库发生变化时：在子版本库git_child中新增文件world.txt并提交到远程仓库：\n\n这个时候依赖它的父版本库git_parent要如何感知这一变化呢？\n方法一这个时候git_parent只需要进入存放子库git_child的目录mymodule，执行git pull就能将子版本库git_child的更新拉取到本地：\n\n方法二当父版本库git_parent依赖的多个子版本库都发生变化时，可以采用如下方法遍历更新所有子库：首先回到版本库主目录，执行以下指令：\ngit submodule foreach git pull\n\n该命令会遍历当前版本库所依赖的所有子版本库，并将它们的更新拉取到父版本库git_parent：\n\n拉取完成后，查看状态，发现mymodule目录下文件发生了变化，所以需要执行一次添加、提交、推送操作：\n\n3.复制父版本库如果将使用了submodule添加依赖了子库的父版本库git_parent，克隆一份到本地的话。在克隆出来的新版本库git_parent2中，原父版本库存放依赖子库的目录虽在，但是内容不在：\n\n进入根据git_parent复制出来的仓库git_parent2，会发现mymodule目录为空：\n\n解决方法：可采用多条命令的分步操作，也可以通过参数将多步操作进行合并。\n分步操作这是在执行了clone操作后的额外操作，还需要做两件事：\n\n手动初始化submodule：\ngit submodule init\n\n手动拉取依赖的子版本库；：\ngit submodule update --recursive\n\n\n执行完两步操作后，子版本库中就有内容了。由此完成了git_parent的克隆；\n合并操作分步操作相对繁琐，还可以通过添加参数的方式，将多步操作进行合并。通过以下指令基于git_parent克隆一份git_parent3：\ngit clone git@github.com:AhuntSun/git_parent.git git_parent3 --recursive\n\n\n--recursive表示递归地克隆git_parent依赖的所有子版本库。\n4.删除子版本库git没有提供直接删除submodule子库的命令，但是我们可以通过其他指令的组合来达到这一目的，分为三步：\n\n将submodule从版本库中删除：\ngit rm --cache mymodule\n\n\n\ngit rm的作用为删除版本库中的文件，并将这一操作纳入暂存区；\n\n\n将submodule从工作区中删除；\n\n\n\n最后将.gitmodules目录删除；\n\n\n完成三步操作后，再进行添加，提交，推送即可完成删除子库的操作：\n\n二、subtree1.简介subtree与submodule的作用是一样的，但是subtree出现得比submodule晚，它的出现是为了弥补submodule存在的问题：\n\n第一：submodule不能在父版本库中修改子版本库的代码，只能在子版本库中修改，是单向的；\n第二：submodule没有直接删除子版本库的功能；\n\n而subtree则可以实现双向数据修改。官方推荐使用subtree替代submodule。\n2.创建子库首先创建两个版本库：git_subtree_parent和git_subtree_child然后在git_subtree_parent中执行git subtree会列出该指令的一些常见的参数：\n\n3.建立关联首先需要给git_subtree_parent添加一个子库git_subtree_child:\n第一步：添加子库的远程地址：\ngit remote add subtree-origin git@github.com:AhuntSun/git_subtree_child.git\n\n添加完成后，父版本库中就有两个远程地址了：\n\n这里的subtree-origin就代表了远程仓库git_subtree_child的地址。\n第二步：建立依赖关系：\ngit subtree add --prefix=subtree subtree-origin master --squash//其中的--prefix=subtree可以写成：--p subtree 或 --prefix subtree\n\n该命令表示将远程地址为subtree-origin的，子版本库上master分支的，文件克隆到subtree目录下；\n\n注意：是在某一分支（如master）上将subtree-origin代表的远程仓库的某一分支（如master）作为子库拉取到subtree文件夹中。可切换到其他分支重复上述操作，也就是说子库的实质就是子分支。\n\n--squash是可选参数，它的含义是合并，压缩的意思。\n\n如果不增加这个参数，则会把远程的子库中指定的分支（这里是master）中的提交一个一个地拉取到本地再去创建一个合并提交；\n如果增加了这个参数，会将远程子库指定分支上的多次提交合并压缩成一次提交再拉取到本地，这样拉取到本地的，远程子库中的，指定分支上的，历史提交记录就没有了。\n\n\n拉取完成后，父版本库中会增添一个subtree目录，里面是子库的文件，相当于把依赖的子库代码拉取到了本地：\n\n此时查看一下父版本库的提交历史：\n会发现其中没有子库李四的提交信息，这是因为--squash参数将他的提交压缩为一次提交，并由父版本库张三进行合并和提交。所以父版本库多出了两次提交。\n随后，我们在父版本库中进行一次推送：\n\n结果远程仓库中多出了一个存放子版本库文件的subtree目录，并且完全脱离了版本库git_subtree_child，仅仅是属于父版本库git_subtree_parent的一个目录。而不像使用submodule那样，是一个点击就会自动跳转到依赖子库的指针：\n\nsubtree的远程父版本库：\n\n\n\nsubmodule的远程父版本库：\n\n\n即submodule与subtree子库的区别为：\n\n4.同步子库变化在子库中创建一个新文件world并推送到远程子库：\n在父库中通过如下指令更新依赖的子库内容：\ngit subtree pull --prefix=subtree subtree-origin master --squash\n\n\n此时查看一下提交历史：\n\n发现没有子库李四的提交信息，这都是--squash的作用。子库的修改交由父库来提交。\n5.参数--squash该参数的作用为：防止子库指定分支上的提交历史污染父版本库。比如在子库的master分支上进行了三次提交分别为：a、b、c，并推送到远程子库。\n首先，复习一下合并分支时遵循的三方合并原则：\n\n当提交4和6需要合并的时候，git会先寻找二者的公共父提交节点，如图中的2，然后在提交2的基础上进行2、4、6的三方合并，合并后得到提交7。\n父仓库执行pull操作时：如果添加参数--squash，就会把远程子库master分支上的这三次提交合并为一次新的提交abc；随后再与父仓库中子库的master分支进行合并，又产生一次提交X。整个pull的过程一共产生了五次提交，如下图所示：\n\n存在的问题：\n由于--squash指令的合并操作，会导致远程master分支上的合并提交abc与本地master分支上的最新提交2，找不到公共父节点，从而合并失败。同时push操作也会出现额外的问题。\n最佳实践：要么全部操作都使用--squash指令，要么全部操作都不使用该参数，这样就不会出错。\n错误示范：\n为了验证，重新创建两个仓库A和B，并通过subtree将B设置为A的子库。这次全程都没有使用参数--squash，重复上述操作：\n\n首先，修改子库文件；\n然后，通过下列指令，在不使用参数--squash的情况下，将远程子库A变化的文件拉取到本地：\n\ngit subtree pull --prefix=subtree subtree-origin master\n\n\n此时查看提交历史：\n\n可以看到子库儿子的提交信息污染了父版本库的提交信息，验证了上述的结论。\n所以要么都使用该指令，要么都不使用才能避免错误；如果不需要子库的提交日志，推荐使用--squash指令。\n\n补充：echo &#39;new line&#39; &gt;&gt; test.txt：表示在test.txt文件末尾追加文本new line；如果是一个&gt;表示替换掉test.txt内的全部内容。\n\n6.修改子库subtree的强大之处在于，它可以在父版本库中修改依赖的子版本库。以下为演示：\n进入父版本库存放子库的subtree目录，修改子库文件child.txt，并推送到远程父仓库：\n\n此时远程父版本库中存放子库文件的subtree目录发生了变化，但是独立的远程子库git_subtree_child并没有发生变化。\n\n修改独立的远程子库：\n可执行以下命令，同步地修改远程子版本库：\ngit subtree push --prefix=subtree subtree-origin master\n\n如下图所示，父库中的子库文件child.txt新增的child2内容，同步到了独立的远程子库中：\n\n\n修改独立的本地子库：\n回到本地子库git_subtree_child，将对应的远程子库进行的修改拉取到本地进行合并同步：\n\n由此无论是远程的还是本地的子库都被修改了。\n\n\n\n实际上使用subtree后，在外部看起来父仓库和子仓库是一个整体的仓库。执行clone操作时，不会像submodule那样需要遍历子库来单独克隆。而是可以将整个父仓库和它所依赖的子库当做一个整体进行克隆。\n\n存在的问题父版本库拉取远程子库进行更新同步会出现的问题：\n\n子仓库第一次修改：\n经历了上述操作，本地子库与远程子库的文件达到了同步，其中文件child.txt的内容都是child~4。在此基础上本地子库为该文件添加child5~6：\n\n然后推送到远程子库。\n\n父仓库第一次拉取：\n随后父版本库通过下述指令，拉取远程子库，与本地父仓库git_subtree_parent中的子库进行同步：\ngit subtree pull --p subtree subtree-origin master --squash\n\n结果出现了合并失败的情况：\n\n我们查看冲突产生的文件：\n\n发现父版本库中的子库与远程子库内容上并无冲突，但是却发生了冲突，这是为什么呢？\n探究冲突产生的原因之前我们先解决冲突，先删除多余的内容：\n\n随后执行git add命令和git commit命令标识解决了冲突：\n\n\n解决完冲突后将该文件推送到独立的远程子库，发现文件并没有发生更新，也就是说git认为我们并没有解决冲突：\n\n\n子仓库第二次修改与父仓库第二次拉取：\n再次修改本地子库的文件并推送到对应的远程仓库，父版本库再次将远程子库更新的文件拉取到本地进行同步：\n\n这次却成功了！为什么同样的操作，有的时候成功有的时候失败呢？\n\n\n解决方案原因出现在--squash指令中。实际上，--squash指令把子库中的提交信息合并了，导致父仓库在执行git pull操作时找不到公共的父节点，从而导致即使文件没有冲突的内容，也会出现合并冲突的情况。其实不使用--squash也会有这种问题，问题的根本原因仍然是三方合并时找不到公共父节点。我们打开gitk：\n\n从图中不难看出，当使用subtree时，子库与父库之间是没有公共节点的，所以时常会因为找不到公共节点而出现合并冲突的情况，此时只需要解决冲突，手动合并即可。\n\n不使用subtree时，普通的版本库中的各分支总会有一个公共节点：\n\n\n再次强调：使用--squash指令时一定要小心，要么都使用它，要么都不使用。\n7.抽离子库git subtree split当开发过程中出现某些子库完全可以复用到其他项目中时，我们希望将它独立出来。\n\n方法一：可以手动将文件拷贝出来。缺点是，这样会丢失关于该子库的提交记录；\n\n方法二：\n使用\ngit subtree split\n\n指令，该指令会把关于独立出来的子库的每次提交都记录起来。但是，这样存在弊端：\n\n比如该独立子库为company.util，当一次提交同时修改了company.util和company.server两个子库时。\n通过上述命令独立出来的子库util只会记录对自身修改的提交，而不会记录对company.server的修改，这样在别人看来这次提交就只修改了util，这是不完整的。\n\n\n\n","categories":["Git"],"tags":["Git","Subtree","SubModule"]},{"title":"git subtree教程","url":"/2019/07/27/Git/subtree%E6%95%99%E7%A8%8B/","content":"关于子仓库或者说是仓库共用，git官方推荐的工具是git subtree。 我自己也用了一段时间的git subtree，感觉比git submodule好用，但是也有一些缺点，在可接受的范围内。所以对于仓库共用，在git subtree 与 git submodule之中选择的话，我推荐git subtree。\ngit subtree 可以实现一个仓库作为其他仓库的子仓库。\n\n使用git subtree 有以下几个原因：\n\n旧版本的git也支持(最老版本可以到 v1.5.2).\ngit subtree与git submodule不同，它不增加任何像.gitmodule这样的新的元数据文件.\ngit subtree对于项目中的其他成员透明，意味着可以不知道git subtree的存在.\n\n当然，git subtree也有它的缺点，但是这些缺点还在可以接受的范围内：\n\n必须学习新的指令(如：git subtree).\n子仓库的更新与推送指令相对复杂。\n\ngit subtree的主要命令有：\ngit subtree add   --prefix=&lt;prefix&gt; &lt;commit&gt;git subtree add   --prefix=&lt;prefix&gt; &lt;repository&gt; &lt;ref&gt;git subtree pull  --prefix=&lt;prefix&gt; &lt;repository&gt; &lt;ref&gt;git subtree push  --prefix=&lt;prefix&gt; &lt;repository&gt; &lt;ref&gt;git subtree merge --prefix=&lt;prefix&gt; &lt;commit&gt;git subtree split --prefix=&lt;prefix&gt; [OPTIONS] [&lt;commit&gt;]\n\n准备我们先准备一个仓库叫photoshop，一个仓库叫libpng，然后我们希望把libpng作为photoshop的子仓库。photoshop的路径为https://github.com/test/photoshop.git，仓库里的文件有：\nphotoshop    |    |-- photoshop.c    |-- photoshop.h    |-- main.c    \\-- README.md\n\nlibPNG的路径为https://github.com/test/libpng.git，仓库里的文件有：\nlibpng    |    |-- libpng.c    |-- libpng.h    \\-- README.md\n\n以下操作均位于父仓库的根目录中。\n在父仓库中新增子仓库我们执行以下命令把libpng添加到photoshop中：\ngit subtree add --prefix=sub/libpng https://github.com/test/libpng.git master --squash\n\n(--squash参数表示不拉取历史信息，而只生成一条commit信息。)\n执行git status可以看到提示新增两条commit：  \n\nimage\ngit log查看详细修改：  \n\nimage\n执行git push把修改推送到远端photoshop仓库，现在本地仓库与远端仓库的目录结构为：\nphotoshop    |    |-- sub/    |   |    |   \\--libpng/    |       |    |       |-- libpng.c    |       |-- libpng.h    |       \\-- README.md    |    |-- photoshop.c    |-- photoshop.h    |-- main.c    \\-- README.md\n\n注意，现在的photoshop仓库对于其他项目人员来说，可以不需要知道libpng是一个子仓库。什么意思呢？当你git clone或者git pull的时候，你拉取到的是整个photoshop(包括libpng在内，libpng就相当于photoshop里的一个普通目录)；当你修改了libpng里的内容后执行git push，你将会把修改push到photoshop上。也就是说photoshop仓库下的libpng与其他文件无异。\n从源仓库拉取更新如果源libpng仓库更新了，photoshop里的libpng如何拉取更新？使用git subtree pull，例如：\ngit subtree pull --prefix=sub/libpng https://github.com/test/libpng.git master --squash\n\n推送修改到源仓库如果在photoshop仓库里修改了libpng，然后想把这个修改推送到源libpng仓库呢？使用git subtree push，例如：\ngit subtree push --prefix=sub/libpng https://github.com/test/libpng.git master\n\n简化git subtree命令我们已经知道了git subtree 的命令的基本用法，但是上述几个命令还是显得有点复杂，特别是子仓库的源仓库地址，特别不方便记忆。这里我们把子仓库的地址作为一个remote，方便记忆：\ngit remote add -f libpng https://github.com/test/libpng.git\n\n然后可以这样来使用git subtree命令：\ngit subtree add --prefix=sub/libpng libpng master --squashgit subtree pull --prefix=sub/libpng libpng master --squashgit subtree push --prefix=sub/libpng libpng master\n\n","categories":["Git"],"tags":["Subtree"]},{"title":"Hexo 博客配置","url":"/2021/10/22/Hexo%E5%8D%9A%E5%AE%A2/Hexo-%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE/","content":"环境准备本地安装 Git NodeJS\n检查环境\ngit -vnode -vnpm -v\n\n切换镜像站,具体参考NPM配置国内源\nnpm config set registry https://registry.npmmirror.com\n\nHexo环境搭建pnpm install -g hexo-cli                # 安装Hexo cli工具hexo init                            # 初始化博客环境npm install                          # 安装依赖库# 插件npm install hexo-asset-img           # 头像npm install hexo-auto-category       # 自动分类npm install hexo-generator-searchdb  # 生成搜索数据库npm install hexo-backlink            # Obsdian链接转换npm install hexo-deploy-git          # git自动发布npm install hexo-theme-next          # hexo NexT主题npm install hexo-server              # hexo服务器npm install hexo-next-giscus         # giscus评论组件npm install hexo-wordcount           # 字数统计\n\nHexo 配置参考官方文档\n...theme: next     # 配置主题nextgiscus:         # 评论配置  enable: true  repo:  # Github repository name  repo_id: # Github repository id  category: # Github discussion category  category_id: # Github discussion category id  # Available values: pathname | url | title | og:title  mapping: title  # Available values: 0 | 1  reactions_enabled: 1   # Available values: 0 | 1  emit_metadata: 1  # Available values: light | light_high_contrast | light_protanopia | light_tritanopia | dark | dark_high_contrast | dark_protanopia | dark_tritanopia | dark_dimmed | preferred_color_scheme | transparent_dark | noborder_light | noborder_dark | noborder_gray | cobalt | purple_dark  theme: light  # Available values: en | zh-CN  lang: zh-CN  # Place the comment box above the comments  input_position: bottom  # Load the comments lazily  loading: lazy  deploy:   # 发布配置  - type: git    repo:        # 仓库发布地址    branch: main # 发布分支    name:        # git用户名 git config user.name &lt;username&gt;    email:       # git邮箱 git config user.email &lt;email&gt;...\n\n注意： 评论部分需要借助Github Discussions, 参考Hexo博客配置Giscus评论\nHexo主题配置安装主题后从npm_modules/&lt;主题名&gt;/文件夹中复制_config.yml到博客根目录并重命名为_config.next.yml,当博客deploy时回自动应用主题配置，一下主题修改都基于此文件进行。\n设置语言NexT主题支持多种语言，只需要编辑_config.next.yml中的language设置即可\n\n\n\n语言\n代码\n设定示例\n\n\n\nEnglish\nen\nlanguage: en\n\n\n简体中文\nzh-CN（注：zh-Hans已经无法使用）\nlanguage: zh-CN\n\n\nFrangais\nfr-FR\nlanguage: fr-FR\n\n\nPortugues\npt\nlanguage: pt  或者  language:pt-BR\n\n\n繁體中文\nzh-hk  或者  zh-tw\nlanguage: zh-hk\n\n\nPycckmi 93bIK\nru\nlanguage: ru\n\n\nDeutsch\nde\nlanguage: de\n\n\n日本語\nja\nlanguage: ja\n\n\nIndonesian\nid\nlanguage: id\n\n\nKorean\nko\nlanguage: ko\n\n\n如果需要添加非内置的字段需要手动添加翻译文件，例如中文的翻译文件路径为node_modules/next/languages/zh-CN.yml\n\n\n\n\n设置关于在source/about/index.md中添加如下内容\n---title: 关于date: 2025-08-27 00:00:00---&lt;个人信息&gt;\n\n选择SchemeScheme 是 NexT 提供的一种特性，借助于 Scheme，NexT 为你提供多种不同的外观。同时，几乎所有的配置都可以 在 Scheme 之间共用。目前 NexT 支持三种 Schem\n\nMuse - 默认 Scheme\nMist - Muse 的紧凑版本\nPisces - 双栏 Scheme\nGemini\n\n菜单配置菜单配置包括三个部分，第一是菜单项（名称和链接），第二是菜单项的显示文本，第三是菜单项对应的图标。 NexT 使用的是 Font Awesome 提供的图标， Font Awesome 提供了 600+ 的图标，可以满足绝大的多数的场景，同时无须担心在 Retina 屏幕下 图标模糊的问题。\nmenu: home: / || home categories: /categories/ || th archives: /archives/ || archive tags: /tags/ || tags #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat about: /about/ || user\n\nNexT 默认的菜单项有（标注 * 的项表示需要手动创建这个页面）：\n注意: 若站点运行在子目录中，请将链接前缀的 &#x2F; 去掉。\n\n\n\n键值\n设定值\n显示文本（简体中文）\n\n\n\nhome\nhome: &#x2F;\n主页\n\n\narchives\narchives: &#x2F;archives\n归档页\n\n\ncategories\ncategories: &#x2F;categories\n分类页 *\n\n\ntags\ntags: &#x2F;tags\n标签页 *\n\n\nabout\nabout: &#x2F;about\n关于页面*\n\n\ncommonweal\ncommonweal: &#x2F;404.html\n公益 404 !\n\n\n侧栏配置默认情况下，侧栏仅在文章页面（拥有目录列表）时才显示，并放置于右侧位置。配置具体如下\n...sidbar:  position: left     # 配置侧栏居左  display: post      # 侧栏显示行为...\n\n侧栏显示位置支持\n\nleft:  居左显示\nright:  居右显示\n\n侧栏显示行为支持\n\npost 默认行为，在文章页面（拥有目录列表）时显示\nalways 所有页面都显示\nhide 在所有页面中都隐藏（可以手动展开）\nremove 完全移除\n\n注册Github账号,Gitea账号(可选)[^注] Github由于网络问题会经常无法链接，可使用Gitea作为中转，先将代码提交道Gitea，然后Gitea配置自动推送到Github\n设置头像avatar: /images/avatar.jpg\n\n头像地址如果是以/起始则表示头像图片放置在博客发布后的目录下，例如测试博客地址是http://localhost:4000,头像图片地址为http://localhost:4000/images/avatar.jpg此配置需要在博客的source/images目录中放置头像图片avatar.jpg\n侧边栏社交链接social:  #GitHub: https://github.com/&lt;username&gt; || fab fa-github  #E-Mail: &lt;email&gt; || fa fa-envelope  #Weibo: https://weibo.com/yourname || fab fa-weibo  #Twitter: https://twitter.com/yourname || fab fa-twitter  #FB Page: https://www.facebook.com/yourname || fab fa-facebook  #StackOverflow: https://stackoverflow.com/yourname || fab fa-stack-overflow  #YouTube: https://youtube.com/yourname || fab fa-youtube  #Instagram: https://instagram.com/yourname || fab fa-instagram  #Skype: skype:yourname?call|chat || fab fa-skype\n\nnext主题默认支持的社交链接 ||符号后是链接的图标\n使用已有配置放开注释即可，如果要添加默认不存在链接示例如下\nsocial:  微信: https://wx.qq.com || weixin\n\n\n注意: 图标对应的名称是FontAwesom图标的名称（不必带 fa- 前缀）\n打赏功能# Reward reward:   wechatpay: /images/custom/wechatpay.jpg   alipay: /images/custom/alipay.jpg \n放开此部分注释并在source/images中放入收款码图片\n站点建立时间footer:  since: 2025\n\n订阅微信公众号# Wechat Subscriber wechat_subscriber:   enabled: true   qcode: /images/wechat-qcode.jpg   description: 欢迎您扫一扫上面的微信公众号，订阅我的博客！\n放开此部分注释，并在source/images中放入公众号二维码\n注意: 此功能需要NexT版本在5.0.1之后\n设置动画NexT 默认开启动画效果，效果使用 JavaScript 编写，因此需要等待 JavaScript 脚本完全加载完毕后才会显示内容。 如果您比较在乎速度，可以将设置此字段的值为 false 来关闭动画。\n# Use velocity to animate everything. motion:   enable: true   async: true   transition:     # Transition variants:     # fadeIn | fadeOut | flipXIn | flipXOut | flipYIn | flipYOut | flipBounceXIn | flipBounceXOut | flipBounceYIn | flipBounceYOut     # swoopIn | swoopOut | whirlIn | whirlOut | shrinkIn | shrinkOut | expandIn | expandOut     # bounceIn | bounceOut | bounceUpIn | bounceUpOut | bounceDownIn | bounceDownOut | bounceLeftIn | bounceLeftOut | bounceRightIn | bounceRightOut     # slideUpIn | slideUpOut | slideDownIn | slideDownOut | slideLeftIn | slideLeftOut | slideRightIn | slideRightOut     # slideUpBigIn | slideUpBigOut | slideDownBigIn | slideDownBigOut | slideLeftBigIn | slideLeftBigOut | slideRightBigIn | slideRightBigOut     # perspectiveUpIn | perspectiveUpOut | perspectiveDownIn | perspectiveDownOut | perspectiveLeftIn | perspectiveLeftOut | perspectiveRightIn | perspectiveRightOut     post_block: fadeIn     post_header: slideDownIn     post_body: slideDownIn     coll_header: slideLeftIn # Only for Pisces | Gemini.     sidebar: slideUpIn\n\n设置全文阅读在首页显示一篇文章的部分内容，并提供一个链接跳转到全文页面是一个常见的需求。 NexT 提供三种方式来控制文章在首页的显示方式。\n\n在文章中使用 &lt;!-- more --&gt; 手动进行截断，Hexo 提供的方式 推荐。\n在文章的 front-matter 中添加 description，并提供文章摘录\n自动形成摘要，需要添加如下配置# Automatically Excerpt. Not recommend. # Please use &lt;!-- more --&gt; in the post to control excerpt accurately. auto_excerpt:   enable: true   length: 150\n\n设置字数统计&#x2F;阅读时长在_config.yml中配置如下\n# Post wordcount display settings # Dependencies: https://github.com/willin/hexo-wordcount post_wordcount:   item_text: true   wordcount: true   min2read: true   totalcount: false   separated_meta: true\n\n加载进度条# Progress bar in the top during page loading.pace: true# Themes list:#pace-theme-big-counter#pace-theme-bounce#pace-theme-barber-shop#pace-theme-center-atom#pace-theme-center-circle#pace-theme-center-radar#pace-theme-center-simple#pace-theme-corner-indicator#pace-theme-fill-left#pace-theme-flash#pace-theme-loading-bar#pace-theme-mac-osx#pace-theme-minimal# For example# pace_theme: pace-theme-center-simplepace_theme: pace-theme-minimal\n\n搜索服务在_config.yml中配置如下\n# hexo-generator-searchdb search:   path: search.xml   field: post   format: html   limit: 10000\n\n在_config.next.yml中配置如下\n# Local search # Dependencies: https://github.com/flashlab/hexo-generator-search local_search:   enable: true   # if auto, trigger search by changing input   # if manual, trigger search by pressing enter key or search button     trigger: auto   # show top n results per article, show all results by setting to -1   top_n_per_article: 1\n\n参考官方文档Hexo 博客使用 Next 主题及美化 | Jiz4oh’s Life\n","tags":["Hexo","静态博客"]},{"title":"Hexo 增加站内文章链接","url":"/2024/08/29/Hexo%E5%8D%9A%E5%AE%A2/Hexo-%E5%A2%9E%E5%8A%A0%E7%AB%99%E5%86%85%E6%96%87%E7%AB%A0%E9%93%BE%E6%8E%A5/","content":"使用markdown的链接语法使用markdown的语法指定url创建站内链接，有绝对地址和相对地址两种方式，绝对地址与相对地址的区别在于是否以/开头：\n使用绝对地址代码如下：\n# 格式 [标题](文章地址)[Hexo 增加站内文章链接](/Hexo博客/Hexo-增加站内文章链接)\n\n\n示例中，Hexo-增加站内文章链接使用的是文章对应的md文件名，使用hexo n创建post时，空格会转换为中划线-。/Hexo是为了文章管理方便在_posts目录下增加的子目录，Hexo-增加站内文章链接.md位于_posts/Hexo/目录下。\n\n结果如下：\nHexo 增加站内文章链接\nHexo对绝对地址和相对地址的处理方式是不一样的。对于绝对地址/Hexo/Hexo-博客配置，生成的目标url不会变化。\n使用相对地址代码如下：\n[Hexo 增加站内文章链接](Hexo/Hexo-增加站内文章链接)\n\n对于相对地址Hexo/Hexo-增加站内文章链接，生成的目标URL会叠加文章的的URL，结果是/Hexo/Hexo/Hexo-增加站内文章链接，这显然不是期望的结果。但是如果是文章内的锚点链接，使用这种方式非常合适。\n代码如下：\n# 格式 [标题](#文章内要跳转的标题)[测试文章内跳转锚点](#测试文章内跳转锚点)\n\n结果如下：跳转文章内测试锚点\n生成的URL可以正确的跳转到文章内的锚点。注意，标题中的空格用-代替。\n使用post_link标签由于Hexo文章的URL规则是可以配置的，在_config.yml中可以配置URL自动添加日期、目录等信息。如果使用markdown语法的链接规则多有不便，一方面需要知道目标URL，一方面如果规则修改或者站点迁移，对应的内容需要修改。\n好在Hexo提供了post_link标签解决这个问题。\n代码如下：\n# 格式 &#123;% post_link 以_post下文件路径 &#x27;显示链接名&#x27;%&#125;&#123;% post_link Hexo博客/Hexo-博客配置 &#x27;Hexo 博客配置&#x27; %&#125;\n\n\n示例中，Hexo-博客配置使用的是文章对应的md文件名，使用hexo n创建post时，空格会转换为中划线-。Hexo是为了文章管理方便在_posts目录下增加的子目录，Hexo-博客配置.md位于_posts/Hexo目录下。\n\n结果如下：\nHexo 博客配置\n\n这样的链接会自动适配_config.yml中的文章URL规则。\n小结对比markdown语法和post_link标签，推荐在文章链接到站内文章时优先使用post_link，链接到文章内锚点时优先使用markdown语法。\n测试文章内跳转锚点文章内锚点跳转示例\n","tags":["Hexo","静态博客"]},{"title":"Hexo博客配置Giscus评论","url":"/2025/08/27/Hexo%E5%8D%9A%E5%AE%A2/Hexo%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AEGiscus%E8%AF%84%E8%AE%BA/","content":"参考如何为博客添加评论系统（基于giscus） | 栞的图书馆5分钟，为你的博客增加评论功能_giscus-CSDN博客如何基于giscus配置评论功能 - 奕皓的个人博客\nHexo NexT 主题使用 utterances 搭建评论系统 | 蓝伟洪的博客Hexo NexT 主题配置 utterances 评论 | Toypipi’s blog\n","tags":["Hexo","Giscus"]},{"title":"使用Github Actions部署Hexo博客","url":"/2021/10/22/Hexo%E5%8D%9A%E5%AE%A2/%E4%BD%BF%E7%94%A8Github-Actions%E9%83%A8%E7%BD%B2Hexo%E5%8D%9A%E5%AE%A2/","content":"前言作为技术博主，博客的高效维护与部署一直是我关注的重点。近期在维护博客时，我遇到了两个核心问题：\n\n内容管理混乱：草稿箱文件堆积，缺乏分类标准，甚至因误操作破坏了原有配置；\n兼容性局限：计划将文章同步至 FastGPT 等 AI 知识库时，发现官方推荐的 Hexo 部署方案（源码与静态文件混存）中，冗余的 public 目录会干扰 RAG 系统提取内容，且源码与发布产物耦合易引发冲突。\n\n为解决这些问题，我采用了源码与发布分离的部署架构：将 Markdown 源文件单独存放在一个仓库，通过 GitHub Actions 自动在另一个仓库构建并发布静态文件。这种方式的优劣对比如下：\n\n\n\n方案\n优点\n缺点\n\n\n\n官方混仓部署\n支持本地手动 &#x2F; 自动发布，预览方便，配置简单\n仓库体积大，源码与产物混合，不利于二次利用\n\n\n本文分离部署\n源码纯净、产物独立，兼容 AI 知识库，自动构建\n本地预览需搭测试环境，配置较复杂（双仓库 + 鉴权）\n\n\n部署核心思路核心逻辑：当源码仓库收到推送时，GitHub Actions 自动将源文件检出到 source/_posts，并从 _hexo 目录复制配置文件还原 Hexo 环境，最终执行构建与发布。\n文件结构设计（源码仓库）：\n|-- _hexo/ # Hexo 核心配置目录 | |-- _config.yml # Hexo 主配置 | |-- _config.next.yml # NexT 主题配置 | |-- package.json # Node 环境依赖 | |-- scaffolds/ # 文章模板（draft/page/post.md） | |-- static/ # 静态资源（头像、支付码等） |-- .github/workflows/ # GitHub Actions 工作流配置 |-- .obsidian/ # Obsidian 编辑器配置（可选）\n\n详细部署步骤1. 生成 SSH 密钥对（用于仓库间鉴权）需要生成一对 SSH 密钥，用于源码仓库向发布仓库推送构建结果：\nssh-keygen -t rsa -C &quot;&lt;github 注册邮箱&gt;&quot;\n\n执行后会在以下路径生成两个文件：\n\n私钥：~/.ssh/id_rsa（Linux&#x2F;Mac）或 C:\\Users\\&lt;用户名&gt;\\.ssh\\id_rsa（Windows）\n公钥：~/.ssh/id_rsa.pub（同上路径）\n\n注意：.ssh为隐藏目录，需要修改系统设置显示此文件夹\n\n2. 准备两个仓库仓库 1：源码仓库（存放 Markdown 与配置）\n新建仓库（例如命名为 hexo-source）\n进入仓库设置：Settings → Secrets and variables → Actions → New repository secret\n添加一个名为 HEXO_DEPLOY_KEY 的密钥，值为私钥 id_rsa 的内容（用记事本打开复制）\n\n\n\n仓库 2：发布仓库（存放静态文件，用于 GitHub Pages）\n仓库名必须为 &lt;你的 GitHub 用户名&gt;.github.io（固定格式，否则 GitHub Pages 无法生效）\n权限需设为公开，并开启 Discussions 功能（进入仓库设置 → Features 勾选）\n配置部署密钥：Settings → Deploy keys → Add deploy key\nTitle 填 HEXO_DEPLOY_PUB\nKey 填入公钥 id_rsa.pub 的内容，并勾选 Allow write access（允许推送权限）\n\n\n\n\n\n3. 配置 Hexo 环境文件在源码仓库中创建 _hexo 目录，放入以下核心文件（可从本地 Hexo 环境中复制, 参考Hexo-博客配置）：\n\n_config.yml：Hexo 主配置（需修改部署相关配置，见步骤 4）\n_config.next.yml：NexT 主题配置（其他主题同理）\npackage.json：依赖配置（需包含 hexo、hexo-deployer-git 等核心依赖）\nscaffolds/：文章模板（draft.md&#x2F;page.md&#x2F;post.md）\n静态资源：如头像（avatar.jpg）、关于页（about.md）等，按实际需求存放\n\n4. 配置部署与工作流文件① Hexo 部署配置（_hexo/_config.yml）在配置文件中添加部署规则，指向发布仓库：\n# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy:  - type: git    repo: git@github.com:&lt;username&gt;/&lt;username&gt;.github.io.git    branch: master    name: &lt;username&gt;    email: &lt;email&gt;\n\n② GitHub Actions 工作流（.github/workflows/hexo-deploy.yml）创建工作流文件，实现自动构建部署：\nname: hexo-deploy  # 工作流名称# 触发条件：向 master 分支推送时执行on:  push:    branches: [&quot;master&quot;]    jobs:  build:    runs-on: ubuntu-latest  # 使用 Ubuntu 环境    steps:      # 1. 配置时区（避免时间显示异常）      - name: Setup Timezone        uses: szenius/set-timezone@v2.0        with:          timezoneLinux: &quot;Asia/Shanghai&quot;            # 2. 拉取源码仓库内容到 source/_posts      - uses: actions/checkout@v3        with:          path: source/_posts            # 3. 安装 Node.js（需与本地开发环境版本一致，这里用 20.x）      - name: Use Node.js 20        uses: actions/setup-node@v4        with:          node-version: &#x27;20&#x27;            # 4. 缓存 NPM 依赖（加速构建）      - name: Cache NPM dependencies        uses: actions/cache@v4        with:          path: node_modules          key: $&#123;&#123; runner.OS &#125;&#125;-npm-cache          restore-keys: |            $&#123;&#123; runner.OS &#125;&#125;-npm-cache            # 5. 配置 SSH 密钥（用于向发布仓库推送）      - name: Setup Git        env:          ACTION_DEPLOY_KEY: $&#123;&#123; secrets.HEXO_DEPLOY_KEY &#125;&#125;  # 引用源码仓库的私钥        run: |          mkdir -p ~/.ssh/          echo &quot;$ACTION_DEPLOY_KEY&quot; &gt; ~/.ssh/id_rsa          chmod 700 ~/.ssh          chmod 600 ~/.ssh/id_rsa  # 严格权限，否则 SSH 会拒绝使用          ssh-keyscan github.com &gt;&gt; ~/.ssh/known_hosts  # 信任 GitHub 主机            # 6. 拉取主题（以 NexT 为例，其他主题修改仓库地址即可）      - name: Use Themes        uses: actions/checkout@v3        with:          repository: next-theme/hexo-theme-next          path: themes/next            # 7. 还原 Hexo 环境（从 _hexo 目录复制配置文件）      - name: Setup Hexo        run: |          npm install -g hexo-cli  # 全局安装 Hexo 命令行工具          # 复制核心配置文件          cp source/_posts/_hexo/_config.yml .          cp source/_posts/_hexo/_config.next.yml .          cp source/_posts/_hexo/package.json .          # 复制文章模板          mkdir scaffolds          cp source/_posts/_hexo/scaffolds/* scaffolds/          # 复制静态页面（关于页、分类页等，按实际需求调整）          mkdir -p source/about source/categories source/tags source/images          cp source/_posts/_hexo/about.md source/about/index.md          cp source/_posts/_hexo/categories.md source/categories/index.md          cp source/_posts/_hexo/tags.md source/tags/index.md          cp source/_posts/_hexo/*.jpg source/images/  # 复制图片资源          # 安装依赖          npm install            # 8. 缓存部署目录（加速后续构建）      - name: Cache Deploy        uses: actions/cache@v4        with:          path: .deploy_git          key: $&#123;&#123; runner.OS &#125;&#125;-deploy-cache          restore-keys: |            $&#123;&#123; runner.OS &#125;&#125;-deploy-cache            # 9. 构建并发布      - name: Deploy        run: |          cd .deploy_git &amp;&amp; git pull  # 拉取最新发布内容，避免冲突          cd ..          hexo clean  # 清理缓存          hexo generate  # 生成静态文件          hexo deploy  # 部署到发布仓库\n\n验证与使用\n将上述文件提交到源码仓库的 master 分支，GitHub Actions 会自动触发工作流；\n进入源码仓库的 Actions 标签页，查看工作流执行状态，若显示绿色对勾则部署成功；\n访问 https://&lt;你的用户名&gt;.github.io，即可看到最新发布的博客。\n\n注意事项\n私钥 HEXO_DEPLOY_KEY 是敏感信息，切勿泄露或提交到仓库；\n发布仓库名必须严格为 &lt;用户名&gt;.github.io，否则 GitHub Pages 无法正常访问；\n若主题是自定义修改过的，建议将主题 fork 到自己的仓库，再在工作流中拉取自己的 fork 版本；\n本地预览时，可在源码仓库中手动搭建 Hexo 环境（复制 _hexo 目录文件，执行 hexo server）。\n\n参考\nHexo官方提供的Github Actions部署示例\n","tags":["Hexo","静态博客"]},{"title":"使用Obsidian配合Hexo写博客","url":"/2024/09/20/Hexo%E5%8D%9A%E5%AE%A2/%E4%BD%BF%E7%94%A8Obsidian%E9%85%8D%E5%90%88Hexo%E5%86%99%E5%8D%9A%E5%AE%A2/","content":"参考【2024】从零开始用Hexo+GithubPage搭建个人网站（保姆级） - 知乎 (zhihu.com)Hexo + Obsidian + Git 完美的博客部署与编辑方案 - 个人文章 - SegmentFault 思否Obsidian+Git完美维护Hexo博客 - 知乎 (zhihu.com)\n","tags":["Hexo","静态博客","Obsidian"]},{"title":"ArchLinux安装","url":"/2018/03/21/Linux/ArchLinux%E5%AE%89%E8%A3%85/","content":"1. 下载镜像 制作启动U盘Arch Linux 官方网站 https://www.archlinux.org/\n制作启动盘工具 Rufus - 轻松创建 USB 启动盘\nLinux下\ndd if=*iso of /dev/sdb bs=41M\n\n2. 网络连接参考 Linux配置网络及SSH配置\n3. 选择软件源推荐国内的用户选择http://mirrors.ustc.edu.cn 默认的mirrorlist是开启所有源的，因此我们使用sed先在所有源的前面加上#\n#sed -i &quot;s/^\\b/#/g&quot; /etc/pacman.d/mirrorlist#nano /etc/pacman.d /mirrorlist\n将mirrors.ustc.edu.cn前面的#去掉\n4. 分区&#x2F;格式化&#x2F;挂载 参考 Linux硬盘分区\n5. 安装基本系统1. 将基本系统安装到根目录上去#pacstrap /mnt base base-devel\n    \n其实，这里安装的基本系统也肯定有自己用不到的冗余功能，例如我就用不到nano文本编辑器，但系统会默认给安上。如果知道基本系统每个文件的作用，其实也完全可以自定义安装。比如：\n\n#pacstrap /mnt bash coreutils file filesystem grub2 linux pacman \\    procps-ng syslog-ng glibc systemd-sysvcompat shawd dhcpcd vi\n\n&gt; 如果你想使用ifconfig之类的工具，请在上面加上net-tools\n\n2. 生成fstab用下面命令生成 fstab。如果想使用 UUIDs，使用 -U 选项；如果想使用标签，用 -L 选项.\n\n#genfstab -U -p /mnt &gt;&gt;/mnt/etc/fstab\n\n&gt; [red]**后面如果出现问题，请不要再次运行genfstab**[red]，如果需要，手动编辑/etc/fstab\n/etc/fstab文件在运行genfstab后应该被检查一下。如果之前你生成了一个EFI系统分区，那么 genfstab给EFI分区添加了错误的选项，会导致无法启动。因此你需要移除EFI分区的所有选项，除了noatime. 对其他分区, 替换&quot;codepage=cp437&quot; 为 &quot;codepage=437&quot; , 会挂载失败导致systemd进入恢复模式。\n\n3. 切换到新系统中#arch-chroot /mnt#sh-4.2#bash\n&gt; 到这一步之后，开始系统的主要配置，如果下面文件不存在，需要手动创建。\n&gt; 理解并完全安装步骤设置是保证系统配置成功的关键。\n\n4. 对新的基本系统进行设置写入本机的字符编码方式#nano /etc/locale.conf #LANG=en_US.UTF-8 #简略写法 echo LANG= en_US.UTF-8 &gt;&gt; locale.conf\n\n\nlocale.conf 文件默认不存在，一般设置LANG就行了，它是其它设置的默认值。\n\n/etc/locale.confLANG=zh_CN.UTF-8LC_TIME=en_GB.UTF-8\n\n修改本机编码# nano /etc/locale.gen  将用不到的编码全删掉，只保留en_US与zh_CN的几行。 \n\n\n默认情况下 &#x2F;etc&#x2F;locale.gen 是一个仅包含注释文档的空文件。选定你需要的本地化类型(移除前面的＃即可), 比如中文系统可以使用:\n\nen_US.UTF-8 UTF-8zh_CN.GB18030 GB18030zh_CN.GBK GBKzh_CN.UTF-8 UTF-8zh_CN GB2312\n\n对系统的编码进行更新\n#locale-gen \n\n写入本机的名称# nano /etc/hostname #简略写法：echo &#123;name&#125; &gt;/etc/hostname，也是一样的。\n\n\n写入键盘布局方案#nano /etc/vconsole.conf\n美式键盘，如下：\nKEYMAP=usFONT=FONT_MAP=\n\n写入时区# nano /etc/timezoneAsia/Shanghai\n\n建立时区的软链接#ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime\n\n设定系统将用的时间方案#hwclock --systohc --utc\n\n\n这个时间方案我是试过很多次，如果是双系统，电脑里还有win系统的话，建议设为：–localtime，否则可设为—utc。不过，我现在虽然也用双系统，但还是设的utc，因为设为–localtime虽然在win下时间不会出错，但回到linux下，经常系统会有些古怪的问题，比如，升级系统之时，报密钥错误。使用–utc，虽然在linux下时间会慢8个多小时，但毕竟对整个系统没有影响。\n\n生成内核的启动镜象。\n#mkinitcpio -p linux\n\n\n安装必要工具\n安装必要的网络工具以便于开机后可以配置网络连接(包括无线)\n\n#pacman –S wpa_supplicant net-tools#pacman -S dialog#pacman -S netctl#pacman -S wireless_tools\n\n6. 安装引导安装grub#pacman -S grub-bios os-prober#grub-install /dev/sda\nUEFI 注意分区,参考: Linux分区.格式化.挂载\n#pacman -S grub-bios efibootmgr os-prober#grub-install --efi-directory=/boot/efi --bootloader-id=arch-grub --target=x86_64-efi\n\n生成启动菜单#grub-mkconfig -o /boot/grub/grub.cfg#nano /boot/grub/grub.cfg\n\n生成grub引导windows如何生成grub引导文件grub.cfg 这里我们需要充分参考点击打开链接grub的说明。首先，需要额外安装一个 os-prober的软件包，直接pacman就行；然后grub-makeconfig 到&#x2F;boot&#x2F;grub&#x2F;grub.cfg 。此时才能生成可以引导多系统的引导文件.如下图。\n开机自启网络#systemctl enable dhcpcd@.service#dhcpcd\n\n卸载挂载的分区并重启#umount /mnt/&#123;boot,home,mnt&#125;# reboot\n\n基本系统已安装完成\n7. 系统配置\n忘记安装net-tools补救\n\nip link show #查看网卡ip link set eth0 up # 启用网卡\n\n\n如果是DHCP的当然简单，直接dhcpcd即可，如果是固定IP的，则要如下操作：\n\n#ip addr add 固定IP/24 dev eth0#ip link set dev eth0 up#ip route add default via 网关\n\n系统更新#pacman –Syu\n\n添加用户#useradd -m 新用户 #新建用户#passwd 新用户     #指定密码：#usermod -a -G video,audio,lp,log,wheel,optical,scanner,games,users,storage,power 新用户 #指定用户所在的组 \n\nsudo权限nano /etc/sudoers (添加sudo权限)\n\n\n放开%wheel %sudo权限\n\nsudo命令补全#sudo pacman -S bash-completion #echo &quot;source /usr/share/bash-completion/bash_completion&quot; &gt;&gt;/home/$USER/.bashrc \n\n更新源列表#pacman -S reflector \n\nreflector是一个可以从arch官方MirrorStatus列表取回最新mirrorlist的脚本，并且可以根据最新同步时间和速度排序。下面先说如何自动配置源列表。直接终端输入命令5（注意备份原有源列表）\n#reflector --verbose --country &#x27;China&#x27; -l 200 -p http --sort rate --save /etc/pacman.d/mirrorlist\n\n安装yaourt#vim /etc/pacman.conf\n\n[archlinuxcn]#The Chinese Arch Linux communities packages.SigLevel = Optional TrustAllServer   = http://repo.archlinuxcn.org/$arch\n\n# pacman -Syu yaourt\n\n安装powerpill#yaourt -S powerpill\n\n\npowerpill是一个可以从多个源多线程下载软件包的程序，类似于迅雷一样，可以明显提升更新速度，相当于pacman的外壳程序，使用方法完全和pacman相同。下面说说powerpill，玩arch的人不知道powerpill是不行的，需要注意的是它也是要调用reflector的，但并不是作为依赖。如果安装reflector后powerpill更新前会默认从mirrorstatus取回45个最新更新的源地址，然后并行下载，否则就是读取&#x2F;etc&#x2F;pacman.d&#x2F;mirrorlist然后配置下载。当然我们推荐第一种，总不能每次都手动执行\n\n7. 驱动显卡安装显卡驱动# pacman -S mesa# lspci | grep VGA（查看本机的显卡类型）# pacman -Ss xf86-video | less（查看能够安装的显卡类型）# pacman -S …… 安装显卡驱动（或者可以直接所有驱动都自动安装）# pacman –S xf86-video-vesa# pacman –S xf86-video-nouveau  #如果是ATI显卡的话，要安xf86-video-ati; # pacman –S virtualbox-guest-utils #虚拟机\n\n安装系统基础程序：# pacman -S xorg-server xorg-xinit xorg-utils xorg-server-utils dbus # 先安装x-window服务# pacman –S xterm xorg-xclock  xorg-twm # 安装测试环境\n\n重设系统的编码方式编辑.xinitrc，把以下内容添加到文件最开始。内可以使用你所喜欢的编辑器，比如nano。\nLANG=zh_CN.UTF-8LC_ALL=&quot;zh_CN.UTF-8&quot;\n\n更新系统的编码：\n#locale-gen\n\n更新一下系统的时间\n# date -s &quot;2013-01-14 14:40:10&quot;# hwclock --systohc\n\n音频管理\n# pacman -S alsa-utils pulseaudio-alsa\n\n安装网络管理工具\n# pacman –S networkmanager network-manager-applet wireless_tools# systemctl enable NetworkManager# systemctl start NetworkManager\n\n安装桌面\n击右键菜单，找到文件管理器，然后进入到目录/usr/share/applications/下，你会看到你已经安装完成的程序，全都可以从这儿启动。此时，你不妨复制几个常用的到你的用户目录：/home/新用户/桌面/下去。复制之后，你会在你的桌面上，看到这些程序的启动器。\n安装完ibus之后，在/home/$USER/.xinitrc文件中，写入：\nexport GTK_IM_MODULE=ibusexport QT_IM_MODULE=ibusexport XMODIFIERS=@im=ibusibus-daemon -d -x\n\nWindows下的磁盘挂载    参考Windows下的磁盘挂载\nXfce主题\n字体及补丁\n# pacman -S ttf-dejavu ttf-ubuntu-font-family ttf-arphic-ukai ttf-arphic-uming# pacman -S wqy-microhei wqy-bitmapfont wqy-zenhei ttf-fireflysung$ yaourt -S cairo-ubuntu libxft-ubuntu freetype2-ubuntu fontconfig-ubuntu       #以普通用户身份执行\n安装系统主题：\nsudo pacman -S gtk-aurora-engine gtk-engine-murrine \n鼠标主题：\nsudo pacman -S xcursor-vanilla-dmz xcursor-vanilla-dmz-aa\n\n图标主题：\n# pacman -S gnome-icon-theme-extras oxygen-icons human-icon-theme lxde-icon-theme tangerine-icon-theme\n\n针对笔记本电脑的配置：（Speed－step 、 Suspend 等功能）\n# pacman -S  gnome-power-manager  volumeicon$ yaourt -S laptop-mode-tools pmount\n\nGrub主题在启动过程中发现Xfce桌面启动载入真心简陋，没有关系，我们在AUR里下载一个balou并设置就好了。\n$ yaourt -S archlinux-themes-balou\n\n下面来配置grub的启动界面。AUR里有一个非常棒的包grub2-theme-archlinux。\n$ yaourt -S grub2-theme-archlinux\n安装后编辑&#x2F;etc&#x2F;default&#x2F;grub，将#GRUB_THEME=&quot;/path/to/gfxtheme&quot;改为GRUB_THEME=&quot;/boot/grub/themes/Archlinux/theme.txt&quot;将GRUB_GFXMODE=auto改为GRUB_GFXMODE=1024x768修改完成后重新生成一下启动文件\n# grub-mkconfig -o /boot/grub/grub.cfg\n\n安装 i3 窗口管理器\n# pacman -S i3\n\n安装 lightdm 显示管理器，\n# pacman -S lightdm-gtk3-greeter\n然后 \n# systemctl enable lightdm# systemctl start lightdm\n\n8. 桌面及美化","categories":["Linux"],"tags":["ArchLinux"]},{"title":"Awesome桌面","url":"/2024/08/29/Linux/Awesome%E6%A1%8C%E9%9D%A2/","content":"","categories":["Linux"],"tags":["Awesome"]},{"title":"Debian安装NFS","url":"/2024/04/23/Linux/Debian%E5%AE%89%E8%A3%85NFS/","content":"服务端 # 安装nfs服务sudo apt install nfs-common nfs-kernel-server portman -y# 创建共享目录sudo mkdir -p /mnt/share/sudo chmod 777 /mnt/share# 编辑映射文件sudo vim /etc/exports# 共享目录/mnt/share\t*(rw,sync)# 设置ACL赋予nfsnobody权限sudo setfacl -m u:nfsbody:rw /mnt/share# 启动NFS服务sudo /etc/init.d/nfs-kernel-server startsudo /etc/init.d/nfs-common start# 检查服务启动sudo showmount -e\n\n\n\n客户端# 安装nfssudo apt install nfs-common# 新建本地文件夹sudo mkdir /mnt/nfs# sudo mount [nfs_server]:[server_dir] [local_mount_point]# [nfs_server] nfs服务器ip# [server_dir] 服务器共享路径# [local_mount_point] 本地挂载路径sudo mount [nfs_server]:[server_dir] [local_mount_point]# 示例sudo mount 192.168.1.100:/mnt/share /mnt/nfs# 查看挂载是否成功df -Th\n\n编辑fstab 配置自动挂载\nsudo vim /etc/fstab# 在最后一行添加 [nfs_server]:/mnt/share\t/mnt/nfs\tnfs\tdefaults\t0\t0\n\n卸载\nsudo umount [local_mount_point] #示例sudo umount /mnt/nfs\n\n\n\n需要认证参考为 Linux 客户端设置具有基于 Kerberos 的身份验证的 NFS 服务器 (linux-console.net)\n安全相关参考如何确保NFS服务安全-腾讯云开发者社区-腾讯云 (tencent.com)\n用户身份映射参考NFS服务的用户身份映射 - wangmo - 博客园 (cnblogs.com)\n","categories":["Linux"],"tags":["NFS"]},{"title":"IPTables配置","url":"/2024/12/10/Linux/IPTables%E9%85%8D%E7%BD%AE/","content":"","categories":["Linux"],"tags":["IPTable"]},{"title":"Gentoo安装","url":"/2023/05/23/Linux/Gentoo%E5%AE%89%E8%A3%85/","content":"准备工作制作启动盘官方镜像Minimal CD Stage国内加速清华大学开源软件镜像站中国科技大学开源镜像站\n使用Rufus制作启动U盘.\n\n连接网络Linux配置网络及SSH配置\n\n分区规划参考 Linux硬盘分区\n挂载分区mkdir /mnt/gentoomount /dev/sdx? /mnt/gentoomkdir /mnt/gentoo/homemount /dev/sdx? /mnt/gentoo/homemkdir /mnt/gentoo/bootmount /dev/sdx? /mnt/gentoo/bootmkdir /mnt/gentoo/boot/efimount /dev/sdx? /mnt/gentoo/boot/efi\n\n配置Portage释放stage# 使用命令行浏览器下载stagelinks http://www.gentoo.org/main/en/mirrors.xml# 发送stage3scp stage3-amd64-*.tar.xz root@192.168.0.2:/mnt/gentoocd /mnt/gentoo# 释放stage3tar xpvf stage3-*.tar.bz2 --xattrs-include=&#x27;*.*&#x27; --numeric-owner\n\n挂载系统必要环境mount --types proc /proc /mnt/gentoo/procmount --rbind /sys /mnt/gentoo/sys#mount --make-rslave /mnt/gentoo/sys (不使用systemd，所以注释掉)mount --rbind /dev /mnt/gentoo/dev#mount --make-rslave /mnt/gentoo/dev (不使用systemd，所以注释掉)mount --rbind /run /mnt/gentoo/run#mount --make-slave /mnt/gentoo/run (不使用systemd，所以注释掉)\n\n复制DNScp --dereference /etc/resolv.conf /mnt/gentoo/etc/\n\n配置软件源常规源选择中国源，这一步是非必须的，提供的/etc/portage/make.conf里已经有中国的所有源了\nmirrorselect -i -o &gt;&gt; /mnt/gentoo/etc/portage/make.conf   \n创建主仓库mkdir -p -v /mnt/gentoo/etc/portage/repos.confcp -v /mnt/gentoo/usr/share/portage/config/repos.conf /mnt/gentoo/etc/portage/repos.conf/gentoo.conf# 加入中国源nano -w /mnt/gentoo/etc/portage/repos.conf/gentoo.conf：    ## 源地址sync-uri = rsync://mirrors.tuna.tsinghua.edu.cn/gentoo-portage/#sync-uri = rsync://rsync.mirrors.ustc.edu.cn/gentoo-portage/#sync-uri = rsync://mirrors.yun-idc.com/gentoo-portage/\n\n二进制源# 修改二进制源地址为国内源nano -w /etc/portage/binrepos.conf/gentoobinhost.conf# 原有内容# ---# These settings were set by the catalyst build script that automatically# built this stage.# Please consider using a local mirror.[gentoobinhost]priority = 1# sync-uri = https://distfiles.gentoo.org/releases/amd64/binpackages/23.0/x86-64sync-uri = https://mirrors.tuna.tsinghua.edu.cn/gentoo/releases/amd64/binpackages/23.0/x86-64/# sync-uri = https://mirrors.ustc.edu.cn/gentoo/releases/amd64/binpackages/23.0/x86-64/\n\n如果启用二进制源需要在USE中添加 getbinpkg binpkg-request-signature \n生成fstabgenfstab -U /mnt/gentoo &gt;&gt; /mnt/gentoo/etc/fstab\n\n生成的fstab格式如下\nUUID=......      /boot/efi      vfat      noauto,defaults,noatime,umask=0077                               0 2UUID=......      /              xfs       defaults,noatime                                                 0 1UUID=......      /home          xfs       noatime,discard    \n\n系统配置进入新系统环境从现在开始，所有的动作将立即在新 Gentoo Linux 环境里生效。\nchroot /mnt/gentoo /bin/bashenv-update\t\t\t\t\t\tsource /etc/profileexport PS1=&quot;(chroot) $&#123;PS1&#125;&quot; # 切换提示符，避免混淆\n\n同步stageemerge-webrsync\n\n^注意: gentoo handbook上提到可以使用emerge -rsync升级软件包数据库到最近2小时的最新版，这是没有必要的，而且下载的速度会极其慢，所以不推荐这样做。单用emerge-webrsync就可以同步数据库到最近3～4天内的最新版了。\n设置profileeselect profile list     #查看profile予设值eselect profile set X    #这里先保持选择默认值，即“default/linux/amd64/17.1 (stable)”\n\n检测cpu指令集# 安装cpuid2cpuflagsemerge --ask app-portage/cpuid2cpuflags# 查看CPU指令集cpuid2cpuflags   echo &quot;*/* $(cpuid2cpuflags)&quot; &gt; /etc/portage/package.use/00cpu-flags\n\n安装CCache(可选，加速编译)emerge --ask ccache mkdir -p /var/cache/ccachechown root:portage /var/cache/ccache -Rchmod 2775 /var/cache/ccache -R\n\n在portage&#x2F;make.conf中添加\nFEATURES=&quot;ccache -test&quot; CCACHE_DIR=&quot;/var/cache/ccache&quot;USE=&quot;... $&#123;FEATURES&#125;&quot; # 在USE中添加$&#123;FEATURES&#125; \n\n安装Aria2(可选，加快包下载)emerge --ask net-misc/aria2\n\n在portage&#x2F;make.conf中添加配置\nDISTDIR=&quot;/var/cache/distfiles&quot;FETCHCOMMAND=&quot;/usr/bin/aria2c -d \\$&#123;DISTDIR&#125; -o \\$&#123;FILE&#125; \\    --allow-overwrite=true --max-tries=5 --max-file-not-found=2 \\    --max-concurrent-downloads=5 --connect-timeout=5 --timeout=5 \\    --split=5 --min-split-size=2M --lowest-speed-limit=20K \\    --max-connection-per-server=9 --uri-selector=feedback \\$&#123;URI&#125;&quot;RESUMECOMMAND=&quot;$&#123;FETCHCOMMAND&#125;&quot;\n\n配置编译选项nano /mnt/gentoo/etc/portage/make.conf\n\n^注意: 设置编译标志 -march&#x3D;native (如果你知道自己处理器的代号，就用自己的处理器代号替换这里的native 比如我的是skylake，如果不确定就使用native)^注意: 设置 MAKEOPTS&#x3D;”-j8” 来定义安装软件时并行编译的数量 这个数字等于你的CPU线程数（也称为逻辑CPU数）参考MAKEOPTS WiKi\n完整的配置文件如下(转自Gentoo安装流程分享(step by step)，第一篇之基本系统的安装，修改了下注释格式，删除不用的部分)\n# These settings were set by the catalyst build script that automatically# built this stage.# Please consult /usr/share/portage/config/make.conf.example for a more# detailed example.# GCC编译配置 -O3代表优化级别,如果采用更高的-Ofast可能会导致部分软件包编译错误, # -march=native代表为本机cpu进行编译,如果是交叉编译需要去掉COMMON_FLAGS=&quot;-march=skylake -O2 -pipe&quot;CFLAGS=&quot;$&#123;COMMON_FLAGS&#125;&quot;CXXFLAGS=&quot;$&#123;COMMON_FLAGS&#125;&quot;FCFLAGS=&quot;$&#123;COMMON_FLAGS&#125;&quot;FFLAGS=&quot;$&#123;COMMON_FLAGS&#125;&quot;# 源代码包构建时传递给`make`的参数# 同时编译的线程数,根据cpu线程数和内存大小/2中较小的MAKEOPTS=&quot;-j8&quot;                # 系统上托管的主软件包存储库,其默认值为 `/var/db/repos/gentoo`PORTDIR=&quot;/var/db/repos/gentoo&quot;# Portage存储下载的源代码归档的位置，默认为新安装的`/var/cache/distfiles`DISTDIR=&quot;/var/cache/distfiles&quot;#Portage临时文件的位置，默认为`/var/tmp`# 如果内存足够大(8G、16G)，那么建议把编译程序时存放临时中间文件的目录设置# 为内存的tmpfs(/tmp目录)，以减少编译时对硬盘的大量读写、延长硬盘使用寿命、# 并加快编译速度；但如果你的内存较小(&lt;=4G)，那么建议把此项注释掉，否则很多# 程序会因内存容量不足而导致编译失败PORTAGE_TMPDIR=&quot;/tmp&quot;# NOTE: This stage was built with the bindist Use flag enabled# This sets the language of build output to English.# Please keep this setting intact when reporting bugs.LC_MESSAGES=C# 同步镜像GENTOO_MIRRORS=&quot;https://mirrors.tuna.tsinghua.edu.cn/gentoo&quot;# 备选# GENTOO_MIRRORS=&quot;https://mirrors.ustc.edu.cn/gentoo/&quot;# GENTOO_MIRRORS=&quot;https://mirrors.aliyun.com/gentoo/&quot;# GENTOO_MIRRORS=&quot;https://mirrors.cloud.tencent.com/gentoo/&quot;# GENTOO_MIRRORS=&quot;https://mirrors.huaweicloud.com/gentoo/&quot;# emerge的默认选项EMERGE_DEFAULT_OPTS=&quot;--keep-going --with-bdeps=y --quiet --ask --verbose&quot;   # 每次安装完包之后自动清理AUTO_CLEAN=&quot;yes&quot;  # 指定软件包的可用性和稳定性级别。# 如果更喜欢最新那这里用~amd64(接受安装和更新处于测试阶段的软件包)ACCEPT_KEYWORDS=&quot;amd64&quot;           # 接受所有许可证的软件ACCEPT_LICENSE=&quot;*&quot;                # 语言设置L10N=&quot;en-US zh-CN en zh&quot; LINGUAS=&quot;en_US zh_CN en zh&quot;          # intel集成显卡和nvidia显卡(不使用novueau)VIDEO_CARDS=&quot;intel i965 iris nvidia&quot;# intel声卡ALSA_CARDS=&quot;hda_intel&quot;# 输入设备 非笔记本去除后面的synapticsINPUT_DEVICES=&quot;libinput synaptics&quot;# 设置GRUB版本GRUB_PLATFORMS=&quot;efi-64&quot;            # 使用ccache来大大提高重新编译时的速度,安装ccache后解除注释# CCACHE=&quot;parallel-fetch ccache&quot;  # ccache使用的目录# CCACHE_DIR=&quot;/var/cache/ccache&quot;     # 使用aria2提高下载速度（不设置也无大碍，设置的话一定要注意指令拼写正确）,# 安装aria2后解除注释# FETCHCOMMAND=&quot;/usr/bin/aria2c -d \\$&#123;DISTDIR&#125; -o \\$&#123;FILE&#125; \\#   --allow-overwrite=true --max-tries=5 --max-file-not-found=2 \\#\t--max-concurrent-downloads=5 --connect-timeout=5  --timeout=5 \\#\t--split=5 --min-split-size=2M --lowest-speed-limit=20K \\#\t--max-connection-per-server=9 --uri-selector=feedback \\$&#123;URI&#125;&quot;# RESUMECOMMAND=&quot;$&#123;FETCHCOMMAND&#125;&quot;# USE变量# 用户希望在系统中启用的Portage特性列表,影响Portage的行为。# 由于这是一个增量变量，可以在不直接覆盖通过 Gentoo profile# 实现的FEATURES值的情况下添加FEATURES值。FEATURES=&quot;&quot;# gnome和kde及其相关组件DESK_ENV=&quot;-gnome -gnome-shell -gnome-keyring -nautilus -kde icu&quot;# 不使用systemd plymouth consolekit 只使用elogind# 旧教程会使用consolekit，elogind是consolekit未来的替代品FUCKSV=&quot;-systemd -bindist -mdev elogind -oss -grub -plymouth -consolekit&quot;# 对于音频相关软件使用pulseaudio alsa jack特性AUDIO=&quot;alsa jack pulseaudio&quot;SOFTWARE=&quot;sudo client git openmp minizip udev blkid efi hwdb smack \\    acpi ccache dbus policykit udisks cjk emoji -test&quot;# 网络相关NET=&quot;network networkmanager connection-sharing wifi http2 dhclient \\    -dhcpcd policykit nftables&quot;# 图形相关VIDEO=&quot;X vulkan layers glamor nvidia gallium&quot;# 定义需要的USE变量USE=&quot;$&#123;DESK_ENV&#125; $&#123;FUCKSV&#125; $&#123;AUDIO&#125; $&#123;NET&#125; $&#123;VIDEO&#125; $&#123;SOFTWARE&#125;&quot;# 二进制包保存路径# PKGDIR=&quot;/var/cache/binpkgs&quot;# 使用二进制软件包,加入USE生效# BIN_PKG=&quot;getbinpkg&quot;# emerge时用到的代理 需要代理时候自行设置# http_proxy=&quot;http://127.0.0.1:8889&quot; # https_proxy=&quot;http://127.0.0.1:8889&quot;\n\n永久禁用nouveau驱动模块强烈要求你禁用Nouveau驱动！！能省掉以后很多莫名其妙的麻烦！\nmkdir /etc/modprobe.d/nano -w /etc/modprobe.d/blacklist.conf# 写入以下内容blacklist nouveaublacklist lbm-nouveauoptions nouveau modeset=0\n\n即便在编译内核前就已经设置内核禁用Nouveau驱动了，但是内核安装时还是会默认把nouveau驱动作为内核模块自动加载。启用了nouveau驱动模块的内核会出现各式各样的莫名其妙的数不清的问题，所以为了避免以后出现这些问题，必须禁用nouveau模块。\n内核配置和编译安装内核源码\nemerge --ask sys-kernel/gentoo-sources# 如果安装多个版本内核时执行eselect kernel list \t# 查看内核列表eselect kernel set 1 \t# 选择内核版本\n\n某些驱动程序在工作之前需要在系统上安装其他固件。这通常是网络接口的情况，尤其是无线网络接口。此外，在使用开源驱动程序时，来自AMD，Nvidia和Intel等供应商的现代视频芯片通常需要外部固件文件。大多数固件都封装在sys-kernel &#x2F; linux-firmware中：\nemerge --ask --quiet sys-kernel/linux-firmware\n\n除了独立显卡硬件和网络接口之外，CPU 可能也需要固件更新。通常这种固件被称为微码（microcode）。有时需要更新版本的微码来修补 CPU 硬件中的不稳定性、安全问题或其他复杂的错误。\nAMD CPU 的微码更新在前面提到的 sys-kernel&#x2F;linux-firmware 软件包内分发。Intel CPU 的微码可以在 sys-firmware&#x2F;intel-microcode 包中找到，并且需要单独安装\n# Intel CPU 执行emerge --ask sys-firmware/intel-microcode\n\n\n三种方法安装内核\n安装系统时可选择安装二进制内核，系统安装完后再配置编译内核，参考 配置Linux内核 - Gentoo Wiki\n\n全自动安装\n当为基于 amd64 的系统安装和编译内核时，Gentoo 推荐使用 sys-kernel&#x2F;gentoo-sources 软件包\nemerge --ask sys-kernel/installkernel\n\n混合安装(推荐方式)\n生成内核配置文件\n将genkernel的默认内核配置文件“generated-config”复制过来，里面已经设置好了绝大部分应用场景以及绝大部分硬件驱动的配置，非常方便，值得借过来使用，只需要在自己手动配置内核的时候将其加载，在其基础上做一点点轻微的修改或完全不修改都可以，对内核新手极其友好！\nemerge --ask sys-kernel/genkernel# 以genkernel的配置文件为基础进行自定义配置cp /usr/share/genkernel/arch/x86_64/generated-config /usr/src/linux/# 备份cp /usr/src/linux/generated-config /usr/src/linux/generated-config.bak # 编译genkernel --mountboot --install all\n\n^注意如果想在以后支持jack低延迟实时音频组件（Jack-Audio-Connection-Kit），则需要vim generated-config，手动设置“CONFIG_CGROUPS&#x3D;y”、“CONFIG_CGROUP_SCHED&#x3D;y”、“CONFIG_RT_GROUP_SCHED&#x3D;y”，然后重新make menuconfig载入保存generated-config一遍，接下来再编译内核。^注意: 使用nvidia显卡闭源驱动，需要将内核配置中“CONFIG_I2C_NVIDIA_GPU”这一项禁用，否则会和官方nvidia-drivers冲突！！！\n\n\n全手动安装\nemerge sys-apps/pciutilscd /usr/src/linux# 配置内核make menuconfig \n\n![[Gentoo安装&#x2F;IMG-20241210170128644.png]]有些内核选项是必须的，必须编译到内核中，而不是作为模块加载。*表示包括到内核中，M表示作为模块加载，[]只有包括到内核中和排除在外两种选项，&lt;&gt;则有包括到内核中、排除在外和以模块加载三种选项。下面这些选项都必须以*方式编译到内核中。\ndevtmpfs支持。\nDevice Drivers ---&gt;  Generic Driver Options ---&gt;    [*] Maintain a devtmpfs filesystem to mount at /dev    [*]   Automount devtmpfs at /dev, after the kernel mounted the rootfs\n\nSCSI磁盘支持。\nDevice Drivers ---&gt;   SCSI device support  ---&gt;      &lt;*&gt; SCSI disk support\n选择支持的文件系统。因为ESP分区用的FAT32格式化的，根目录用的XFS格式化的，所以这里这两项（FAT32也就是VFAT）必须包括到内核中，虚拟内存和proc文件系统也是必选的。其实这里还可以取消掉不需要的文件系统，但是对于新手不建议取消任何自己不明白的东西，很容易弄的最后内核没办法启动。\nFile systems ---&gt;  &lt; &gt; Second extended fs support  &lt; &gt; The Extended 3 (ext3) filesystem  &lt;*&gt; The Extended 4 (ext4) filesystem  &lt; &gt; Reiserfs support  &lt; &gt; JFS filesystem support  &lt; &gt; XFS filesystem support  &lt; &gt; Btrfs filesystem support  DOS/FAT/NT Filesystems  ---&gt;    &lt;*&gt; MSDOS fs support    &lt;*&gt; VFAT (Windows-95) fs support Pseudo Filesystems ---&gt;    [*] /proc file system support    [*] Tmpfs virtual memory file system support (former shm fs)\n如果处理器是多核的，还需要开启SMP（对称多处理器支持）。\nProcessor type and features  ---&gt;  [*] Symmetric multi-processing support\nUSB也必须启用\nDevice Drivers ---&gt;  HID support  ---&gt;    -*- HID bus support    &lt;*&gt;   Generic HID driver    [*]   Battery level reporting for HID devices      USB HID support  ---&gt;        &lt;*&gt; USB HID transport layer  [*] USB support  ---&gt;    &lt;*&gt;     xHCI HCD (USB 3.0) support    &lt;*&gt;     EHCI HCD (USB 2.0) support    &lt;*&gt;     OHCI HCD (USB 1.1) support\n\n系统体系相关的内核配置\n因为选择了multlib，所以32和64位的程序都会安装。为了支持32位程序，必须启用32位程序模拟功能。这里其实倒是不用怎么改，默认已经都选上了。\nProcessor type and features  ---&gt;   [*] Machine Check / overheating reporting    [*]   Intel MCE Features   [*]   AMD MCE Features   Processor family (AMD-Opteron/Athlon64)  ---&gt;      ( ) Opteron/Athlon64/Hammer/K8      ( ) Intel P4 / older Netburst based Xeon      ( ) Core 2/newer Xeon      ( ) Intel Atom      (*) Generic-x86-64Binary Emulations  ---&gt;   [*] IA32 Emulation\n启用GPT支持，因为前面我用的GPT分区表，EFI启动方式，所以这两项也必须启用。\n-*- Enable the block layer ---&gt;   Partition Types ---&gt;      [*] Advanced partition selection      [*] EFI GUID Partition support\n\nEFI的支持。\nProcessor type and features  ---&gt;    [*] EFI runtime service support     [*]   EFI stub support    [*]     EFI mixed-mode support Firmware Drivers  ---&gt;    EFI (Extensible Firmware Interface) Support  ---&gt;        &lt;*&gt; EFI Variable Support via sysfs\n\n\n\n# 编译内核make -j12 #（CPU核心数根据机器cpu调整）      make modules_installmake install\n\n使用二进制内核\n# 安装二进制内核emerge --ask sys-kernel/gentoo-kernel-bin\n\n可选：生成一个initramfs\n在某些情况中需要建立一个initramfs——一个基于内存的初始化文件系统。最觉的原因是当重要的文件系统位置（如&#x2F;usr&#x2F;或&#x2F;var&#x2F;）在分离的分区。通过一个initramfs，这些分区可以使用initramfs里面的工具来完成挂载。\n用dracut生成内核的initramfs，快速且方便，新手友好\nemerge --ask sys-kernel/dracutcd /bootdracut --hostonly\n\n或者使用genkernel生成内核的initramfs\ncp /usr/src/linux/generated-config /etc/kernels/kernel-config-&lt;内核版本号&gt;-gentoo-x86_64genkernel --install initramfs\n\n\n\n系统环境配置配置主机名#nano -w /etc/conf.d/hostnameecho &quot;HOSTNAME&quot; &gt; /etc/hostname\n\n配置系统时区ls /usr/share/zoneinfoecho &quot;Asia/Shanghai&quot; &gt; /etc/timezone# 解决时间差8小时问题（双系统时会遇到Windows时间不对）sudo rm /etc/localtimesudo ln -sv /usr/share/zoneinfo/Universal /etc/localtimesudo emerge --config sys-libs/timezone-data\n\n配置编码nano -w /etc/locale.gen \t\t#将以下几项取消注释，如果没有手动输入en_US ISO-8859-1en_US.UTF-8 UTF-8zh_CN GBK zh_CN.UTF-8 UTF-8locale-gen \t\t\t\t\t\t# 更新\n\n设置系统locale#查看可用系统时区和地区配置eselect locale list  #这里只能选择“en-US.utf8”！！假如设置成了中文后，整个系统的终端命令行会乱码！！！eselect locale set X    # 更新环境env-update &amp;&amp; source /etc/profile &amp;&amp; export PS1=&quot;(chroot) $&#123;PS1&#125;&quot;\n\n配置sudo自动补全sudo emerge --ask app-shells/bash-completion# 添加 bash-completion 全局 USE 标记sudo vim /etc/protage/make.confUSE=&quot;... bash-completion&quot;sudo emerge --avuDN world# 启用bash-completion的功能sudo eselect bashcomp enable base# sudo bashcomp-config enable base# 查看哪些命令支持bash-completionsudo eselect bashcomp list\n\n安装网络工具# 无线emerge --ask net-wireless/iwemerge --ask net-wireless/wpa_supplicant# 有线emerge --ask net-misc/netifrc # openrc 自带# emerge --ask net-misc/systemd-networkd# PPPoE环境emerge --ask net-dialup/ppp# 如果使用GUI可跳过# 要在引导时激活网络接口，需要将它们添加到默认运行级别# 首先使用 ifconfig 查看网络接口名称cd /etc/init.d/ln -s net.lo net.eno1 # 此处网卡名称需要和实际网卡名对应rc-update add net.eno1 default\n![[Gentoo安装&#x2F;IMG-20241210170128726.png]]安装配置networkmanager\n最方便支持多种联网方式的工具是NetworkManager,基本满足所有需求，但同时它的依赖有点多。如果使用桌面环境的话建议安装。\nnano -w /etc/portage/make.conf:USE=“networkmanager connection-sharing dhclient policykit ppp wifi -dhcpcd”emerge net-misc/networkmanager nano -w /etc/dhcp/dhclient.conf：send host-name &quot;Gentoo&quot;    #your hostnamenano -w /etc/NetworkManager/NetworkManager.conf[connectivity]uri=http://nmcheck.gnome.org/check_network_status.txtnano -w /etc/NetworkManager/NetworkManager.conf[main]plugins=keyfiledns=dnsmasqhostname-mode=nonerc-update del dhcpcdrc-update add NetworkManager default# systemctl disable dhcpcd# systemctl enable networkmanager#gpasswd -a &lt;你的桌面使用用户名&gt; plugdev   #没有这一步，用户将不能使用networkmanager，也就不能上网。不过先跳过这一步，在设置系统用户的时候再做。nano -w /etc/dnsmasq.conf:server=114.114.114.114\n\n安装必要的工具# 系统日志emerge --ask app-admin/sysklogdrc-update add sysklogd default# systemctl enable sysklogd# systemctl start sysklogd# 计划任务管理emerge --ask sys-process/cronierc-update add cronie default# systemctl enable cronie# systemctl start cronie# 文件索引emerge --ask sys-apps/mlocate# 电源管理emerge --ask sys-power/acpidrc-update add acpid default# systemctl enable acpid# systemctl start acpid# CPU温度管理emerge sys-power/thermaldrc-update add thermald default# systemctl enable thermald # systemctl start thermald# 设备管理工具emerge --ask virtual/udevrc-update add udev sysinit# systemctl enable udev# systemctl start udev\n\n\n\n配置系统用户安装sudo\nemerge app-admin/sudonano -w /etc/sudoers\n\n把 %wheel ALL=(ALL) ALL 这一行去掉注释，如果希望执行sudu不需要密码则取消注释%wheel ALL=(ALL) NOPASSWD:ALL\n添加用户\ngroupadd sudo useradd -m -G users,wheel,usb,portage,video,audio,sudo -s /bin/bash [用户名]chmod 700 /home/[用户名] -R\n\n设置密码\n# 设置root密码passwd rootpasswd &#123;用户名&#125;\n\n添加操作系统启动项在/etc/portage/make.conf中添加grub配置\nGRUB_PLATFORMS=&quot;efi-64&quot;\n\n安装grub2\nemerge --ask sys-boot/grub:2emerge --ask sys-boot/os-prober # 用于识别其他分区的系统（双系统）\n\ngrub安装到硬盘并生成开机启动项\ngrub-install --target=x86_64-efi --efi-directory=/boot/efi --bootloader-id=Gentoogrub-mkconfig -o /boot/grub/grub.cfg\n\nmount -o remount,rw /sys/firmware/efi/efivarsos-prober\n\n如果出现No space left on device，请运行以下命令，之后再重复上述步骤\nmount -t efivarfs efivarfs /sys/firmware/efi/efivarsrm /sys/firmware/efi/efivars/dump-*\n\ngrub默认配置添加自定义配置，可提高intel cpu的稳定性和性能\nnano -w /etc/default/grub：GRUB_CMDLINE_LINUX_DEFAULT=&quot;intel_idle.max_cstate=0 processor.max_cstate=1&quot;grub-mkconfig -o /boot/grub/grub.cfg\n\n清理rm /stage3-*.tag.ge# 退出chrootexit# 卸载umount -lR /mnt/gentoo# 重启reboot# 成功开机并进入系统后grub-mkconfig -o /boot/grub/grub.cfg\n\n如果开机不正常参考挂载文件系统(不要执行分区和mkfs操作)，可重新chroot进入系统修改错误的配置。\n桌面环境安装基础环境# 从 x11-base/xorg-drivers-21.1 开始,x11-base/xorg-drivers更改 [USE 标志]设置# 这将弃用x11-drivers/xf86-video-intel驱动程序，以支持内置的通用模式设置DDX驱动程序# 具有video_cards_i915USE 标志集将继续安装 Intel DDX 驱动程序。emerge --ask x11-base/xorg-drivers# 英伟达显卡emerge --ask x11-drivers/nvidia-drivers# 安装xorg-serveremerge --ask x11-base/xorg-server# 安装双显卡设置工具emerge --ask x11-apps/xrandr # 让nvidia自动设置双显卡prime配置sudo rm /etc/X11/xorg.conf sudo nvidia-xconfig --prime # 安装完更新当前系统组件环境env-update &amp;&amp; source /etc/profile\n\n^注意: 以后每次重新编译安装内核kernel后，均须要运行一遍“emerge @module-rebuild”，重新编译安装nvidia驱动模块加载到内核之中，否则nvidia驱动无法加载！！！\nlsmod | grep nvidiasudo rmmod nvidiasudo modprobe nvidialsmod|grep nvidiasudo vim /etc/modules-load.d/nvidia.conf:nvidiasudo vim /etc/modprobe.d/nvidia-drm.conf:options nvidia-drm modeset=1sudo rc-update add modules bootsudo reboot \n\nLightDM# 安装LightDM，使用KDE可忽略sudo emerge --ask gui-libs/display-manager-initsudo emerge --ask x11-misc/lightdm # 如果不安装桌面管理器需要加入环境，登录后自动启动桌面echo &quot;XSESSION=\\&quot;awesome\\&quot;&quot; &gt; /etc/env.d/90xsessionenv-update &amp;&amp; source /etc/profile# openrcnano -w /etc/conf.d/display-managerDISPLAYMANAGER=&quot;lightdm&quot;# 设置默认开机启动rc-update add display-manager default# 设置dubs默认开机启动，虽然display-manager也会启动它，但有时候会出现奇怪的问题rc-update add dbus default# 手动启动rc-service dbus start rc-service display-manager start# systemd# systemctl enable lightdm.service\n\nKDE# 安装KDE桌面可忽略上边LightDM,同时需要删除USE中`-kde`sudo emerge --ask x11-misc/sddmsudo emerge --ask kde-plasma/plasma-meta# 安装Dock# 安装完打开latte-dock后会自动设置为开机自启动sudo emerge --ask kde-misc/latte-dock# 修改登陆管理器配置文件nano -w /etc/conf.d/display-manager# --- xdm内容DISPLAYMANAGER=&quot;sddm&quot;#---# 添加SDDM开机启动sudo rc-update add xdm default# 启动SDDMsudo rc-service xdm start # Systemd# sudo systemctl enable xdm# sudo systemctl start xdm\n\nAwesome# awesome 平铺式桌面emerge --ask x11-wm/awesome # 测试mkdir -p ~/.config/awesome/cp /etc/xdg/awesome/rc.lua ~/.config/awesome/rc.luaawesome -k# 壁纸支持emerge --ask media-gfx/feh# 在~/.config/awesome/theme/theme中添加一下内容theme.wallpaper_cmd = &#123; &quot;wesetbg -f .config/awesome/themes/awesome-wallpaper.png&quot; &#125;\n\nMate# 选择profileeselect profile listeselect profile set 0 # 选择default/linux/amd64/23.0/desktop# 更新emerge -auvDU @world# Meta 桌面emerge --ask mate-base/mate# 修改xsession配置nano -w /etc/env.d/90xsession#--- 90xsession内容XSESSION=&quot;Mate&quot;#--- # 修改LightDM配置(需要安装LightDM)nano -w /etc/conf.d/display-manager#--- display-manager内容DISPLAYMANAGER=&quot;lightdm&quot;\n\nXfce# xfce4桌面emerge --ask xfce-base/xfce4-meta # 测试桌面启动指令startxfce4 # 启动Xfce桌面# Pulseaudio音量控制emerge --ask xfce-extra/xfce4-volumed-pulse# 蓝牙音乐播放组件emerge --ask xfce-extra/xfce4-pulseaudio-plugin# 显示所有正在运行的程序的列表，以及每个程序占用的CPU和内存消耗。 emerge --ask xfce-extra/xfce4-taskmanager# 监视和管理电源使用情况的应用程序。 这对笔记本电脑特别重要！# 电源管理器允许用户调节屏幕亮度，选择最大性能或节电模式，# 并在盖子关闭或按下按钮时设置休眠，暂停和关闭操作emerge --ask xfce-extra/xfce4-power-manager# 适合笔记本电脑用户。 它显示电池百分比，剩余时间，电源（交流或电池），风扇状态，警告，# 甚至可以配置为在特定功率级别执行命令。 此功能可用于在电池电量几乎耗尽时将笔记本电脑置于休眠模式。xfce-extra/xfce4-battery-plugin# 添加几个窗口管理器主题emerge --ask x11-themes/xfwm4-themes# 一个X11终端，比准系统更可配置和有用 xterm emerge --ask x11-terms/xfce4-terminal# Xfce的默认图形文件管理器。emerge --ask xfce-base/thunar# 允许用户从Thunar内预览某些类型的文件，例如图像和字体。emerge --ask xfce-extra/tumbler# manages自动挂载可移动介质和驱动器。emerge --ask xfce-extra/thunar-volman# 嵌入面板的一个小命令行。 它比打开终端运行命令更快。emerge --ask xfce-extra/xfce4-verve-plugin# 提供一种方便的方法，只需点击鼠标即可安装/etc/fstab中列出的设备。emerge --ask xfce-extra/xfce4-mount-plugin# 允许用户监视硬件传感器，例如CPU温度，风扇RPM，硬盘驱动器温度，主板电压等。emerge --ask xfce-extra/xfce4-sensors-plugin\n\n音频控制emerge --ask alsa-utilsemerge --ask alsa-plugins\n\n中文字体emerge --ask media-fonts/arphicfontsemerge --ask media-fonts/noto-cjkemerge --ask media-fonts/source-han-sansemerge --ask media-fonts/wqy-microheiemerge --ask media-fonts/wqy-zenheieselect fontconfig list eselect fontconfig enable X X X # 选择所有wqy开头的项\n\n输入法# 输入法主题框架# 其中， app-i18n/fcitx:5 是 fcitx 的主程序# 　　　 app-i18n/fcitx-configtool:5 是它的配置工具# 　　　 app-i18n/fcitx-qt:5 用于支持在 qt 程序上使用它# 　　　 app-i18n/fcitx-gtk:5 用于支持在 gtk 程序上使用它emerge -vj app-i18n/fcitx:5 app-i18n/fcitx-configtool:5 app-i18n/fcitx-qt:5 app-i18n/fcitx-gtk:5# 安装完成后再用户的~/.xsession文件内添加export XMODIFIERS=&quot;@im=fcitx&quot;export QT_IM_MODULE=fcitxexport GTK_IM_MODULE=fcitxexport SDL_IM_MODULE=fcitx\n\n常用命令# 使用常规(基于源)更新# --ask(-a)控制Portage显示要更新的软件列表，并提供是否更新选择# --verbose(-v)在屏幕上输出完整的文件列表# --update(-u)更新包的最佳版本# --deep(-D)更新系统中的每个软件包# --newuse(-N)USE标记变更后，要使用Portage检查USE标记的变动是否导致需要安装新的软件或将现有的软件包重新编译sudo emerge --ask --verbose --update --deep --newuse @world# 等价简写emerge -avuDN @worldemerge -av --deepclean#gentookit包里的一个软件，用来检查系统的依赖是否都满足,自动安装缺失的依赖revdep-rebuild# 使用二进制包更新系统emerge --ask --verbose --update --deep --changed-use --getbinpkg @world# 告诉 Portage 不要对一些指定的包或分类创建二进制包emerge -uDN @world --buildpkg --buildpkg-exclude &quot;virtual/* sys-kernel/*-sources&quot;# 合并use标记etc-update -3 # 自动合并# 刷新环境变量source /etc/profile # 清理旧版本的内核emerge --prune sys-kernel/gentoo-kernel sys-kernel/gentoo-kernel-bin\n\n\n\nemerge 使用二进制包选项说明\n\n\n\n选项\n说明\n\n\n\n–usepkg (-k)\n尝试使用本地可用的 packages 目录中的二进制包。如果未找到二进制包，将执行常规（基于源）安装。\n\n\n–usepkgonly (-K)\n类似 –usepkg (-k) ，但如果找不到二进制包，则失败。\n\n\n–getbinpkg (-g)\n从远程二进制包主机下载二进制包。如果未找到二进制包，将执行常规（基于源）安装。\n\n\n–getbinpkgonly (-G)\n类似于 –getbinpkg (-g) ，但如果无法下载二进制包，则会失败\n\n\nUSE变量说明 官方文档USE是Gentoo为用户提供的最具威力的变量之一。很多程序通过它可以选择编译或者不编译某些可选的支持。例如，一些程 序可以在编译时加入对gtk或是对qt的支持。其它的程序可以在编译时加入或不加入对于SLL的支持。有些程序甚至可以在编译时加入对 framebuffer的支持（svgalib）以取代X11（X服务器）。大多数的发行版会使用尽可能多的支持特性编译它们的软件包，这既增加了软件的大小也减慢了启动时间，而这些还没有算上可能会涉及到的大量依赖性问题。Gentoo可以让你自己定义软件编译的选项，而这正是USE要做的事。在USE变量里可以定义关键字，它被用来对应相应的编译选项。例如，ssl将会把ssl支持编译到程序中以支持它。-X会移除其对于X服务器的支持（注意前面的减号）。gnome gtk -kde -qt4将会以支持GNOME（和GTK）但不支持KDE（和Qt）的方式编译软件，使系统为GNOME做完全调整（如果架构支持）。默认的USE设置全放在了系统所使用的Gentoo配置文件的make.defaults文件中。Gentoo对它的配置文件们使用了一个（复杂的）继承系统，在这个阶段我们不去深入。最简单的检查当前活动的USE标记的办法是运行emerge –info并选择以USE开头的那一行:\nemerge --info |grep ^USE\n![[Gentoo安装&#x2F;IMG-20241210170128821.png]]可以在系统的&#x2F;usr&#x2F;portage&#x2F;profiles&#x2F;use.desc中找到可用的USE标记的完整描述。\nless /usr/share/portage/profile/use.desc\n\n\n### 常用软件```bashsudo emerge --ask media-video/mpv# 电子邮件客户端sudo emerge mail-client/thunderbird# 视频播放器sudo emerge media-video/mplayer# 音乐播放器sudo emerge media-sound/exaile# 虚拟机sudo emerge app-emulation/virt-managersudo emerge app-emulation/virtualbox# VIMsudo emerge app-editors/vim\n\n\n\n参考文章\nGentoo AMD64 Handbook - Gentoo Wiki\n开始使用gentoo linux——gentoo安装笔记（上）\n开始使用gentoo linux——gentoo安装笔记（下）\nGentoo安装流程分享(step by step)，第二篇之KDE Plasma桌面的安装配置 - 知乎 (zhihu.com)\ngentoo linux配置intel和nvidia双显卡电脑，使用prime方案 - 简书 (jianshu.com)\n","categories":["Linux"],"tags":["Gentoo"]},{"title":"KVM常用命令","url":"/2024/09/02/Linux/KVM%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","content":"添加删除# 查看虚拟机virsh list --all# 创建虚拟机virt-install -virt-type=kvm --name=&#123;虚拟机名&#125; --vcpus=4 \\    --memory=1024 --location=&#123;iso文件&#125; \\    --disk path=&#123;虚拟机硬盘存放路径&#125;.qcow2,size=30,format=qcow2 \\    --network bridge=virbr0 --graphics none --extra-args=&#x27;console=ttyS0&#x27;    --force# 删除虚拟机virsh undefine &#123;虚拟机名&#125;\n\n\n\n开关机# 开启虚拟机virsh start &#123;虚拟机名&#125;# 关闭虚拟机virsh shutdown &#123;虚拟机名&#125;# 强制关机virsh destroy &#123;虚拟机名&#125;# 挂起虚拟机virsh suspend &#123;虚拟机名&#125;# 恢复挂起的virsh resume &#123;虚拟机名&#125;# 设置虚拟机和物理机开机一起启动virsh autostart &#123;虚拟机名&#125;# 取消虚拟机开机启动virsh autostart &#123;虚拟机名&#125;\n\n\n\n备份克隆# 通过配置文件启动virsh create /etc/libvirt/qemu/&#123;虚拟机名&#125;.xml# 备份虚拟机配置文件virsh dumpxml &#123;虚拟机名&#125; &gt; &#123;存储路径&#125;# 恢复备份虚拟机virsh create &#123;虚拟机名&#125;# 虚拟机克隆virt-clone -o &#123;虚拟机名&#125; -n localhost -f /virtual/KVM/&#123;虚拟机名&#125;.qcow2\n\n\n\n快照# 创建快照virsh snapshot-create &#123;虚拟机名&#125;# 查看快照virsh snapshot-list &#123;虚拟机名&#125;# 恢复快照virsh snapshot-revert &#123;虚拟机名&#125; &#123;快照名称&#125;# 删除快照virsh snapshot-delete &#123;虚拟机名&#125; &#123;快照名称&#125;\n\n","categories":["Linux"],"tags":["KVM","虚拟机"]},{"title":"Linux4.4内核配置","url":"/2022/01/01/Linux/Linux4.4%E5%86%85%E6%A0%B8%E9%85%8D%E7%BD%AE/","content":"[Linux-4.4-x86_64 内核配置选项简介 金步国] (jinbuguo.com)\n","categories":["Linux"],"tags":["Kernel"]},{"title":"Linux修改MAC地址","url":"/2025/03/26/Linux/Linux%E4%BF%AE%E6%94%B9MAC%E5%9C%B0%E5%9D%80/","content":"临时修改方法一\nsudo apt update &amp; sudo apt install net-tools    # 安装 net-toolssudo ifconfig eth0 down                         # 停用网卡sudo ifconfig eth0 hw ether AA:BB:CC:DD:EE:FF   # 设置 MAC 地址sudo ifconfig eth0 up                           # 启用网卡\n\n方法二\nsudo ip link set dev eth0 down                      # 停用网卡 sudo ip link set dev eth0 address AA:BB:CC:DD:EE:FF # 设置 MAC 地址sudo ip link set dev eth0 up                        # 启用网卡\n\n永久修改注意： 永久修改需要停止NetworkManager服务，此服务可能导致修改不生效\nsudo systemctl stop NetworkManager.servicesudo systemctl disable NetworkManager.service\n\n方法一\n编辑&#96;&#x2F;etc&#x2F;init.d&#x2F;rc.local&#96;&#96;文件,在此配置文件最后追加临时修改网卡MAC命令\n# 修改 ech0 网卡的 MAC 地址sudo ifconfig eth0 down # 网卡名称可使用 ifconfig 或 ip addr 查看sudo ifconfig eth0 hw ether AA:BB:CC:DD:EE:FFsudo ifconfig eth0 up\n方法二\n编辑/etc/network/interfaces文件，在此文件后追加\nauto eth0                         # 网卡自动启动iface eth0 inet static            # 静态 IPaddress 192.168.1.2               # IP 地址netmask 255.255.255.0             # 掩码gateway 192.168.1.1               # 网关hwaddress ether AA:BB:CC:DD:EE:FF # MAC 地址dns-nameservers 223.5.5.5         # DNS 多个用空格隔开dns-search .com                   # 限制 .com 的查询走上边设置的DNS服务器\n\n修改完成需要重启网络服务使配置生效\nsudo systemctl restart networking.service # 不同系统服务名可能有不太一样，如果找不到就重启系统sudo reboot","categories":["Linux"],"tags":["Linux","MAC"]},{"title":"Linux内核TCP网络参数.md","url":"/2024/12/11/Linux/Linux%E5%86%85%E6%A0%B8TCP%E7%BD%91%E7%BB%9C%E5%8F%82%E6%95%B0/","content":"sudo vim /etc/sysctl.d/99-sysctl.conf：     #重启后生效fs.inotify.max_user_watches = 600000dev.i915.perf_stream_paranoid = 0vm.swappiness = 1net.ipv6.conf.all.accept_ra = 2fs.file-max = 6553560net.core.rmem_max = 67108864net.core.wmem_max = 67108864net.core.rmem_default = 65536net.core.wmem_default = 65536net.core.optmem_max = 10000000net.core.netdev_max_backlog = 8096net.core.somaxconn = 8096net.ipv4.ip_default_ttl = 128net.ipv4.tcp_timestamps = 1net.ipv4.tcp_syncookies = 1net.ipv4.icmp_echo_ignore_broadcasts = 1net.ipv4.icmp_ignore_bogus_error_responses = 1net.ipv4.conf.default.accept_source_route = 0net.ipv4.tcp_slow_start_after_idle = 0net.ipv4.route.gc_timeout = 100net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_fin_timeout = 30net.ipv4.tcp_keepalive_time = 1200net.ipv4.tcp_keepalive_probes = 3net.ipv4.tcp_keepalive_intvl = 15net.ipv4.tcp_fin_timeout = 30net.ipv4.tcp_syn_retries = 2net.ipv4.tcp_synack_retries = 2net.ipv4.tcp_window_scaling = 1net.ipv4.tcp_ecn = 1net.ipv4.tcp_sack = 1net.ipv4.tcp_fack = 1net.ipv4.tcp_low_latency = 0net.ipv4.tcp_max_tw_buckets = 5000net.ipv4.tcp_fastopen = 3net.ipv4.tcp_frto = 2net.ipv4.tcp_frto_response = 0net.ipv4.tcp_rmem = 4096 87380 67108864net.ipv4.tcp_wmem = 4096 65536 67108864net.ipv4.tcp_mtu_probing = 1net.ipv4.tcp_slow_start_after_idle = 0net.ipv4.tcp_max_syn_backlog = 30000net.ipv4.tcp_max_orphans = 262114net.ipv4.netfilter.ip_conntrack_max = 204800net.ipv4.conf.all.rp_filter = 1net.ipv4.conf.default.rp_filter = 1# for high-latency network Google BBR    #个人PC不建议开启BBR，对网速不会有提升，还会降低wifi吞吐量；还是等BBR2正式版出了再开启BBR2吧，BBR2对wifi就没有影响了#net.ipv4.tcp_congestion_control = bbrnet.core.default_qdisc = fq_codelnet.ipv4.tcp_congestion_control = cubicnet.ipv6.conf.all.disable_ipv6 = 0net.ipv6.conf.default.disable_ipv6 = 0net.ipv6.conf.lo.disable_ipv6 = 0net.ipv6.ip_default_ttl = 128\n\nsudo vim /etc/security/limits.conf：* soft nofile 65536* hard nofile 65536* soft noproc 65536 * hard noproc 65536","categories":["Linux"],"tags":["Linux"]},{"title":"Linux实现U盘插入自动挂载","url":"/2025/03/27/Linux/Linux%E5%AE%9E%E7%8E%B0U%E7%9B%98%E6%8F%92%E5%85%A5%E8%87%AA%E5%8A%A8%E6%8C%82%E8%BD%BD/","content":"方式一通过udev规则监听设备事件，编写/etc/udev/rules.d/99-udev-mount.rules规则实现U盘插入捕获U盘插入事件\n# 插入U盘自动挂载ACTION==&quot;add&quot;, KERNEL==&quot;sd[a-z]*&quot;, RUN+=&quot;/bin/mkdir -p /media/udev-%k&quot;, RUN+=&quot;/bin/mount /dev/%k /media/udev-%k&quot;# 移除U盘自动卸载ACTION==&quot;remove&quot;, KERNEL==&quot;sd[a-z]*&quot;, RUN+=&quot;/bin/umount /media/udev-%k&quot;\n\n规则编辑完成后执行以下命令使规则生效\nsudo udevadm control --reload\n","categories":["Linux"],"tags":["Linux","U盘","自动挂载"]},{"title":"Linux硬盘分区","url":"/2018/03/22/Linux/Linux%E7%A1%AC%E7%9B%98%E5%88%86%E5%8C%BA/","content":"环境检查ls /sys/firmware/efi/efivars #UEFI/BIOS检测\n若该目录不存在，则 ArchISO 是以 BIOS&#x2F;CSM 模式启动，否则是以 UEFI 模式启动。\n\n通常而言，UEFI 系统须使用 GPT 分区才能引导，BIOS 系统须使用 MBR 分区才能引导。\n\n分区fdiskfdisk -l //查看所有分区情况\n常用fdisk命令：p 显示当前磁盘分区，d 删除指定分区，n 创建新分区， a 为指定分区创建启动标记，t 更改分区格式， w将磁盘分区信息写入磁盘。\nparted# parted /dev/sda检查 MINOR #对文件系统进行一个简单的检查cp [FROM-DEVICE] FROM-MINOR TO-MINOR #将文件系统复制到另一个分区help [COMMAND] #打印通用求助信息，或关于 COMMAND 的信息mklabel 标签类型 #创建新的磁盘标签 (分区表)mkfs MINOR 文件系统类型 #在 MINOR 创建类型为“文件系统类型”的文件系统mkpart 分区类型 [文件系统类型] 起始点 终止点 #创建一个分区mkpartfs 分区类型 文件系统类型 起始点 终止点 #创建一个带有文件系统的分区move MINOR 起始点 终止点 #移动编号为 MINOR 的分区name MINOR 名称 #将编号为 MINOR 的分区命名为“名称”print [MINOR] #打印分区表，或者分区quit #退出程序rescue 起始点 终止点 #挽救临近“起始点”、“终止点”的遗失的分区resize MINOR 起始点 终止点 #改变位于编号为 MINOR 的分区中文件系统的大小rm MINOR #删除编号为 MINOR 的分区select 设备 #选择要编辑的设备set MINOR 标志 状态 #改变编号为 MINOR 的分区的标志\n\n格式化分区mkfs.vfat -F 32 /dev/sda1 #生成ESP分区的文件系统FAT32mkswap /dev/sda2 #格式化swapmkfs.ext4 /dev/sda3 #格式化ext4mkfs.xfx /dev/sda4 #格式化xfs\n\n分区方案/dev/sda1 /boot 500M/dev/sda2 swap 8G(根据内存大小调整)/dev/sda3 / 200G/dev/sda4 /home 剩余所有空间\n\n挂载分区#mount /dev/sda6 /mnt # 挂载根分区\n非UEFI挂载boot\n# mkdir -p /mnt/boot# mount /dev/sda1 /mnt/boot\n\n建立efi目录，把EFI分区装载到刚建立的efi目录上。\n#mkdir -p /mnt/boot/efi#mount /dev/sdc1 /mnt/boot/efi\n\n挂载交换分区和home\n#swap on /dev/sda5#mkdir -p /mnt/home#mount /dev/sda7 /mnt/home\n\n生成引导\nBIOS：\n\n\n依赖包： grub os-prober\n\n# grub-install --recheck /dev/&lt;目标磁盘&gt;# grub-mkconfig -o /boot/grub/grub.cfg\n\n\nUEFI：—如果BIOS是UEFI的，就要用下面的命令安装grub了\n\n\n依赖包： dosfstools grub efibootmgr\n\n# grub-install --target=x86_64-efi --efi-directory=&lt;EFI 分区挂载点&gt; --bootloader-id=arch_grub --recheck# grub-mkconfig -o /boot/grub/grub.cfg\n\n低格填零\n# dd if=/dev/zero of=/dev/sda bs=16M","categories":["Linux"],"tags":["Parted","分区"]},{"title":"Linux系统监视器Conky配置","url":"/2024/09/03/Linux/Linux%E7%B3%BB%E7%BB%9F%E7%9B%91%E8%A7%86%E5%99%A8Conky%E9%85%8D%E7%BD%AE/","content":"安装sudo apt install lm-sensors curl hddtemp  # 安装工具sensors-detect # 检测传感器sudo apt install conky # 安装conky &amp; # 运行conky\n\n传感器数据样例\nacpitz-virtual-0-Adapter: Virtual devicetemp1: +49.5°C (crit = +99.0°C)coretemp-isa-0000Adapter: ISA adapterPhysical id 0: +49.0°C (high = +100.0°C, crit = +100.0°C)Core 0: +49.0°C (high = +100.0°C, crit = +100.0°C)Core 1: +49.0°C (high = +100.0°C, crit = +100.0°C)\n:TODO conky 默认运行效果截图\nconky默认以一个弹窗的形式运行，并使用位于&#x2F;etc&#x2F;conky&#x2F;conky.conf的基础配置文件\n集成到桌面cp /etc/conky/conky.conf /home/$USER/.conkyrc # 复制默认配置文件","categories":["Linux"],"tags":["Linux软件源","Conky"]},{"title":"Linux设置swap分区","url":"/2022/01/01/Linux/Linux%E8%AE%BE%E7%BD%AEswap%E5%88%86%E5%8C%BA/","content":"","categories":["Linux"],"tags":["交换空间","SWAP"]},{"title":"Linux配置sudo无密码","url":"/2025/03/19/Linux/Linux%E9%85%8D%E7%BD%AEsudo%E6%97%A0%E5%AF%86%E7%A0%81/","content":"方法1最简单的一种方法，将当前用户添加到root组。这样做之后该用户将拥有所有root权限，从而使用户在使用sudo时不再需要输入密码。\nsudo adduser &#123;当前用户名&#125; root \n\n注意： 将用户添加到root组后，该用户将拥有最高权限，因此在执行系统级操作时要特别小心，以避免可能的系统破坏。\n方法2（推荐）通过编辑/etc/sudoers文件来配置特定用户或组的sudo行为。这种方法允许更灵活的控制哪些命令可以绕过密码提示。![[Linux配置sudo无密码&#x2F;IMG-20250319160639846.png]]\n单用户配置\n&#123;用户名&#125; ALL=(ALL:ALL) NOPASSWD:ALL #在 root 后新添加一行\n\n用户组配置\n%&#123;用户组&#125; ALL=(ALL:ALL) NOPASSWD:ALL # 在 %sudo 后添加\n使用此方式需将用户添加进组\nsudo usermod -a -G &#123;用户组&#125; &#123;用户名&#125;","categories":["Linux"],"tags":["sudo"]},{"title":"Linux配置网络及SSH配置","url":"/2018/05/24/Linux/Linux%E9%85%8D%E7%BD%AE%E7%BD%91%E7%BB%9C%E5%8F%8ASSH%E9%85%8D%E7%BD%AE/","content":"识别接口名称# 需要 net-toolsifconfig\n\n\n如果使用标准的ifconfig命令没有显示出接口，尝试使用带有-a选项的相同的命令。这个选项强制这个工具去显示系统检测到的所有的网络接口，不管他们是up或down状态。如果ifconfig -a没有提供结果，则硬件有错误或者接口驱动没有加载到内核中。\n\n# 新版本系统大部分支持ip addr\n\n\n\ndhcpDHCP（动态主机配置协议）使自动接受网络信息（IP地址、掩码、广播地址、网关、名称服务器等）变得容易。这只在网络中有DHCP服务器（或者如果ISP提供商提供一个DHCP服务）时有用.\ndhcpcd eth0 # eth0 为网口名称,根据上一步识别出的接口名称修改\n\n\n\nifconfig命令# 启用/禁用网卡ifconfig eth0 up/down# 设置IP地址及掩码ifconfig eth0 &#123;IP地址&#125; netmask &#123;掩码&#125; up# 设置默认网关route add default gw &#123;网关&#125;# 配置DNSnano -w /etc.resolv.conf#使用下边模板填充nameserver &#123;名称服务器&#125;\n\n\n花括号中内容使用具体的地址填充\n\nip命令# 启用/禁用网卡ip link set dev eth0 up/down# 设置Ip地址及掩码,掩码一般用 24 相当于255.255.255.0ip addr add &#123;IP地址&#125;/&#123;掩码&#125; dev eth0# 删除ip addr del dev eth0 &#123;IP&#125;/&#123;掩码&#125;# 刷新接口IP(删除所有)ip addr flush eth0# 设置默认网关ip route add default via &#123;网关&#125;\n\n网关的配置参考\nip route命令\nLinux上添加路由，删除路由，修改路由配置（route add, route del, 路由表项基本知识）\n\n| 子网掩码用来划分网络区域| 子网掩码非0的位对应的ip上的数字表示这个ip的网络位| 子网掩码0位对应的数字是ip的主机位| 网络位表示网络区域| 主机位表示网络区域里某台主机|| 11111111.11111111.11111111.00000000 &#x3D; 255.255.255.0 &#x3D; 24| ——————————————  —————|          网络位                                      主机位\n| 网络位一致，主机位不一致的2个IP可以直接通讯|| 172.25.254.10&#x2F;24         #24&#x3D;255.255.255.0|| 172.25.254.20&#x2F;24|| 172.25.0.1&#x2F;16            #16&#x3D;255.255.0.0| 前两个可以直接通讯，最后一个与其他俩个不能直接通讯\n\n无线网连接当使用一块无线（802.11）网卡，在继续之前需要先配置无线设置。要查看当前无线网卡的设置，你可以使用iw。\n# 查看连接信息iw dev wlan0 info# 检查连接状态iw dev wlan0 link# 连接网络 （确保接口处于活动状态）iw dev wlan0 connect -w &#123;网络名称&#125; key 0:d:&#123;密码&#125; \n\n如果无线网络配置为WPA或WPA2，则需要使用wpa_supplicant。\n# 查找附近热点wpa_cli -i wlan0 scan# 生成连接配置文件wpa_passphrase &#123;网络名称&#125; &#123;密码&#125; &gt; /etc/wpa_supplicant.conf # 连接网络# -D 驱动程序名称（可以是多个驱动程序：nl80211,wext）# -i 接口名称# -c 配置文件# -B 在后台运行守护进程wpa_supplicant -D nl80211 -i wlan0 -c /etc/wpa_supplicant.conf -B\n\n\n\nSSH配置nano -w /etc/ssh/sshd_config# 放开注释PasswordAuthentication yesPermitRootLogin yes# 启用SSH密钥对登录，取消如下行的注释符PubkeyAuthentication yesAuthorizeKeysFile .ssh/authorized_keys\n\n启动SSHD# 启动SSH服务(需要有可登录的账户)/etc/init.d/sshd start\n\n","categories":["Linux"]},{"title":"OpenSSL生成自签名证书","url":"/2024/09/03/Linux/OpenSSL%E7%94%9F%E6%88%90%E8%87%AA%E7%AD%BE%E5%90%8D%E8%AF%81%E4%B9%A6/","content":"名词解释CA(Certificate Authority)证书授权机构,  负责发放和管理数字证书的权威机构，有自己的证书，可以拿自己的证书给别人签名。\nRootCA根证书，权威机构持有的证书，安装根证书意味着对这个证书机构的信任，所有其他证书都由这个根证书来签发。只需要把这个根证书添加到受信任的根证书，所有其他由此根证书签发的证书都会被自动信任。\nSubCA中间证书机构，由权威机构签发的证书，\nCSR(Certificate Signing Request)证书请求文件，证书申请者在申请数字证书时生成私钥的同时也生成证书请求文件，证书申请者只要把CSR文件提交给证书颁发机构后，证书颁发机构使用其根证书给私钥签名就生成了证书公钥文件，也就是颁发给用户的证书。\n常用后缀名\n\n\n格式\n说明\n\n\n\n.crt,.cer\n证书文件\n\n\n.key\n私钥文件\n\n\n.csr\n证书签名请求文件\n\n\n.pem\nbase64编码证书文件,可以单独放证书或密钥，也可以同时放两个。Apache 和 NGINX 服务器偏向于使用这种编码格式，也是 openssl 默认采用的信息存放方式。\n\n\n.der\n二进制证书文件，可包含所有私钥、公钥和证书，是大多数浏览器的缺省格式，常见于 Windows 系统中的证书格式。\n\n\n证书链在证书链中，通常分为三级结构，分别是根证书、中间证书、服务器证书。正确的证书链顺序中服务器证书处在最底端，里面包含服务器域名域名服务器公钥和签名值等。服务器证书的上一级是中间证书，可以由多张证书组合在一起，最上级是根证书。对服务器身份进行校验时，需要验证一整个证书链。每一级证书都有签名值，根证书使用自己的根CA公钥验证自己的签名，也用来验证中间证书的签名值，中间证书的公钥用来验证下一级证书的签名值。\n\n生成根证书生成根私钥# 生成CA认证机构的证书密钥# 需要设置密码(输入两次)openssl genrsa -des3 -out root-ca.priv.key 4096# 去除密钥里的密码,有密码的话每次使用的时候都要输入密码才能使用。# 需要再输入一次上一步的密码openssl rsa -in root-ca.priv.key -out root-ca.key\n\n第一次生成的私钥，是带有 passphrase 的。这带来一个副作用，就是需要在使用过程中输入密码。这对于一些特定场景来说会带来一些问题。比如：Apache 的自动启动过程，或者一些工具，甚至有没有提供输入 passphrase 的机会。其实是可以将 3DES 的加密从秘钥中移除的，这样，使用的过程中就不再需要输入 passphrase。这也带来另一个问题，如果其他人获取到了未加密的私钥，对应的证书也需要被吊销，以避免带来危害。\n生成自签名的根证书请求-subj 参考证书请求文件参数说明\n# 生成根证书自签名请求openssl req -new -key root-ca.key \\    -subj &quot;/C=CN/ST=Tianjin/L=Tianjin/O=Example/OU=DEV/CN=Example Root&quot; \\    -out root-ca.csr \n\n生成自签名根证书# 参数说明# -x509\t使用X.509证书结构生成证书，X.509 证书的结构是用 ASN1(Abstract Syntax Notation One)进行描述数据结构。# -days 证书有效期,按天来算openssl x509 -req -in root-ca.csr -signkey root-ca.key -out root-ca.crt -days 3650\n\n\n\n生成中间证书如果不是复杂场景可以跳过此步骤，使用根证书直接生成客户端证书\n 使用root-ca签发sub-ca的证书签名请求,中间证书指的是可以允许继续生成下级证书，否则的话默认生成终端证书，即使可以用中间证书生成下一级客户端和服务端等用户证书，最终验证的无法通过。\n生成中间证书私钥# 生成私钥,方式1(参考根证书私钥)openssl genrsa -des3 -out mid-ca.priv.key 4096openssl rsa -in mid-ca.priv.key -out mid-ca.key# 生成私钥,方式2openssl genpkey -algorithm RSA -out mid-ca.key -pkeyopt rsa_keygen_bits:4096\n\n生成中间证书请求-subj参考证书请求文件参数说明\n# 生成中间证书自签名请求openssl req -new -key root-ca.key \\    -subj &quot;/C=CN/ST=Tianjin/L=Tianjin/O=Example/OU=DEV/CN=Example Root&quot; \\    -out mid-ca.csr # 同时生成key和csropenssl req -new -newkey rsa:4096 -nodes -keyout mid-ca.key -out mid-ca.csr \\    -subj=&quot;/C=CN/ST=Tianjin/L=Tianjin/O=Example/OU=DEV/CN=Example Mid&quot;\n\n生成中间证书# 生成证书openssl x509 -req -extfile &lt;(printf &quot;subjectKeyIdentifier=hash\\nauthorityKeyIdentifier=keyid:always,issuer:always&quot;) \\    -days 3650 -in mid-ca.csr -CA root-ca.crt -CAkey root-ca.key \\    -CAcreateserial -out mid-ca.crt\n\n验证中间证书openssl verify -CAfile root-ca.crt mid-ca.crt\n\n\n\n生成终端证书假设服务器域名为example.io\n生成终端证书私钥# 生成私钥，方式1(参考根证书私钥)openssl genrsa -des3 -out example.io.priv.key 4096openssl rsa -in example.io.priv.key -out example.io.priv.key# 生成私钥，方式2openssl genpkey -algorithm RSA -out example.io.key -pkeyopt rsa_keygen_bits:4096\n\n\n\n生成终端证书请求-subj 参考证书请求文件参数说明\n# 生成终端证书自签名请求openssl req -new -key example.io.key -out example.io.csr -subj=&quot;/CN=example.io&quot;\n\n\n\n生成终端证书 # 生成证书,如果不使用中间证书可把mid-ca.crt替换为root-ca.crtopenssl x509 -req -days 3650 \\    -extfile v3.ext    -CA root-ca.crt -CAkey root-ca.key -CAcreateserial \\    -in example.io.csr -signkey example.io.key \\    -out example.io.crt    openssl x509 -req -extfile v3.ext -days 365 -in example.io.csr -CA mid-ca.crt -CAkey mid-ca.key -CAcreateserial -out example.io.crt# 导出pfx,openssl pkcs12 -export -out example.io.pfx -inkey example.io.key -in example.io.crt\n\nv3.ext参考X.509扩展配置\n注意: v3.ext中basicConstraints=CA:FALSE为必选项，否则生成证书无法使用\n验证终端证书openssl verify -CAfile root-ca.crt example.io.crt\n\n\n\n查看证书信息# 查看公钥的内容,如果为.PEM ,则会以 base 64 明文方式显示openssl rsa -noout -text -in cakey.key# 查看证书的内容命令为openssl x509 -noout -text -in cacert.crt# 证书编码格式转换# PEM 转为 DERopenssl x509 -in cacert.crt -outform der -out cacert.der# DER 转为 PEMopenssl x509 -in cert.crt -inform der -outform pem -out cacert.pem\n\n\n\n证书有效性验证可以利用openssl 的s_server命令来模拟一个服务端，要使用到证书管理员生成的证书client.crt，以及申请人在创建csr时生成的 client.key\nopenssl s_server -cert example.io.crt -key example.io.key -debug -HTTP -accept 443\n\n然后浏览器访问 https://ip地址来查看证书是否有效（要先导入根证书到\n信任的根证书颁发机构）。\n吊销证书一般由于用户私钥泄露等情况才需要吊销一个未过期的证书。\n假设需要被吊销的证书文件为 cert.pem\n# 生成证书吊销列表文件# 可选参数#   -crldays 下一个吊销列表将在n天后发布#   -crlhours 下一个吊销列表将在n小时后发布openssl ca -revoke cert.pem # 查看吊销列表openssl crl -in testca.crl -text -noout\n\n\n\n附件证书请求文件参数说明\n\n\n参数\n说明\n\n\n\n\n&#x2F;C\nCountry Name (2 letter code)\n两字母的国家代码，例如 “CN”。\n\n\n&#x2F;ST\nState or Province Name\n州或省的全名。\n\n\n&#x2F;L\nLocality Name (e.g., city)\n城市或地区的全名。\n\n\n&#x2F;O\nOrganization Name (e.g., company)\n公司或组织的全名。\n\n\n&#x2F;OU\nOrganizational Unit Name (e.g., section)\n部门或单位的全名。\n\n\n&#x2F;CN\nCommon Name (e.g., your name or your server’s hostname)\n通常是你的服务器的主机名。\n\n\nemailAddress\nEmail Address\n电子邮件地址，用于证书联系。\n\n\n这些信息将用于填写证书请求文件。在实际情况中，一些字段可能不是必需的，具体取决于你的使用场景和证书颁发机构（CA）的要求。通常，“Common Name” 是最重要的字段，应该设置为与你的服务器域名或主机名相匹配的值。其他字段的值可以根据实际情况填写。\n示例\n/C=CN/ST=Tianjin/L=Tianjin/O=Example/OU=DEV/CN=example.com/emailAddress=dev@example.com\n\n\n\nX.509扩展配置v3.ext\nauthorityKeyIdentifier=keyid,issuersubjectKeyIdentifier=hashbasicConstraints=CA:FALSEkeyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment#extendedKeyUsage = serverAuthsubjectAltName = @alt_names[alt_names]DNS.1=example.ioDNS.2=*.example.ioIP.3=192.168.0.2\n\n extendedKeyUsage 可以指定证书目的，即用途，一般有\n​\tserverAuth 保证远程计算机的身份\n​\tclientAuth 向远程计算机证明你的身份\n​\tcodeSigning 确保软件来自软件发布者，保护软件在发行后不被更改\n​\temailProtection 保护电子邮件消息\n​\ttimeStamping 允许用当前时间签名数据,如果不指定，则默认为 所有应用程序策略\nSubjectAlternativeName\n​\tDNS.1用来确保网站的域名必须时*.example.com，\n​\tIP.1用来确保网站的IP地址，如果证书里面的内容和实际对应不上，浏览器就会报错。\n参考构建安全的X.509三级证书体系：OpenSSL实战指南-百度开发者中心 (baidu.com)\n如何创建自签名的 SSL 证书 - HappyVK - 博客园 (cnblogs.com)\n关于OpeSSL生成自签名证书-包含完整证书链生成（全网最全） - 52只鱼 - 博客园 (cnblogs.com)\n","categories":["Linux"],"tags":["Https证书","OpenSSL"]},{"title":"Systemd服务管理","url":"/2022/01/01/Linux/Systemd%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86/","content":"可能是史上最全面易懂的 Systemd 服务管理教程！( 强烈建议收藏 )-腾讯云开发者社区-腾讯云 (tencent.com)\n","categories":["Linux"],"tags":["Systemd"]},{"title":"Ubuntu/Debian安装PostgreSQL和TimescaleDB插件","url":"/2022/07/01/Linux/Ubuntu-Debian%E5%AE%89%E8%A3%85PostgreSQL%E5%92%8CTimescaleDB%E6%8F%92%E4%BB%B6/","content":"导入pg源及签名\nsudo sh -c &#x27;echo &quot;deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main&quot; &gt; /etc/apt/sources.list.d/pgdg.list&#x27;wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -\n\n导入TimeScalaDB 源及签名debian版\nsh -c &quot;echo &#x27;deb [signed-by=/usr/share/keyrings/timescale.keyring] https://packagecloud.io/timescale/timescaledb/debian/ $(lsb_release -c -s) main&#x27; &gt; /etc/apt/sources.list.d/timescaledb.list&quot;wget --quiet -O - https://packagecloud.io/timescale/timescaledb/gpgkey | gpg --dearmor -o /usr/share/keyrings/timescale.keyring\n\nubuntu版\nsh -c &quot;echo &#x27;deb [signed-by=/usr/share/keyrings/timescale.keyring] https://packagecloud.io/timescale/timescaledb/ubuntu/ $(lsb_release -c -s) main&#x27; &gt; /etc/apt/sources.list.d/timescaledb.list&quot;wget --quiet -O - https://packagecloud.io/timescale/timescaledb/gpgkey | gpg --dearmor -o /usr/share/keyrings/timescale.keyring\n\n安装\napt install postgresql-14\n\n启动pg\nservice postgresql startapt install postgresql-14-postgis-3apt install timescaledb-2-2.5.1-postgresql-14create databases test;\\c testcreate extension postgis;create extension timescaledb;\n\n创建timescaledb扩展时会报一下错误\nFATAL:  extension &quot;timescaledb&quot; must be preloadedHINT:  Please preload the timescaledb library via shared_preload_libraries.This can be done by editing the config file at: /etc/postgresql/14/main/postgresql.confand adding &#x27;timescaledb&#x27; to the list in the shared_preload_libraries config.        # Modify postgresql.conf:        shared_preload_libraries = &#x27;timescaledb&#x27;Another way to do this, if not preloading other libraries, is with the command:        echo &quot;shared_preload_libraries = &#x27;timescaledb&#x27;&quot; &gt;&gt; /etc/postgresql/14/main/postgresql.conf(Will require a database restart.)If you REALLY know what you are doing and would like to load the library without preloading, you can disable this check with:        SET timescaledb.allow_install_without_preload = &#x27;on&#x27;;server closed the connection unexpectedly        This probably means the server terminated abnormally        before or while processing the request.The connection to the server was lost. Attempting reset: Succeeded.\n\n根据提示修改配置文件\necho &quot;shared_preload_libraries = &#x27;timescaledb&#x27;&quot; &gt;&gt; /etc/postgresql/14/main/postgresql.conf\n\n重启pg\nservice postgresql restart\n\n再次建立扩展\ncreate extension timescaledb;\n\n查看已安装好的扩展\n\\dx","categories":["Linux"],"tags":["PostgreSQL","TimescaleDB"]},{"title":"Ubuntu18.04安装ROS-Melodic","url":"/2025/09/04/Linux/Ubuntu18.04%E5%AE%89%E8%A3%85ROS-Melodic/","content":"系统要求\n操作系统: Ubuntu 18.04 (Bionic Beaver)\nROS 版本: Melodic Morenia (官方长期支持版本)\nPython 版本: 2.7.x (ROS Melodic 默认使用)\n\n安装步骤1. 配置软件源和密钥sudo sh -c &#x27;echo &quot;deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main&quot; &gt; /etc/apt/sources.list.d/ros-latest.list&#x27;sudo apt-key adv --keyserver &#x27;hkp://keyserver.ubuntu.com:80&#x27; --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654\n\n2. 更新软件包列表sudo apt update\n\n3. 安装 ROS Melodic完整桌面版 (推荐，包含 GUI 工具、仿真器和常用库):\nsudo apt install ros-melodic-desktop-full\n\n其他可选版本:\nsudo apt install ros-melodic-desktop    # 基础桌面版（无仿真器）sudo apt install ros-melodic-ros-base   # 最小核心版（仅通信库和工具）\n\n4. 初始化 rosdepsudo rosdep initrosdep update\n\n5. 设置环境变量echo &quot;source /opt/ros/melodic/setup.bash&quot; &gt;&gt; ~/.bashrcsource ~/.bashrc\n\n6. 安装构建工具和依赖sudo apt install python-rosinstall python-rosinstall-generator python-wstool build-essential\n\n7. 创建示例工作空间 (可选)mkdir -p ~/catkin_ws/srccd ~/catkin_ws/catkin_makesource devel/setup.bash\n\n验证安装打开新终端，运行：\nroscore\n\n如果看到类似以下输出，说明安装成功：\n... logging to /home/username/.ros/log/xxx/roslaunch-hostname-xxx.logChecking log directory for disk usage. This may take a while.Press Ctrl-C to interruptDone checking log file disk usage. Usage is &lt;1GB.started roslaunch server http://hostname:xxx/ros_comm version 1.14.3\n\n常见问题解决1. 密钥获取失败如果 apt-key adv 失败，可以手动下载并添加：\ncurl -sSL &#x27;http://keyserver.ubuntu.com/pks/lookup?op=get&amp;search=0xC1CF6E31E6BADE8868B172B4F42ED6FBAB17C654&#x27; | sudo apt-key add -\n\n2. 网络问题如果下载速度慢，可以替换为国内镜像源（如清华源）：\nsudo sh -c &#x27;. /etc/lsb-release &amp;&amp; echo &quot;deb https://mirrors.tuna.tsinghua.edu.cn/ros/ubuntu/ `lsb_release -cs` main&quot; &gt; /etc/apt/sources.list.d/ros-latest.list&#x27;\n\n3. Python 版本验证确保系统中已安装 Python 2.7：\npython --version  # 应显示 Python 2.7.x\n\n测试命令安装完成后，可以使用以下命令测试 ROS 功能：\n\nroscore - 启动 ROS master\nrosrun roscpp_tutorials talker - 运行发布者节点\nrosrun roscpp_tutorials listener - 运行订阅者节点\n\n参考资源\nROS Melodic 官方文档\nROS 安装指南\n\n","categories":["Linux"],"tags":["Linux","ROS","Ubuntu"]},{"title":"Ubuntu部署LIO-SAM","url":"/2025/09/04/Linux/Ubuntu%E9%83%A8%E7%BD%B2LIO-SAM/","content":"概述LIO-SAM (Lidar Inertial Odometry and Mapping) 是一个紧耦合的激光雷达惯性里程计框架，集成了 IMU 预积分和 GPS 数据，适用于机器人建图和定位。\n环境要求\n\n\n组件\n版本\n下载地址\n\n\n\nUbuntu\n18.04+\n-\n\n\nROS\nMelodic\n-\n\n\ngtsam\n4.0.2\nGitHub\n\n\nEigen\n3.3.7\nGitLab\n\n\nLIO-SAM\n最新版\nGitHub\n\n\n安装步骤1. 安装系统依赖# 更新系统包列表sudo apt update# 安装必要的开发工具和依赖库sudo apt install -y build-essential cmake libboost-all-dev\n\n2. 安装 Eigen 库# 下载并解压 Eigenwget https://gitlab.com/libeigen/eigen/-/archive/3.3.7/eigen-3.3.7.tar.gztar -zxvf eigen-3.3.7.tar.gz# 编译安装cd eigen-3.3.7mkdir build &amp;&amp; cd buildsudo cmake ..sudo make install# 创建符号链接以便系统找到 Eigen 头文件sudo cp -r /usr/local/include/eigen3/Eigen/ /usr/local/include/\n\n3. 安装 ROS Melodic# 设置 ROS 软件源（清华镜像）sudo sh -c &#x27;. /etc/lsb-release &amp;&amp; echo &quot;deb http://mirrors.tuna.tsinghua.edu.cn/ros/ubuntu/ $DISTRIB_CODENAME main&quot; &gt; /etc/apt/sources.list.d/ros-latest.list&#x27;# 添加 ROS 密钥sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys F42ED6FBAB17C654# 更新包列表并安装 ROSsudo apt updatesudo apt-get install -y ros-melodic-desktop-full# 安装 ROS 开发工具sudo apt-get install -y ros-melodic-rqt* python-rosdep python-rosinstall python-rosinstall-generator python-wstool build-essential# 初始化 rosdepsudo rosdep initrosdep update\n\n4. 配置 ROS 环境# 将 ROS 环境变量添加到 bashrcecho &quot;source /opt/ros/melodic/setup.bash&quot; &gt;&gt; ~/.bashrcsource ~/.bashrc\n\n5. 安装 gtsam# 克隆 gtsam 仓库git clone https://github.com/borglab/gtsam.gitcd gtsam# 切换到 4.0.2 版本git checkout 4.0.2# 编译安装mkdir build &amp;&amp; cd buildcmake ..make -j$(nproc)sudo make install\n\n6. 安装 LIO-SAM# 创建工作空间mkdir -p ~/catkin_ws/srccd ~/catkin_ws/src# 克隆 LIO-SAMgit clone https://github.com/TixiaoShan/LIO-SAM.git# 安装依赖cd ~/catkin_wsrosdep install --from-paths src --ignore-src -y# 编译catkin_make -j$(nproc)# 设置工作空间环境echo &quot;source ~/catkin_ws/devel/setup.bash&quot; &gt;&gt; ~/.bashrcsource ~/.bashrc\n\n验证安装测试 ROS 安装# 启动 ROS 核心roscore# 新终端中检查 ROS 环境echo $ROS_PACKAGE_PATH\n\n测试 LIO-SAM 编译# 检查 LIO-SAM 包是否存在rospack find lio_sam# 尝试运行节点（需要相应的启动文件）roslaunch lio_sam run.launch\n\n常见问题解决1. Eigen 头文件找不到问题：编译时出现 fatal error: Eigen/Dense: No such file or directory\n解决方案：\n# 确保 Eigen 头文件在正确位置sudo ln -s /usr/local/include/eigen3/Eigen /usr/local/include/Eigen\n\n2. gtsam 版本不兼容问题：需要特定版本的 gtsam\n解决方案：\n# 确保使用 gtsam 4.0.2 版本cd gtsamgit checkout 4.0.2\n\n3. ROS 依赖问题问题：缺少 ROS 包依赖\n解决方案：\n# 安装所有缺失的依赖rosdep install --from-paths src --ignore-src -y\n\n使用说明启动 LIO-SAM# 启动 LIO-SAM 主要节点roslaunch lio_sam run.launch# 启动可视化工具roslaunch lio_sam visualization.launch\n\n数据播放# 播放 bag 文件rosbag play your_data.bag\n\n目录结构~/catkin_ws/└── src/    └── LIO-SAM/        ├── config/          # 配置文件        ├── launch/          # 启动文件        ├── src/            # 源代码        └── package.xml     # ROS 包配置\n\n注意事项\n版本匹配：确保所有组件的版本兼容性\n内存要求：编译过程需要足够的内存，建议 8GB+ RAM\n网络连接：下载依赖需要稳定的网络连接\n权限问题：某些操作需要 sudo 权限\n\n后续步骤\n配置参数：根据你的传感器调整 config/params.yaml\n数据采集：使用你的传感器采集数据\n性能调优：根据实际场景调整算法参数\n\n参考资源\nLIO-SAM 官方文档\nROS Melodic 安装指南\ngtsam 文档\n\n","categories":["Linux"],"tags":["Linux","Ubuntu","机器人","LIO-SAM","SLAM"]},{"title":"Ubuntu部署ROS","url":"/2025/08/29/Linux/Ubuntu%E9%83%A8%E7%BD%B2ROS/","content":"准备建议准备一个干净、换好源的 Ubuntu 16.04 及以上版本（建议 清华源 ），本教程也适用其他 ROS1版本。\n查看ubuntu 版本\nlsb_release -a\n根据自己的 Ubuntu 的版本选择 ROS 版本 (示例是 Ubuntu 18.04 所以对应ROS版本为 melodic）![[Ubuntu部署ROS&#x2F;IMG-20250829234441526.png]]\nROS安装1. 安装源sudo sh -c &#x27;. /etc/lsb-release &amp;&amp; echo &quot;deb http://mirrors.tuna.tsinghua.edu.cn/ros/ubuntu/ `lsb_release -cs` main&quot; &gt; /etc/apt/sources.list.d/ros-latest.list&#x27;\n\n2. 设置密钥sudo apt-key adv --keyserver &#x27;hkp://keyserver.ubuntu.com:80&#x27; --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654\n\n3. 安装sudo apt updatesudo apt install ros-melodic-desktop# 其他版本替换对应的版本（例如 noetic ）# sudo apt install ros-noetic-desktop\n\n4. 配置环境变量echo &quot;source /opt/ros/melodic/setup.bash&quot; &gt;&gt; ~/.bashrcsource ~/.bashrc  #使环境生效# 替换对应版本同上# echo &quot;source /opt/ros/noetic/setup.bash&quot; &gt;&gt; ~/.bashrc\n\n5. 配置rosdep在使用许多 ROS 工具之前，需要初始化 rosdep，有些功能包源码编译需要rosdep 来安装这些系统依赖项，不配置也不影响ros使用，所以后面需要时再来配置也可以。 rosdep 请求的文件都放在 github 上的, 推荐使用代理。\n# 安装依赖sudo apt install python-rosdep python-rosinstall python-rosinstall-generator python-wstool build-essential# 对于Ubuntu20# sudo apt install python3-rosdep python3-rosinstall python3-rosinstall-generator python3-wstool build-essential# 初始化sudo rosdep initrosdep update\n\n测试roscorerosrun turtlesim turtlesim_noderosrun turtlesim turtle_teleop_key\n\n参考官方文档(melodic)ubuntu18.04安装ROS Melodic（最详细配置）-CSDN博客基于Ubuntu18.04的ROS Melodic环境详细配置（含各种大坑及填坑）[ROS 系列学习教程] ROS与操作系统版本对应关系_ros版本-CSDN博客\n","categories":["Linux"],"tags":["Linux","ROS","Ubuntu"]},{"title":"Windows与Linux文件互传工具","url":"/2024/03/10/Linux/Windows%E4%B8%8ELinux%E6%96%87%E4%BB%B6%E4%BA%92%E4%BC%A0%E5%B7%A5%E5%85%B7/","content":"参考\npscp使用详解 Windows与Linux文件互传工具_Linux教程_Linux公社-Linux系统门户网站 (linuxidc.com)\npsftp的用法（超级详细）_psftp压缩文件夹命令-CSDN博客\n","categories":["Linux"],"tags":["pscp","scp","sftp","psftp"]},{"title":"wpa_supplicant及wpa_cli使用方法","url":"/2019/08/04/Linux/wpa_supplicant%E5%8F%8Awpa_cli%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/","content":"wpa_supplicant是一个连接、配置WIFI的工具，它主要包含wpa_supplicant与wpa_cli两个程序。通常情况下，可以通过wpa_cli来进行WIFI的配置与连接，如果有特殊的需要，可以编写应用程序直接调用wpa_supplicant的接口直接开发。\n启动wpa_supplicant应用$ wpa_supplicant -D nl80211 -i wlan0 -c /etc/wpa_supplicant.conf -B\n\n/etc/wpa_supplicant.conf文件里，添加下面代码:\nctrl_interface=/var/run/wpa_supplicant update_config=1\n\n启动wpa_cli应用$ wpa_cli -i wlan0 scan # 搜索附近wifi网络 $ wpa_cli -i wlan0 scan_result # 打印搜索wifi网络结果 $ wpa_cli -i wlan0 add_network # 添加一个网络连接\n\n如果要连接加密方式是[WPA-PSK-CCMP+TKIP][WPA2-PSK-CCMP+TKIP][ESS] (wpa加密)，wifi名称是name，wifi密码是：psk。\n$ wpa_cli -i wlan0 set_network 0 ssid &#x27;&quot;name&quot;&#x27; $ wpa_cli -i wlan0 set_network 0 psk &#x27;&quot;psk&quot;&#x27; $ wpa_cli -i wlan0 enable_network 0\n\n如果要连接加密方式是[WEP][ESS] (wep加密)，wifi名称是name，wifi密码是psk。\n$ wpa_cli -i wlan0 set_network 0 ssid &#x27;&quot;name&quot;&#x27; $ wpa_cli -i wlan0 set_network 0 key_mgmt NONE $ wpa_cli -i wlan0 set_network 0 wep_key0 &#x27;&quot;psk&quot;&#x27; $ wpa_cli -i wlan0 enable_network 0\n\n如果要连接加密方式是[ESS] (无加密)，wifi名称是name。\n$ wpa_cli -i wlan0 set_network 0 ssid &#x27;&quot;name&quot;&#x27; $ wpa_cli -i wlan0 set_network 0 key_mgmt NONE $ wpa_cli -i wlan0 enable_network 0\n\n分配ip/netmask/gateway/dns$ udhcpc -i wlan0 -s /etc/udhcpc.script -q\n\n执行完毕，就可以连接网络了。\n保存连接$ wpa_cli -i wlan0 save_config\n\n断开连接$ wpa_cli -i wlan0 disable_network 0\n\n连接已有的连接$ wpa_cli -i wlan0 list_network #列举所有保存的连接 $ wpa_cli -i wlan0 select_network 0 #连接第1个保存的连接 $ wpa_cli -i wlan0 enable_network 0 #使能第1个保存的连接\n\n断开wifi$ ifconfig wlan0 down $ killall udhcpc $ killall wpa_supplicant\n\nwpa_wifi_tool使用方法wpa_wifi_tool是基于wpa_supplicant及wpa_cli的一个用于快速设置wifi的工具，方便调试时连接wifi使用。使用方法：1、运行wpa_wifi_tool;2、输入help进行命令查看;3、s进行SSID扫描;4、c[n]进行wifi连接，连接时若为新的SSID则需输入密码，若为已保存的SSID则可以使用保存过的密码或者重新输入密码;5、e退出工具。\n","categories":["Linux"],"tags":["wifi","wpa_cli","wpa_supplicant","无线","Wi-Fi"]},{"title":"编译Qt 4.8.7源码","url":"/2025/08/04/Linux/%E7%BC%96%E8%AF%91Qt%204.8.7%E6%BA%90%E7%A0%81/","content":"一、先来看一篇转载文章《在 VS2015 中使用 Qt4》\nhttp://tangzx.qiniudn.com/post-0111-qt4-vs2015.html 最早的原文，看不到了\nhttps://github.com/district10/qt4-vs2015x64 原作者的github，里面的东东都下载不了了\n二、firecat本人的教程\n0、Qt官方\nQt4.8.7官方源码下载\nhttps://download.qt.io/new_archive&#x2F;qt&#x2F;4.8&#x2F;4.8.7&#x2F;\n官网的exe只提供了MSVC2010，没有更高版本的。高版本需要自己下载源码编译。\n源码里面的配置文件已经提供了MSVC 2015的编译选项，\\qt-everywhere-opensource-src-4.8.7\\mkspecs\\win32-msvc2015\n参照官方提供的编译文档一步一步执行即可；但是配置文件里没有提供MSVC 2017的编译选项。\n官方编译的文档\nhttps://doc.qt.io/archives/qt-4.8/installation.html\nhttps://doc.qt.io/archives/qt-4.8/configure-options.html\nhttps://doc.qt.io/archives/qt-4.8/install-win.html\nhttps://doc.qt.io/archives/qt-4.8/install-mac.html\nhttps://doc.qt.io/qt-5/build-sources.html\n1、Qt 4.8.7+MSVC 2017\n推荐使用第三方提供的源码，它已经是修改好的，里面含有MSVC 2017编译选项，可以编译。\nhttps://github.com/scharsig/Qt Qt4.8.7+MSVC2017源码\nhttps://forum.qt.io/topic/91623/building-qt-4-8-7-with-visual-studio-2017 Qt4.8.7+MSVC2017论坛\nhttps://github.com/sandym/qt-patches 仅供参考，编译补丁\nhttps://github.com/Homebrew/formula-patches/tree/master/qt 仅供参考，编译补丁\nhttps://github.com/BartVandewoestyne/qt_4_8_7_with_vs2017_patch 仅供参考，编译补丁\n完整的编译过程：\n下载第三方源码https://github.com/scharsig/Qt/tree/master/qt-4.8.7-vs2017 然后解压\n-–step1—\nWindows桌面-开始-程序-Visual Studio 2017-Visual Studio Tools-VC-x86 Native Tools Command Prompt for VS 2017\n-–step2—\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise&gt;cd F:\\Qt\\setup-exe\\4.8.7\\Qt-master\\qt-4.8.7-vs2017\n-–step3—\nF:\\Qt\\setup-exe\\4.8.7\\Qt-master\\qt-4.8.7-vs2017&gt;configure -help\n-–step4—\nF:\\Qt\\setup-exe\\4.8.7\\Qt-master\\qt-4.8.7-vs2017&gt;configure -make nmake -debug-and-release -opensource -confirm-license -platform win32-msvc2017 -prefix F:\\Qt\\Qt4.8.7-msvc2017 -nomake examples -nomake tests\n如果不想编译这么多功能模块，可以精简为：\nconfigure -make nmake -debug-and-release -opensource -confirm-license -platform win32-msvc2017 -prefix F:\\Qt\\Qt4.8.7-msvc2017 \\  -no-qt3support -no-multimedia \\  -no-audio-backend -no-phonon -no-phonon-backend -no-libtiff \\  -no-libmng -no-dbus -no-nis -nomake examples -nomake tests\n -release              Compile and link Qt with debugging turned off. -debug                Compile and link Qt with debugging turned on. -nomake tests         Disable building of tests to speed up compilation -nomake examples      Disable building of examples to speed up compilation -confirm-license      Automatically acknowledge the LGPL 2.1 license.\n\n-–step5—\nF:\\Qt\\setup-exe\\4.8.7\\Qt-master\\qt-4.8.7-vs2017&gt;nmake\n-–step6—\nF:\\Qt\\setup-exe\\4.8.7\\Qt-master\\qt-4.8.7-vs2017&gt;nmake install\n-–step7—\n添加到Qt Creator\n![[编译Qt 4.8.7源码&#x2F;IMG-20250807081809727.png]]\n-–step8—\n新建项目测试，Qt Creator+Qt4.8.7+MSVC2017编译项目时，如果报错：\n\nintermediate\\moc\\moc_rs_actionzoompan.cpp:-1: error: C1041: 无法打开程序数据库“F:\\CADCAM\\QCAD\\src\\build-LibreCAD-v1.0.4-qt4-Desktop_Qt_4_8_7_MSVC2017_32bit-Debug\\librecad\\vc140.pdb”；如果要将多个 CL.EXE 写入同一个 .PDB 文件，请使用 &#x2F;FS\n\n解决办法：\n在Qt Creator的项目文件，即.pro文件中，可以通过QMAKE_CXXFLAGS来给MSVC编译器传递编译开关。\nQMAKE_CXXFLAGS +&#x3D; &#x2F;FS\nwin32-msvc*:QMAKE_CXXFLAGS += /wd&quot;4819&quot; QMAKE_CXXFLAGS_RELEASE_WITH_DEBUGINFO -= -Zc:strictStrings \n\nMSVC 2017编译器常见错误的解决：\nhttps://docs.microsoft.com/en-us/cpp/error-messages/compiler-errors-1/c-cpp-build-errors?view=vs-2017\n2、Mac OS+Qt 4.8.7\n笔者的Mac OS版本是MacOS-10.15-Catalina，高版本的OS和Clang已经不再支持Qt官方发布的Qt4了。\n解决办法可以参见我的另一篇博文：https://blog.csdn.net/libaineu2004/article/details/104740623\nhttps://trac.macports.org/ticket/58651 mac下编译qt4遇到问题\nhttps://github.com/macports/macports-ports/tree/master/aqua/qt4-mac mac编译补丁\n","categories":["Linux"],"tags":["Qt源码编译"]},{"title":"Docker使用","url":"/2017/02/10/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/Docker%E4%BD%BF%E7%94%A8/","content":"非常详细的 Docker 学习笔记 - Docker - 服务器软件 - 深度开源 (open-open.com)\nDocker-创建和分享应用（3） - 头痛不头痛 - 博客园 (cnblogs.com)\n常用docker命令，及一些坑_dockerfile 2&gt;&amp;1-CSDN博客\nDocker常用命令_docker -i -t -v-CSDN博客\nDocker 常用命令 - Phuker’s Blog\n详解Docker 容器基础系统镜像打包_docker_脚本之家 (jb51.net)\n一种docker基础镜像制作方法_docker 从iso制作镜像-CSDN博客\n系统运维|两种方式创建你自己的 Docker 基本映像 (linux.cn)\n","categories":["容器技术"],"tags":["Docker"]},{"title":"Docker编译多系统架构镜像","url":"/2025/03/20/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/Docker%E7%BC%96%E8%AF%91%E5%A4%9A%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E9%95%9C%E5%83%8F/","content":"Docker 19.03以上版本可以使用 docker buildx build命令使用BuildKit构建镜像。该命令支持--platform参数可以同时构建多种系统架构的Docker镜像。\n新建builder实例Docker for Linux不支持构建arm架构镜像，可以运行一个新的容器让其支持该特性，Docker Desktop版本无需进行此项设置。\ndocker run --rm --privileged tonistiigi/binfmt:latest --install all \n由于Docker默认的build实例不支持同时指定多个 --platform，必须首先创建一个新的builder实例。\n# 适用于国内环境$ docker buildx create --use --name=mybuilder-cn --driver docker-container --driver-opt image=dockerpracticesig/buildkit:master# 适用于腾讯云环境(腾讯云主机、coding.net 持续集成)$ docker buildx create --use --name=mybuilder-cn --driver docker-container --driver-opt image=dockerpracticesig/buildkit:master-tencent# $ docker buildx create --name mybuilder --driver docker-container$ docker buildx use mybuilder\n\n构建镜像\nFROM --platform=$TARGETPLATFORM alpineRUN uname -a &gt; os.txtCMD [&quot;cat&quot;, &quot;os.txt&quot;]\n\ndocker buildx build --platform linux/arm,linux/arm64,linux/amd64 -t &#123;镜像名称&#125; . --push# 查看镜像信息docker buildx imagetools inspect &#123;镜像名称&#125;\n--push 参数表示将构建好的镜像推送到Docker仓库\n架构相关变量TARGETPLATFORM构建镜像的目标平台，例如 linux/amd64，linux/arm/v7，windows/amd64\nTARGETOS构建镜像的OS类型，例如 linux，windows\nTARGETARCH构建镜像的架构类型，例如 amd64，arm\nBUILDPLATFORM构建镜像主机平台，例如 linux/amd64\nBUILDOS构建镜像主机的OS类型，例如 linux\nBUILDARCH构建镜像主机的架构类型，例如 amd64\nBUILDVARIANTBUILDPLATFORM的变种，该变量可能为空，例如 v7\n使用举例例如要构建 linux/arm/v7和 linux/amd64两种架构的镜像\nFROM docker.io/library/python:3.10-alpine# 使用变量必须申明ARG TARGETOSARG TARGETARCHWORKDIR /appCOPY main.py /app# ENTRYPOINT [/app]\n","categories":["容器技术"],"tags":["Docker"]},{"title":"Docker部署单节点ETCD","url":"/2025/03/17/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/Docker%E9%83%A8%E7%BD%B2%E5%8D%95%E8%8A%82%E7%82%B9ETCD/","content":"准备镜像选择quay.io&#x2F;coreos&#x2F;etcd:3.2.7bitname&#x2F;etcd\n创建ETCD数据目录# data 存储容器持久化数据# config 存储容器使用的配置文件mkdir -p /usr/local/docker/etcd/&#123;data,config&#125;\n\n创建ETCD配置文件配置文件路径为 /usr/local/docker/etcd/config/etcd.config.yml\nname: etcd # etcd member 名称，可根据实际情况修改data-dir: /var/etcd #etcd 数据目录，可根据实际情况修改listen-client-urls: http://0.0.0.0:2379 #client 流量监听地址，没特殊需求按文档填写即可advertise-client-urls: http://0.0.0.0:2379 # 该 member 向外部通告的客户端 url 列表，单节点部署时不需要修改，集群部署模式需修改为容器所在节点对外提供服务的 IPlisten-peer-urls: http://0.0.0.0:2380 # peer 流量监听地址，没特殊需求按文档填写即可initial-advertise-peer-urls: http://0.0.0.0:2380 # 该 member 向同一集群内其他 member 通告的 peer url 列表，单节点部署时不需要修改，集群部署模式需修改为容器所在节点对外提供服务的 IPinitial-cluster: etcd=http://0.0.0.0:2380 # 初始化集群节点信息，单节点部署时不需要修改，集群部署模式需要填写集群中所有 member 的信息initial-cluster-token: etcd-cluster  # 初始化集群时使用的 token，随便写initial-cluster-state: new # 初始化集群状态，可选的值为 **new** 或者 **existing**，通常采用 **new**logger: zaplog-level: info# log-outputs: stderr\n创建并启动ETCD服务docker run -d --name etcd -p 2379:2379 -p 2380:2380 -v /usr/local/docker/etcd/data:/var/etcd -v /usr/local/docker/etcd/config:/var/lib/etcd/config quay.io/coreos/etcd: 3.5.12 \n\n使用docker-compose部署创建Docker-compose\nversion: &#x27;3&#x27;services:  etcd:    container_name: etcd    image: quay.io/coreos/etcd:v3.5.12    command: /usr/local/bin/etcd --config-file=/var/lib/etcd/config/etcd.conf.yml    volumes:    - $&#123;DOCKER_VOLUME_DIRECTORY:-.&#125;/data:/var/lib/etcd    - $&#123;DOCKER_VOLUME_DIRECTORY:-.&#125;/config/etcd.config.yml:/var/lib/etcd/conf/etcd.conf.yml    ports:    - 2379:2379    - 2380:2380    restart: alwaysnetworks: # 船舰一个新的bridge模式网络，名称 etcd-tier,名称可以根据需求自定义  default:    name: etcd-tier    driver: bridge    \n\n基于环境变量配置, 配置参考配置文件方式\nversion: &#x27;3&#x27;services:  etcd:    container_name: etcd    image: quay.io/coreos/etcd:v3.5.12    environment:    - ETCD_NAME=etcd    - ETCD_DATA_DIR=    - ETCD_LISTEN_CLIENT_URLS=    - ETCD_ADVERTISE_CLIENT_URLS=    - ETCD_LISTEN_PEER_URLS=    - ETCD_INSTALL_ADVERTISE_PEER_URLS=    - ETCD_INSTALL_CLUSTER_TOKEN=    - ETCD_INSTALL_CLUSTER    - ETCD_INSTALL_CLUSTER_STATE=new    - ETCD_LOGGER=zap    - ETCD_LOG_LEVEL=info    - ALLOW_NONE_AUTHENTICATION=&quot;yes&quot; # 允许无身份验证访问    - TZ=&quot;Asia/Shanghai&quot;    volumes:    - $&#123;DOCKER_VOLUME_DIRECTORY:=.&#125;/data:/var/etcd    - /etc/localtime:/etc/localtime:rw    ports:    - 2379:2379    - 2380:2380    restart: alwaysnetworks:  default:    name: etcd-tier    driver: bridge\n\n创建并启动etcd\ncd &#123;docker-compose文件所在目录&#125;docker compose up -d \n\n测试命令etcdctl --endpoints=192.168.1.2:2379 --write-out=table endpoint healthetcdctl --endpoints=192.168.1.2:2379 --write-out=table endpoint status# 查看member状态etcdctl --endpoints=192.168.1.2:2379 --write-out=table member list# 写入数据etcdctl --endpoints=192.168.1.2:2379 put foo bar# 读取数据etcdctl --endpoints=192.168.1.2:2379 get foo","categories":["容器技术"],"tags":["Docker","ETCD"]},{"title":"EdgeX Foundry","url":"/2022/07/27/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/EdgeX-Foundry/","content":"https://blog.csdn.net/Jason_LiQuan/article/details/109717954https://www.jianshu.com/nb/78768https://www.hangge.com/blog/cache/detail_2351.htmlhttps://unblocked-pw.github.io/https://blog.csdn.net/ewtewtewrt/article/details/110161010https://bthub11.xyz/cnhttps://blog.csdn.net/ewtewtewrt/article/details/110382703https://www.tpbaysproxy.com/https://github.com/fwonggh/Bthubhttps://limetorrent.cc/https://blog.csdn.net/woaizard100/article/details/80910356https://blog.csdn.net/woaizard100/category_7776741.htmlhttps://cloud.tencent.com/developer/article/1671077https://www.cnblogs.com/harrychinese/p/quartz_net.html#:~:text=Quartz.Net%20%E6%9C%89%E4%B8%A4%E7%B1%BB%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2C%201.%20Quartz.%E7%B3%BB%E7%BB%9F%E7%BA%A7%E5%88%AB%E9%85%8D%E7%BD%AE%2C%20%E9%BB%98%E8%AE%A4%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%90%8D%E4%B8%BA%20quartz.config%20%2C%20%E6%98%AFjava,job%2Ftrigger%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2C%20%E9%BB%98%E8%AE%A4%E5%90%8D%E7%A7%B0%E4%B8%BA%20quartz_jobs.xml%2C%20%E7%94%A8%E6%9D%A5%E9%85%8D%E7%BD%AE%20job%20%E5%92%8C%20trigger%20%E5%AE%9A%E4%B9%89%E4%BF%A1%E6%81%AF.https://www.cnblogs.com/z-huan/p/7412181.htmlhttps://www.cnblogs.com/abeam/p/8044460.htmlhttps://blog.csdn.net/freewebsys/article/details/107950520https://cloud.tencent.com/developer/article/1171966https://blog.csdn.net/mr_zhongjie/article/details/106916512https://www.jianshu.com/p/e48dbd087133https://blog.csdn.net/tianhuanqingyun/article/details/90454329https://blog.csdn.net/Frank_Abagnale/article/details/114333740https://blog.csdn.net/emqx_broker/article/details/106490836https://blog.csdn.net/qq_36827625/article/details/106502620https://blog.csdn.net/qq_41626768/article/details/109384703https://www.jianshu.com/p/af515094244bhttps://my.oschina.net/LFAPAC/blog/4522385https://www.jianshu.com/p/f6b7f6781481https://mp.weixin.qq.com/s?__biz=MzI1OTI5NjU0Mg==&amp;mid=2247484968&amp;idx=1&amp;sn=44e773b6a0df47b7634ca5f8c1014649&amp;chksm=ea7a5a59dd0dd34f002b01a5249e0afe61ae9597d36949abb95cc2e28c2e085cfdd68b59c26e&amp;scene=132#wechat_redirecthttps://blog.csdn.net/flystreet7/article/details/122086529\n","categories":["容器技术"]},{"title":"K3s安装","url":"/2024/03/11/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/K3S%E5%AE%89%E8%A3%85/","content":"安装基础环境新装环境# master安装curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | \\    INSTALL_K3S_MIRROR=cn \\    INSTALL_K3S_EXEC=&#x27;--write-kubeconfig-mode=644&#x27; sh -#  加入其他节点curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | \\    K3S_URL=https://&lt;k3s-server-ip&gt;:6443 \\    K3S_TOKEN=&lt;token&gt; \\    INSTALL_K3S_EXEC=&#x27;--write-kubeconfig-mode=644&#x27; sh -# EXEC参数# --write-kubeconfig-mode=644 设置配置文件权限# --service-node-port-range=1-65535 解除端口限制，默认30000-32767# --advertise-address=192.168.1.1 指定集群管理IP,默认端口6443# --disable=traefik 禁用Traefik Ingress# --default-local-storage-path=/mnt/storage/k3s # 自定义本地存储（local-path-config）的默认存储路径 # 环境变量# INSTALL_K3S_MIRROR=cn 设置未中国区镜像# INSTALL_K3S_SKIP_SELINUX_RPM=true 安装由于selinux导致失败时可加此配置跳过k3s selinux配置,注意是在 INSTALL_K3S_MIRROR后添加\n\n其中&lt;k3s-server-ip&gt;是K3s服务器的IP地址，&lt;token&gt;是由K3s服务器生成的唯一令牌。可以使用以下命令在K3s服务器上获取此令牌：\nsudo cat /var/lib/rancher/k3s/server/node-token\n\n设置 kubeconfig 文件路径用于对 Kubernetes 集群的访问。\necho &quot;export KUBECONFIG=/etc/rancher/k3s/k3s.yaml&quot; &gt;&gt; ~/.bashrc\n\n现有环境修改sudo systemctl stop k3s.servicevim /etc/systemd/system/k3s.service # 修改ExecStart# 原有内容ExecStart=/usr/local/bin/k3s \\\tserver \\\t\t&#x27;--write-kubeconfig-mode=644&#x27;# 修改后ExecStart=/usr/local/bin/k3s \\\tserver \\\t\t&#x27;--write-kubeconfig-mode=644&#x27; \\        &#x27;--service-node-port-range=1-65535&#x27; \\        &#x27;--default-local-storage-path=/mnt/storage/k3s&#x27; \\          sudo systemctl daemon-reloadsudo systemctl start k3s.service\n\n安装管理工具Helm#安装helmcurl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash# ubuntu 使用snap安装sudo snap install helm --classic# 离线安装# 下载最新版离线安装包 https://github.com/helm/helm/releasestar xf helm-v2.11.0-linux-amd64.tar.gzcp linux-amd64/helm linux-amd64/tiller /usr/local/bin/\n\n添加命令自动补全# 安装自动补全sudo apt install bash-completionsource /usr/share/bash-completion/bash_completion# kubectl自动补全# 临时使用echo &#x27;source &lt; (kubectl completion bash)&#x27; &gt;&gt; ~/.bashrc # 永久生效kubectl completion bash | sudo tee /etc/bash_completion/kubectl &gt; /dev/null # helm 自动补全# 临时使用echo &#x27;source &lt; (helm completion bash)&#x27; &gt;&gt; ~/.bashrc# 永久生效helm completion bash | sudo tee /etc/bash_completion/helm &gt; /dev/null\n\n\n常用Helm ChartsArtifact Hub\nBitnami Helm Charts\nMicrosoft\n常用命令# 查看集权所有资源kubectl get all -A -o wide# 查看指定命名空间kubectl get all -n &#123;namespace name&#125;# 查看容器日志kubectl logs -n &#123;namespace name&#125; pod/&#123;pod name&#125;# 查看指定命名空间下资源详细信息kubectl describe -n &#123;namespace name&#125; [service|pod|secret|carificate|...]# 查看节点相关kubectl get node --show-labels -o wide# 重启podkubectl rollout restart &#123;pod name&#125;  -n # 伸缩实例数量kubectl scale deploy whoami --replicas=5# 查看 k3s 集群配置文件kubectl cluster-info## Helm常用命令# 获取charts的values文件helm show values bitnami/redis &gt; values.yaml\n\n\n\n测试# 创建2副本的whoami应用，默认1副本kubectl create deploy whoami --image=traefik/whoami --replicas=2# 查看部署应用信息kubectl describe deploy whoami# 监控Pod状态，通过缩容\\扩容可直观看到Pod的调度状态kubectl get pods --watchkubectl scale deploy whoami --replicas=5# 请求链路理解request public-ip -&gt; node-port -&gt; svc-port -&gt; pod-port -&gt; container# 发布K3s内网的服务kubectl expose deploy whoami --port=80# 查看服务状态kubectl get svc whoami -owidekubectl describe svc whoami# 映射端口到宿主机# --tareget-port 容器映射端口# --external-ip 指定公网IP# --prot 集群内暴露端口# --node-port type=NodePort时提供给集群外访问的端口kubectl expose deploy whoami --type=LoadBalancer --port=80 --external-ip &lt;PUBLIC_IP&gt;# 清空测试kubectl delete all --all\n\n\n\n配置国内源(私有镜像库)K3s 默认的 containerd 配置文件目录为&#x2F;var&#x2F;lib&#x2F;rancher&#x2F;k3s&#x2F;agent&#x2F;etc&#x2F;containerd&#x2F;config.toml，但直接操作 containerd 的配置文件去设置镜像仓库或加速器相比于操作 docker 要复杂许多。K3s 为了简化配置 containerd 镜像仓库的复杂度，K3s 会在启动时检查&#x2F;etc&#x2F;rancher&#x2F;k3s&#x2F;中是否存在 registries.yaml 文件，如果存在该文件，就会根据 registries.yaml 的内容转换为 containerd 的配置并存储到&#x2F;var&#x2F;lib&#x2F;rancher&#x2F;k3s&#x2F;agent&#x2F;etc&#x2F;containerd&#x2F;config.toml，从而降低了配置 containerd 镜像仓库的复杂度。\nK3s 镜像仓库配置文件由两大部分组成：mirrors 和 configs:\n\nMirrors 是一个用于定义专用镜像仓库的名称和 endpoint 的指令\nConfigs 部分定义了每个 mirror 的 TLS 和证书配置。对于每个 mirror，你可以定义 auth 和&#x2F;或 tls\n\ncontainerd 使用了类似 K8S 中 svc 与 endpoint 的概念，svc 可以理解为访问名称，这个名称会解析到对应的 endpoint 上。也可以理解 mirror 配置就是一个反向代理，它把客户端的请求代理到 endpoint 配置的后端镜像仓库。mirror 名称可以随意填写，但是必须符合 IP 或域名的定义规则。并且可以配置多个 endpoint，默认解析到第一个 endpoint，如果第一个 endpoint 没有返回数据，则自动切换到第二个 endpoint，以此类推。\nmirrors:  &quot;172.31.6.200:5000&quot;:    endpoint:      - &quot;http://172.31.6.200:5000&quot;  &quot;rancher.ksd.top:5000&quot;:    endpoint:      - &quot;http://172.31.6.200:5000&quot;  &quot;docker.io&quot;:    endpoint:      - &quot;https://fogjl973.mirror.aliyuncs.com&quot;      - &quot;https://registry-1.docker.io&quot;\n\n非安全（http）私有仓库配置配置非安全（http）私有仓库，只需要在 endpoint 中指定 http 协议头的地址即可。\n在没有 TLS 通信的情况下，需要为 endpoints 指定 http:&#x2F;&#x2F;，否则将默认为 https。\n无认证mirrors:  &quot;172.31.6.200:5000&quot;:    endpoint:      - &quot;http://172.31.6.200:5000&quot;\n\n有认证mirrors:  &quot;35.182.134.80&quot;:    endpoint:      - &quot;http://35.182.134.80&quot;configs:  &quot;35.182.134.80&quot;:    auth:      username: admin # this is the registry username      password: Harbor12345 # this is the registry password\n\n\n\n安全（https）私有仓库配置使用授信 ssl 证书mirrors:  &quot;harbor.kingsd.top&quot;:    endpoint:      - &quot;https://harbor.kingsd.top&quot;configs:  &quot;harbor.kingsd.top&quot;:    auth:      username: admin # this is the registry username      password: Harbor12345 # this is the registry password\n\n使用自签 ssl 证书如果后端仓库使用的是自签名的 ssl 证书，那么需要配置 CA 证书 用于 ssl 证书的校验。\nmirrors:  &quot;harbor-ksd.kingsd.top&quot;:    endpoint:      - &quot;https://harbor-ksd.kingsd.top&quot;configs:  &quot;harbor-ksd.kingsd.top&quot;:    auth:      username: admin # this is the registry username      password: Harbor12345 # this is the registry password    tls:      ca_file: /opt/certs/ca.crt\n\nssl 双向认证如果镜像仓库配置了双向认证，那么需要为 containerd 配置 ssl 证书用于 镜像仓库对 containerd 做认证。\nmirrors:  &quot;harbor-ksd.kingsd.top&quot;:    endpoint:      - &quot;https://harbor-ksd.kingsd.top&quot;configs:  &quot;harbor-ksd.kingsd.top&quot;:    auth:      username: admin # this is the registry username      password: Harbor12345 # this is the registry password    tls:      ca_file: /opt/certs/ca.crt # path to the ca file used in the registry      cert_file: /opt/certs/harbor-ksd.kingsd.top.cert # path to the cert file used in the registry      key_file: /opt/certs/harbor-ksd.kingsd.top.key # path to the key file used in the registry\n\n\n\n加速器配置Containerd 与 docker 都有默认仓库，均为 docker.io 。如果配置中未指定 mirror 为 docker.io，containerd 后会自动加载 docker.io 配置。与 docker 不同的是，containerd 可以修改 docker.io 对应的 endpoint（默认为 https://registry-1.docker.io），而 docker 无法修改。\nDocker 中可以通过 registry-mirrors 设置镜像加速地址。如果 pull 的镜像不带仓库地址（项目名+镜像名:tag），则会从默认镜像仓库去拉取镜像。如果配置了镜像加速地址，会先访问镜像加速仓库，如果没有返回数据，再访问默认的镜像仓库。\nContainerd 目前没有直接配置镜像加速的功能，但 containerd 中可以修改 docker.io 对应的 endpoint，所以可以通过修改 endpoint 来实现镜像加速下载。因为 endpoint 是轮询访问，所以可以给 docker.io 配置多个仓库地址来实现 加速地址+默认仓库地址。如下配置示例：\nmirrors:  &quot;docker.io&quot;:    endpoint:      - &quot;https://fogjl973.mirror.aliyuncs.com&quot;      - &quot;https://registry-1.docker.io&quot;\n\n\n\n参考\nKubernetes 入门到实践：搭建 K3s 集群初体验 - 知乎 (zhihu.com)\n离线安装Air-Gap Install | K3s\n","categories":["容器技术"],"tags":["Kubernetes","K8s","K3s"]},{"title":"K3s导出证书","url":"/2024/04/02/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/K3s%E5%AF%BC%E5%87%BA%E8%AF%81%E4%B9%A6/","content":"# 导出根证书kubectl get secret example-secret -o jsonpath=&#x27;&#123;.data.ca\\.crt&#125;&#x27;| base64 --decodekubectl get secret example-secret -o jsonpath=&#x27;&#123;.data.tls\\.crt&#125;&#x27;| base64 --decodekubectl get secret example-secret -o jsonpath=&#x27;&#123;.data.tls\\.key&#125;&#x27;| base64 --decode\n\n导出Secret\nkubectl get secret example-secret -o yaml &gt; example-secret.yaml\n\n导出内容格式如下\napiVersion: v1data:  ca.crt: ...  tls.crt: ...  tls.key: ...kind: Secretmetadata:  annotations:    cert-manager.io/alt-names: &#x27;...&#x27;    cert-manager.io/certificate-name: ...    cert-manager.io/common-name: Tianjin Pengan    cert-manager.io/ip-sans: 192.168.0.2    cert-manager.io/issuer-group: cert-manager.io    cert-manager.io/issuer-kind: ClusterIssuer    cert-manager.io/issuer-name: selfsigned-cluster-issuer    cert-manager.io/subject-organizations: ...    cert-manager.io/uri-sans: &quot;&quot;  creationTimestamp: &quot;2024-09-10T10:54:59Z&quot;  labels:    controller.cert-manager.io/fao: &quot;true&quot;  name: tjpengan-io-secret  namespace: default  resourceVersion: &quot;1730340&quot;  uid: 1c7d877b-ed86-4a1a-ad8c-0d8466c46506type: kubernetes.io/tls\n\nBase64解码\n# certcat example-secret.yaml | grep tls.crt | awk &#x27;&#123;print $2&#125;&#x27; | base64 --decode &gt; example-secret.cert#keycat example-secret.yaml | grep tls.key | awk &#x27;&#123;print $2&#125;&#x27; | base64 --decode &gt; example-secret.key\n\n\n","categories":["容器技术"],"tags":["Https证书","Kubernetes","K3s","TLS"]},{"title":"K3s部署Dashboard","url":"/2024/04/08/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/K3s%E9%83%A8%E7%BD%B2Dashboard/","content":"Helm部署helm repo add kubernetes-dashboard https://kubernetes.github.io/dashboard/#helm会使用kubectl默认的KUBECONFIG配置，这里我们需要将KUBECONFIG换成k3s的否则会链接失败。export KUBECONFIG=/etc/rancher/k3s/k3s.yaml#注意要指定端口号等信息，方便访问# service.type=NodePort 默认是ClusterIP只能本机访问 # service.nodePort=30080 指定访问端口号# replicaCount=2 2个节点# helm v2helm upgrade --install kubernetes-dashboard kubernetes-dashboard/kubernetes-dashboard \\--create-namespace \\--namespace kubernetes-dashboard  \\# --set service.type=NodePort \\# --set service.nodePort=30080 \\# --set replicaCount=2# helm v3+helm install kubernetes-dashboard kubernetes-dashboard/kubernetes-dashboard \\--create-namespace \\--namespace kubernetes-dashboard \\# --set service.type=NodePort \\# --set service.nodePort=30080 \\# --set replicaCount=2\n\n\n\n配置远程访问NodePort暴露端口kubectl -n kubernetes-dashboard edit service kubernetes-dashboard-web\n\n# Please edit the object below. Lines beginning with a &#x27;#&#x27; will be ignored,# and an empty file will abort the edit. If an error occurs while saving this file will be# reopened with the relevant failures.#apiVersion: v1...  name: kubernetes-dashboard  namespace: kubernetes-dashboard  resourceVersion: &quot;343478&quot;  selfLink: /api/v1/namespaces/kubernetes-dashboard/services/kubernetes-dashboard  uid: 8e48f478-993d-11e7-87e0-901b0e532516spec:  clusterIP: 10.100.124.90  externalTrafficPolicy: Cluster  ports:  - port: 443    protocol: TCP    targetPort: 8443  selector:    k8s-app: kubernetes-dashboard  sessionAffinity: None  # 修改开放端口方式  #type: ClusterIP  type: NodePortstatus:  loadBalancer: &#123;&#125;\n\n\n\nTraefik Ingress反向代理创建证书请求文件dashboard-cert-manager.yaml\napiVersion: cert-manager.io/v1kind: Certificatemetadata:  name: k3s-chemmy-io  namespace: defaultspec:  secretName: k3s-chemmy-io-tls  issuerRef:    name: letsencrypt-staging    kind: ClusterIssuer  commonName: k3s.chemmy.io  dnsNames:  - k3s.sample.net\n\n此配置文件是测试版，正式版参考K3s部署cert-manager\nkubectl apply -f dashboard-cert-manager.yaml# 查看kubectl get certificates# 如果状态不是READY，检查 kubectl describe certificates k3s-chemmy-io# 清理证书kubectl delete certificates k3s-chemmy-iokubectl delete secrets k3s-chemmy-io-tls\n\n\n\n\n\n配置账户新建dashboard-admin.yaml\n# 创建ServiceAccountapiVersion: v1kind: ServiceAccountmetadata:  name: admin-user  namespace: kubernetes-dashboard---#创建clusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata:  name: admin-userroleRef:  apiGroup: rbac.authorization.k8s.io  kind: ClusterRole  name: cluster-adminsubjects:  - kind: ServiceAccount    name: admin-user    namespace: kubernetes-dashboard\n\n新建用户\n# 部署用户资源kubectl apply -f dashboard-admin.yaml\n\n获取token\n# v1.24+sudo k3s kubectl -n kubernetes-dashboard create token admin-user# v1.23 及之前的版本sudo k3s kubectl -n kubernetes-dashboard describe secret admin-user-token | grep &#x27;^token&#x27;\n\n\n\nKubectl部署最新版本只支持Helm,旧版本v2.7支持Kubectl部署\n下载 recommended.yaml\nkubectl apply -f recommended.yaml\n\n修改recommended.yaml\n...---kind: ServiceapiVersion: v1metadata:  labels:    k8s-app: kubernetes-dashboard  name: kubernetes-dashboard  namespace: kubernetes-dashboardspec:  # 直接暴露端口使用NodePort,Traefik使用ClusterIP  #type: ClusterIP  type: NodePort  ports:    - port: 443      targetPort: 8443  selector:    k8s-app: kubernetes-dashboard---...\n\ndashboard的默认webui证书是自动生成的，由于时间和名称存在问题，导致谷歌和ie浏览器无法打开登录界面，经过测试Firefox可以正常打开。解决证书问题参考Kubernetes Dashboard的安装与坑 - 简书 (jianshu.com)\n---# 注释内置自动生成的证书 #apiVersion: v1#kind: Secret#metadata:#  labels:#    k8s-app: kubernetes-dashboard#  name: kubernetes-dashboard-certs#  namespace: kubernetes-dashboard#type: Opaque ---...--- kind: DeploymentapiVersion: apps/v1metadata:  labels:    k8s-app: kubernetes-dashboard  name: kubernetes-dashboard  namespace: kubernetes-dashboardspec:  replicas: 1  revisionHistoryLimit: 10  selector:    matchLabels:      k8s-app: kubernetes-dashboard  template:    metadata:      labels:        k8s-app: kubernetes-dashboard    spec:      containers:        - name: kubernetes-dashboard          image: kubernetesui/dashboard:v2.1.0          imagePullPolicy: Always          ports:            - containerPort: 8443              protocol: TCP          args:          # 注释自动生成证书          #  - --auto-generate-certificates            - --namespace=kubernetes-dashboard            # 添加证书配置及证书文件映射            - --token-ttl=3600            - --bind-address=0.0.0.0            - --tls-cert-file=tls.crt            - --tls-key-file=tls.key            # Uncomment the following line to manually specify Kubernetes API server Host            # If not specified, Dashboard will attempt to auto discover the API server and connect            # to it. Uncomment only if the default does not work.            # - --apiserver-host=http://my-address:port          volumeMounts:            - name: kubernetes-dashboard-certs              mountPath: /certs              # Create on-disk volume to store exec logs            - mountPath: /tmp              name: tmp-volume          livenessProbe:            httpGet:              scheme: HTTPS              path: /              port: 8443            initialDelaySeconds: 30            timeoutSeconds: 30          securityContext:            allowPrivilegeEscalation: false            readOnlyRootFilesystem: true            runAsUser: 1001            runAsGroup: 2001      volumes:        - name: kubernetes-dashboard-certs          secret:            secretName: kubernetes-dashboard-certs        - name: tmp-volume          emptyDir: &#123;&#125;      serviceAccountName: kubernetes-dashboard      nodeSelector:        &quot;kubernetes.io/os&quot;: linux      # Comment the following tolerations if Dashboard must not be deployed on master      tolerations:        - key: node-role.kubernetes.io/master          effect: NoSchedule ---...\n\n生成证书文件 tls.crt,tls.csr,tls.key\n# 生成keyopenssl genrsa -out tls.key 2048# 生成csropenssl req -new -out tls.csr -key tls.key -subj &#x27;/CN=0.0.0.0&#x27;# 生成openssl x509 -req -in tls.csr -signkey tls.key -out tls.crt #创建secretkubectl create secret generic kubernetes-dashboard-certs --from-file=tls.crt --from-file=tls.key -n kubernetes-dashboard\n\nsubj子参数解释\n\n\n\n缩写\n翻译\n英文对照\n\n\n\nC\n国家名称缩写\nCountry Name (2 letter code)\n\n\nST\n州或省名称\nState or Province Name (full name)\n\n\nL\n城市或区域称\nLocality Name (eg, city)\n\n\nO\n组织名（或公司名）\nOrganization Name (eg, company)\n\n\nOU\n组织单位名称（或部门名）\nOrganizational Unit Name (eg, section)\n\n\nCN\n服务器域名&#x2F;证书拥有者名称\nCommon Name (e.g. server FQDN or YOUR name)\n\n\nemailAddress\n邮件地址\nEmail\n\n\n参考\nk3s集群单节点部署与集群内DashBoard部署 - 知乎 (zhihu.com)\nk3s集群搭建并安装kubernetes-dashboard - 东峰叵,com - 博客园 (cnblogs.com)\n[K8S 快速入门（十九）通过Helm 安装 Kubernetes Dashboard_helm安装dashboard ingress-CSDN博客](https://blog.csdn.net/weixin_41947378/article/details/111661539#:~:text=通过Helm 安装 Kubernetes Dashboard 1 1. 下载 %23,外网访问 %23 将svc的ClusterIP改为NotePort，外网访问  … 5 5. 令牌方式登录仪表盘)\n使用 traefik ingress暴露kubernetes-dashbord - HTTPS版本_svclb-traefik-CSDN博客\nKubernetes dashboardv2.7.0安装指南：从零开始搭建可视化界面 - 知乎\n","categories":["容器技术"],"tags":["Kubernetes","K3s","Dashboard"]},{"title":"基于K3S搭建DevOps","url":"/2024/03/12/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/K3s%E9%83%A8%E7%BD%B2DevOps/","content":"K3s安装参考 K3S安装\n组件配置信息开放端口\n\n\n\n端口\n用途\n\n\n\n53\nCoreDNS服务，替代修改Hosts方式实现内网域名访问\n\n\n5432&#x2F;3306\nPostgreSQL&#x2F;MySQL数据库（二选一即可）\n\n\n443，80\nHTTPS、HTTP访问入口，Traefik\n\n\n6379\nRedis缓存\n\n\n8022\nSSH管理端口\n\n\n22\ngit+ssh方式代码上传\n\n\n域名规划\n\n\n\n组件\n访问地址\n说明\n\n\n\nCert-Manager\n\n证书管理服务，有公网域名推荐使用，内网部署可生成自签名证书\n\n\nTraefik Dashboard\nhttps://dashboard.example.io\n反向代理&#x2F;负载均衡\n\n\nHarbor\nhttps://harbor.example.io\n私有镜像库,镜像缓存\n\n\nGitea\nhttps://gitea.example.io\n源代码仓库\n\n\nTekton\nhttps://tekton.example.io\n云原生持续集成\n\n\nDrone\nhttps://drone.example.io\n容器化持续集成\n\n\nSonar Qube\nhttps://sonar.example.io\n静态代码审查。\n\n\nArgoCD\nhttps://argocd.example.io\n持续部署组件\n\n\n组件部署Traefik```### ArgoCDHelm方式部署```bash\n\nMySQL参考 K3s部署MySQL\n# k3s使用 local-path 部署kubectl apply -f https://gitee.com/Chemmy/kube-template/MySQL/mysql-pvc-local-path.yaml# 部署mysql-configkubectl apply -f https://gitee.com/Chemmy/kube-template/MySQL/mysql-config.yaml# 部署deploykubectl apply -f https://gitee.com/Chemmy/kube-template/MySQL/mysql-deployment.yaml# 部署service(NodePort 方式)kubectl apply -f https://gitee.com/Chemmy/kube-template/MySQL/mysql-service.yaml\n\nPostgresSQL参考 K3s部署PostgreSQL\n# k3s使用 local-path 部署kubectl apply -f https://gitee.com/Chemmy/kube-template/PostgreSQL/postgres-pvc-local-path.yaml# 部署configkubectl apply -fhttps://gitee.com/Chemmy/kube-template/PostgreSQL/postgres-config.yaml# 部署deploykubectl apply -fhttps://gitee.com/Chemmy/kube-template/PostgreSQL/postgres-deployment.yaml# 部署service(NodePort 方式)kubectl apply -fhttps://gitee.com/Chemmy/kube-template/PostgreSQL/postgres-service.yaml\n\n\ncert-manager参考k3s证书管理\n# 添加镜像源helm repo add jetstack https://charts.jetstack.iohelm upgrade cert-manager jetstack/cert-manager \\\t--namespace cert-manager \\\t--install --create-namespace \\\t--set crds.enabled=true\n\nHarbor参考K3s部署Harbor私有镜像仓库\n\n\nGitea参考K3s部署Gitea\n\n\nTekton参考[[K3s部署Tenton]]\n```### Drone (已弃用)参考[K3s部署Drone](K3s部署Drone.md)```bash\n\n\n\nSonarQube参考K3s部署SonarQube\n\n\n\n\n组件之间联动配置参考Gitea官方文档\nGitea README\nDrone官方文档\nHelm官方文档\nHarbor官方文档\nTraefik Proxy Documentation - Traefik\nk3s 部署gitea+drone_golang k3s-CSDN博客\nHarbor 结合 Traefik 的 HA 安装配置-腾讯云开发者社区-腾讯云 (tencent.com)\nTraefik - Kubernetes 配置TCP&#x2F;HTTP服务-腾讯云开发者社区-腾讯云 (tencent.com)\nDrone CI使用docker插件构建和推送镜像 - wosperry - 博客园 (cnblogs.com)\n在 Kubernetes 上部署 Drone 持续集成环境 | Hanggi - NGNL\nGitea 与 Drone 集成实践：完全基于 Docker 搭建的轻量级 CI&#x2F;CD 系统 - Gitea - 博客园 (cnblogs.com)\nHelm Chart Kubernetes安装SonarQube_helm安装sunaqube-CSDN博客\n","categories":["容器技术"],"tags":["Kubernetes","K8s","K3s","Drone","Gitea","Harbor","DevOps"]},{"title":"K3s部署EMQX.md","url":"/2024/11/12/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/K3s%E9%83%A8%E7%BD%B2EMQX.md/","content":"https://www.emqx.com/zh/blog/emqx-mqtt-broker-k8s-cluster\n","categories":["容器技术"],"tags":["Kubernetes","K3s","EMQX","mqtt"]},{"title":"K3s部署Harbor(私有镜像仓库)","url":"/2024/04/10/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/K3s%E9%83%A8%E7%BD%B2Harbor%E7%A7%81%E6%9C%89%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/","content":"准备环境证书[[..&#x2F;杂项&#x2F;OpenSSL生成自签名证书|OpenSSL生成自签名证书]]\nk3s证书管理\n\n默认配置文件helm show values harbor/harbor &gt; harbor-values.yaml\n\n\n\n安装配置清单harbor-value.yaml\nexpose:  type: ingress  tls:    enabled: true    certSource: secret    secret:      secretName: &quot;example.io&quot;      notarySecretName: &quot;example.io&quot;  ingress:    hosts:      core: harbor.example.io      notary: notary.example.io    controller: default    annotations:      ingress.kubernetes.io/ssl-redirect: &quot;true&quot;      ingress.kubernetes.io/proxy-body-size: &quot;0&quot;      kubernetes.io/ingress.class: &quot;traefik&quot;      traefik.ingress.kubernetes.io/router.tls: &quot;true&quot;      traefik.ingress.kubernetes.io/router.entrypoints: websecureexternalURL: https://harbor.example.ioharborAdminPassword: &quot;Harbor123456&quot;logLevel: infochartmuseum:  enabled: truedatabase:  type: external  external:    host: &quot;postgres.devops.svc.cluster.local&quot;    port: &quot;5432&quot;    username: &quot;harbor&quot;    password: &quot;harbor&quot;redis:  type: external  external:    addr: &quot;redis.devops.svc.cluster.local:6379&quot;    password: &quot;passwd&quot;\n\nharbor-ingress.yaml\napiVersion: traefik.containo.us/v1alpha1kind: IngressRoutemetadata:  namespace: kube-ops  name: harbor-httpspec:  entryPoints:    - websecure  tls:    secretName: all-xxxx-com  routes:    - match: Host(`harbor.example.com`) &amp;&amp; PathPrefix(`/`)      kind: Rule      services:        - name: harbor-portal          port: 80---apiVersion: traefik.containo.us/v1alpha1kind: IngressRoutemetadata:  namespace: kube-ops  name: harbor-apispec:  entryPoints:    - websecure  tls:    secretName: all-xxxx-com  routes:    - match: Host(`harbor.example.com`) &amp;&amp; PathPrefix(`/api/`)      kind: Rule      services:        - name: harbor-core          port: 80---apiVersion: traefik.containo.us/v1alpha1kind: IngressRoutemetadata:  namespace: kube-ops  name: harbor-servicespec:  entryPoints:    - websecure  tls:    secretName: all-xxxx-com  routes:    - match: Host(`harbor.example.com`) &amp;&amp; PathPrefix(`/service/`)      kind: Rule      services:        - name: harbor-core          port: 80---apiVersion: traefik.containo.us/v1alpha1kind: IngressRoutemetadata:  namespace: kube-ops  name: harbor-v2spec:  entryPoints:    - websecure  tls:    secretName: all-xxxx-com  routes:    - match: Host(`harbor.example.com`) &amp;&amp; PathPrefix(`/v2`)      kind: Rule      services:        - name: harbor-core          port: 80---apiVersion: traefik.containo.us/v1alpha1kind: IngressRoutemetadata:  namespace: kube-ops  name: harbor-chartrepospec:  entryPoints:    - websecure  tls:    secretName: all-xxxx-com  routes:    - match: Host(`harbor.example.com`) &amp;&amp; PathPrefix(`/chartrepo/`)      kind: Rule      services:        - name: harbor-core          port: 80---apiVersion: traefik.containo.us/v1alpha1kind: IngressRoutemetadata:  namespace: kube-ops  name: harbor-cspec:  entryPoints:    - websecure  tls:    secretName: all-xxxx-com  routes:    - match: Host(`harbor.example.com`) &amp;&amp; PathPrefix(`/c/`)      kind: Rule      services:        - name: harbor-core          port: 80\n\n\n\n安装Harbor# 添加Harbor仓库helm repo add harbor https://helm.goharbor.io# 使用部署或升级Harborhelm upgrade harbor harbor/harbor --namespace harbor \\\t--install --create-namespace \\\t-f harbor-values.yaml\n\n\n\n配置配置library仓库源kubectl edit configmap harobr-registry -n harbor# 在auth: 后边添加新节点proxy:  remoteurl: &quot;https://registry-1.docker.io&quot;\n\n使用Harbor配置镜像缓存参考\nHarbor 搭建镜像代理 | Northes\nKubernetes ≥ 1.25 Containerd配置Harbor私有镜像仓库_containerd登录镜像仓库-CSDN博客\n结合Cert-Manager完成Harbor的Https证书自动签发 | 风格 | 风起于青萍之末 (lusyoe.github.io)\nContainerd容器镜像管理-腾讯云开发者社区-腾讯云 (tencent.com)\n通过helm在k8s上搭建Harbor - 简书 (jianshu.com)\nKubernetes 集群仓库 harbor Helm3 部署-腾讯云开发者社区-腾讯云 (tencent.com)\ncontainerd基本使用命令 - 杨梅冲 - 博客园 (cnblogs.com)\nKubernetes1.21搭建harbor-腾讯云开发者社区-腾讯云 (tencent.com)\n","categories":["容器技术"],"tags":["Kubernetes","K3s","Harbor"]},{"title":"K3s部署Locust","url":"/2024/06/01/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/K3s%E9%83%A8%E7%BD%B2Locust/","content":"参考\nkubernetes Traefik ingress配置详解 - lvelvis - 博客园 (cnblogs.com)\n","categories":["容器技术"],"tags":["Kubernetes","K3s","Locust"]},{"title":"K3s部署MySQL","url":"/2024/04/26/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/K3s%E9%83%A8%E7%BD%B2MySQL/","content":"参考\n利用Kubernetes搭建便携式开发环境之MySQL和Redis - 知乎 (zhihu.com)\n","categories":["容器技术"],"tags":["Kubernetes","K3s","MySQL"]},{"title":"K3s部署PostgreSQL","url":"/2024/04/28/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/K3s%E9%83%A8%E7%BD%B2PostgreSQL/","content":"","categories":["容器技术"],"tags":["PostgreSQL","Kubernetes","K8s","K3s"]},{"title":"K3s部署Redis","url":"/2024/04/02/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/K3s%E9%83%A8%E7%BD%B2Redis/","content":"Kubectl部署配置文件\nHelm部署添加helm库\n# 添加库helm repo add bitnami https://charts.bitnami.com/bitnami# 更新库缓存helm repo update # 搜索redis镜像helm search repo redis# 获取package的values.yamlhelm show values bitnami/redis &gt; values-default.yaml\n\n配置 values.yaml\nauth:  password: 123456 # redis 访问密码master:  service:    type: NodePort\t\t# 服务对外暴露端口方式  persistence:\t\t\t# 配置点存储    storageClass: &quot;&quot;    size: 8Gireplica:\t\t\t\t  service:    type: NodePort  persistence:    storageClass: &quot;&quot;    size: 8Gi\n\n部署\nhelm install -f values.yaml redis bitnami/redis --namespace --create-namespace\n\n\n\n参考\nkubernetes环境部署单节点redis - 紫色飞猪 - 博客园 (cnblogs.com)\nK8S如何部署Redis（单机、集群）_k8部署redis单节点-CSDN博客\n4. K8S发布redis主从-CSDN博客\nredis集群 - Helm3-安装Redis - 全栈工程师进阶 - SegmentFault 思否\n","categories":["容器技术"],"tags":["Kubernetes","K3s","Redis"]},{"title":"K3s部署Registry镜像仓库","url":"/2024/07/08/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/K3s%E9%83%A8%E7%BD%B2Registry%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/","content":"参考Docker学习：部署本地私有镜像仓库registry （高级应用）_docker registry部署-CSDN博客\n三分钟Docker-推送本地镜像到仓库-腾讯云开发者社区-腾讯云 (tencent.com)\nDocker registry 、网络类型、跨主机访问 –3_docker it does not belong to any of this network-CSDN博客\ndocker registry:设置私有的镜像缓存仓库 | shikanon\n私有docker registry的ssl访问实现-腾讯云开发者社区-腾讯云 (tencent.com)\n","categories":["容器技术"],"tags":["Kubernetes","K3s","registry","私有镜像仓库","镜像缓存"]},{"title":"K3s部署Tekton","url":"/2025/05/29/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/K3s%E9%83%A8%E7%BD%B2Tekton/","content":"","categories":["容器技术"],"tags":["DevOps","Tekton","CI"]},{"title":"K3s配置NVIDIA GPU","url":"/2024/04/02/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/K3s%E9%85%8D%E7%BD%AENVIDIA-GPU/","content":"在K3s中配置使用NVIDIA GPUS | fissssssh (aiursoft.cn)\n","categories":["容器技术"],"tags":["Kubernetes","K3s","NVIDIA"]},{"title":"K3s 配置 Traefik Ingress","url":"/2024/06/01/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/K3s%E9%85%8D%E7%BD%AEtraefik/","content":"启用DashboardK3s (≥1.21)默认没有启用 Traefik Dashboard。如果要在 K3s 中启用  Dashborad，我们可以借助 HelmChartConfig 来自定义由 Helm 部署的 Traefik 并启用 Dashboard。\n\n不建议手动编辑 /var/lib/rancher/K3s/server/manifests/traefik.yaml 来修改 Traefik 配置文件，因为 K3s 重启后会覆盖修改的内容。\n建议通过在 /var/lib/rancher/K3s/server/manifests 中创建一个额外的 HelmChartConfig 清单来自定义 Traefik 配置，请参考：http://docs.rancher.cn/docs/K3\n\ncat &gt;&gt; /var/lib/rancher/K3s/server/manifests/traefik-config.yaml &lt;&lt; EOFapiVersion: helm.cattle.io/v1kind: HelmChartConfigmetadata:  name: traefik  namespace: kube-systemspec:  valuesContent: |-    dashboard:      enabled: true    ports:      traefik:        expose: true    logs:      access:        enabled: trueEOF\nK8s 修改 traefik-vlues.yaml 中ingressRoute.dashboard并应用配置\nhelm upgrade traefik traefik/traefik \\    --namespace traefik -f traefik-vlues.yaml\n配置Service及路由规则cat &gt;&gt; traefik-dashboard.yaml &lt;&lt; EOFapiVersion: v1kind: Servicemetadata:  name: traefik  namespace: kube-system spec:  allocateLoadBalancerNodePorts: true  ports:  - name: web    nodePort: 80    port: 80    protocol: TCP    targetPort: web  - name: websecure    nodePort: 443    port: 443    protocol: TCP    targetPort: websecure  selector:    app.kubernetes.io/instance: traefik-kube-system    app.kubernetes.io/name: traefik  type: LoadBalancer---apiVersion: traefik.io/v1alpha1kind: IngressRoutemetadata:  name: traefik-dashboard-webspec:  entryPoints:    - web  routes:    - kind: Rule      match: PathPrefix(`/dashboard`) || PathPrefix(`/api`)      services:        - name: api@internal          kind: TraefikService---apiVersion: traefik.io/v1alpha1kind: IngressRoutemetadata:  name: traefik-dashboard-websecurespec:  entryPoints:    - websecure  routes:    - kind: Rule      match: PathPrefix(`/dashboard`) || PathPrefix(`/api`)      services:        - name: api@internal          kind: TraefikService  tls:    secretName: traefik-dashboard-tlsEOF\n\nkubectl apply -f traefik-dashboard.yaml\n\n访问Dashboard需要在最后加一个/ 否则可能出现page not found\n配置IngressRoute# 搭建测试环境kubectl create deploy whoami --image=traefik/whoami --replicas=2kubectl expose deploy whoami --port=80\n\nHTTP\n#whoami-no-tls-ingress-route.yaml apiVersion: traefik.containo.us/v1alpha1kind: IngressRoutemetadata:  name: whoami-ingress-web  namespace: defaultspec:  entryPoints:    - web  routes:    - match: Host(`192.168.0.2`) &amp;&amp; PathPrefix(`/notls`)      kind: Rule      services:        - name: whoami          port: 80\n\nHTTPS\n# 用 openssl 来创建一个自签名的证书openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj &quot;/CN=domain.example.com&quot;kubectl create secret tls whoami-tls --cert=tls.crt --key=tls.key\n# whoami-tls-ingress-route.yamlapiVersion: traefik.containo.us/v1alpha1kind: IngressRoutemetadata:  name: whoami-ingress-websecure  namespace: defaultspec:  entryPoints:    - websecure  routes:    - match: Host(`192.168.0.2`) &amp;&amp; PathPrefix(`/tls`)      kind: Rule      services:        - name: whoami          port: 80  tls:    secretName: whoami-tls\n证书生成参考k3s证书管理\nTCP&#x2F;UDP默认配置文件下，只有traefik(9000)、web(80)、websecure(443)以及metrics(9100)开放，如果想要反代MySQL tcp又想自定义端口的话，需要单独在配置文件中进行配置。\napiVersion: traefik.containo.us/v1alpha1kind: IngressRouteTCP #IngressRouteUDPmetadata:  name: redis  namespace: devopsspec:  entryPoints:    - redis  routes:  - match: HostSNI(`*`)    services:    - name: redis      port: 6379\n\n TCP Routers与HTTP Routers的routes有所不同：\n\nTCP Routers match采用HostSNI,而HTTP Routers match直接匹配Host。\nTCP Routers只能定位TCP服务（不能定位HTTP服务）。\n如果HTTP Routers和TCP Routers都侦听相同的入口点，则TCP Routers将在HTTP Routers之前应用。如果找不到与TCP Routers匹配的路由，则HTTP Routers将接管。\n\n参考\nK3s版本 &gt; v.121(Traefik 2.x)\nK3S 中 Traefik v2 安装及采坑纪实 - 知乎 (zhihu.com)\nk3s开启traefik的dashboard网页-CSDN博客\nStep by Step！教你如何在k3s集群上使用Traefik 2.x - k3s中文社区 - 博客园 (cnblogs.com)\ntraefik系列之一 | 简介、部署和配置-腾讯云开发者社区-腾讯云 (tencent.com)\n还不会Traefik？看这篇文章就够了！ - 知乎 (zhihu.com)\nk3s 使用 Letsencrypt 和 Traefik 完成 https 入口部署-腾讯云开发者社区-腾讯云 (tencent.com)\n[Kubernetes环境Traefik部署与应用 - Tiscs - 博客园 (cnblogs.com)](https://www.cnblogs.com/tiscs/p/notes-k8s-traefik.html#:~:text=安装Traefik 1 配置 Helm Repo helm repo add, … 3 其他准备工作 获取 traefik 服务的负载均衡器地址。 )\nTraefik - Kubernetes 配置TCP&#x2F;HTTP服务-腾讯云开发者社区-腾讯云 (tencent.com)\ncert-manager管理内网k8s开发环境证书 - hueidou163 - 博客园 (cnblogs.com)\nKubernetes (K8S)中Traefik路由(ingressRoute)-腾讯云开发者社区-腾讯云 (tencent.com)\nDashboard无法访问问题参考\n如何在 K3s 中启用 Traefik Dashborad - RancherLabs - 博客园 (cnblogs.com)\nHow to Expose and Enable K3s with Traefik Dashboard (thriveread.com)\nkubernetes - How to expose traefik v2 dashboard in k3d&#x2F;k3s via configuration? - Stack Overflow\nkubernetes - 云原生 07：改用 K3s，并使用 K3s 内置的 Traefik 做 Ingress 网关 - 小鲜 - SegmentFault 思否\nK8s中使用traefik（基础） - AGou’s Blog\n","categories":["容器技术"],"tags":["Kubernetes","K3s","Traefik","Ingress"]},{"title":"K3s配置内网域名解析","url":"/2024/07/20/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/K3s%E9%85%8D%E7%BD%AE%E5%86%85%E7%BD%91%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90/","content":"K3s 启动后，会自动帮我们安装好 CoreDNS，不需要手动安装。如果你想修改 CoreDNS 的配置，常用的有两种方式：\n\n直接修改 CoreDNS 的 configmap 来调整 CoreDNS 的参数，例如：kubectl -n kube-system edit configmap coredns\n修改 K3s manifests 中的 CoreDNS 配置文件，文件位置：/var/lib/rancher/k3s/server/manifests/coredns.yaml\n\n这两种方式虽然简单，但都有相同的弊端：当你重启 K3s 服务或者升级 K3s 时，由于 K3s 会重新初始化 manifests 中的 CoreDNS 等配置，所以会覆盖掉你通过以上两种方式修改的 coredns 配置。\n如果你想修改 K3s 中 CoreDNS 中的配置，并且持久生效的话，可以通过额外的 coredns-custom configmap 安装到 CoreDNS 容器中，并从包含的文件中导入覆盖和额外的 CoreDNS 配置。\napiVersion: v1kind: ConfigMapmetadata:  name: coredns-custom  namespace: kube-systemdata:  log.override: |    log  example.server: |    example.io &#123;      errors      cache 30      hosts &#123;        192.168.0.2 test1.example.io # 内网域名映射地址        fallthrough      &#125;    &#125;\n\n\n\nConfigMap 的 name 一定刚要是 coredns-custom 才能够被 coredns 的 deployment 识别并挂载。\n在其他Pod中验证CoreDNS配置是否生效\nkubectl create deploy nginx --image=nginx:latest # 创建deploykubectl get pod -w # 等待nginx状态变为runningkubectl exec -it ngix-***** -- /bin/bash # 切入容器，注意容器ID与上一步中查看容器ID一致### 容器内操作ping test1.example.io nslookup test1.example.io\n\n","categories":["容器技术"],"tags":["Kubernetes","K3s","CoreDNS","域名解析"]},{"title":"KubeEdge","url":"/2022/07/27/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/KubeEdge/","content":"https://www.cnblogs.com/tttlv/p/14397699.htmlhttps://www.cnblogs.com/ltaodream/p/15135365.htmlhttps://blog.csdn.net/weixin_42142364/article/details/111084493https://blog.csdn.net/Obese_Tiger/article/details/104741708?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522160378122119724836762566%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=160378122119724836762566&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~baidu_landing_v2~default-8-104741708.first_rank_ecpm_v3_pc_rank_v2&amp;utm_term=kubeedge%E5%AE%89%E8%A3%85&amp;spm=1018.2118.3001.4187https://blog.csdn.net/PinocchioNE/article/details/109337365https://www.jianshu.com/p/c6fc46563cb6https://www.dogfei.cn/archives/kubeedge#https://www.cnblogs.com/dream397/p/14628425.htmlhttps://blog.csdn.net/MSSC_/article/details/114866906https://zhuanlan.zhihu.com/p/350335104https://www.cnblogs.com/kkbill/p/12600541.htmlhttps://blog.csdn.net/weixin_38159695/article/details/118486461\n","categories":["容器技术"]},{"title":"Kubernetes","url":"/2022/07/27/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/Kubernetes/","content":"https://blog.csdn.net/IUNIQUE/article/details/121787708https://www.jianshu.com/p/3de558d8b57ahttps://www.cnblogs.com/chalon/p/14840216.htmlhttps://blog.csdn.net/f95_sljz/article/details/105544338https://www.cnblogs.com/zhaobowen/p/13399708.htmlhttps://www.cnblogs.com/UncleZhao/p/14646127.htmlhttps://segmentfault.com/a/1190000021036626https://www.cnblogs.com/ltaodream/p/15116711.htmlhttps://knner.wang/2019/11/13/docker-io-gcr-io-k8s-gcr-io-quay-io-Chinese-source.htmlhttps://www.cnblogs.com/kevingrace/p/12778066.htmlhttps://www.cnblogs.com/hujinzhong/p/14995169.htmlhttps://www.cnblogs.com/chenyishi/category/1359251.htmlhttps://oldtang.com/1772.htmlhttps://www.kubernetes.org.cn/7315.htmlhttps://blog.csdn.net/networken/article/details/84571373https://blog.csdn.net/JENREY/article/details/84205838https://blog.csdn.net/ggggyj/article/details/104922023https://zhuanlan.zhihu.com/p/109803657https://www.cnblogs.com/cptao/p/10912644.htmlhttps://blog.51cto.com/billy98/2350660https://z.itpub.net/article/detail/68E9894E9257CC55D0AD3643AD3E9C89https://blog.csdn.net/w13657909078/article/details/120141490?spm=1001.2014.3001.5501https://blog.csdn.net/w13657909078/article/details/120342636?spm=1001.2101.3001.6650.7&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-7.pc_relevant_default&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-7.pc_relevant_default&amp;utm_relevant_index=10\n将 .NET 微服务部署到 Kubernetes - Learn | Microsoft Docs\nKubernetes + .NET Core 的落地实践 - 腾讯云开发者社区-腾讯云\nhttps://www.cnblogs.com/harlanzhang/category/1362182.htmlhttps://cloud.tencent.com/developer/article/1450346https://www.cnblogs.com/dingcong1201/p/15472764.html#1-minikubehttps://yiqisoft.cn/blog/server-side/171.htmlhttps://blog.csdn.net/lwkhdx/article/details/103879460https://www.helloworld.net/p/ObLHGeiALU2Dhttps://blog.51cto.com/lvzhenjiang/2473866\nhelm3实战教程 | helm3常用命令和部署应用实战案例 - 知乎\nkubernetes实战篇之helm完整示例 - 周国通 - 博客园\n利用Kubernetes搭建便携式开发环境之MySQL和Redis - 知乎\nKubernetes使用helm部署单机版mysql(使用hostPath数据卷) - Sureing - 博客园\n从零开始建立 EMQX MQTT 服务器的 K8S 集群 | EMQ\nKubernetes集群部署Prometheus和Grafana - 运维人在路上 - 博客园\nKubernetes K8S之存储Secret详解 - 踏歌行666 - 博客园\nDevOps笔记 - k3s 默认ingress 配置 - 知乎\n如何用NFS共享ZFS文件系统——详细教程 - 掘金\n","categories":["容器技术"]},{"title":"Kubernetes PV/PVC配置模板","url":"/2024/04/11/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/Kubernetes%E5%AD%98%E5%82%A8%E5%8D%B7%E6%A8%A1%E6%9D%BF/","content":"本地路径映射（HostPath）\n\nHostPath 卷存在许多安全风险，最佳做法是尽可能避免使用 HostPath。 当必须使用 HostPath 卷时，它的范围应仅限于所需的文件或目录，并以只读方式挂载。\n\napiVersion: v1kind: Podmetadata:  name: test-pdspec:  containers:  - image: registry.k8s.io/test-webserver    name: test-container    volumeMounts:    - mountPath: /test-pd      name: test-volume  volumes:  - name: test-volume    hostPath:      # 宿主机上目录位置      path: /data      # 此字段为可选      type: Directory\n\n支持的 type 值如下:\n\n\n\n取值\n行为\n\n\n\n\n空字符串（默认）用于向后兼容，这意味着在安装 hostPath 卷之前不会执行任何检查。\n\n\nDirectoryOrCreate\n如果在给定路径上什么都不存在，那么将根据需要创建空目录，权限设置为 0755，具有与 kubelet 相同的组和属主信息。\n\n\nDirectory\n在给定路径上必须存在的目录。\n\n\nFileOrCreate\n如果在给定路径上什么都不存在，那么将在那里根据需要创建空文件，权限设置为 0644，具有与 kubelet 相同的组和所有权。\n\n\nFile\n在给定路径上必须存在的文件。\n\n\nSocket\n在给定路径上必须存在的 UNIX 套接字。\n\n\nCharDevice\n在给定路径上必须存在的字符设备。\n\n\nBlockDevice\n在给定路径上必须存在的块设备。\n\n\napiVersion: storage.k8s.io/v1kind: StorageClassmetadata:  name: example-vol-defaultprovisioner: vendor-name.example\n\n\n\nlocal\n\nlocal 卷只能用作静态创建的持久卷。不支持动态配置。\n与 hostPath 卷相比，local 卷能够以持久和可移植的方式使用，而无需手动将 Pod 调度到节点。系统通过查看 PersistentVolume 的节点亲和性配置，就能了解卷的节点约束。\n\n使用 local 卷时，你需要设置 PersistentVolume 对象的 nodeAffinity 字段。 Kubernetes 调度器使用 PersistentVolume 的 nodeAffinity 信息来将使用 local 卷的 Pod 调度到正确的节点。\nPersistentVolume 对象的 volumeMode 字段可被设置为 “Block” （而不是默认值 “Filesystem”），以将 local 卷作为原始块设备暴露出来。\napiVersion: v1kind: PersistentVolumemetadata:  name: example-pvspec:  capacity:    storage: 100Gi  volumeMode: Filesystem  accessModes:  - ReadWriteOnce  persistentVolumeReclaimPolicy: Delete  storageClassName: local-storage  local:    path: /mnt/disks/ssd1  nodeAffinity:    required:      nodeSelectorTerms:      - matchExpressions:        - key: kubernetes.io/hostname          operator: In          values:          - example-node\n\n\n\n\n\nNFS映射\n\n\nMinio\n\n\nCeph\n\n\n","categories":["容器技术"],"tags":["Kubernetes","K3s","PV","PVC"]},{"title":"Kubernetes搭建","url":"/2020/12/29/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/Kubernetes%E6%90%AD%E5%BB%BA/","content":"官方文档(中文)\n\n\n\n节点名称\n节点IP\n配置\n系统版本\n\n\n\nVIP\n192.168.50.220\n虚拟IP\n\n\n\nk8s-master-221\n192.168.50.221\n4核 2G\ndebian 11\n\n\nk8s-master-222\n192.168.50.222\n4核 2G\ndebian 11\n\n\nk8s-master-223\n192.168.50.223\n4核 2G\ndebian 11\n\n\nk8s-node-224\n192.168.50.224\n4核 2G\ndebian 11\n\n\nk8s-node-225\n192.168.50.225\n4核 2G\ndebian 11\n\n\n主机配置时间同步\n\n配置 hostname注意节名称不能重复\nhostnamectl --static set-hostname k8s-master-221\n\n配置防火墙service iptables stop iptables -Fsystemctl stop firewalld &amp;&amp; systemctl disable firewalld\n如果需要打开防火墙，执行以下配置\n# master节点执行ufw allow 6443/tcpufw allow 2379/tcpufw allow 2380/tcpufw allow 10250/tcpufw allow 10251/tcpufw allow 10252/tcpufw allow 10255/tcpufw reload# worker节点执行ufw allow 10250/tcpufw allow 30000:32767/tcpufw reload\n\n关闭交换分区swapoff -aset -ri &#x27;s/.*swap.*/#&amp;/&#x27; /etc/fstab\n若需允许交换分区参考官方文档 交换分区的配置\n配置hostscat &gt;&gt; /etc/hosts &lt;&lt; EOF192.168.50.221 k8s-master-221192.168.50.222 k8s-master-222192.168.50.223 k8s-master-223192.168.50.224 k8s-worker-224192.168.50.225 k8s-worker-225EOF\n\n开启 bridge 网桥过滤功能# 桥接的ipv4流量转到iptablescat &lt;&lt; EOF | sudo tee /etc/modules-load.d/k8s.confoverlaybr_netfilterEOFsudo modprobe overlaysudo modprobe br_netfilter# 设置所需的 sysctl 参数,参数在重新启动后保持不变cat &lt;&lt; EOF | sudo tee /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-iptables  = 1 # 开启网桥模式(必须)net.bridge.bridge-nf-call-ip6tables = 1 # 开启网桥模式(必须)net.ipv4.ip_forward                 = 1 # 转发模式(默认开启)vm.panic_on_oom                     = 0 # 开启OOM(默认开启)vm.swappiness                       = 0 # 禁止使用swap空间vm.overcommit_memory                = 1 # 不检查物理内存是否够用EOF# 应用 sysctl 参数而不重新启动sudo sysctl --system\n\n配置 IPVSmodprobe br_netfiltercat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt; EOF#!/bin/bashmodprobe -- ip_vsmodprobe -- ip_vs_rrmodprobe -- ip_vs_wrrmodprobe -- ip_vs_shmodprobe -- nf_conntrack_ipvEOF\n\n安装工具安装 Containerd# 安装apt update apt install -y containerd# 导出默认配置containerd config default | sudo tee /etc/containerd/config.toml &gt;/dev/null 2&gt;&amp;1\n设置cgroupdriver为systemd,编辑 /etc/containerd/config.toml 文件，找到 [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc.options] 部分，添加一行内容：SystemdCgroup = true\nsed -i &#x27;s/SystemdCgroup \\= false/SystemdCgroup \\= true/g&#x27; /etc/containerd/config.toml\n\n\n重启containerd并设置开机启动\nsystemctl restart containerdsystemctl enable containerd\n\n安装 keadm,kubelete,kubectl# 添加安装源# 安装apt update apt install -y kubelet kubeadm kubectl apt-mark hold kubelet kubeadm kubectl\n部署高可用(仅 master 节点)安装apt install keepalived haproxy\n\n修改haproxy配置/etc/haproxy/haproxy.cfg\nglobal  maxconn  2000  ulimit-n  16384  log  127.0.0.1 local0 err  stats timeout 30sdefaults  log global  mode  http  option  httplog  timeout connect 5000  timeout client  50000  timeout server  50000  timeout http-request 15s  timeout http-keep-alive 15sfrontend monitor-in  bind *:33305  mode http  option httplog  monitor-uri /monitorfrontend k8s-master  bind 0.0.0.0:16443  bind 127.0.0.1:16443  mode tcp  option tcplog  tcp-request inspect-delay 5s  default_backend k8s-masterbackend k8s-master  mode tcp  option tcplog  option tcp-check  balance roundrobin  default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100  server k8s-master1\t172.16.12.111:6443  check    server k8s-master2\t172.16.12.112:6443  check  server k8s-master3\t172.16.12.113:6443  check\n\n配置 keepalived\ninterface         # 网卡名称mcast_src_ip      # 节点ipvirtual_ipaddress # vip地址\n\nk8s-master-221配置文件/etc/keepalived/keepalived.conf\n! Configuration File for keepalivedglobal_defs &#123;    router_id LVS_DEVELscript_user root    enable_script_security&#125;vrrp_script chk_apiserver &#123;    script &quot;/etc/keepalived/check_apiserver.sh&quot; #健康检查脚本    interval 5    weight -5    fall 2      rise 1&#125;vrrp_instance VI_1 &#123;    state MASTER\t\t\t\t\t#高可用主1    interface eth0\t\t\t\t\t#网卡名称    mcast_src_ip 192.168.50.221\t\t#该节点 IP    virtual_router_id 51    priority 100\t\t\t\t    #设置最高级优先级    advert_int 2    authentication &#123;        auth_type PASS        auth_pass K8SHA_KA_AUTH    &#125;    virtual_ipaddress &#123;        192.168.50.220\t\t\t    #vip地址    &#125;    track_script &#123;       chk_apiserver    &#125;&#125;\n\nk8s-master-222配置文件/etc/keepalived/keepalived.conf\n! Configuration File for keepalivedglobal_defs &#123;    router_id LVS_DEVELscript_user root    enable_script_security&#125;vrrp_script chk_apiserver &#123;    script &quot;/etc/keepalived/check_apiserver.sh&quot;    interval 5    weight -5    fall 2      rise 1&#125;vrrp_instance VI_1 &#123;    state BACKUP\t\t\t\t\t#高可用 从1    interface ens33\t\t\t\t\t#网卡名称    mcast_src_ip 192.168.50.222\t    #该节点 IP    virtual_router_id 51    priority 50\t\t\t\t        #设置优先级    advert_int 2    authentication &#123;        auth_type PASS        auth_pass K8SHA_KA_AUTH    &#125;    virtual_ipaddress &#123;        192.168.50.220\t\t\t    #vip地址    &#125;    track_script &#123;       chk_apiserver    &#125;&#125;\n\nk8s-master-222配置文件/etc/keepalived/keepalived.conf\n! Configuration File for keepalivedglobal_defs &#123;    router_id LVS_DEVELscript_user root    enable_script_security&#125;vrrp_script chk_apiserver &#123;    script &quot;/etc/keepalived/check_apiserver.sh&quot;    interval 5    weight -5    fall 2      rise 1&#125;vrrp_instance VI_1 &#123;    state BACKUP\t\t\t\t\t#高可用从2    interface ens33\t\t\t\t\t#网卡名称    mcast_src_ip 192.168.50.223\t\t#该节点 IP    virtual_router_id 51    priority 49\t\t\t\t        #设置优先级    advert_int 2    authentication &#123;        auth_type PASS        auth_pass K8SHA_KA_AUTH    &#125;    virtual_ipaddress &#123;        192.168.50.220\t\t\t    #vip地址    &#125;    track_script &#123;       chk_apiserver    &#125;&#125;\n健康检查脚本 /etc/keepalived/check_apiserver.sh\n#!/bin/basherr=0for k in $(seq 1 3);do    check_code=$(pgrep haproxy)    if [[ $check_code == &quot;&quot; ]]; then        err=$(expr $err + 1)        sleep 1        continue    else        err=0        break    fidoneif [[ $err != &quot;0&quot; ]]; then    echo &quot;systemctl stop keepalived&quot;    /usr/bin/systemctl stop keepalived    exit 1else    exit 0fi\n给监测脚本添加执行权限\nchmod +x /etc/keepalived/check_apiserver.sh\n启动keepalive和haproxy\nsystemctl daemon-reload# 启动并设置开机启动# systemctl enable --now haproxysystemctl start haproxy &amp;&amp; systemctl enable haproxy# systemctl enable --now keepalivedsystemctl start keepalived &amp;&amp; systemctl enbale keepalived\n测试vip漂移# 查看ip与viphostname -I# 测试vip的16443端口是否通nc -v 192.168.50.220 16443\n\n初始化集群拉取镜像# 查看需要的镜像文件kubeadm config images list # 拉取镜像kubeadm config images pull \n\nmaster 节点初始化# 导出默认初始化配置kubeadm config print init-defaults &gt; kubeadm-config.yaml# token过期后生成信息tokenkubeadm token create --print-join-command\n\nmaster 节点加入集群# master节点需要生成certificate-keykubeadm init --control-plane-endpoint=192.168.50.220:16443kubeadm join 192.168.50.220:16443 --token &#123;token&#125; \\    --discovery-token-ca-cert-hash &#123;&#125; \\    --control-plane --certificate-key &#123;&#125;\n\nworker 节点加入集群kubeadm join 192.168.50.220:16643 --token &#123;token&#125; \\    --discovery-token-ca-cert-hash &#123;&#125; \n\n从集群种移除节点\nkubectl delete node &#123;node-name&#125;\n\n配置环境变量，用于访问集群cat &lt;&lt; EOF &gt;&gt; ~/.bashrcexport KUBECONFIG=/etc/kubernetes/admin/confEOFsource ~/.bashrc\n查看集群节点状态\n# 查看节点状态kubectl get nodes# 查看系统组件kubectl get all -n kube-system -o wide\n\n安装网络组件(只在master-221节点操作)CalicoFlannel\n去除 master节点污点如果你打算让Master节点也参与到平常的Pod调度(生产环境一般不会这样做，以保证master节点的稳定性)，那么你需要使用以下命令将Master节点上的 taint(污点标记)解除\nkubectl taint nodes --all node-role.kubernetes.io/master-\n\n最后我们使用以下命令查看当前集群的状态，发现Scheduler和Controller Manager组件处理不健康状态：\nkubectl get cs\n解决上述问题需要将每个Master节点上的 &#x2F;etc&#x2F;kubernetes&#x2F;manifests&#x2F;kube-scheduler.yaml 和 &#x2F;etc&#x2F;kubernetes&#x2F;manifests&#x2F;kube-controller-manager.yaml 文件中的- –port&#x3D;0注释掉,然后重启一下各Master节点上的kubelet即可.\n测试集群kubectl create deployment nginx --image nginx --replicas 2kubectl expose deployment nginx --name nginx --type NodePort --port 80 --target-port 80 --node-port 8080curl http://192.168.50.220:8080\n\n\n参考如何用 Kubeadm 在 Debian 11 上安装 Kubernetes 集群 | Linux 中国 - 知乎 (zhihu.com)Kubernetes多主多从高可用集群部署 - 个人文章 - SegmentFault 思否搭建多主节点k8s高可用集群(三主两从一VIP）_kubernetes部署多主多从集群-CSDN博客github - 基于Ubuntu22.04部署KubeEdge-v1.18.0环境 - 云原生_KubeEdge - SegmentFault 思否\n","categories":["容器技术"],"tags":["Kubernetes","环境搭建"]},{"title":"Kubernetes安装Traefik","url":"/2024/09/26/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/Kubernetes%E9%83%A8%E7%BD%B2Traefik/","content":"安装helm repo add traefik https://helm.traefik.io/traefikhelm repo update helm upgrade traefik traefik/traefik \\    --install --create-namespace \\    --namespace=traefik # 导出配置文件helm show values traefik/traefik &gt; traefik-values.yaml\n\n修改配置traefik-values.yaml\n# Default values for Traefik# This is a YAML-formatted file.# Declare variables to be passed into templates  image:  # @schema additionalProperties: false  # -- Traefik image host registry  registry: docker.io  # -- Traefik image repository  repository: traefik  # -- defaults to appVersion  tag:  # @schema type:[string, null]  # -- Traefik image pull policy  pullPolicy: IfNotPresent  # -- Add additional label to all resourcescommonLabels: &#123;&#125;  deployment:  # -- Enable deployment  enabled: true  # -- Deployment or DaemonSet  kind: Deployment  # -- Number of pods of the deployment (only applies when kind == Deployment)  replicas: 1  # -- Number of old history to retain to allow rollback (If not set, default Kubernetes value is set to 10)  revisionHistoryLimit:  # @schema type:[integer, null];minimum:0  # -- Amount of time (in seconds) before Kubernetes will send the SIGKILL signal if Traefik does not shut down  terminationGracePeriodSeconds: 60  # -- The minimum number of seconds Traefik needs to be up and running before the DaemonSet/Deployment controller considers it available  minReadySeconds: 0  ## -- Override the liveness/readiness port. This is useful to integrate traefik  ## with an external Load Balancer that performs healthchecks.  ## Default: ports.traefik.port  healthchecksPort:  # @schema type:[integer, null];minimum:0  ## -- Override the liveness/readiness host. Useful for getting ping to respond on non-default entryPoint.  ## Default: ports.traefik.hostIP if set, otherwise Pod IP  healthchecksHost: &quot;&quot;  ## -- Override the liveness/readiness scheme. Useful for getting ping to  ## respond on websecure entryPoint.  healthchecksScheme:   # @schema enum:[HTTP, HTTPS, null]; type:[string, null]; default: HTTP  ## -- Override the readiness path.  ## Default: /ping  readinessPath: &quot;&quot;  # -- Override the liveness path.  # Default: /ping  livenessPath: &quot;&quot;  # -- Additional deployment annotations (e.g. for jaeger-operator sidecar injection)  annotations: &#123;&#125;  # -- Additional deployment labels (e.g. for filtering deployment by custom labels)  labels: &#123;&#125;  # -- Additional pod annotations (e.g. for mesh injection or prometheus scraping)  # It supports templating. One can set it with values like traefik/name: &#x27;&#123;&#123; template &quot;traefik.name&quot; . &#125;&#125;&#x27;  podAnnotations: &#123;&#125;  # -- Additional Pod labels (e.g. for filtering Pod by custom labels)  podLabels: &#123;&#125;  # -- Additional containers (e.g. for metric offloading sidecars)  additionalContainers: []  # https://docs.datadoghq.com/developers/dogstatsd/unix_socket/?tab=host  # - name: socat-proxy  #   image: alpine/socat:1.0.5  #   args: [&quot;-s&quot;, &quot;-u&quot;, &quot;udp-recv:8125&quot;, &quot;unix-sendto:/socket/socket&quot;]  #   volumeMounts:  #     - name: dsdsocket  #       mountPath: /socket  # -- Additional volumes available for use with initContainers and additionalContainers  additionalVolumes: []  # - name: dsdsocket  #   hostPath:  #     path: /var/run/statsd-exporter  # -- Additional initContainers (e.g. for setting file permission as shown below)  initContainers: []  # The &quot;volume-permissions&quot; init container is required if you run into permission issues.  # Related issue: https://github.com/traefik/traefik-helm-chart/issues/396  # - name: volume-permissions  #   image: busybox:latest  #   command: [&quot;sh&quot;, &quot;-c&quot;, &quot;touch /data/acme.json; chmod -v 600 /data/acme.json&quot;]  #   volumeMounts:  #     - name: data  #       mountPath: /data  # -- Use process namespace sharing  shareProcessNamespace: false  # -- Custom pod DNS policy. Apply if `hostNetwork: true`  dnsPolicy: &quot;&quot;  # -- Custom pod [DNS config](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.30/#poddnsconfig-v1-core)  dnsConfig: &#123;&#125;  # -- Custom [host aliases](https://kubernetes.io/docs/tasks/network/customize-hosts-file-for-pods/)  hostAliases: []  # -- Pull secret for fetching traefik container image  imagePullSecrets: []  # -- Pod lifecycle actions  lifecycle: &#123;&#125;  # preStop:  #   exec:  #     command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;sleep 40&quot;]  # postStart:  #   httpGet:  #     path: /ping  #     port: 9000  #     host: localhost  #     scheme: HTTP  # -- Set a runtimeClassName on pod  runtimeClassName: &quot;&quot;  # -- [Pod Disruption Budget](https://kubernetes.io/docs/reference/kubernetes-api/policy-resources/pod-disruption-budget-v1/)podDisruptionBudget:  # @schema additionalProperties: false  enabled: false  maxUnavailable:  # @schema type:[string, integer, null];minimum:0  minAvailable:    # @schema type:[string, integer, null];minimum:0  # -- Create a default IngressClass for TraefikingressClass:  # @schema additionalProperties: false  enabled: true  isDefaultClass: true  name: &quot;&quot;  core:  # @schema additionalProperties: false  # -- Can be used to use globally v2 router syntax  # See https://doc.traefik.io/traefik/v3.0/migration/v2-to-v3/#new-v3-syntax-notable-changes  defaultRuleSyntax: &quot;&quot;  # Traefik experimental featuresexperimental:  # -- Enable traefik experimental plugins  plugins: &#123;&#125;  # demo:  #   moduleName: github.com/traefik/plugindemo  #   version: v0.2.1  kubernetesGateway:    # -- Enable traefik experimental GatewayClass CRD    enabled: false  gateway:  # -- When providers.kubernetesGateway.enabled, deploy a default gateway  enabled: true  # -- Set a custom name to gateway  name: &quot;&quot;  # -- By default, Gateway is created in the same `Namespace` than Traefik.  namespace: &quot;&quot;  # -- Additional gateway annotations (e.g. for cert-manager.io/issuer)  annotations: &#123;&#125;  # -- Define listeners  listeners:    web:      # -- Port is the network port. Multiple listeners may use the same port, subject to the Listener compatibility rules.      # The port must match a port declared in ports section.      port: 8000      # -- Optional hostname. See [Hostname](https://gateway-api.sigs.k8s.io/reference/spec/#gateway.networking.k8s.io/v1.Hostname)      hostname: &quot;&quot;      # Specify expected protocol on this listener. See [ProtocolType](https://gateway-api.sigs.k8s.io/reference/spec/#gateway.networking.k8s.io/v1.ProtocolType)      protocol: HTTP      # -- Routes are restricted to namespace of the gateway [by default](https://gateway-api.sigs.k8s.io/reference/spec/#gateway.networking.k8s.io/v1.FromNamespaces      namespacePolicy:  # @schema type:[string, null]    # websecure listener is disabled by default because certificateRefs needs to be added,    # or you may specify TLS protocol with Passthrough mode and add &quot;--providers.kubernetesGateway.experimentalChannel=true&quot; in additionalArguments section.    # websecure:    #   # -- Port is the network port. Multiple listeners may use the same port, subject to the Listener compatibility rules.    #   # The port must match a port declared in ports section.    #   port: 8443    #   # -- Optional hostname. See [Hostname](https://gateway-api.sigs.k8s.io/reference/spec/#gateway.networking.k8s.io/v1.Hostname)    #   hostname:    #   # Specify expected protocol on this listener See [ProtocolType](https://gateway-api.sigs.k8s.io/reference/spec/#gateway.networking.k8s.io/v1.ProtocolType)    #   protocol: HTTPS    #   # -- Routes are restricted to namespace of the gateway [by default](https://gateway-api.sigs.k8s.io/reference/spec/#gateway.networking.k8s.io/v1.FromNamespaces)    #   namespacePolicy:    #   # -- Add certificates for TLS or HTTPS protocols. See [GatewayTLSConfig](https://gateway-api.sigs.k8s.io/reference/spec/#gateway.networking.k8s.io%2fv1.GatewayTLSConfig)    #   certificateRefs:    #   # -- TLS behavior for the TLS session initiated by the client. See [TLSModeType](https://gateway-api.sigs.k8s.io/reference/spec/#gateway.networking.k8s.io/v1.TLSModeType).    #   mode:  gatewayClass:  # @schema additionalProperties: false  # -- When providers.kubernetesGateway.enabled and gateway.enabled, deploy a default gatewayClass  enabled: true  # -- Set a custom name to GatewayClass  name: &quot;&quot;  # -- Additional gatewayClass labels (e.g. for filtering gateway objects by custom labels)  labels: &#123;&#125;  ingressRoute:  dashboard:    # -- Create an IngressRoute for the dashboard    enabled: true # 修改此处，启用dashboard    # -- Additional ingressRoute annotations (e.g. for kubernetes.io/ingress.class)    annotations: # 修改此处,添加配置      ingress.kubernetes.io/ssl-redirect: &quot;true&quot;      ingress.kubernetes.io/proxy-body-size: &quot;0&quot;      kubernetes.io/ingress.class: &quot;traefik&quot;      traefik.ingress.kubernetes.io/router.tls: &quot;true&quot;      traefik.ingress.kubernetes.io/router.entrypoints: websecure    # -- Additional ingressRoute labels (e.g. for filtering IngressRoute by custom labels)    labels: &#123;&#125;    # -- The router match rule used for the dashboard ingressRoute    matchRule: PathPrefix(`/dashboard`) || PathPrefix(`/api`)    # -- The internal service used for the dashboard ingressRoute    services:      - name: api@internal        kind: TraefikService    # -- Specify the allowed entrypoints to use for the dashboard ingress route, (e.g. traefik, web, websecure).    # By default, it&#x27;s using traefik entrypoint, which is not exposed.    # /!\\ Do not expose your dashboard without any protection over the internet /!\\    entryPoints: [&quot;traefik&quot;]    # -- Additional ingressRoute middlewares (e.g. for authentication)    middlewares: []    # -- TLS options (e.g. secret containing certificate)    tls: # 修改此处，配置证书,需要cert-manager      enabled: true      certSource: secret      secret:        secretName: &quot;traefik-tls-secret&quot;          healthcheck:    # -- Create an IngressRoute for the healthcheck probe    enabled: false    # -- Additional ingressRoute annotations (e.g. for kubernetes.io/ingress.class)    annotations: &#123;&#125;    # -- Additional ingressRoute labels (e.g. for filtering IngressRoute by custom labels)    labels: &#123;&#125;    # -- The router match rule used for the healthcheck ingressRoute    matchRule: PathPrefix(`/ping`)    # -- The internal service used for the healthcheck ingressRoute    services:      - name: ping@internal        kind: TraefikService    # -- Specify the allowed entrypoints to use for the healthcheck ingress route, (e.g. traefik, web, websecure).    # By default, it&#x27;s using traefik entrypoint, which is not exposed.    entryPoints: [&quot;traefik&quot;]    # -- Additional ingressRoute middlewares (e.g. for authentication)    middlewares: []    # -- TLS options (e.g. secret containing certificate)    tls: &#123;&#125;  updateStrategy:  # @schema additionalProperties: false  # -- Customize updateStrategy of Deployment or DaemonSet  type: RollingUpdate  rollingUpdate:    maxUnavailable: 0  # @schema type:[integer, string, null]    maxSurge: 1        # @schema type:[integer, string, null]  readinessProbe:  # @schema additionalProperties: false  # -- The number of consecutive failures allowed before considering the probe as failed.  failureThreshold: 1  # -- The number of seconds to wait before starting the first probe.  initialDelaySeconds: 2  # -- The number of seconds to wait between consecutive probes.  periodSeconds: 10  # -- The minimum consecutive successes required to consider the probe successful.  successThreshold: 1  # -- The number of seconds to wait for a probe response before considering it as failed.  timeoutSeconds: 2livenessProbe:  # @schema additionalProperties: false  # -- The number of consecutive failures allowed before considering the probe as failed.  failureThreshold: 3  # -- The number of seconds to wait before starting the first probe.  initialDelaySeconds: 2  # -- The number of seconds to wait between consecutive probes.  periodSeconds: 10  # -- The minimum consecutive successes required to consider the probe successful.  successThreshold: 1  # -- The number of seconds to wait for a probe response before considering it as failed.  timeoutSeconds: 2  # -- Define [Startup Probe](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-startup-probes)startupProbe: &#123;&#125;  providers:  # @schema additionalProperties: false  kubernetesCRD:    # -- Load Kubernetes IngressRoute provider    enabled: true    # -- Allows IngressRoute to reference resources in namespace other than theirs    allowCrossNamespace: false    # -- Allows to reference ExternalName services in IngressRoute    allowExternalNameServices: false    # -- Allows to return 503 when there is no endpoints available    allowEmptyServices: true    # -- When the parameter is set, only resources containing an annotation with the same value are processed. Otherwise, resources missing the annotation, having an empty value, or the value traefik are processed. It will also set required annotation on Dashboard and Healthcheck IngressRoute when enabled.    ingressClass: &quot;&quot;    # labelSelector: environment=production,method=traefik    # -- Array of namespaces to watch. If left empty, Traefik watches all namespaces.    namespaces: []    # -- Defines whether to use Native Kubernetes load-balancing mode by default.    nativeLBByDefault: false    kubernetesIngress:    # -- Load Kubernetes Ingress provider    enabled: true    # -- Allows to reference ExternalName services in Ingress    allowExternalNameServices: false    # -- Allows to return 503 when there is no endpoints available    allowEmptyServices: true    # -- When ingressClass is set, only Ingresses containing an annotation with the same value are processed. Otherwise, Ingresses missing the annotation, having an empty value, or the value traefik are processed.    ingressClass:  # @schema type:[string, null]    # labelSelector: environment=production,method=traefik    # -- Array of namespaces to watch. If left empty, Traefik watches all namespaces.    namespaces: []    # IP used for Kubernetes Ingress endpoints    publishedService:      enabled: false      # Published Kubernetes Service to copy status from. Format: namespace/servicename      # By default this Traefik service      # pathOverride: &quot;&quot;    # -- Defines whether to use Native Kubernetes load-balancing mode by default.    nativeLBByDefault: false    kubernetesGateway:    # -- Enable Traefik Gateway provider for Gateway API    enabled: false    # -- Toggles support for the Experimental Channel resources (Gateway API release channels documentation).    # This option currently enables support for TCPRoute and TLSRoute.    experimentalChannel: false    # -- Array of namespaces to watch. If left empty, Traefik watches all namespaces.    namespaces: []    # -- A label selector can be defined to filter on specific GatewayClass objects only.    labelselector: &quot;&quot;    file:    # -- Create a file provider    enabled: false    # -- Allows Traefik to automatically watch for file changes    watch: true    # -- File content (YAML format, go template supported) (see https://doc.traefik.io/traefik/providers/file/)    content: &quot;&quot;  # -- Add volumes to the traefik pod. The volume name will be passed to tpl.# This can be used to mount a cert pair or a configmap that holds a config.toml file.# After the volume has been mounted, add the configs into traefik by using the `additionalArguments` list below, eg:# `additionalArguments:# - &quot;--providers.file.filename=/config/dynamic.toml&quot;# - &quot;--ping&quot;# - &quot;--ping.entrypoint=web&quot;`volumes: []# - name: public-cert#   mountPath: &quot;/certs&quot;#   type: secret# - name: &#x27;&#123;&#123; printf &quot;%s-configs&quot; .Release.Name &#125;&#125;&#x27;#   mountPath: &quot;/config&quot;#   type: configMap  # -- Additional volumeMounts to add to the Traefik containeradditionalVolumeMounts: []# -- For instance when using a logshipper for access logs# - name: traefik-logs#   mountPath: /var/log/traefik  logs:  general:    # -- Set [logs format](https://doc.traefik.io/traefik/observability/logs/#format)    format:  # @schema enum:[&quot;common&quot;, &quot;json&quot;, null]; type:[string, null]; default: &quot;common&quot;    # By default, the level is set to INFO.    # -- Alternative logging levels are DEBUG, PANIC, FATAL, ERROR, WARN, and INFO.    level: &quot;INFO&quot;  # @schema enum:[INFO,WARN,ERROR,FATAL,PANIC,DEBUG]; default: &quot;INFO&quot;    # -- To write the logs into a log file, use the filePath option.    filePath: &quot;&quot;    # -- When set to true and format is common, it disables the colorized output.    noColor: false  access:    # -- To enable access logs    enabled: false    # -- Set [access log format](https://doc.traefik.io/traefik/observability/access-logs/#format)    format:  # @schema enum:[&quot;CLF&quot;, &quot;json&quot;, null]; type:[string, null]; default: &quot;CLF&quot;    # filePath: &quot;/var/log/traefik/access.log    # -- Set [bufferingSize](https://doc.traefik.io/traefik/observability/access-logs/#bufferingsize)    bufferingSize:  # @schema type:[integer, null]    # -- Set [filtering](https://docs.traefik.io/observability/access-logs/#filtering)    filters: &#123;&#125;    statuscodes: &quot;&quot;    retryattempts: false    minduration: &quot;&quot;    # -- Enables accessLogs for internal resources. Default: false.    addInternals: false    fields:      general:        # -- Set default mode for fields.names        defaultmode: keep  # @schema enum:[keep, drop, redact]; default: keep        # -- Names of the fields to limit.        names: &#123;&#125;      # -- [Limit logged fields or headers](https://doc.traefik.io/traefik/observability/access-logs/#limiting-the-fieldsincluding-headers)      headers:        # -- Set default mode for fields.headers        defaultmode: drop  # @schema enum:[keep, drop, redact]; default: drop        names: &#123;&#125;  metrics:  ## -- Enable metrics for internal resources. Default: false  addInternals: false    ## -- Prometheus is enabled by default.  ## -- It can be disabled by setting &quot;prometheus: null&quot;  prometheus:    # -- Entry point used to expose metrics.    entryPoint: metrics    ## Enable metrics on entry points. Default: true    addEntryPointsLabels:  # @schema type:[boolean, null]    ## Enable metrics on routers. Default: false    addRoutersLabels:  # @schema type:[boolean, null]    ## Enable metrics on services. Default: true    addServicesLabels:  # @schema type:[boolean, null]    ## Buckets for latency metrics. Default=&quot;0.1,0.3,1.2,5.0&quot;    buckets: &quot;&quot;    ## When manualRouting is true, it disables the default internal router in    ## order to allow creating a custom router for prometheus@internal service.    manualRouting: false    service:      # -- Create a dedicated metrics service to use with ServiceMonitor      enabled: false      labels: &#123;&#125;      annotations: &#123;&#125;    # -- When set to true, it won&#x27;t check if Prometheus Operator CRDs are deployed    disableAPICheck:  # @schema type:[boolean, null]    serviceMonitor:      # -- Enable optional CR for Prometheus Operator. See EXAMPLES.md for more details.      enabled: false      metricRelabelings: []      relabelings: []      jobLabel: &quot;&quot;      interval: &quot;&quot;      honorLabels: false      scrapeTimeout: &quot;&quot;      honorTimestamps: false      enableHttp2: false      followRedirects: false      additionalLabels: &#123;&#125;      namespace: &quot;&quot;      namespaceSelector: &#123;&#125;    prometheusRule:      # -- Enable optional CR for Prometheus Operator. See EXAMPLES.md for more details.      enabled: false      additionalLabels: &#123;&#125;      namespace: &quot;&quot;    #  datadog:  #    ## Address instructs exporter to send metrics to datadog-agent at this address.  #    address: &quot;127.0.0.1:8125&quot;  #    ## The interval used by the exporter to push metrics to datadog-agent. Default=10s  #    # pushInterval: 30s  #    ## The prefix to use for metrics collection. Default=&quot;traefik&quot;  #    # prefix: traefik  #    ## Enable metrics on entry points. Default=true  #    # addEntryPointsLabels: false  #    ## Enable metrics on routers. Default=false  #    # addRoutersLabels: true  #    ## Enable metrics on services. Default=true  #    # addServicesLabels: false  #  influxdb2:  #    ## Address instructs exporter to send metrics to influxdb v2 at this address.  #    address: localhost:8086  #    ## Token with which to connect to InfluxDB v2.  #    token: xxx  #    ## Organisation where metrics will be stored.  #    org: &quot;&quot;  #    ## Bucket where metrics will be stored.  #    bucket: &quot;&quot;  #    ## The interval used by the exporter to push metrics to influxdb. Default=10s  #    # pushInterval: 30s  #    ## Additional labels (influxdb tags) on all metrics.  #    # additionalLabels:  #    #   env: production  #    #   foo: bar  #    ## Enable metrics on entry points. Default=true  #    # addEntryPointsLabels: false  #    ## Enable metrics on routers. Default=false  #    # addRoutersLabels: true  #    ## Enable metrics on services. Default=true  #    # addServicesLabels: false  #  statsd:  #    ## Address instructs exporter to send metrics to statsd at this address.  #    address: localhost:8125  #    ## The interval used by the exporter to push metrics to influxdb. Default=10s  #    # pushInterval: 30s  #    ## The prefix to use for metrics collection. Default=&quot;traefik&quot;  #    # prefix: traefik  #    ## Enable metrics on entry points. Default=true  #    # addEntryPointsLabels: false  #    ## Enable metrics on routers. Default=false  #    # addRoutersLabels: true  #    ## Enable metrics on services. Default=true  #    # addServicesLabels: false  otlp:    # -- Set to true in order to enable the OpenTelemetry metrics    enabled: false    # -- Enable metrics on entry points. Default: true    addEntryPointsLabels:  # @schema type:[boolean, null]    # -- Enable metrics on routers. Default: false    addRoutersLabels:  # @schema type:[boolean, null]    # -- Enable metrics on services. Default: true    addServicesLabels:  # @schema type:[boolean, null]    # -- Explicit boundaries for Histogram data points. Default: [.005, .01, .025, .05, .1, .25, .5, 1, 2.5, 5, 10]    explicitBoundaries: []    # -- Interval at which metrics are sent to the OpenTelemetry Collector. Default: 10s    pushInterval: &quot;&quot;    http:      # -- Set to true in order to send metrics to the OpenTelemetry Collector using HTTP.      enabled: false      # -- Format: &lt;scheme&gt;://&lt;host&gt;:&lt;port&gt;&lt;path&gt;. Default: http://localhost:4318/v1/metrics      endpoint: &quot;&quot;      # -- Additional headers sent with metrics by the reporter to the OpenTelemetry Collector.      headers: &#123;&#125;      ## Defines the TLS configuration used by the reporter to send metrics to the OpenTelemetry Collector.      tls:        # -- The path to the certificate authority, it defaults to the system bundle.        ca: &quot;&quot;        # -- The path to the public certificate. When using this option, setting the key option is required.        cert: &quot;&quot;        # -- The path to the private key. When using this option, setting the cert option is required.        key: &quot;&quot;        # -- When set to true, the TLS connection accepts any certificate presented by the server regardless of the hostnames it covers.        insecureSkipVerify:  # @schema type:[boolean, null]    grpc:      # -- Set to true in order to send metrics to the OpenTelemetry Collector using gRPC      enabled: false      # -- Format: &lt;scheme&gt;://&lt;host&gt;:&lt;port&gt;&lt;path&gt;. Default: http://localhost:4318/v1/metrics      endpoint: &quot;&quot;      # -- Allows reporter to send metrics to the OpenTelemetry Collector without using a secured protocol.      insecure: false      ## Defines the TLS configuration used by the reporter to send metrics to the OpenTelemetry Collector.      tls:        # -- The path to the certificate authority, it defaults to the system bundle.        ca: &quot;&quot;        # -- The path to the public certificate. When using this option, setting the key option is required.        cert: &quot;&quot;        # -- The path to the private key. When using this option, setting the cert option is required.        key: &quot;&quot;        # -- When set to true, the TLS connection accepts any certificate presented by the server regardless of the hostnames it covers.        insecureSkipVerify: false  ## Tracing# -- https://doc.traefik.io/traefik/observability/tracing/overview/tracing:  # @schema additionalProperties: false  # -- Enables tracing for internal resources. Default: false.  addInternals: false  otlp:    # -- See https://doc.traefik.io/traefik/v3.0/observability/tracing/opentelemetry/    enabled: false    http:      # -- Set to true in order to send metrics to the OpenTelemetry Collector using HTTP.      enabled: false      # -- Format: &lt;scheme&gt;://&lt;host&gt;:&lt;port&gt;&lt;path&gt;. Default: http://localhost:4318/v1/metrics      endpoint: &quot;&quot;      # -- Additional headers sent with metrics by the reporter to the OpenTelemetry Collector.      headers: &#123;&#125;      ## Defines the TLS configuration used by the reporter to send metrics to the OpenTelemetry Collector.      tls:        # -- The path to the certificate authority, it defaults to the system bundle.        ca: &quot;&quot;        # -- The path to the public certificate. When using this option, setting the key option is required.        cert: &quot;&quot;        # -- The path to the private key. When using this option, setting the cert option is required.        key: &quot;&quot;        # -- When set to true, the TLS connection accepts any certificate presented by the server regardless of the hostnames it covers.        insecureSkipVerify: false    grpc:      # -- Set to true in order to send metrics to the OpenTelemetry Collector using gRPC      enabled: false      # -- Format: &lt;scheme&gt;://&lt;host&gt;:&lt;port&gt;&lt;path&gt;. Default: http://localhost:4318/v1/metrics      endpoint: &quot;&quot;      # -- Allows reporter to send metrics to the OpenTelemetry Collector without using a secured protocol.      insecure: false      ## Defines the TLS configuration used by the reporter to send metrics to the OpenTelemetry Collector.      tls:        # -- The path to the certificate authority, it defaults to the system bundle.        ca: &quot;&quot;        # -- The path to the public certificate. When using this option, setting the key option is required.        cert: &quot;&quot;        # -- The path to the private key. When using this option, setting the cert option is required.        key: &quot;&quot;        # -- When set to true, the TLS connection accepts any certificate presented by the server regardless of the hostnames it covers.        insecureSkipVerify: false  # -- Global command arguments to be passed to all traefik&#x27;s podsglobalArguments:- &quot;--global.checknewversion&quot;- &quot;--global.sendanonymoususage&quot;  # -- Additional arguments to be passed at Traefik&#x27;s binary# See [CLI Reference](https://docs.traefik.io/reference/static-configuration/cli/)# Use curly braces to pass values: `helm install --set=&quot;additionalArguments=&#123;--providers.kubernetesingress.ingressclass=traefik-internal,--log.level=DEBUG&#125;&quot;`additionalArguments: []#  - &quot;--providers.kubernetesingress.ingressclass=traefik-internal&quot;#  - &quot;--log.level=DEBUG&quot;  # -- Environment variables to be passed to Traefik&#x27;s binary# @default -- See _values.yaml_env:- name: POD_NAME  valueFrom:    fieldRef:      fieldPath: metadata.name- name: POD_NAMESPACE  valueFrom:    fieldRef:      fieldPath: metadata.namespace  # -- Environment variables to be passed to Traefik&#x27;s binary from configMaps or secretsenvFrom: []  ports:  redis: # 添加此部分，用于暴露Redis对外访问    port: 6379    expose: true    exposedPort: 6379 # 对外暴露端口    protocol: TCP  mysql: #添加此部分，用于暴露MySQL对外访问    port: 3306    expose: true    exposedPort: 3306 # 对外暴露端口    protocol: TCP  traefik:    port: 9000    # -- Use hostPort if set.    hostPort:  # @schema type:[integer, null]; minimum:0    # -- Use hostIP if set. If not set, Kubernetes will default to 0.0.0.0, which    # means it&#x27;s listening on all your interfaces and all your IPs. You may want    # to set this value if you need traefik to listen on specific interface    # only.    hostIP:  # @schema type:[string, null]      # Defines whether the port is exposed if service.type is LoadBalancer or    # NodePort.    #    # -- You SHOULD NOT expose the traefik port on production deployments.    # If you want to access it from outside your cluster,    # use `kubectl port-forward` or create a secure ingress    expose:      default: false    # -- The exposed port for this service    exposedPort: 9000    # -- The port protocol (TCP/UDP)    protocol: TCP  web:    ## -- Enable this entrypoint as a default entrypoint. When a service doesn&#x27;t explicitly set an entrypoint it will only use this entrypoint.    # asDefault: true    port: 8000    # hostPort: 8000    # containerPort: 8000    expose:      default: true    exposedPort: 80    ## -- Different target traefik port on the cluster, useful for IP type LB    targetPort:  # @schema type:[integer, null]; minimum:0    # The port protocol (TCP/UDP)    protocol: TCP    # -- See [upstream documentation](https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport)    nodePort:  # @schema type:[integer, null]; minimum:0    # Port Redirections    # Added in 2.2, you can make permanent redirects via entrypoints.    # https://docs.traefik.io/routing/entrypoints/#redirection    redirectTo: &#123;&#125;    forwardedHeaders:      # -- Trust forwarded headers information (X-Forwarded-*).      trustedIPs: []      insecure: false    proxyProtocol:      # -- Enable the Proxy Protocol header parsing for the entry point      trustedIPs: []      insecure: false    # -- Set transport settings for the entrypoint; see also    # https://doc.traefik.io/traefik/routing/entrypoints/#transport    transport:      respondingTimeouts:        readTimeout:   # @schema type:[string, integer, null]        writeTimeout:  # @schema type:[string, integer, null]        idleTimeout:   # @schema type:[string, integer, null]      lifeCycle:        requestAcceptGraceTimeout:  # @schema type:[string, integer, null]        graceTimeOut:               # @schema type:[string, integer, null]      keepAliveMaxRequests:         # @schema type:[integer, null]; minimum:0      keepAliveMaxTime:             # @schema type:[string, integer, null]  websecure:    ## -- Enable this entrypoint as a default entrypoint. When a service doesn&#x27;t explicitly set an entrypoint it will only use this entrypoint.    # asDefault: true    port: 8443    hostPort:  # @schema type:[integer, null]; minimum:0    containerPort:  # @schema type:[integer, null]; minimum:0    expose:      default: true    exposedPort: 443    ## -- Different target traefik port on the cluster, useful for IP type LB    targetPort:  # @schema type:[integer, null]; minimum:0    ## -- The port protocol (TCP/UDP)    protocol: TCP    # -- See [upstream documentation](https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport)    nodePort:  # @schema type:[integer, null]; minimum:0    # -- See [upstream documentation](https://kubernetes.io/docs/concepts/services-networking/service/#application-protocol)    appProtocol:  # @schema type:[string, null]    # -- See [upstream documentation](https://doc.traefik.io/traefik/routing/entrypoints/#allowacmebypass)    allowACMEByPass: false    http3:      ## -- Enable HTTP/3 on the entrypoint      ## Enabling it will also enable http3 experimental feature      ## https://doc.traefik.io/traefik/routing/entrypoints/#http3      ## There are known limitations when trying to listen on same ports for      ## TCP &amp; UDP (Http3). There is a workaround in this chart using dual Service.      ## https://github.com/kubernetes/kubernetes/issues/47249#issuecomment-587960741      enabled: false      advertisedPort:  # @schema type:[integer, null]; minimum:0    forwardedHeaders:        # -- Trust forwarded headers information (X-Forwarded-*).      trustedIPs: []      insecure: false    proxyProtocol:      # -- Enable the Proxy Protocol header parsing for the entry point      trustedIPs: []      insecure: false    # -- See [upstream documentation](https://doc.traefik.io/traefik/routing/entrypoints/#transport)    transport:      respondingTimeouts:        readTimeout:   # @schema type:[string, integer, null]        writeTimeout:  # @schema type:[string, integer, null]        idleTimeout:   # @schema type:[string, integer, null]      lifeCycle:        requestAcceptGraceTimeout:  # @schema type:[string, integer, null]        graceTimeOut:               # @schema type:[string, integer, null]      keepAliveMaxRequests:         # @schema type:[integer, null]; minimum:0      keepAliveMaxTime:             # @schema type:[string, integer, null]    # --  See [upstream documentation](https://doc.traefik.io/traefik/routing/entrypoints/#tls)    tls:      enabled: true      options: &quot;&quot;      certResolver: &quot;&quot;      domains: []    # -- One can apply Middlewares on an entrypoint    # https://doc.traefik.io/traefik/middlewares/overview/    # https://doc.traefik.io/traefik/routing/entrypoints/#middlewares    # -- /!\\ It introduces here a link between your static configuration and your dynamic configuration /!\\    # It follows the provider naming convention: https://doc.traefik.io/traefik/providers/overview/#provider-namespace    #   - namespace-name1@kubernetescrd    #   - namespace-name2@kubernetescrd    middlewares: []  metrics:    # -- When using hostNetwork, use another port to avoid conflict with node exporter:    # https://github.com/prometheus/prometheus/wiki/Default-port-allocations    port: 9100    # -- You may not want to expose the metrics port on production deployments.    # If you want to access it from outside your cluster,    # use `kubectl port-forward` or create a secure ingress    expose:      default: false    # -- The exposed port for this service    exposedPort: 9100    # -- The port protocol (TCP/UDP)    protocol: TCP  # -- TLS Options are created as [TLSOption CRDs](https://doc.traefik.io/traefik/https/tls/#tls-options)# When using `labelSelector`, you&#x27;ll need to set labels on tlsOption accordingly.# See EXAMPLE.md for details.tlsOptions: &#123;&#125;  # -- TLS Store are created as [TLSStore CRDs](https://doc.traefik.io/traefik/https/tls/#default-certificate). This is useful if you want to set a default certificate. See EXAMPLE.md for details.tlsStore: &#123;&#125;  service:  enabled: true  ## -- Single service is using `MixedProtocolLBService` feature gate.  ## -- When set to false, it will create two Service, one for TCP and one for UDP.  single: true  type: LoadBalancer  # -- Additional annotations applied to both TCP and UDP services (e.g. for cloud provider specific config)  annotations: &#123;&#125;  # -- Additional annotations for TCP service only  annotationsTCP: &#123;&#125;  # -- Additional annotations for UDP service only  annotationsUDP: &#123;&#125;  # -- Additional service labels (e.g. for filtering Service by custom labels)  labels: &#123;&#125;  # -- Additional entries here will be added to the service spec.  # -- Cannot contain type, selector or ports entries.  spec: &#123;&#125;  # externalTrafficPolicy: Cluster  # loadBalancerIP: &quot;1.2.3.4&quot;  # clusterIP: &quot;2.3.4.5&quot;  loadBalancerSourceRanges: []  # - 192.168.0.1/32  # - 172.16.0.0/16  ## -- Class of the load balancer implementation  # loadBalancerClass: service.k8s.aws/nlb  externalIPs: []  # - 1.2.3.4  ## One of SingleStack, PreferDualStack, or RequireDualStack.  # ipFamilyPolicy: SingleStack  ## List of IP families (e.g. IPv4 and/or IPv6).  ## ref: https://kubernetes.io/docs/concepts/services-networking/dual-stack/#services  # ipFamilies:  #   - IPv4  #   - IPv6  ##  additionalServices: &#123;&#125;  ## -- An additional and optional internal Service.  ## Same parameters as external Service  # internal:  #   type: ClusterIP  #   # labels: &#123;&#125;  #   # annotations: &#123;&#125;  #   # spec: &#123;&#125;  #   # loadBalancerSourceRanges: []  #   # externalIPs: []  #   # ipFamilies: [ &quot;IPv4&quot;,&quot;IPv6&quot; ]  autoscaling:  # -- Create HorizontalPodAutoscaler object.  # See EXAMPLES.md for more details.  enabled: false  persistence:  # -- Enable persistence using Persistent Volume Claims  # ref: http://kubernetes.io/docs/user-guide/persistent-volumes/  # It can be used to store TLS certificates, see `storage` in certResolvers  enabled: false  name: data  existingClaim: &quot;&quot;  accessMode: ReadWriteOnce  size: 128Mi  storageClass: &quot;&quot;  volumeName: &quot;&quot;  path: /data  annotations: &#123;&#125;  # -- Only mount a subpath of the Volume into the pod  subPath: &quot;&quot;  # -- Certificates resolvers configuration.# Ref: https://doc.traefik.io/traefik/https/acme/#certificate-resolvers# See EXAMPLES.md for more details.certResolvers: &#123;&#125;  # -- If hostNetwork is true, runs traefik in the host network namespace# To prevent unschedulabel pods due to port collisions, if hostNetwork=true# and replicas&gt;1, a pod anti-affinity is recommended and will be set if the# affinity is left as default.hostNetwork: false  # -- Whether Role Based Access Control objects like roles and rolebindings should be createdrbac:  # @schema additionalProperties: false  enabled: true  # When set to true:  # 1. Use `Role` and `RoleBinding` instead of `ClusterRole` and `ClusterRoleBinding`.  # 2. Set `disableIngressClassLookup` on Kubernetes Ingress providers with Traefik Proxy v3 until v3.1.1  # 3. Set `disableClusterScopeResources` on Kubernetes Ingress and CRD providers with Traefik Proxy v3.1.2+  # **NOTE**: `IngressClass`, `NodePortLB` and **Gateway** provider cannot be used with namespaced RBAC.  # See [upstream documentation](https://doc.traefik.io/traefik/providers/kubernetes-ingress/#disableclusterscoperesources) for more details.  namespaced: false  # Enable user-facing roles  # https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles  aggregateTo: []  # List of Kubernetes secrets that are accessible for Traefik. If empty, then access is granted to every secret.  secretResourceNames: []  # -- Enable to create a PodSecurityPolicy and assign it to the Service Account via RoleBinding or ClusterRoleBindingpodSecurityPolicy:  enabled: false  # -- The service account the pods will use to interact with the Kubernetes APIserviceAccount:  # @schema additionalProperties: false  # If set, an existing service account is used  # If not set, a service account is created automatically using the fullname template  name: &quot;&quot;  # -- Additional serviceAccount annotations (e.g. for oidc authentication)serviceAccountAnnotations: &#123;&#125;  # -- [Resources](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/) for `traefik` container.resources: &#123;&#125;  # -- This example pod anti-affinity forces the scheduler to put traefik pods# -- on nodes where no other traefik pods are scheduled.# It should be used when hostNetwork: true to prevent port conflictsaffinity: &#123;&#125;#  podAntiAffinity:#    requiredDuringSchedulingIgnoredDuringExecution:#      - labelSelector:#          matchLabels:#            app.kubernetes.io/name: &#x27;&#123;&#123; template &quot;traefik.name&quot; . &#125;&#125;&#x27;#            app.kubernetes.io/instance: &#x27;&#123;&#123; .Release.Name &#125;&#125;-&#123;&#123; .Release.Namespace &#125;&#125;&#x27;#        topologyKey: kubernetes.io/hostname  # -- nodeSelector is the simplest recommended form of node selection constraint.nodeSelector: &#123;&#125;# -- Tolerations allow the scheduler to schedule pods with matching taints.tolerations: []# -- You can use topology spread constraints to control# how Pods are spread across your cluster among failure-domains.topologySpreadConstraints: []# This example topologySpreadConstraints forces the scheduler to put traefik pods# on nodes where no other traefik pods are scheduled.#  - labelSelector:#      matchLabels:#        app: &#x27;&#123;&#123; template &quot;traefik.name&quot; . &#125;&#125;&#x27;#    maxSkew: 1#    topologyKey: kubernetes.io/hostname#    whenUnsatisfiable: DoNotSchedule  # -- [Pod Priority and Preemption](https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/)priorityClassName: &quot;&quot;  # -- [SecurityContext](https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#security-context-1)# @default -- See _values.yaml_securityContext:  allowPrivilegeEscalation: false  capabilities:    drop: [ALL]  readOnlyRootFilesystem: true  # -- [Pod Security Context](https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#security-context)# @default -- See _values.yaml_podSecurityContext:  runAsGroup: 65532  runAsNonRoot: true  runAsUser: 65532  ## -- Extra objects to deploy (value evaluated as a template)## In some cases, it can avoid the need for additional, extended or adhoc deployments.# See #595 for more details and traefik/tests/values/extra.yaml for example.extraObjects: []  # -- This field override the default Release Namespace for Helm.# It will not affect optional CRDs such as `ServiceMonitor` and `PrometheusRules`namespaceOverride: &quot;&quot;  ## -- This field override the default app.kubernetes.io/instance label for all Objects.instanceLabelOverride: &quot;&quot;  # Traefik Hub configuration. See https://doc.traefik.io/traefik-hub/hub:  # -- Name of `Secret` with key &#x27;token&#x27; set to a valid license token.  # It enables API Gateway.  token: &quot;&quot;  apimanagement:    # -- Set to true in order to enable API Management. Requires a valid license token.    enabled: false    admission:      # -- WebHook admission server listen address. Default: &quot;0.0.0.0:9943&quot;.      listenAddr: &quot;&quot;      # -- Certificate of the WebHook admission server. Default: &quot;hub-agent-cert&quot;.      secretName: &quot;&quot;    ratelimit:    redis:      # -- Enable Redis Cluster. Default: true.      cluster:    # @schema type:[boolean, null]      # -- Database used to store information. Default: &quot;0&quot;.      database:   # @schema type:[string, null]      # -- Endpoints of the Redis instances to connect to. Default: &quot;&quot;.      endpoints: &quot;&quot;      # -- The username to use when connecting to Redis endpoints. Default: &quot;&quot;.      username: &quot;&quot;      # -- The password to use when connecting to Redis endpoints. Default: &quot;&quot;.      password: &quot;&quot;      sentinel:        # -- Name of the set of main nodes to use for main selection. Required when using Sentinel. Default: &quot;&quot;.        masterset: &quot;&quot;        # -- Username to use for sentinel authentication (can be different from endpoint username). Default: &quot;&quot;.        username: &quot;&quot;        # -- Password to use for sentinel authentication (can be different from endpoint password). Default: &quot;&quot;.        password: &quot;&quot;      # -- Timeout applied on connection with redis. Default: &quot;0s&quot;.      timeout: &quot;&quot;      tls:        # -- Path to the certificate authority used for the secured connection.        ca: &quot;&quot;        # -- Path to the public certificate used for the secure connection.        cert: &quot;&quot;        # -- Path to the private key used for the secure connection.        key: &quot;&quot;        # -- When insecureSkipVerify is set to true, the TLS connection accepts any certificate presented by the server. Default: false.        insecureSkipVerify: false  # Enable export of errors logs to the platform. Default: true.  sendlogs:  # @schema type:[boolean, null]\n\n应用配置helm upgrade traefik traefik/traefik \\    --namespace traefik -f traefik-values.yaml\n\n\nIngressRouteTCP示例mysql-traefik-ingress.yaml\napiVersion: apps/v1kind: StatefulSetmetadata:  name: mysql  namespace: defaultspec: ...---apiVersion: v1kind: Servicemetadata:  name: mysql-svc  namespace: defaultspec:  selector:     app: mysql  ports:  - port: 3306    name: mysql-tcp    protocol: TCP  clusterIP: None # 定义Headless Service---apiVersion: traefik.io/v1alpha1kind: IngressRouteTCPmetadata:  name: mysql-ingress  namespace: default #根据实际情况修改,或应用文件时指定spec:  entryPoints:    - mysql  routes:    - match: HostSNI(`*`)      services:        - name: mysql-svc          namespace: default","categories":["容器技术"],"tags":["Kubernetes","Ingress","traefik"]},{"title":"Podman配置代理","url":"/2025/08/01/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/Podman%E9%85%8D%E7%BD%AE%E4%BB%A3%E7%90%86/","content":"方法1: 为当前用户设置环境变量为当前用户设置 HTTP_PROXY 和 HTTPS_PROXY 环境变量,Podman 将自动读取这些环境变量并使用代理。\n# Bashexport HTTP_PROXY=&quot;http://代理地址:端口&quot;  export HTTPS_PROXY=&quot;https://代理地址:端口&quot;# 对于 bash, 也可以在 ~/.bashrc 中添加上述命令使其永久有效# Fishset -x HTTP_PROXY &quot;http://代理地址:端口&quot;set -x HTTPS_PROXY &quot;https://代理地址:端口&quot;# 对于 fish,也可以在 ~/.config/fish/config.fish 中添加以上命令\n\n如果代理需要身份验证,可以在 URL 中添加用户名和密码。格式如下:\nhttp://用户名:密码@代理地址:端口\n\n方法2：为 Podman 服务设置配置文件通过编辑 &#x2F;etc&#x2F;containers&#x2F;registries.conf 配置文件为 Podman 服务设置代理。在该文件中添加如下内容:\n[registries.search]registries = [&#x27;docker.io&#x27;, &#x27;quay.io&#x27;][registries.insecure]registries = [][registries.block]registries = [][registries.unqualified-search-registries][registry.mirrors][registry.configs][registry.configs.REGISTRY_NAME.HOSTNAME/HOSTPATH]  unqualified-search-registries = [&quot;registry.fedoraproject.org&quot;, &quot;registry.access.redhat.com&quot;, &quot;docker.io&quot;]blocked=false [registry.configs.REGISTRY_NAME.HOSTNAME]http-proxy=&quot;http://代理地址:端口&quot;https-proxy=&quot;https://代理地址:端口&quot;\n\n替换 REGISTRY_NAME.HOSTNAME 为您要配置的注册表,如 docker.io。如果代理需要身份验证,则使用类似 http:&#x2F;&#x2F;user:&#112;&#97;&#115;&#115;&#119;&#x6f;&#114;&#x64;&#x40;&#112;&#114;&#x6f;&#x78;&#121;&#x2e;&#x65;&#x78;&#97;&#109;&#112;&#x6c;&#x65;&#x2e;&#x63;&#111;&#109;:8080 的格式。\n方法3: 为单个 Podman 命令设置代理为单个 Podman 命令临时设置代理,方法是在命令前添加 –build-arg 参数。例如:\npodman --build-arg HTTP_PROXY=&quot;http://代理地址:端口&quot; --build-arg HTTPS_PROXY=&quot;https://代理地址:端口&quot; pull nginx\n\n方法四: 配置 http-proxy.conf$ systemctl status podman● podman.service - Podman API Service   Loaded: loaded (/usr/lib/systemd/system/podman.service; enabled; vendor preset: disabled)  Drop-In: /etc/systemd/system/podman.service.d           └─http-proxy.conf   Active: inactive (dead) since Mon 2023-11-20 18:45:12 CST; 3 months 22 days ago     Docs: man:podman-system-service(1)  Process: 50669 ExecStart=/usr/bin/podman $LOGGING system service (code=exited, status=0/SUCCESS) Main PID: 50669 (code=exited, status=0/SUCCESS)Nov 20 18:45:07 downlaod systemd[1]: Starting Podman API Service...Nov 20 18:45:07 downlaod systemd[1]: Started Podman API Service.Nov 20 18:45:07 downlaod podman[50669]: time=&quot;2023-11-20T18:45:07+08:00&quot; level=info msg=&quot;/usr/bin/podman filtering at log level&gt;Nov 20 18:45:07 downlaod podman[50669]: time=&quot;2023-11-20T18:45:07+08:00&quot; level=info msg=&quot;Not using native diff for overlay, thi&gt;Nov 20 18:45:07 downlaod podman[50669]: time=&quot;2023-11-20T18:45:07+08:00&quot; level=info msg=&quot;Setting parallel job count to 13&quot;Nov 20 18:45:07 downlaod podman[50669]: time=&quot;2023-11-20T18:45:07+08:00&quot; level=info msg=&quot;Using systemd socket activation to det&gt;Nov 20 18:45:07 downlaod podman[50669]: time=&quot;2023-11-20T18:45:07+08:00&quot; level=info msg=&quot;API service listening on \\&quot;/run/podman&gt;Nov 20 18:45:12 downlaod systemd[1]: podman.service: Succeeded.$ cat /etc/systemd/system/podman.service.d/http-proxy.conf [Service]Environment=&quot;HTTP_PROXY=http://192.168.21.101:7890&quot;Environment=&quot;HTTPS_PROXY=http://192.168.21.101:7890&quot;Environment=&quot;NO_PROXY=localhost,127.0.0.1,.coding.net,.tencentyun.com,.myqcloud.com,harbor.bsgchina.com&quot;","categories":["容器技术"],"tags":["Podman","Proxy","代理"]},{"title":"K3s证书管理","url":"/2024/04/02/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/k3s%E8%AF%81%E4%B9%A6%E7%AE%A1%E7%90%86/","content":"手动管理证书生成证书参考[[..&#x2F;杂项&#x2F;OpenSSL生成自签名证书|OpenSSL生成自签名证书]]\n导入证书kubectl create secrets tls example-io-tls --key example.io.key --cert example.io.crt\n\n手动管理证书可忽略下边的安装过程，跳转到证书配置\n使用cert-manager管理证书部署cert-manager方式一： 使用Helm部署(推荐)\n# 添加镜像源helm repo add jetstack https://charts.jetstack.io#获取配置文件helm show values jetstack/cert-manager &gt; cert-manager-values.yaml# 部署cert-mangaerhelm upgrade cert-manager jetstack/cert-manager \\\t--namespace cert-manager \\\t--install --create-namespace \\\t--set crds.enabled=true\n\n方式二： 使用kubectl部署\n# Kubernetes 1.16+kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.8.0/cert-manager.yaml# Kubernetes &lt;1.16kubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v1.1.0/cert-manager-legacy.yaml# Kubernetes 1.15+kubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v0.16.1/cert-manager.yaml# Kubernetes &lt;1.15kubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v0.16.1/cert-manager-legacy.yaml\n\n\n\n创建ClusterIssuer&#x2F;Issuer公网域名证书Issuer 与 ClusterIssuer 的区别是 ClusterIssuer 可跨命名空间使用，而 Issuer 需在每个命名空间下配置后才可使用。这里我们使用 ClusterIssuer，其类型选择 Let‘s Encrypt。\n正式环境速率限制(每个注册域名可签发的证书数量（每周 50 份）)，使用测试环境测试一切正常后再切换正式环境。\nletsencrypt-issuer-staging.yaml\napiVersion: cert-manager.io/v1kind: ClusterIssuermetadata:  name: letsencrypt-stagingspec:  acme:    email: &lt;YOUR EMAIL&gt; # replice this     server: https://acme-staging-v02.api.letsencrypt.org/directory    privateKeySecretRef:      name: letsencrypt-staging    solvers:    - http01:        ingress:          class: traefik      selector: &#123;&#125;\n\nletsencrypt-issuer-prod\napiVersion: cert-manager.io/v1kind: ClusterIssuermetadata:  name: letsencrypt-prodspec:  acme:    email: &lt;YOUR EMAIL&gt; # replice this     server: https://acme-v02.api.letsencrypt.org/directory    privateKeySecretRef:      name: letsencrypt-prod    solvers:    - http01:        ingress:          class: traefik      selector: &#123;&#125;\n\n\n\n说明：\nmetadata.name 创建的签发机构的名称，创建证书的时候会引用spec.acme.email 邮箱，证书快过期的时候会有邮件提醒，不过cert-manager会利用acme协议自动给我们重新颁发证书来续期spec.acme.server acme 协议的服务端，由官方给出spec.acme.privateKeySecretRef 指示此签发机构的私钥将要存储到哪个Secret对象中spec.acme.solvers.http01 指示签发机构使用HTTP-01的方式进行acme协议 (还可以用DNS方式，acme协议的目的是证明这台机器和域名都是属于你的，然后才准许给你颁发证书)\n\n自签名证书selfsigned-issuer.yaml\napiVersion: cert-manager.io/v1kind: ClusterIssuermetadata:  name: selfsigned-cluster-issuerspec:  selfSigned: &#123;&#125;---apiVersion: cert-manager.io/v1kind: Certificatemetadata:  name: selfsigned-caspec:  isCA: true  commonName: selfsigned-ca  secretName: root-secret  privateKey:    algorithm: ECDSA    size: 256  subjects:    organizations:    -   issuerRef:    name: selfsigned-cluster-issuer    kind: ClusterIssuer    group: cert-manager.io#---    ## 使用自定义根证书## 导入根证书 kubectl create secret tls ca-secret --key root-ca.key --cert root-ca.crt#apiVersion: cert-manager.io/v1#kind: ClusterIssuer#metadata:#  name: selfsigned-cluster-issuer#spec:#  ca:#    secretName: ca-secret\n\n\nspec.subjects.organizations: \n\n创建域名证书公网域名证书example-io-tls.yaml\napiVersion: cert-manager.io/v1kind: Certificatemetadata:  name: example-io-tlsspec:  secretName: example-io-secret #   issuerRef:    name: letsencrypt-staging # 使用自签名证书时替换为 selfsigned-cluster-issuer    kind: ClusterIssuer  duration: 2160h  renewBefore: 360h  dnsNames:  - example.io  ipAddresses:  - 192.168.1.1\n\n生产环境使用建议\n实际生产环境中使用cert-manager可以考虑以下建议：\n\n将CA的Secret及Issuer放在某个独立的命名空间中，与其它业务的命名空间隔离起来。\n如果是CA类型的Issuer，要记得定期更新根CA证书。\n如果服务可被公网访问，同时又不想花钱买域名证书，可以采用Letsencrypt类型的Issuer，目前支持两种方式验证域名的所有权，基于DNS记录的验证方案和基于文件的HTTP验证方案。\ncert-manager还提供ingress-shim方式，自动为Ingress资源生成证书，只需要在Ingress资源上打上一些标签即可，详细可参考这里。\n\n\nspec.secretName 指示证书最终存到哪个 Secret 中\nspec.issuerRef.kind 值为 ClusterIssuer 说明签发机构不在本 namespace 下，而是在全局\nspec.issuerRef.name 我们创建的签发机构的名称 (ClusterIssuer.metadata.name)\nspec.duration 证书过期时间\nspec.renewBefore 在过期前自动更新\nspec.dnsNames 指示该证书的可以用于哪些域名\nspec.acme.config.http01.domains 指示该证书的可以用于哪些域名\n\nTraefik配置证书终端安装证书获取CA证书，root-ca.crt,k3s导出证书 参考K3s导出证书\n\nk8s中使用cert-manager玩转证书-腾讯云开发者社区-腾讯云 (tencent.com)\nk8s 使用cert-manager证书管理自签-CSDN博客\n k8s部署cert-manager实现证书自动化_cert-manager.yaml-CSDN博客\nCert-Manager 实现 K8s 服务域名证书自动化续签 - 知乎 (zhihu.com)\n手把手教你使用 cert-manager 签发免费证书 - 腾讯云原生 - 博客园 (cnblogs.com)\n在 k3s 内使用 cert-manager 管理证书 (bowser1704.github.io)\n用 k3s 轻松管理 SSL 证书 | Linux 中国 - 知乎\nk8s中级篇-cert-manager+Let‘s Encrypt自动证书签发_cert-manager let’s encrypt-CSDN博客k3s 使用 Letsencrypt 和 Traefik 完成 https 入口部署-腾讯云开发者社区-腾讯云 (tencent.com)\n容器服务 使用 cert-manager 签发免费证书-实践教程-文档中心-腾讯云 (tencent.com)\n使用cert-manager为Traefik IngressRoute自动签发Let’s Encrypt证书 – 桃又的技术笔记 (taoyouh.cn)\n内网证书\ncert-manager管理内网k8s开发环境证书 - hueidou163 - 博客园 (cnblogs.com)\nSelfSigned - cert-manager (k8s-docs.github.io)\nk8s 使用cert-manager证书管理自签-CSDN博客\nKubernetes (K8S) 中Traefik自动申请证书-腾讯云开发者社区-腾讯云 (tencent.com)\nk8s ingress配置自签名证书，并解决Kubernetes Ingress Controller Fake Certificate-CSDN博客\nK8s &amp; K3s 集群中应用自动签发 Https 证书 - 流雨声 - 博客园 (cnblogs.com)\n","categories":["容器技术"],"tags":["Https证书","Kubernetes","K3s","TLS","cert-manager"]},{"title":"kubectl管理多集群","url":"/2025/08/13/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/kubectl%E7%AE%A1%E7%90%86%E5%A4%9A%E9%9B%86%E7%BE%A4/","content":"1. K3s指定集群管理IP在k3s.service中添加启动参数\n--advertise-address=&lt;192.168.x.x&gt;\n详细参考官方文档以及 K3S安装\n查看当前Context\nkubectl config current-context\n\n2. 配置集群信息查看context列表\nkubectl config get-contexts\n输出中带有*的Context表示当前活动的Context\n切换到指定Context\nkubectl config use-context &lt;context_name&gt;# 示例：切换到dev-ctxkubectl config use-context dev-ctx\n\n 在指定Context中执行命令，一般用于临时使用\nkubectl  --context=&lt;context_name&gt; &lt;exec_cmd&gt;# 示例：在dev-ctx下执行get podskubectl --context=dev-ctx get pods\n\n3. 合并配置文件在 Kubernetes 环境中，使用 kubectl 管理多个集群非常常见。通过配置 kubeconfig 文件，可以轻松切换和管理多个集群。以下是实现方法的详细步骤。\n方法 1: 合并多个配置文件\n\n准备配置文件 假设已有两个集群的配置文件：_&#x2F;.kube&#x2F;config1_ 和 _&#x2F;.kube&#x2F;config2_。\n\n合并配置文件 使用以下命令将多个配置文件合并为一个：\n\n\nKUBECONFIG&#x3D;&#x2F;.kube&#x2F;config1:&#x2F;.kube&#x2F;config2 kubectl config view –merge –flatten &gt; ~&#x2F;.kube&#x2F;config\n\n验证合并结果 查看合并后的配置：\n\nkubectl config view\n方法 2: 配置环境变量\n\n设置环境变量 将多个配置文件路径添加到 KUBECONFIG 环境变量中：\n\nexport KUBECONFIG&#x3D;&#x2F;.kube&#x2F;config:&#x2F;.kube&#x2F;test-config\n\n验证配置 执行以下命令查看所有集群信息：\n\nkubectl config get-contexts\n方法 3: 手动编辑配置文件\n\n打开配置文件 编辑 ~&#x2F;.kube&#x2F;config 文件，将其他集群的 cluster_、_context 和 user 信息粘贴到现有配置中。\n\n格式示例：\n\n\napiVersion: v1clusters:- cluster:server: https://127.0.0.1:6443name: cluster1- cluster:server: https://192.168.0.1:6443name: cluster2contexts:- context:cluster: cluster1user: user1name: context1- context:cluster: cluster2user: user2name: context2current-context: context1\n切换集群上下文\n\n查看当前上下文：\nkubectl config current-context\n\n\n切换到其他上下文：\nkubectl config use-context &lt;context_name&gt;\n最佳实践\n\n使用合并或环境变量的方法更高效，避免手动编辑出错。\n\n定期备份 kubeconfig 文件，防止误操作导致数据丢失。\n\n确保每个集群的访问凭证和权限正确无误。\n\n\n通过以上方法，您可以轻松管理多个 Kubernetes 集群，提高运维效率。\n大家好！在 云原生 的世界里，和 Kubernetes 打交道是家常便饭。如果我们像我一样，需要同时管理多个 Kubernetes 集群——比如一个用于严谨发布的 生产环境 ，一个用于大胆实验的 测试环境 ，甚至还有本地开发环境——那么高效、安全地在它们之间切换就成了必备技能。\n很多朋友（包括我自己有时也会！）可能会因为一段时间没用而忘记 kubectl 中那些用于切换配置的命令。别担心，这很正常！今天，我们就来系统地回顾一下 kubectl 配置管理的核心概念—— 上下文（Context） ，以及如何利用它在不同集群间自如切换。\n核心概念：kubeconfig 文件与上下文（Context）kubectl 的所有配置信息都存储在一个或多个 YAML 文件中，默认情况下是 $HOME/.kube/config 。这个文件我们通常称为 kubeconfig 文件。把它想象成我们的 Kubernetes “护照”，里面记录了我们能访问哪些集群，用什么身份访问。\n一个 kubeconfig 文件通常包含三个主要部分：\n\nClusters（集群） ：定义了我们要连接的 Kubernetes 集群的信息，比如 API Server 的地址和集群的 CA 证书。\nUsers（用户） ：定义了访问集群所使用的凭证，可能是用户名&#x2F;密码、Token 或客户端证书。\nContexts（上下文） ：这是连接 集群 和 用户 的桥梁。一个 Context 定义了使用哪个 User 凭证去访问哪个 Cluster。\n\n关键点： 我们可以通过切换 Context 来改变 kubectl 当前操作的目标集群和使用的身份。\n管理 kubeconfig 的常用 kubectl config 命令kubectl 提供了一套 config 子命令来帮助我们查看和管理 kubeconfig 文件。以下是几个最核心、最常用的命令：\n1. 查看当前配置：kubectl config view这个命令会显示我们当前的 kubeconfig 文件内容（或者合并后的内容，如果我们配置了多个文件）。它会隐藏敏感信息（如证书和 Token 的具体内容），非常适合快速检查配置概览。\nkubectl config viewbash1\n\n如果我们想看某个特定 Context 的详细信息，可以加上 --context 参数：\n# 查看名为 &#x27;prod-cluster&#x27; 的 context 细节kubectl config view --context=prod-clusterbash12\n\n2. 列出所有可用的上下文：kubectl config get-contexts这是 最常用 的命令之一，它会列出我们在 kubeconfig 文件中定义的所有 Context。当前正在使用的 Context 会在名称前用星号 * 标记。\nkubectl config get-contexts# 输出示例：# CURRENT   NAME                 CLUSTER              AUTHINFO             NAMESPACE# * test-cluster         kubernetes-test      user-test#           prod-cluster         kubernetes-prod      user-prod            production#           docker-desktop       docker-desktop       docker-desktopbash123456\n\n从上面的输出可以清晰地看到：\n\n当前激活的 Context 是 test-cluster 。\n还有名为 prod-cluster 和 docker-desktop 的 Context 可供切换。\n\n3. 查看当前使用的上下文：kubectl config current-context如果我们只想快速确认当前 kubectl 命令会作用于哪个 Context（哪个集群），这个命令最直接：\nkubectl config current-context# 输出示例：# test-clusterbash123\n\n4. 切换上下文：kubectl config use-context 这绝对是 核心中的核心 ！当我们需要将 kubectl 的操作目标从一个集群切换到另一个集群时，就使用这个命令。\n假设我们想从当前的 test-cluster 切换到 prod-cluster ：\nkubectl config use-context prod-cluster# 输出示例：# Switched to context &quot;prod-cluster&quot;.bash123\n\n切换成功后，我们可以再次使用 kubectl config current-context 或 kubectl config get-contexts 来验证当前上下文是否已更改。\nkubectl config current-context# 输出示例：# prod-clusterkubectl config get-contexts# 输出示例：# CURRENT   NAME                 CLUSTER              AUTHINFO             NAMESPACE#           test-cluster         kubernetes-test      user-test# * prod-cluster         kubernetes-prod      user-prod            production#           docker-desktop       docker-desktop       docker-desktopbash12345678910\n\n现在，所有后续的 kubectl 命令（如 kubectl get pods, kubectl apply -f ... 等）都会默认发送到 prod-cluster 所定义的集群，并使用 user-prod 的身份进行认证。\n实践场景：在生产和测试集群间切换假设我们的 kubeconfig 文件中已经配置好了代表生产环境和 测试环境 的 Context，可能分别命名为 production 和 testing 。\n我们的日常操作流程可能是这样的：\n\n检查当前在哪： kubectl config current-contextbash1\n 或者看列表： kubectl config get-contextsbash1\n需要操作测试环境： kubectl config use-context testing# 验证一下（可选但推荐）kubectl config current-context# 现在可以对测试环境执行操作了kubectl get pods -n test-namespacebash12345\n需要紧急处理生产环境问题： kubectl config use-context production# 验证一下kubectl config current-context# 操作生产环境（请务必小心！）kubectl get deployment -n critical-appbash12345\n完成生产环境操作，切回测试环境继续工作： kubectl config use-context testingbash1\n\n提升效率的小贴士\n清晰命名 Context ：给我们的 Context 起一个能清晰表明环境和用途的名字，比如 gke-prod-eu, eks-dev-us, local-minikube 等。避免使用模糊不清的名字。\n使用 Shell 别名 ：很多人喜欢为 kubectl 设置别名，比如 alias k=kubectl 。这样我们的命令可以更短： k config get-contexts, k config use-context my-context 。\n考虑使用辅助工具 ：社区有一些流行的小工具可以让我们更方便地切换 Context 和 Namespace，例如：\nkubectx (用于切换 Context)\nkubens (用于切换 Namespace)  这些工具通常提供交互式选择或更简洁的命令，可以显著提高效率。可以通过包管理器（如 Homebrew, apt, yum）或直接下载二进制文件来安装它们。\n\n\n注意 kubeconfig 文件的安全性 ： kubeconfig 文件包含了访问集群的凭证，务必妥善保管，不要泄露给未授权的人员。\n\n总结管理多个 Kubernetes 集群配置并不复杂，核心就在于理解和运用 kubeconfig 文件中的 Context 概念。通过掌握 kubectl config 的几个关键子命令：\n\nview: 查看配置概览\nget-contexts: 列出所有可用上下文\ncurrent-context: 显示当前激活的上下文\nuse-context &lt;context-name&gt;: 切换到指定的上下文\n\n我们就能轻松地在不同的 Kubernetes 环境（如生产和测试）之间安全、高效地切换了。希望这篇回顾能帮我们重新找回操作 kubectl 多集群配置的熟悉感！\n\n\n","categories":["容器技术"]},{"title":"使用Podman替代DockerDesktop","url":"/2025/06/25/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8Podman%E6%9B%BF%E4%BB%A3DockerDesktop/","content":"\n安装依赖环境\n# 启用虚拟化平台dism /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart#　启用linux子系统dism /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /allwsl --installwsl --update\n\n安装Podman \n# 安装DockerCLI，用于兼容Docker命令winget install --id Docker.DockerCLI# 安装Podmanwinget install --id RedHat.Podman# 安装Podman Desktop (可选)winget install --id RedHat.Podman-Desktop # 初始化Podmanpodman machine init # 配置端口转发wsl sudo sysctl net.ipv4.ip_forward=1\n\n配置wsl虚拟机\n# 修改默认软件源sudo sed -e &#x27;s|^metalink=|#metalink=|g&#x27; \\    -e &#x27;s|^#baseurl=http://download.example/pub/fedora/linux|baseurl=https://mirrors.tuna.tsinghua.edu.cn/fedora|g&#x27; \\    -i.bak \\    /etc/yum.repos.d/fedora.repo \\    /etc/yum.repos.d/fedora-updates.reposudo dnf makecache\n\n测试\ndocker run --rm -d -p 80:80 --name httpd docker.io/library/httpd:latest\n配置镜像加速podman的配置文件在容器内 /etc/containers/registries.conf,配置格式如下\nunqualified-search-regustrues = [&quot;docker.io&quot;][[registry]]                      # 注意此处配置不需要加&#x27;https&#x27;prefix = &quot;docker.io&quot;              # 访问地址location = &quot;docker.m.daocloud.io&quot; # 加速地址\n\n配置私有镜像库\n\n\n[[registry]]location = &quot;harbor.example.io&quot;insecure = true\n如果访问地址为https需要配置信任证书\nsudo mkdir /etc/containers/certs.dsudo cp &lt;path to cert&gt; /etc/containers/certs.d/ca.crt\n\n\n配置文件翻译# 有关此配置文件的更多信息，请参阅 containers-registries.conf(5)。## 注意：使用未完全限定镜像名称的风险# 我们建议始终使用包括注册表服务器（完整 DNS 名称）、命名空间、镜像名称和标签在内的完全限定镜像名称# （例如，registry.redhat.io/ubi8/ubi:latest）。通过摘要（例如，# quay.io/repository/name@digest）拉取镜像可以进一步消除标签的不确定性。# 使用短名称时，始终存在镜像被伪造的风险。例如，用户想从某个注册表中拉取名为# `foobar` 的镜像，并期望该镜像来自 myregistry.com。如果# myregistry.com 不是搜索列表中的第一个，攻击者可能会在列表中靠前的位置# 放置另一个名为 `foobar` 的镜像。用户可能会意外拉取并运行攻击者的镜像和代码，而不是# 预期的内容。我们建议只添加完全可信的注册表（即，不允许未知或匿名用户# 创建任意名称的账户的注册表）。这将防止镜像被伪造、抢占或以其他方式变得不安全。# 如果有必要使用这些注册表，它应该添加到列表的末尾。## # 一个主机[:端口]格式的注册表数组，当拉取未完全限定镜像时，按顺序尝试这些注册表。unqualified-search-registries = [&quot;registry.fedoraproject.org&quot;, &quot;registry.access.redhat.com&quot;, &quot;docker.io&quot;]## [[registry]]# # &quot;prefix&quot; 字段用于选择相关的 [[registry]] TOML 表；# # 使用输入镜像名称时，只有与该名称最长匹配的 TOML 表会被使用# # （考虑到命名空间/库/标签/摘要分隔符）。# ## # 如果缺少 prefix 字段，则默认与 &quot;location&quot; 字段相同。prefix = &quot;example.com/foo&quot;## # 如果为 true，则允许未加密的 HTTP 连接以及使用不受信任证书的 TLS 连接。insecure = false## # 如果为 true，则禁止拉取匹配名称的镜像。blocked = false## # &quot;prefix&quot; 所在命名空间的物理位置。# ## # 默认情况下，与 &quot;prefix&quot; 相同（在这种情况下，可以省略 &quot;prefix&quot;，并且 [[registry]] TOML 表只指定 &quot;location&quot;）。# ## # 例如：假设# #   prefix = &quot;example.com/foo&quot;# #   location = &quot;internal-registry-for-example.net/bar&quot;# # 那么对镜像 example.com/foo/myimage:latest 的请求实际上会与# # internal-registry-for-example.net/bar/myimage:latest 镜像匹配。location = &quot;internal-registry-for-example.com/bar&quot;## # &quot;prefix&quot; 所在命名空间的（可能部分的）镜像。# ## # 将按指定顺序尝试这些镜像；第一个可以联系到并包含镜像的将被使用# # （如果所有镜像都没有该镜像，则最后尝试 &quot;registry.location&quot; 字段指定的主位置，或者使用未修改的用户指定引用）。# ## # &quot;mirror&quot; 数组中的每个 TOML 表可以包含以下字段，语义与直接在 [[registry]] TOML 表中指定的相同：# # - location# # - insecure[[registry.mirror]]location = &quot;example-mirror-0.local/mirror-for-foo&quot;[[registry.mirror]]location = &quot;example-mirror-1.local/mirrors/foo&quot;insecure = true# # 根据上述配置，拉取 example.com/foo/image:latest 时将按顺序尝试：# # 1. example-mirror-0.local/mirror-for-foo/image:latest# # 2. example-mirror-1.local/mirrors/foo/image:latest# # 3. internal-registry-for-example.net/bar/image:latest# # 并使用第一个存在的镜像。## short-name-mode=&quot;enforcing&quot;# 强制使用完全限定镜像名称​[[registry]]location=&quot;localhost:5000&quot;insecure=true# 允许使用不安全的连接拉取本地镜像。\n\n","categories":["容器技术"],"tags":["Docker","Podman"]},{"title":"制作Helm镜像","url":"/2024/07/22/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/%E5%88%B6%E4%BD%9CHelm%E9%95%9C%E5%83%8F/","content":"Helm 从入门到实践 | 从 0 开始制作一个 Helm Charts-CSDN博客\n","categories":["容器技术"],"tags":["Helm"]},{"title":"KubeEdge设备孪生设计","url":"/2024/07/04/%E6%95%B0%E6%8D%AE%E5%BA%93/KubeEdge%E8%AE%BE%E5%A4%87%E5%AD%AA%E7%94%9F%E8%AE%BE%E8%AE%A1/","content":"KubeEdge中的数据结构设计\nDevice\n\n\n\n字段\n类型\n说明\n\n\n\nID\nstring\n设备唯一编码\n\n\nName\nstring\n设备名称\n\n\nDescription\nstring\n设别描述\n\n\nState\nstring\n设备状态\n\n\nLastOnline\nDateTime\n最后在线时间\n\n\nAttributes\nMap&lt;string,MsgAttr&gt;\n设备属性(上报属性)\n\n\nTwin\nMap&lt;string,MsgTwin&gt;\n设备孪生属性(可控制属性)\n\n\nMsgAttr\n\n\n\n字段\n类型\n说明\n\n\n\nValue\nstring\n属性名称\n\n\nOptional\nbool\n是否可为空\n\n\nMetadata\nTypeMetadata\n属性类型元数据\n\n\nMsgTwin\n\n\n\n字段\n类型\n说明\n\n\n\nExpected\nTwinValue\n期望值\n\n\nActual\nTwinValue\n实际值\n\n\nOptional\nbool\n是否可为空\n\n\nMetadata\nTypeMetadata\n属性类型元数据\n\n\nExpectedVersion\nTwinVersion\n期望值版本\n\n\nActualVersion\nTwinVersion\n实际值版本\n\n\n\n数据库表设计\nDevice\n\n\n\n字段\n类型\n说明\n\n\n\nID\n\n设备实例唯一ID\n\n\nName\n\n设备实例名称\n\n\nDescription\n\n设备描述\n\n\nState\n\n设备状态\n\n\nLastOnline\n\n最后在线时间\n\n\nDeviceAttr\n\n\n\n字段\n类型\n说明\n\n\n\nID\n\n属性实例唯一ID\n\n\nDeviceId\n\n设备实例唯一ID\n\n\nName\n\n设备名称\n\n\nDescription\n\n设备描述\n\n\nValue\n\n设备属性值\n\n\nOptional\nbool\n是否可空\n\n\nAttrType\n\n属性类型\n\n\nMetadata\n\n属性元数据\n\n\nDeviceTwin\n\n\n\n字段\n类型\n说明\n\n\n\nID\n\n\n\n\nDeviceID\n\n\n\n\nName\n\n\n\n\nDescription\n\n\n\n\nExpected\n\n\n\n\nActual\n\n\n\n\nExpectedMeta\n\n\n\n\nActualMeta\n\n\n\n\nExpectedVersion\n\n\n\n\nActualVersion\n\n\n\n\nOptional\n\n\n\n\nAttrType\n\n\n\n\nMetadata\n\n\n\n\n","categories":["数据库"],"tags":["数字孪生","KubeEdge"]},{"title":"国内常用源镜像地址","url":"/2024/04/01/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/%E5%9B%BD%E5%86%85%E5%B8%B8%E7%94%A8%E6%BA%90%E9%95%9C%E5%83%8F%E5%9C%B0%E5%9D%80/","content":"Linux 源清华 https://mirrors.tuna.tsinghua.edu.cn\n阿里 http://mirrors.aliyun.com\n腾讯 https://mirrors.tencent.com\n华为 https://mirrors.huaweicloud.com\n中国科技大学 https://mirrors.ustc.edu.cn\n华中科技大学 http://mirror.hust.edu.cn\nDocker 镜像仓库DockerHub(docker.io)网易 http://hub-mirror.c.163.com\n中国科技大学 https://docker.mirrors.ustc.edu.cn  (不可用)\n道客 https://docker.m.daocloud.cn (参考官方文档)\n腾讯 https://mirror.ccs.tencentyun.com\n华为 https://mirror.swr.myhuaweicloud.com\n阿里云 https://registry.cn-hangzhou.aliyuncs.com\n[^注]: 阿里可申请私有加速，需注册账号,注册后地址修改为 https:&#x2F;&#x2F;{私有ID}.mirror.aliyuncs.com。详细信息参考官方文档\n谷歌镜像仓库(gcr.io k8s.gcr.io)阿里 https://registry.aliyuncs.com/google_containers\n中科大 https://gcr.mirrors.ustc.edu.cn (2022.8之后不再更新镜像,校外访问返回403)\n华为 https://mirror.swr.myhuaweicloud.com\n道客 https://m.daocloud.io/k8s.gcr.io 文档\nCoreOS镜像仓库(quay.io )道客 https://m.daocloud.io/quay.io 参考支持镜像列表\nGithub镜像仓库(ghcr.io )道客 https://m.daocloud.io/ghcr.io 参考支持镜像列表\nHelm 源ArtifactHub https://artifacthub.io/\n华为 https://mirrors.huaweicloud.com/helm/\nbitnami https://charts.bitnami.com/bitnami\nGoogle https://gcr.io/kubernetes-helm\n容器配置Docker(&#x2F;etc&#x2F;docker&#x2F;daemon.json )\n&#123;  &quot;registry-mirrors&quot;: [      &quot;https://registry.docker-cn.com&quot;,      &quot;https://docker.mirrors.ustc.edu.cn&quot;,      &quot;http://hub-mirror.c.163.com&quot;  ],    &quot;insecure-registries&quot;: [],    &quot;exec-opts&quot;:[&quot;native.cgroupdriver=systemd&quot;]&#125;\n\nContainerd(&#x2F;etc&#x2F;containerd&#x2F;config.toml)\n[plugins.cri.registry][plugins.cri.registry.mirrors][plugins.cri.registry.mirrors.&quot;quay.io&quot;]endpoint = [&quot;https://quay.tencentcloudcr.com&quot;][plugins.cri.registry.mirrors.&quot;docker.io&quot;]endpoint = [&quot;https://mirror.ccs.tencentyun.com&quot;]\n\nK3s中Containerd容器(&#x2F;var&#x2F;lib&#x2F;rancher&#x2F;k3s&#x2F;agent&#x2F;etc&#x2F;containerd&#x2F;config.toml)\nK3s 默认的 containerd 配置文件目录为&#x2F;var&#x2F;lib&#x2F;rancher&#x2F;k3s&#x2F;agent&#x2F;etc&#x2F;containerd&#x2F;config.toml，但直接操作 containerd 的配置文件去设置镜像仓库或加速器相比于操作 docker 要复杂许多。K3s 为了简化配置 containerd 镜像仓库的复杂度，K3s 会在启动时检查&#x2F;etc&#x2F;rancher&#x2F;k3s&#x2F;中是否存在  文件，如果存在该文件，就会根据 registries.yaml 的内容转换为 containerd 的配置并存储到&#x2F;var&#x2F;lib&#x2F;rancher&#x2F;k3s&#x2F;agent&#x2F;etc&#x2F;containerd&#x2F;config.toml，从而降低了配置 containerd 镜像仓库的复杂度。\nmirrors:  &quot;172.31.6.200:5000&quot;:    endpoint:      - &quot;http://172.31.6.200:5000&quot;  &quot;rancher.ksd.top:5000&quot;:    endpoint:      - &quot;http://172.31.6.200:5000&quot;  &quot;docker.io&quot;:    endpoint:      - &quot;https://fogjl973.mirror.aliyuncs.com&quot;      - &quot;https://registry-1.docker.io&quot;\n\ncontainerd 与 docker 都有默认仓库，并且都为 docker.io。如果配置中未指定 mirror 为 docker.io，重启 containerd 后会自动加载 docker.io 配置。与 docker 不同的是，containerd 可以修改 docker.io 对应的 endpoint（ 默认为 https://registry-1.docker.io ），而 docker 无法修改。\ndocker 中可以通过 registry-mirrors 设置镜像加速地址。如果 pull 的镜像不带仓库地址（项目名+镜像名:tag），则会从默认镜像仓库去拉取镜像。如果配置了镜像加速地址，会先访问镜像加速仓库，如果没有返回数据，再访问默认吧镜像仓库。\nk3s完整配置文件\nmirrors:  &quot;192.168.50.119&quot;:    endpoint:      - &quot;http://192.168.50.119&quot;  &quot;docker.io&quot;:    endpoint:      - &quot;https://7bezldxe.mirror.aliyuncs.com&quot;      - &quot;https://registry-1.docker.io&quot;configs:  &quot;192.168.50.119&quot;:    auth:      username: &#x27;&#x27; # this is the registry username      password: &#x27;&#x27; # this is the registry password    tls:      cert_file: &#x27;&#x27; # path to the cert file used in the registry      key_file: &#x27;&#x27; # path to the key file used in the registry      ca_file: &#x27;&#x27; # path to the ca file used in the registry  &quot;docker.io&quot;:    auth:      username: &#x27;&#x27; # this is the registry username      password: &#x27;&#x27; # this is the registry password    tls:      cert_file: &#x27;&#x27; # path to the cert file used in the registry      key_file: &#x27;&#x27; # path to the key file used in the registry      ca_file: &#x27;&#x27; # path to the ca file used in the registry\n\n\n\n\n\n镜像转换\n#gcr.iodocker pull gcr.io/kubernetes-helm/tiller:v2.16.1docker pull gcr.mirrors.ustc.edu.cn/kubernetes-helm/tiller:v2.16.1#k8s.gcr.io#docker pull k8s.gcr.io/kube-proxy:v1.15.5docker pull gcr.mirrors.ustc.edu.cn/google-containers/kube-proxy:v1.15.5#quay.iodocker pull quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.26.1docker pull quay.mirrors.ustc.edu.cn/kubernetes-ingress-controller/nginx-ingress-controller:0.26.1\n\n\n转换为gcr.io镜像\ndocker pull registry.aliyuncs.com/google_containers/coredns:1.6.5docker tag registry.aliyuncs.com/google_containers/coredns:1.6.5 k8s.gcr.io/coredns:1.6.5docker rmi registry.aliyuncs.com/google_containers/coredns:1.6.5\nK8S批量下载docker images\nkubeadm config images list\n\n#!/bin/bashimages=(  # 下面的镜像应该去除&quot;k8s.gcr.io/&quot;的前缀，版本换成上面获取到的版本    kube-apiserver:v1.12.1    kube-controller-manager:v1.12.1    kube-scheduler:v1.12.1    kube-proxy:v1.12.1    pause:3.1    etcd:3.2.24    coredns:1.2.2)for imageName in $&#123;images[@]&#125; ; do    docker pull registry.aliyuncs.com/google_containers/$imageName    docker tag registry.aliyuncs.com/google_containers/$imageName k8s.gcr.io/$imageName    docker rmi registry.aliyuncs.com/google_containers/$imageNamedone\n\n更新版\n#!/bin/bashurl=registry.aliyuncs.comversion=v1.16.4images=(`kubeadm config images list --kubernetes-version=$version|awk -F &#x27;/&#x27; &#x27;&#123;print $2&#125;&#x27;`)for imagename in $&#123;images[@]&#125; ; do  docker pull $url/$imagename  docker tag $url/$imagename k8s.gcr.io/$imagename  docker rmi -f $url/$imagenamedone\n\n\n或(V1.3以上)\nkubeadm init --image-repository registry.aliyuncs.com/google_containers \\--kubernetes-version v1.13.0 --pod-network-cidr 192.168.1.100/24\n\n\n","categories":["容器技术"],"tags":["Linux软件源","DockerHub镜像"]},{"title":"设备孪生表结构设计","url":"/2024/07/04/%E6%95%B0%E6%8D%AE%E5%BA%93/%E8%AE%BE%E5%A4%87%E5%AD%AA%E7%94%9F%E8%A1%A8%E7%BB%93%E6%9E%84%E8%AE%BE%E8%AE%A1/","content":"DEVICE\n\n\n\n字段\n类型\n说明\n\n\n\nID\nint\n自增ID\n\n\nSN\nvarchar(20)\n设备唯一编码\n\n\nNAME\nvarchar(20)\n设备名称\n\n\nMARKED\nBOOL\n设备是否标记\n\n\nIP\nvarchar(15)\n设备IP地址\n\n\nLOCATION\nvarchar(200)\n设备安装位置\n\n\nDEVICE_ATTR\n\n\n\n字段\n类型\n说明\n\n\n\nID\nint\n自增ID\n\n\nKEY\nvarchar(20)\n属性名\n\n\nCHANNEL\n\n\n\n\nVALUE\nint\n属性值\n\n\nDEVICE_ID\nint\n属性所属设备ID\n\n\nSCALE\nint\n缩放倍率，当数值有小数时可用倍率缩放\n\n\nUNIT\nvarchar(20)\n数值单位\n\n\nDEVICE_STATE\n\n\n\n字段\n类型\n说明\n\n\n\nID\nint\n自增ID\n\n\nDEVICE_ID\nint\n属性所属设备ID\n\n\nPORT\nint\n设备接收端口\n\n\nVALUE\nint\n数值\n\n\nUNIT\nvarchar(20)\n数值单位\n\n\nDEVICE_LINKAGE\n\n\n\n字段\n类型\n说明\n\n\n\nID\nint\n自增ID\n\n\nCAT\n\n\n\n\nDEVICE_ID\nint\n属性所属设备ID\n\n\nPORT\nint\n设备接收端口\n\n\nTARGET\n\n联动目标\n\n\nTRIGGER\n\n联动触发器\n\n\nTRIGGER_ALARM\n\n联动触发告警\n\n\nACTION\n\n联动动作\n\n\nPARAM\n\n参数\n\n\nDEVICE_ALARM\n\n\n\n字段\n类型\n说明\n\n\n\nID\n\n自增ID\n\n\nAPP_ID\n\n固件ID\n\n\nCAT\n\n\n\n\nREPORTER\n\n\n\n\nPORT\n\n端口\n\n\nCODE\n\n编码\n\n\nMSG\n\n消息\n\n\nALARM_TYPE\n\n告警类型\n\n\nSEVERITY\n\n\n\n\nSTATUS\n\n状态\n\n\n","categories":["数据库"],"tags":["数字孪生"]},{"title":"FRP配置","url":"/2023/07/07/%E6%9D%82%E9%A1%B9/FRP%E9%85%8D%E7%BD%AE/","content":"服务端配置[common]# TCP通信端口bind_port = 7000 #UDP通信端口bind_udp_port = 7001# 最大连接数max_pool_count = 50# 仪表板界面配置dashboard_port=7500dashboard_user=admindashboard_pwd=admin# 允许使用的端口号,可以指定范围也可以用‘，’分割allow_ports = 18081-18090,8080\n\n服务端开机自启配置sudo vim /etc/systemd/system/frps.servicesudo systemctl enable frps.servicesudo systemctl start frps.service\n\n启动文件\n[Unit]Description = Frp Server ServiceAfter = network.target[Service]Type = simpleUser = nobodyRestart = on-failureRestartSec = 5sExecStart = /usr/local/bin/frps -c /usr/local/etc/frp/frps.ini[Install]WantedBy = multi-user.target\n\n\n\n客户端配置[common]#替换IP地址为服务端IPserver_addr=0.0.0.0server_port=7000# windows远程桌面[rdp]type=tcp# 映射IPlocal_ip=127.0.0.1 # 映射端口（本地）local_port=3389# 远程端口（服务器）注意端口要在允许端口内切未被占用remote_port=18087\n\n","categories":["杂项"],"tags":["环境搭建"]},{"title":"公司常见后缀的含义","url":"/2025/05/30/%E6%9D%82%E9%A1%B9/%E5%85%AC%E5%8F%B8%E5%B8%B8%E8%A7%81%E5%90%8E%E7%BC%80%E7%9A%84%E5%90%AB%E4%B9%89/","content":"1. Co., Ltd.\n全称：Company Limited\n含义：有限责任公司，常见于英国、中国及亚洲地区\n特点：”Co.“为Company缩写，”.“表示缩写符号，”,”用于分隔前后词\n\n2. Inc.\n全称：Incorporated\n含义：股份有限公司，多用于美国、加拿大\n示例：Apple Inc.，强调股东责任限于股份投资\n\n3. LLC\n全称：Limited Liability Company\n含义：有限责任公司（美国特有形式）\n特点：兼具合伙制灵活性与股份制有限责任，如Google LLC\n\n4. GmbH\n全称：Gesellschaft mit beschränkter Haftung\n含义：有限责任公司，德国及德语区专用\n示例：Bosch GmbH1\n\n5. AG\n全称：Aktiengesellschaft\n含义：股份有限公司，德国及瑞士常见\n示例：BMW AG\n\n6. S.A.- 全称：Société Anonyme（法）/Sociedad Anónima（西）\n- 含义：股份有限公司，流行于法国、西班牙等拉丁语系国家\n- 示例：L’Oréal S.A.1\n\n7. Plc\n全称：Public Limited Company\n含义：公众有限公司（英国上市企业专用）\n示例：HSBC Holdings plc1\n\n8. 株式会社（Kabushiki Kaisha）\n缩写：KK\n含义：日本股份有限公司\n示例：Toyota Motor Corporation KK\n\n地域差异提示：\n\n英国”Ltd.”与美国”LLC”虽均表有限责任，但法律结构不同\n荷兰用”BV”（私人有限公司），意大利用”S.p.A.”（股份公司）\n\n","categories":["杂项"]},{"title":"FFmpeg mp3转pcm","url":"/2022/06/24/%E6%9D%82%E9%A1%B9/ffmpeg-mp3%E8%BD%ACpcm/","content":"大端数据格式\nffmpeg -i test.mp3 -f s16be -ar 16000 -ac 1 -acodec pcm_s16be pcm16k.pcm\n\n小端数据格式\nffmpeg -i test.mp3 -f s16le -ar 16000 -ac 1 -acodec pcm_s16le pcm16k.pcm\n\n说明:\n\n-acodec pcm_s16be：输出pcm格式，采用signed 16编码，字节序为大尾端（小尾端为le)；\n-ar 16000: 采样率为16000\n-ac 1: 声道数为1\n\n","categories":["杂项"],"tags":["FFmp"]},{"title":"在CMD命令行中切换到管理员权限模式","url":"/2018/06/10/%E6%9D%82%E9%A1%B9/%E5%9C%A8CMD%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%AD%E5%88%87%E6%8D%A2%E5%88%B0%E7%AE%A1%E7%90%86%E5%91%98%E6%9D%83%E9%99%90%E6%A8%A1%E5%BC%8F/","content":"方式1：\n搜索CMD Ctrl+Shift+Enter\n方式2：\n打开CMD，输入\nrunas /noprofile /user:Administrator cmd\n\n输入Administrator账户的密码\n\nrunas 允许用户用其他权限运行指定的工具和程序\n&#x2F;noprofile 指定不加载用户的配置文件\n&#x2F;user:UserAccountName 指定在其下运行程序的账户\n\n常见问题\n运行runas 指令输入密码报错“无法启动服务，原因可能是已被禁用或与其关联的设备没有启动。”\n这是因为“Secondary Logo”服务没有启动，这个服务是”在不同凭据下启用启动过程“。直接在cmd中输入services.msc,将服务从禁用改为手动就好了，之后再次输入runas命令就可以使用administrator账户运行。\n","categories":["杂项"]},{"title":"物联网国标","url":"/2022/11/01/%E6%9D%82%E9%A1%B9/%E7%89%A9%E8%81%94%E7%BD%91%E5%9B%BD%E6%A0%87/","content":"GB&#x2F;T 35134-2017  物联网智能家居 设备描述方法\nGB&#x2F;T 35143-2017  物联网智能家居 数据和设备编码\nGB&#x2F;T 35317-2017 公安物联网系统信息安全等级保护要求\nGB&#x2F;T 35318-2017 公安物联网感知终端安全防护技术要求\nGB&#x2F;T 35319-2017  物联网 系统接口要求\nGB&#x2F;T 35419-2017  物联网标识体系 Ecode在一维条码中的存储\nGB&#x2F;T 35420-2017  物联网标识体系 Ecode在二维码中的存储\nGB&#x2F;T 35421-2017  物联网标识体系 Ecode在射频标签中的存储\nGB&#x2F;T 35422-2017  物联网标识体系 Ecode的注册与管理\nGB&#x2F;T 35423-2017  物联网标识体系 Ecode在NFC标签中的存储\nGB&#x2F;T 35592-2017  公安物联网感知终端接入安全技术要求\nGB&#x2F;T 35136-2017  智能家居自动控制设备通用技术要求\nGB&#x2F;T 35255-2017  LED公共照明智能系统接口应用层通信协议\nGB&#x2F;T 35291-2017  信息安全技术 智能密码钥匙应用接口规范\nGB&#x2F;T 30269.502-2017  信息技术 传感器网络 第502部分：标识：传感节点标识符解析\nGB&#x2F;T 30269.602-2017  信息技术 传感器网络 第602部分：信息安全：低速率无线传感器网络网络层和应用支持子层安全规范\nGB&#x2F;T 30269.801-2017  信息技术 传感器网络 第801部分：测试：通用要求\nGB&#x2F;T 30269.803-2017  信息技术 传感器网络 第803部分：测试：低速无线传感器网络网络层和应用支持子层\nGB&#x2F;T 35129-2017  面向食品制造业的射频识别系统 环境适应性要求\nGB&#x2F;T 35130-2017  面向食品制造业的射频识别系统 射频标签信息与编码规范\nGB&#x2F;T 35135-2017  面向食品制造业的射频识别系统 应用要求\nGB&#x2F;T 17626.6-2017  电磁兼容 试验和测量技术 射频场感应的传导骚扰抗扰度\nGB&#x2F;T 35290-2017  信息安全技术 射频识别（RFID）系统通用安全技术要求\nGB&#x2F;T 35120-2017  制造过程物联的数字化模型信息交换规范\nGB&#x2F;T 35122-2017  制造过程物联的数字化模型信息表达规范\nGB&#x2F;T 35128-2017  集团企业经营管理信息化核心构件\nGB&#x2F;T 34966.1-2017  卫星导航增强信息互联网传输 第1部分：播发体制\nGB&#x2F;T 34966.2-2017  卫星导航增强信息互联网传输 第2部分：接口要求\nGB&#x2F;T 34966.3-2017  卫星导航增强信息互联网传输 第3部分：数据传输格式\nGB&#x2F;T 35403.1-2017  国家物品编码与基础信息通用规范 第1部分：总体框架\nGB&#x2F;T 35589-2017  信息技术 大数据 技术参考模型\n","categories":["杂项"],"tags":["国标"]},{"title":"解决SuperMicro主板风扇转速过低告警","url":"/2023/07/10/%E6%9D%82%E9%A1%B9/%E8%A7%A3%E5%86%B3SuperMicro%E4%B8%BB%E6%9D%BF%E9%A3%8E%E6%89%87%E8%BD%AC%E9%80%9F%E8%BF%87%E4%BD%8E%E5%91%8A%E8%AD%A6/","content":"解决SuperMicro主板风扇转速过低告警现象 系统启动后风扇忽高忽低，进入IPMI后台可以看到，看到传感器日志里大量的告警\n \n 造成此问题的原因是风扇转速过低，触发了超微的风扇转速允许的下限，从而强制满速运转，而在满速后主板又很快发现没有问题，且此时温度较低，风扇开始降速，直到降速到下限以下，重复此过程。\n在进入IPMI后台管理界面后风扇速度有四种智能模式可调\n\nStandard: zone0和zone1 风速为50%\n\nOptimal: 风速为30%\n\nFull: 风速为100%\n\nHeavy IO: zone0 为50%，zone1 为75%\n\n\n\n解决方法1. 在服务器上安装IPMItoolapt install ipmitool # Ubuntu/Debian指令yum install ipmitool # CentOS指令\n\n\n\n2. 设置风扇转速# 风扇名可以看告警里边的对应风扇名ipmitool sensor thresh FAN1 lower 100 125 125ipmitool sensor thresh FANA lower 100 125 125\n\n3. Windows 下远程操作IPMIipmitool windows 版 下载地址\nipmitool -H [IPMI网口IP地址] -U [IMPI账户] -P [IPMI密码] sensor thresh FAN1 lower 100 125 125ipmitool -H [IPMI网口IP地址] -U [IMPI账户] -P [IPMI密码] sensor thresh FANA lower 100 125 125\n\n\n\n问题如果你运行上面的命令后，风扇转速回落后马上又返回原样，这表明服务器的自动调速覆盖了你手动设置的转速。你需要切换服务器风扇策略为全速（Full Speed），在这个策略下服务器不会使用自动调节转速，因此也不会覆盖你手动设置的转速。\n运行下面的命令切换到全速模式（也可以进入IPMI界面调整）：\nipmitool -H [IPMI网口IP地址] -U [IMPI账户] -P [IPMI密码] 0x30 0x45 0x01 0x01# 最后一个0x01表示全速模式。如果为0x00则表示标准（Standard）；0x02表示最优（Optimal）\n\n\n\n参考1.解决超微 SuperMicro 主板风扇反复高低转速问题 - 哔哩哔哩 (bilibili.com)\n超微服务器Supermicro X9&#x2F;X10&#x2F;X11设置风扇转速 - 辰宸的备忘录 (licc.tech)\nipmitool常用命令详解_ipmitool lan set_owlcity123的博客-CSDN博客\n","categories":["杂项"],"tags":["超微","SuperMicro","转速过低告警"]},{"title":"解决QDebug打印中文乱码问题","url":"/2025/09/10/%E6%9D%82%E9%A1%B9/%E8%A7%A3%E5%86%B3QDebug%E6%89%93%E5%8D%B0%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98/","content":"在使用 Qt 开发时，qDebug 打印包含中文的 QString 可能会出现乱码。这通常是由于字符编码不一致导致的。\n#include &lt;QDebug&gt;#include &lt;QTextCodec&gt;#include &lt;Windows.h&gt;int main() &#123;\t//设置QTextCodec\tQTextCodec *codec = QTextCodec::codecForName(&quot;UTF-8&quot;);\tQTextCodec::setCodecForLocale(codec);\t\t// 将字符串转换为 UTF-8 编码，然后再传递给 qDebug 打印。\tqDebug() &lt;&lt; QString::fromUtf8(u8&quot;你好，世界！&quot;);\treturn 0;&#125;\n\n"},{"title":"阵列卡接口型号","url":"/2024/09/23/%E6%9D%82%E9%A1%B9/%E9%98%B5%E5%88%97%E5%8D%A1%E6%8E%A5%E5%8F%A3%E5%9E%8B%E5%8F%B7/","content":"接口型号SFF SAS接口_8087接口-CSDN博客\n","categories":["杂项"],"tags":["阵列卡"]},{"title":"C语言学习笔记-1","url":"/2023/09/08/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/C%E8%AF%AD%E8%A8%80/C%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/","content":"","categories":["学习笔记","C语言"],"tags":["C语言"]},{"title":"GoLang学习笔记","url":"/2025/03/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Golang/Golang%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/","content":"","categories":["学习笔记","Golang"],"tags":["学习笔记","Golang"]},{"title":"Python学习笔记-1","url":"/2025/03/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Python/Python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/","content":"","categories":["学习笔记","Python"],"tags":["学习笔记","Python"]},{"title":"Qt学习笔记-1","url":"/2025/03/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Qt/Qt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/","content":"","categories":["学习笔记","Qt"],"tags":["学习笔记","Golang"]},{"title":"8种主要排序算法的CSharp实现","url":"/2019/11/30/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/8%E7%A7%8D%E4%B8%BB%E8%A6%81%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E7%9A%84C%E5%AE%9E%E7%8E%B0/","content":"8种主要排序算法的C#实现\nExcerpt8种主要排序算法的实现及优化，包含选择排序，冒泡排序，插入排序，快速排序，归并排序，堆排序，希尔排序，基数排序。文末实际测试并比较。\n\n\n新的一年到了，很多园友都辞职要去追求更好的工作环境，我也是其中一个，呵呵！\n最近闲暇的时候我开始重温一些常用的算法。老早就买了《算法导论》，一直都没啃下去。\n这本书确实很好，只是太难读了，总是读了几章就又读不下去了！工作上也几乎用不到。\n我这段时间发现看这些排序算法比以前容易了很多，就借此机会将它们整理总结起来。\n一是方便以后重温，二是可以应对笔试面试。同时也希望这篇博文可以帮助各位刚辞职和正在学习排序算法的园友。\nPS：有可能实现的代码并不是最优的，如果有什么错误或者值得改进的地方，还请大家帮忙指出。\n简介排序算法是我们编程中遇到的最多的算法。目前主流的算法有8种。\n  平均时间复杂度从高到低依次是：\n     冒泡排序（o(n2)），选择排序（o(n2)），插入排序（o(n2)），堆排序（o(nlogn)），\n     归并排序（o(nlogn)），快速排序（o(nlogn)）， 希尔排序（o(n1.25)），基数排序（o(n)）\n这些平均时间复杂度是参照维基百科排序算法罗列的。\n是计算的理论平均值，并不意味着你的代码实现能达到这样的程度。\n例如希尔排序，时间复杂度是由选择的步长决定的。基数排序时间复杂度最小，\n但我实现的基数排序的速度并不是最快的，后面的结果测试图可以看到。\n本文代码实现使用的数据源类型为IList，这样可以兼容int[]和List(虽然int[]有ToList()，\nList有ToArray()，哈哈！)。\n选择排序选择排序是我觉得最简单暴力的排序方式了。\n以前刚接触排序算法的时候，感觉算法太多搞不清，唯独记得选择排序的做法及实现。\n原理：找出参与排序的数组最大值，放到末尾（或找到最小值放到开头） 维基入口\n实现如下：\n\n&lt;span&gt; 1&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; SelectSort(IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&lt;span&gt; data)&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;             &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;0&lt;/span&gt;; i &amp;lt; data.Count - &lt;span&gt;1&lt;/span&gt;; i++&lt;span&gt;)&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;                 &lt;span&gt;int&lt;/span&gt; min =&lt;span&gt; i;&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;                 &lt;span&gt;int&lt;/span&gt; temp =&lt;span&gt; data[i];&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;                 &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; j = i + &lt;span&gt;1&lt;/span&gt;; j &amp;lt; data.Count; j++&lt;span&gt;)&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; &lt;span&gt;                &#123;&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;                     &lt;span&gt;if&lt;/span&gt; (data[j] &amp;lt;&lt;span&gt; temp)&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; &lt;span&gt;                    &#123;&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;                         min =&lt;span&gt; j;&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;                         temp =&lt;span&gt; data[j];&lt;/span&gt;&lt;span&gt;13&lt;/span&gt; &lt;span&gt;                    &#125;&lt;/span&gt;&lt;span&gt;14&lt;/span&gt; &lt;span&gt;                &#125;&lt;/span&gt;&lt;span&gt;15&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (min !=&lt;span&gt; i)&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; &lt;span&gt;                    Swap(data, min, i);&lt;/span&gt;&lt;span&gt;17&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;         &#125;\n\n\n过程解析：将剩余数组的最小数交换到开头。\n冒泡排序冒泡排序是笔试面试经常考的内容，虽然它是这些算法里排序速度最慢的（汗），后面有测试为证。\n原理：从头开始，每一个元素和它的下一个元素比较，如果它大，就将它与比较的元素交换，否则不动。\n这意味着，大的元素总是在向后慢慢移动直到遇到比它更大的元素。所以每一轮交换完成都能将最大值\n冒到最后。  维基入口\n实现如下：\n\n&lt;span&gt; 1&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; BubbleSort(IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&lt;span&gt; data)&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;             &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = data.Count - &lt;span&gt;1&lt;/span&gt;; i &amp;gt; &lt;span&gt;0&lt;/span&gt;; i--&lt;span&gt;)&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;                 &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; j = &lt;span&gt;0&lt;/span&gt;; j &amp;lt; i; j++&lt;span&gt;)&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; &lt;span&gt;                &#123;&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;                     &lt;span&gt;if&lt;/span&gt; (data[j] &amp;gt; data[j + &lt;span&gt;1&lt;/span&gt;&lt;span&gt;])&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;                         Swap(data, j, j + &lt;span&gt;1&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt; &lt;span&gt;                &#125;&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;         &#125;\n\n\n过程解析：中需要注意的是j&lt;i，每轮冒完泡必然会将最大值排到数组末尾，所以需要排序的数应该是在减少的。\n很多网上版本每轮冒完泡后依然还是将所有的数进行第二轮冒泡即j&lt;data.Count-1，这样会增加比较次数。\n通过标识提升冒泡排序在维基上看到，可以通过添加标识来分辨剩余的数是否已经有序来减少比较次数。感觉很有意思，可以试试。\n实现如下：\n\n&lt;span&gt; 1&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; BubbleSortImprovedWithFlag(IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&lt;span&gt; data)&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;             &lt;span&gt;bool&lt;/span&gt;&lt;span&gt; flag;&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;             &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = data.Count - &lt;span&gt;1&lt;/span&gt;; i &amp;gt; &lt;span&gt;0&lt;/span&gt;; i--&lt;span&gt;)&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;                 flag = &lt;span&gt;true&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;                 &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; j = &lt;span&gt;0&lt;/span&gt;; j &amp;lt; i; j++&lt;span&gt;)&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; &lt;span&gt;                &#123;&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;                     &lt;span&gt;if&lt;/span&gt; (data[j] &amp;gt; data[j + &lt;span&gt;1&lt;/span&gt;&lt;span&gt;])&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; &lt;span&gt;                    &#123;&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;                         Swap(data, j, j + &lt;span&gt;1&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;                         flag = &lt;span&gt;false&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;13&lt;/span&gt; &lt;span&gt;                    &#125;&lt;/span&gt;&lt;span&gt;14&lt;/span&gt; &lt;span&gt;                &#125;&lt;/span&gt;&lt;span&gt;15&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (flag) &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;17&lt;/span&gt;         &#125;\n\n\n过程解析：发现某轮冒泡没有任何数进行交换（即已经有序），就跳出排序。\n我起初也以为这个方法是应该有不错效果的，可是实际测试结果并不如想的那样。和未优化耗费时间一样（对于随机数列）。\n由果推因，那么应该是冒泡排序对于随机数列，当剩余数列有序的时候，也没几个数要排列了！？\n不过如果已经是有序数列或者部分有序的话，这个冒泡方法将会提升很大速度。\n鸡尾酒排序（来回排序）对冒泡排序进行更大的优化冒泡排序只是单向冒泡，而鸡尾酒来回反复双向冒泡。\n原理：自左向右将大数冒到末尾，然后将剩余数列再自右向左将小数冒到开头，如此循环往复。维基入口\n实现如下：\n\n&lt;span&gt; 1&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; BubbleCocktailSort(IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&lt;span&gt; data)&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;             &lt;span&gt;bool&lt;/span&gt;&lt;span&gt; flag;&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; m = &lt;span&gt;0&lt;/span&gt;, n = &lt;span&gt;0&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;             &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = data.Count - &lt;span&gt;1&lt;/span&gt;; i &amp;gt; &lt;span&gt;0&lt;/span&gt;; i--&lt;span&gt;)&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;                 flag = &lt;span&gt;true&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (i % &lt;span&gt;2&lt;/span&gt; == &lt;span&gt;0&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt; &lt;span&gt;                &#123;&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;                     &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; j = n; j &amp;lt; data.Count - &lt;span&gt;1&lt;/span&gt; - m; j++&lt;span&gt;)&lt;/span&gt;&lt;span&gt;11&lt;/span&gt; &lt;span&gt;                    &#123;&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;                         &lt;span&gt;if&lt;/span&gt; (data[j] &amp;gt; data[j + &lt;span&gt;1&lt;/span&gt;&lt;span&gt;])&lt;/span&gt;&lt;span&gt;13&lt;/span&gt; &lt;span&gt;                        &#123;&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;                             Swap(data, j, j + &lt;span&gt;1&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;&lt;span&gt;15&lt;/span&gt;                             flag = &lt;span&gt;false&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; &lt;span&gt;                        &#125;&lt;/span&gt;&lt;span&gt;17&lt;/span&gt; &lt;span&gt;                    &#125;&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;                     &lt;span&gt;if&lt;/span&gt; (flag) &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;19&lt;/span&gt;                     m++&lt;span&gt;;&lt;/span&gt;&lt;span&gt;20&lt;/span&gt; &lt;span&gt;                &#125;&lt;/span&gt;&lt;span&gt;21&lt;/span&gt;                 &lt;span&gt;else&lt;/span&gt;&lt;span&gt;22&lt;/span&gt; &lt;span&gt;                &#123;&lt;/span&gt;&lt;span&gt;23&lt;/span&gt;                     &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; k = data.Count - &lt;span&gt;1&lt;/span&gt; - m; k &amp;gt; n; k--&lt;span&gt;)&lt;/span&gt;&lt;span&gt;24&lt;/span&gt; &lt;span&gt;                    &#123;&lt;/span&gt;&lt;span&gt;25&lt;/span&gt;                         &lt;span&gt;if&lt;/span&gt; (data[k] &amp;lt; data[k - &lt;span&gt;1&lt;/span&gt;&lt;span&gt;])&lt;/span&gt;&lt;span&gt;26&lt;/span&gt; &lt;span&gt;                        &#123;&lt;/span&gt;&lt;span&gt;27&lt;/span&gt;                             Swap(data, k, k - &lt;span&gt;1&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;&lt;span&gt;28&lt;/span&gt;                             flag = &lt;span&gt;false&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;29&lt;/span&gt; &lt;span&gt;                        &#125;&lt;/span&gt;&lt;span&gt;30&lt;/span&gt; &lt;span&gt;                    &#125;&lt;/span&gt;&lt;span&gt;31&lt;/span&gt;                     &lt;span&gt;if&lt;/span&gt; (flag) &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;32&lt;/span&gt;                     n++&lt;span&gt;;&lt;/span&gt;&lt;span&gt;33&lt;/span&gt; &lt;span&gt;                &#125;&lt;/span&gt;&lt;span&gt;34&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;35&lt;/span&gt;         &#125;\n\n\n过程解析：分析第i轮冒泡，i是偶数则将剩余数列最大值向右冒泡至末尾，是奇数则将剩余数列最小值\n向左冒泡至开头。对于剩余数列，n为始，data.Count-1-m为末。\n来回冒泡比单向冒泡：对于随机数列，更容易得到有序的剩余数列。因此这里使用标识将会提升的更加明显。\n插入排序插入排序是一种对于有序数列高效的排序。非常聪明的排序。只是对于随机数列，效率一般，交换的频率高。\n原理：通过构建有序数列，将未排序的数从后向前比较，找到合适位置并插入。维基入口\n第一个数当作有序数列。\n实现如下：\n\n&lt;span&gt; 1&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; InsertSort(IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&lt;span&gt; data)&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt;&lt;span&gt; temp;&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;             &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;1&lt;/span&gt;; i &amp;lt; data.Count; i++&lt;span&gt;)&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;                 temp =&lt;span&gt; data[i];&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;                 &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; j = i - &lt;span&gt;1&lt;/span&gt;; j &amp;gt;= &lt;span&gt;0&lt;/span&gt;; j--&lt;span&gt;)&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; &lt;span&gt;                &#123;&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;                     &lt;span&gt;if&lt;/span&gt; (data[j] &amp;gt;&lt;span&gt; temp)&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; &lt;span&gt;                    &#123;&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;                         data[j + &lt;span&gt;1&lt;/span&gt;] =&lt;span&gt; data[j];&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;                         &lt;span&gt;if&lt;/span&gt; (j == &lt;span&gt;0&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;13&lt;/span&gt; &lt;span&gt;                        &#123;&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;                             data[&lt;span&gt;0&lt;/span&gt;] =&lt;span&gt; temp;&lt;/span&gt;&lt;span&gt;15&lt;/span&gt;                             &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; &lt;span&gt;                        &#125;&lt;/span&gt;&lt;span&gt;17&lt;/span&gt; &lt;span&gt;                    &#125;&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;                     &lt;span&gt;else&lt;/span&gt;&lt;span&gt;19&lt;/span&gt; &lt;span&gt;                    &#123;&lt;/span&gt;&lt;span&gt;20&lt;/span&gt;                         data[j + &lt;span&gt;1&lt;/span&gt;] =&lt;span&gt; temp;&lt;/span&gt;&lt;span&gt;21&lt;/span&gt;                         &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;22&lt;/span&gt; &lt;span&gt;                    &#125;&lt;/span&gt;&lt;span&gt;23&lt;/span&gt; &lt;span&gt;                &#125;&lt;/span&gt;&lt;span&gt;24&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;25&lt;/span&gt;         &#125;\n\n\n过程解析：将要排序的数（索引为i）存储起来，向前查找合适位置j+1，将i-1到j+1的元素依次向后\n移动一位，空出j+1，然后将之前存储的值放在这个位置。\n这个方法写的不如维基上的简洁清晰，由于合适位置是j+1所以多出了对j&#x3D;&#x3D;0的判断，但实际效率影响无差别。\n建议比照维基和我写的排序，自行选择。\n二分查找法优化插入排序插入排序主要工作是在有序的数列中对要排序的数查找合适的位置，而查找里面经典的二分查找法正可以适用。\n原理：通过二分查找法的方式找到一个位置索引。当要排序的数插入这个位置时，大于前一个数，小于后一个数。\n实现如下：\n\n&lt;span&gt; 1&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; InsertSortImprovedWithBinarySearch(IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&lt;span&gt; data)&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt;&lt;span&gt; temp;&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt;&lt;span&gt; tempIndex;&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;             &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;1&lt;/span&gt;; i &amp;lt; data.Count; i++&lt;span&gt;)&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;                 temp =&lt;span&gt; data[i];&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;                 tempIndex = BinarySearchForInsertSort(data, &lt;span&gt;0&lt;/span&gt;&lt;span&gt;, i, i);&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;                 &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; j = i - &lt;span&gt;1&lt;/span&gt;; j &amp;gt;= tempIndex; j--&lt;span&gt;)&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; &lt;span&gt;                &#123;&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;                     data[j + &lt;span&gt;1&lt;/span&gt;] =&lt;span&gt; data[j];&lt;/span&gt;&lt;span&gt;12&lt;/span&gt; &lt;span&gt;                &#125;&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;                 data[tempIndex] =&lt;span&gt; temp;&lt;/span&gt;&lt;span&gt;14&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; &lt;span&gt;        &#125;&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; &lt;span&gt;17&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; BinarySearchForInsertSort(IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; data, &lt;span&gt;int&lt;/span&gt; low, &lt;span&gt;int&lt;/span&gt; high, &lt;span&gt;int&lt;/span&gt;&lt;span&gt; key)&lt;/span&gt;&lt;span&gt;18&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt;19&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (low &amp;gt;= data.Count - &lt;span&gt;1&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;20&lt;/span&gt;                 &lt;span&gt;return&lt;/span&gt; data.Count - &lt;span&gt;1&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;21&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (high &amp;lt;= &lt;span&gt;0&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;22&lt;/span&gt;                 &lt;span&gt;return&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;23&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; mid = (low + high) / &lt;span&gt;2&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;24&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (mid == key) &lt;span&gt;return&lt;/span&gt;&lt;span&gt; mid;&lt;/span&gt;&lt;span&gt;25&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (data[key] &amp;gt;&lt;span&gt; data[mid])&lt;/span&gt;&lt;span&gt;26&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt;27&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (data[key] &amp;lt; data[mid + &lt;span&gt;1&lt;/span&gt;&lt;span&gt;])&lt;/span&gt;&lt;span&gt;28&lt;/span&gt;                     &lt;span&gt;return&lt;/span&gt; mid + &lt;span&gt;1&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;29&lt;/span&gt;                 &lt;span&gt;return&lt;/span&gt; BinarySearchForInsertSort(data, mid + &lt;span&gt;1&lt;/span&gt;&lt;span&gt;, high, key);&lt;/span&gt;&lt;span&gt;30&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;31&lt;/span&gt;             &lt;span&gt;else  &lt;span&gt;// data[key] &amp;lt;= data[mid]&lt;/span&gt;&lt;/span&gt;&lt;span&gt;32&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt;33&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (mid - &lt;span&gt;1&lt;/span&gt; &amp;lt; &lt;span&gt;0&lt;/span&gt;) &lt;span&gt;return&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;34&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (data[key] &amp;gt; data[mid - &lt;span&gt;1&lt;/span&gt;&lt;span&gt;])&lt;/span&gt;&lt;span&gt;35&lt;/span&gt;                     &lt;span&gt;return&lt;/span&gt;&lt;span&gt; mid;&lt;/span&gt;&lt;span&gt;36&lt;/span&gt;                 &lt;span&gt;return&lt;/span&gt; BinarySearchForInsertSort(data, low, mid - &lt;span&gt;1&lt;/span&gt;&lt;span&gt;, key);&lt;/span&gt;&lt;span&gt;37&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;38&lt;/span&gt;         &#125;\n\n\n 过程解析：需要注意的是二分查找方法实现中high-low&#x3D;&#x3D;1的时候mid&#x3D;&#x3D;low，所以需要33行\nmid-1&lt;0即mid&#x3D;&#x3D;0的判断，否则下行会索引越界。\n快速排序快速排序是一种有效比较较多的高效排序。它包含了“分而治之”以及“哨兵”的思想。\n原理：从数列中挑选一个数作为“哨兵”，使比它小的放在它的左侧，比它大的放在它的右侧。将要排序是数列递归地分割到\n最小数列，每次都让分割出的数列符合“哨兵”的规则，自然就将数列变得有序。 维基入口\n实现如下：\n\n&lt;span&gt; 1&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; QuickSortStrict(IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&lt;span&gt; data)&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;             QuickSortStrict(data, &lt;span&gt;0&lt;/span&gt;, data.Count - &lt;span&gt;1&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; &lt;span&gt;        &#125;&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; &lt;span&gt; 6&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; QuickSortStrict(IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; data, &lt;span&gt;int&lt;/span&gt; low, &lt;span&gt;int&lt;/span&gt;&lt;span&gt; high)&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (low &amp;gt;= high) &lt;span&gt;return&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; temp =&lt;span&gt; data[low];&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; i = low + &lt;span&gt;1&lt;/span&gt;, j =&lt;span&gt; high;&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;             &lt;span&gt;while&lt;/span&gt; (&lt;span&gt;true&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;12&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;                 &lt;span&gt;while&lt;/span&gt; (data[j] &amp;gt; temp) j--&lt;span&gt;;&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;                 &lt;span&gt;while&lt;/span&gt; (data[i] &amp;lt; temp &amp;amp;&amp;amp; i &amp;lt; j) i++&lt;span&gt;;&lt;/span&gt;&lt;span&gt;15&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (i &amp;gt;= j) &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; &lt;span&gt;                Swap(data, i, j);&lt;/span&gt;&lt;span&gt;17&lt;/span&gt;                 i++; j--&lt;span&gt;;&lt;/span&gt;&lt;span&gt;18&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;19&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (j !=&lt;span&gt; low)&lt;/span&gt;&lt;span&gt;20&lt;/span&gt; &lt;span&gt;                Swap(data, low, j);&lt;/span&gt;&lt;span&gt;21&lt;/span&gt;             QuickSortStrict(data, j + &lt;span&gt;1&lt;/span&gt;&lt;span&gt;, high);&lt;/span&gt;&lt;span&gt;22&lt;/span&gt;             QuickSortStrict(data, low, j - &lt;span&gt;1&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;&lt;span&gt;23&lt;/span&gt;         &#125;\n\n\n过程解析：取的哨兵是数列的第一个值，然后从第二个和末尾同时查找，左侧要显示的是小于哨兵的值，\n所以要找到不小于的i，右侧要显示的是大于哨兵的值，所以要找到不大于的j。将找到的i和j的数交换，\n这样可以减少交换次数。i&gt;&#x3D;j时，数列全部查找了一遍，而不符合条件j必然是在小的那一边，而哨兵\n是第一个数，位置本应是小于自己的数。所以将哨兵与j交换，使符合“哨兵”的规则。\n这个版本的缺点在于如果是有序数列排序的话，递归次数会很可怕的。\n另一个版本这是维基上的一个C#版本，我觉得很有意思。这个版本并没有严格符合“哨兵”的规则。但却将“分而治之”\n以及“哨兵”思想融入其中，代码简洁。\n实现如下：\n\n&lt;span&gt; 1&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; QuickSortRelax(IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&lt;span&gt; data)&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;             QuickSortRelax(data, &lt;span&gt;0&lt;/span&gt;, data.Count - &lt;span&gt;1&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; &lt;span&gt;        &#125;&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; &lt;span&gt; 6&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; QuickSortRelax(IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; data, &lt;span&gt;int&lt;/span&gt; low, &lt;span&gt;int&lt;/span&gt;&lt;span&gt; high)&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (low &amp;gt;= high) &lt;span&gt;return&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; temp = data[(low + high) / &lt;span&gt;2&lt;/span&gt;&lt;span&gt;];&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; i = low - &lt;span&gt;1&lt;/span&gt;, j = high + &lt;span&gt;1&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;             &lt;span&gt;while&lt;/span&gt; (&lt;span&gt;true&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;12&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;                 &lt;span&gt;while&lt;/span&gt; (data[++i] &amp;lt;&lt;span&gt; temp) ;&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;                 &lt;span&gt;while&lt;/span&gt; (data[--j] &amp;gt;&lt;span&gt; temp) ;&lt;/span&gt;&lt;span&gt;15&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (i &amp;gt;= j) &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; &lt;span&gt;                Swap(data, i, j);&lt;/span&gt;&lt;span&gt;17&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;             QuickSortRelax(data, j + &lt;span&gt;1&lt;/span&gt;&lt;span&gt;, high);&lt;/span&gt;&lt;span&gt;19&lt;/span&gt;             QuickSortRelax(data, low, i - &lt;span&gt;1&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;&lt;span&gt;20&lt;/span&gt;         &#125;\n\n\n过程解析：取的哨兵是数列中间的数。将数列分成两波，左侧小于等于哨兵，右侧大于等于哨兵。\n也就是说，哨兵不一定处于两波数的中间。虽然哨兵不在中间，但不妨碍“哨兵”的思想的实现。所以\n这个实现也可以达到快速排序的效果。但却造成了每次递归完成，要排序的数列数总和没有减少（除非i&#x3D;&#x3D;j）。\n针对这个版本的缺点，我进行了优化实现如下：\n\n&lt;span&gt; 1&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; QuickSortRelaxImproved(IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&lt;span&gt; data)&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;             QuickSortRelaxImproved(data, &lt;span&gt;0&lt;/span&gt;, data.Count - &lt;span&gt;1&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; &lt;span&gt;        &#125;&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; &lt;span&gt; 6&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; QuickSortRelaxImproved(IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; data, &lt;span&gt;int&lt;/span&gt; low, &lt;span&gt;int&lt;/span&gt;&lt;span&gt; high)&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (low &amp;gt;= high) &lt;span&gt;return&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; temp = data[(low + high) / &lt;span&gt;2&lt;/span&gt;&lt;span&gt;];&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; i = low - &lt;span&gt;1&lt;/span&gt;, j = high + &lt;span&gt;1&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; index = (low + high) / &lt;span&gt;2&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;             &lt;span&gt;while&lt;/span&gt; (&lt;span&gt;true&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;13&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;                 &lt;span&gt;while&lt;/span&gt; (data[++i] &amp;lt;&lt;span&gt; temp) ;&lt;/span&gt;&lt;span&gt;15&lt;/span&gt;                 &lt;span&gt;while&lt;/span&gt; (data[--j] &amp;gt;&lt;span&gt; temp) ;&lt;/span&gt;&lt;span&gt;16&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (i &amp;gt;= j) &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;17&lt;/span&gt; &lt;span&gt;                Swap(data, i, j);&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (i == index) index =&lt;span&gt; j;&lt;/span&gt;&lt;span&gt;19&lt;/span&gt;                 &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (j == index) index =&lt;span&gt; i;&lt;/span&gt;&lt;span&gt;20&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;21&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (j ==&lt;span&gt; i)&lt;/span&gt;&lt;span&gt;22&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt;23&lt;/span&gt;                 QuickSortRelaxImproved(data, j + &lt;span&gt;1&lt;/span&gt;&lt;span&gt;, high);&lt;/span&gt;&lt;span&gt;24&lt;/span&gt;                 QuickSortRelaxImproved(data, low, i - &lt;span&gt;1&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;&lt;span&gt;25&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;26&lt;/span&gt;             &lt;span&gt;else&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt;i-j==1&lt;/span&gt;&lt;span&gt;27&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt;28&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (index &amp;gt;=&lt;span&gt; i)&lt;/span&gt;&lt;span&gt;29&lt;/span&gt; &lt;span&gt;                &#123;&lt;/span&gt;&lt;span&gt;30&lt;/span&gt;                     &lt;span&gt;if&lt;/span&gt; (index !=&lt;span&gt; i)&lt;/span&gt;&lt;span&gt;31&lt;/span&gt; &lt;span&gt;                        Swap(data, index, i);&lt;/span&gt;&lt;span&gt;32&lt;/span&gt;                     QuickSortRelaxImproved(data, i + &lt;span&gt;1&lt;/span&gt;&lt;span&gt;, high);&lt;/span&gt;&lt;span&gt;33&lt;/span&gt;                     QuickSortRelaxImproved(data, low, i - &lt;span&gt;1&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;&lt;span&gt;34&lt;/span&gt; &lt;span&gt;                &#125;&lt;/span&gt;&lt;span&gt;35&lt;/span&gt;                 &lt;span&gt;else &lt;span&gt;//&lt;/span&gt;&lt;span&gt;index &amp;lt; i&lt;/span&gt;&lt;/span&gt;&lt;span&gt;36&lt;/span&gt; &lt;span&gt;                &#123;&lt;/span&gt;&lt;span&gt;37&lt;/span&gt;                     &lt;span&gt;if&lt;/span&gt; (index !=&lt;span&gt; j)&lt;/span&gt;&lt;span&gt;38&lt;/span&gt; &lt;span&gt;                        Swap(data, index, j);&lt;/span&gt;&lt;span&gt;39&lt;/span&gt;                     QuickSortRelaxImproved(data, j + &lt;span&gt;1&lt;/span&gt;&lt;span&gt;, high);&lt;/span&gt;&lt;span&gt;40&lt;/span&gt;                     QuickSortRelaxImproved(data, low, j - &lt;span&gt;1&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;&lt;span&gt;41&lt;/span&gt; &lt;span&gt;                &#125;&lt;/span&gt;&lt;span&gt;42&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;43&lt;/span&gt;         &#125;\n\n\n过程解析：定义了一个变量Index，来跟踪哨兵的位置。发现哨兵最后在小于自己的那堆，\n那就与j交换，否则与i交换。达到每次递归都能减少要排序的数列数总和的目的。\n归并排序归并排序也是采用“分而治之”的方式。刚发现分治法是一种算法范式，我还一直以为是一种需要意会的思想呢。\n不好意思了，孤陋寡闻了，哈哈！\n原理：将两个有序的数列，通过比较，合并为一个有序数列。 维基入口\n为方便理解，此处实现用了List的一些方法，随后有IList版本。\n实现如下：\n\n&lt;span&gt; 1&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; List&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; MergeSortOnlyList(List&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; data, &lt;span&gt;int&lt;/span&gt; low, &lt;span&gt;int&lt;/span&gt;&lt;span&gt; high)&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (low ==&lt;span&gt; high)&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;                 &lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; List&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&lt;span&gt; &#123; data[low] &#125;;&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;             List&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; mergeData = &lt;span&gt;new&lt;/span&gt; List&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&lt;span&gt;();&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; mid = (low + high) / &lt;span&gt;2&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;             List&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; leftData =&lt;span&gt; MergeSortOnlyList(data, low, mid);&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;             List&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; rightData = MergeSortOnlyList(data, mid + &lt;span&gt;1&lt;/span&gt;&lt;span&gt;, high);&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;0&lt;/span&gt;, j = &lt;span&gt;0&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;             &lt;span&gt;while&lt;/span&gt; (&lt;span&gt;true&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;11&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (leftData[i] &amp;lt;&lt;span&gt; rightData[j])&lt;/span&gt;&lt;span&gt;13&lt;/span&gt; &lt;span&gt;                &#123;&lt;/span&gt;&lt;span&gt;14&lt;/span&gt; &lt;span&gt;                    mergeData.Add(leftData[i]);&lt;/span&gt;&lt;span&gt;15&lt;/span&gt;                     &lt;span&gt;if&lt;/span&gt; (++i ==&lt;span&gt; leftData.Count)&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; &lt;span&gt;                    &#123;&lt;/span&gt;&lt;span&gt;17&lt;/span&gt;                         mergeData.AddRange(rightData.GetRange(j, rightData.Count -&lt;span&gt; j));&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;                         &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;19&lt;/span&gt; &lt;span&gt;                    &#125;&lt;/span&gt;&lt;span&gt;20&lt;/span&gt; &lt;span&gt;                &#125;&lt;/span&gt;&lt;span&gt;21&lt;/span&gt;                 &lt;span&gt;else&lt;/span&gt;&lt;span&gt;22&lt;/span&gt; &lt;span&gt;                &#123;&lt;/span&gt;&lt;span&gt;23&lt;/span&gt; &lt;span&gt;                    mergeData.Add(rightData[j]);&lt;/span&gt;&lt;span&gt;24&lt;/span&gt;                     &lt;span&gt;if&lt;/span&gt; (++j ==&lt;span&gt; rightData.Count)&lt;/span&gt;&lt;span&gt;25&lt;/span&gt; &lt;span&gt;                    &#123;&lt;/span&gt;&lt;span&gt;26&lt;/span&gt;                         mergeData.AddRange(leftData.GetRange(i, leftData.Count -&lt;span&gt; i));&lt;/span&gt;&lt;span&gt;27&lt;/span&gt;                         &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;28&lt;/span&gt; &lt;span&gt;                    &#125;&lt;/span&gt;&lt;span&gt;29&lt;/span&gt; &lt;span&gt;                &#125;&lt;/span&gt;&lt;span&gt;30&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;31&lt;/span&gt;             &lt;span&gt;return&lt;/span&gt;&lt;span&gt; mergeData;&lt;/span&gt;&lt;span&gt;32&lt;/span&gt; &lt;span&gt;        &#125;&lt;/span&gt;&lt;span&gt;33&lt;/span&gt; &lt;span&gt;34&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; List&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; MergeSortOnlyList(List&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&lt;span&gt; data)&lt;/span&gt;&lt;span&gt;35&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt;36&lt;/span&gt;             data = MergeSortOnlyList(data, &lt;span&gt;0&lt;/span&gt;, data.Count - &lt;span&gt;1&lt;/span&gt;&lt;span&gt;);  &lt;span&gt;//不会改变外部引用 参照&lt;a href=&quot;http://www.cnblogs.com/fatbird/p/parametersInCsharp.html&quot; target=&quot;_blank&quot;&gt;C#参数传递&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;37&lt;/span&gt;             &lt;span&gt;return&lt;/span&gt;&lt;span&gt; data;&lt;/span&gt;&lt;span&gt;38&lt;/span&gt;         &#125;\n\n\n过程解析：将数列分为两部分，分别得到两部分数列的有序版本，然后逐个比较，将比较出的小数逐个放进\n新的空数列中。当一个数列放完后，将另一个数列剩余数全部放进去。\nIList版本实现如下：\n\n&lt;span&gt; 1&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; MergeSort(IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&lt;span&gt; data)&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;             data = MergeSort(data, &lt;span&gt;0&lt;/span&gt;, data.Count - &lt;span&gt;1&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;             &lt;span&gt;return&lt;/span&gt;&lt;span&gt; data;&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; &lt;span&gt;        &#125;&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; &lt;span&gt; 7&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; MergeSort(IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; data, &lt;span&gt;int&lt;/span&gt; low, &lt;span&gt;int&lt;/span&gt;&lt;span&gt; high)&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; length = high - low + &lt;span&gt;1&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;             IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; mergeData =&lt;span&gt; NewInstance(data, length);&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (low ==&lt;span&gt; high)&lt;/span&gt;&lt;span&gt;12&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;                 mergeData[&lt;span&gt;0&lt;/span&gt;] =&lt;span&gt; data[low];&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;                 &lt;span&gt;return&lt;/span&gt;&lt;span&gt; mergeData;&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;16&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; mid = (low + high) / &lt;span&gt;2&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;17&lt;/span&gt;             IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; leftData =&lt;span&gt; MergeSort(data, low, mid);&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;             IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; rightData = MergeSort(data, mid + &lt;span&gt;1&lt;/span&gt;&lt;span&gt;, high);&lt;/span&gt;&lt;span&gt;19&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;0&lt;/span&gt;, j = &lt;span&gt;0&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;20&lt;/span&gt;             &lt;span&gt;while&lt;/span&gt; (&lt;span&gt;true&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;21&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt;22&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (leftData[i] &amp;lt;&lt;span&gt; rightData[j])&lt;/span&gt;&lt;span&gt;23&lt;/span&gt; &lt;span&gt;                &#123;&lt;/span&gt;&lt;span&gt;24&lt;/span&gt;                     mergeData[i + j] = leftData[i++]; &lt;span&gt;//&lt;/span&gt;&lt;span&gt;不能使用Add,Array Length不可变&lt;/span&gt;&lt;span&gt;25&lt;/span&gt;                     &lt;span&gt;if&lt;/span&gt; (i ==&lt;span&gt; leftData.Count)&lt;/span&gt;&lt;span&gt;26&lt;/span&gt; &lt;span&gt;                    &#123;&lt;/span&gt;&lt;span&gt;27&lt;/span&gt;                         &lt;span&gt;int&lt;/span&gt; rightLeft = rightData.Count -&lt;span&gt; j;&lt;/span&gt;&lt;span&gt;28&lt;/span&gt;                         &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; m = &lt;span&gt;0&lt;/span&gt;; m &amp;lt; rightLeft; m++&lt;span&gt;)&lt;/span&gt;&lt;span&gt;29&lt;/span&gt; &lt;span&gt;                        &#123;&lt;/span&gt;&lt;span&gt;30&lt;/span&gt;                             mergeData[i + j] = rightData[j++&lt;span&gt;];&lt;/span&gt;&lt;span&gt;31&lt;/span&gt; &lt;span&gt;                        &#125;&lt;/span&gt;&lt;span&gt;32&lt;/span&gt;                         &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;33&lt;/span&gt; &lt;span&gt;                    &#125;&lt;/span&gt;&lt;span&gt;34&lt;/span&gt; &lt;span&gt;                &#125;&lt;/span&gt;&lt;span&gt;35&lt;/span&gt;                 &lt;span&gt;else&lt;/span&gt;&lt;span&gt;36&lt;/span&gt; &lt;span&gt;                &#123;&lt;/span&gt;&lt;span&gt;37&lt;/span&gt;                     mergeData[i + j] = rightData[j++&lt;span&gt;];&lt;/span&gt;&lt;span&gt;38&lt;/span&gt;                     &lt;span&gt;if&lt;/span&gt; (j ==&lt;span&gt; rightData.Count)&lt;/span&gt;&lt;span&gt;39&lt;/span&gt; &lt;span&gt;                    &#123;&lt;/span&gt;&lt;span&gt;40&lt;/span&gt;                         &lt;span&gt;int&lt;/span&gt; leftleft = leftData.Count -&lt;span&gt; i;&lt;/span&gt;&lt;span&gt;41&lt;/span&gt;                         &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; n = &lt;span&gt;0&lt;/span&gt;; n &amp;lt; leftleft; n++&lt;span&gt;)&lt;/span&gt;&lt;span&gt;42&lt;/span&gt; &lt;span&gt;                        &#123;&lt;/span&gt;&lt;span&gt;43&lt;/span&gt;                             mergeData[i + j] = leftData[i++&lt;span&gt;];&lt;/span&gt;&lt;span&gt;44&lt;/span&gt; &lt;span&gt;                        &#125;&lt;/span&gt;&lt;span&gt;45&lt;/span&gt;                         &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;46&lt;/span&gt; &lt;span&gt;                    &#125;&lt;/span&gt;&lt;span&gt;47&lt;/span&gt; &lt;span&gt;                &#125;&lt;/span&gt;&lt;span&gt;48&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;49&lt;/span&gt;             &lt;span&gt;return&lt;/span&gt;&lt;span&gt; mergeData;&lt;/span&gt;&lt;span&gt;50&lt;/span&gt; &lt;span&gt;51&lt;/span&gt;         &#125;\n\n\n过程原理与上个一样，此处就不赘述了。\n堆排序堆排序是根据堆这种数据结构设计的一种算法。堆的特性：父节点的值总是小于（或大于）它的子节点。近似二叉树。\n原理：将数列构建为最大堆数列（即父节点总是最大值），将最大值（即根节点）交换到数列末尾。这样要排序的数列数总和减少，\n同时根节点不再是最大值，调整最大堆数列。如此重复，最后得到有序数列。 维基入口   有趣的演示\n实现准备：如何将数列构造为堆——父节点i的左子节点为2i+1，右子节点为2i+2。节点i的父节点为floor((i-1)&#x2F;2)。\n实现如下（这个实现判断和临时变量使用太多，导致效率低，评论中@小城故事提出了更好的实现）：\n\n&lt;span&gt; 1&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; HeapSort(IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&lt;span&gt; data)&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt; &lt;span&gt;            BuildMaxHeapify(data);&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; j =&lt;span&gt; data.Count;&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;             &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;0&lt;/span&gt;; i &amp;lt;&lt;span&gt; j; )&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;                 Swap(data, i, --&lt;span&gt;j);&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (j - &lt;span&gt;2&lt;/span&gt; &amp;lt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;)  &lt;span&gt;//只剩下1个数 j代表余下要排列的数的个数&lt;/span&gt;&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;                     &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;                 &lt;span&gt;int&lt;/span&gt; k = &lt;span&gt;0&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;                 &lt;span&gt;while&lt;/span&gt; (&lt;span&gt;true&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;12&lt;/span&gt; &lt;span&gt;                &#123;&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;                     &lt;span&gt;if&lt;/span&gt; (k &amp;gt; (j - &lt;span&gt;2&lt;/span&gt;) / &lt;span&gt;2&lt;/span&gt;) &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;  &lt;span&gt;//即：k &amp;gt; ((j-1)-1)/2&lt;/span&gt; &lt;span&gt;超出最后一个父节点的位置  &lt;/span&gt;&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;                     &lt;span&gt;else&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; &lt;span&gt;                    &#123;&lt;/span&gt;&lt;span&gt;16&lt;/span&gt;                         &lt;span&gt;int&lt;/span&gt; temp =&lt;span&gt; k;&lt;/span&gt;&lt;span&gt;17&lt;/span&gt;                         k = ReSortMaxBranch(data, k, &lt;span&gt;2&lt;/span&gt; * k + &lt;span&gt;1&lt;/span&gt;, &lt;span&gt;2&lt;/span&gt; * k + &lt;span&gt;2&lt;/span&gt;, j - &lt;span&gt;1&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;                         &lt;span&gt;if&lt;/span&gt; (temp == k) &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;19&lt;/span&gt; &lt;span&gt;                    &#125;&lt;/span&gt;&lt;span&gt;20&lt;/span&gt; &lt;span&gt;                &#125;&lt;/span&gt;&lt;span&gt;21&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;22&lt;/span&gt; &lt;span&gt;        &#125;&lt;/span&gt;&lt;span&gt;23&lt;/span&gt; &lt;span&gt;24&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; BuildMaxHeapify(IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&lt;span&gt; data)&lt;/span&gt;&lt;span&gt;25&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt;26&lt;/span&gt;             &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = data.Count / &lt;span&gt;2&lt;/span&gt; - &lt;span&gt;1&lt;/span&gt;; i &amp;gt;= &lt;span&gt;0&lt;/span&gt;; i--&lt;span&gt;)  &lt;span&gt;//(data.Count-1)-1)/2为数列最大父节点索引&lt;/span&gt;&lt;/span&gt;&lt;span&gt;27&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt;28&lt;/span&gt;                 &lt;span&gt;int&lt;/span&gt; temp =&lt;span&gt; i;&lt;/span&gt;&lt;span&gt;29&lt;/span&gt;                 temp = ReSortMaxBranch(data, i, &lt;span&gt;2&lt;/span&gt; * i + &lt;span&gt;1&lt;/span&gt;, &lt;span&gt;2&lt;/span&gt; * i + &lt;span&gt;2&lt;/span&gt;, data.Count - &lt;span&gt;1&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;&lt;span&gt;30&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (temp !=&lt;span&gt; i)&lt;/span&gt;&lt;span&gt;31&lt;/span&gt; &lt;span&gt;                &#123;&lt;/span&gt;&lt;span&gt;32&lt;/span&gt;                     &lt;span&gt;int&lt;/span&gt; k =&lt;span&gt; i;&lt;/span&gt;&lt;span&gt;33&lt;/span&gt;                     &lt;span&gt;while&lt;/span&gt; (k != temp &amp;amp;&amp;amp; temp &amp;lt;= data.Count / &lt;span&gt;2&lt;/span&gt; - &lt;span&gt;1&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;34&lt;/span&gt; &lt;span&gt;                    &#123;&lt;/span&gt;&lt;span&gt;35&lt;/span&gt;                         k =&lt;span&gt; temp;&lt;/span&gt;&lt;span&gt;36&lt;/span&gt;                         temp = ReSortMaxBranch(data, temp, &lt;span&gt;2&lt;/span&gt; * temp + &lt;span&gt;1&lt;/span&gt;, &lt;span&gt;2&lt;/span&gt; * temp + &lt;span&gt;2&lt;/span&gt;, data.Count - &lt;span&gt;1&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;&lt;span&gt;37&lt;/span&gt; &lt;span&gt;                    &#125;&lt;/span&gt;&lt;span&gt;38&lt;/span&gt; &lt;span&gt;                &#125;&lt;/span&gt;&lt;span&gt;39&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;40&lt;/span&gt; &lt;span&gt;        &#125;&lt;/span&gt;&lt;span&gt;41&lt;/span&gt; &lt;span&gt;42&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; ReSortMaxBranch(IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; data, &lt;span&gt;int&lt;/span&gt; maxIndex, &lt;span&gt;int&lt;/span&gt; left, &lt;span&gt;int&lt;/span&gt; right, &lt;span&gt;int&lt;/span&gt;&lt;span&gt; lastIndex)&lt;/span&gt;&lt;span&gt;43&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt;44&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt;&lt;span&gt; temp;&lt;/span&gt;&lt;span&gt;45&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (right &amp;gt;&lt;span&gt; lastIndex)  &lt;span&gt;//父节点只有一个子节点&lt;/span&gt;&lt;/span&gt;&lt;span&gt;46&lt;/span&gt;                 temp =&lt;span&gt; left;&lt;/span&gt;&lt;span&gt;47&lt;/span&gt;             &lt;span&gt;else&lt;/span&gt;&lt;span&gt;48&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt;49&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (data[left] &amp;gt;&lt;span&gt; data[right])&lt;/span&gt;&lt;span&gt;50&lt;/span&gt;                     temp =&lt;span&gt; left;&lt;/span&gt;&lt;span&gt;51&lt;/span&gt;                 &lt;span&gt;else&lt;/span&gt; temp =&lt;span&gt; right;&lt;/span&gt;&lt;span&gt;52&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;53&lt;/span&gt; &lt;span&gt;54&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (data[maxIndex] &amp;lt;&lt;span&gt; data[temp])&lt;/span&gt;&lt;span&gt;55&lt;/span&gt; &lt;span&gt;                Swap(data, maxIndex, temp);&lt;/span&gt;&lt;span&gt;56&lt;/span&gt;             &lt;span&gt;else&lt;/span&gt; temp =&lt;span&gt; maxIndex;&lt;/span&gt;&lt;span&gt;57&lt;/span&gt;             &lt;span&gt;return&lt;/span&gt;&lt;span&gt; temp;&lt;/span&gt;&lt;span&gt;58&lt;/span&gt;         &#125;\n\n\n过程解析：BuildMaxHeapify为排序前构建的最大堆数列方法，主要内容为从最后一个父节点开始往前将每个三角组合\n（即父节点与它的两个子节点）符合父节点值最大的规则。ReSortMaxBranch为将三角调整为父节点值最大，\n并返回该值之前的索引，用来判断是否进行了交换，以及原来的父节点值交换到了什么位置。在HeapSort里首先\n构建了最大堆数列，然后将根节点交换到末尾，根节点不是最大值了，在while语句中对最大堆数列进行调整。\n插曲：自从看了Martin Fowler大师《重构》第三版，我发现我更不喜欢写注释了。每次都想着尽量让方法的名字更贴切，\n即使会造成方法的名字很长很丑。这算不算曲解了大师的意思啊！？上面的代码注释都是写博客的时候现加的（源代码很干净的。汗!）。\n希尔排序希尔排序是插入排序的一种更高效的改进版本。\n在前面介绍的插入排序，我们知道1.它对有序数列排序的效率是非常高的 2.要排序的数向前移动是一步步进行的导致插入排序效率低。\n希尔排序正是利用第一点，改善第二点，达到更理想的效果。\n原理：通过奇妙的步长，插入排序间隔步长的元素，随后逐渐缩短步长至1，实现数列的插入排序。 维基入口\n疑问：可以想象到排序间隔步长的数，会逐渐让数列变得有序，提升最后步长为1时标准插入排序的效率。在维基上看到这么\n一句话“可能希尔排序最重要的地方在于当用较小步长排序后，以前用的较大步长仍然是有序的”注意用词是‘可能’。我的疑问是\n这是个正确的命题吗？如何证明呢？看维基上也是由果推因，说是如果不是这样，就不会排序那么快了。可这我感觉还是太牵强了，\n哪位大哥发现相关资料，希望能分享出来，不胜感激。\n实现如下：\n\n&lt;span&gt; 1&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; ShellSort(IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&lt;span&gt; data)&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt;&lt;span&gt; temp;&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;             &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; gap = data.Count / &lt;span&gt;2&lt;/span&gt;; gap &amp;gt; &lt;span&gt;0&lt;/span&gt;; gap /= &lt;span&gt;2&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;                 &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = gap; i &amp;lt; data.Count; i +=&lt;span&gt; gap)&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; &lt;span&gt;                &#123;&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;                     temp =&lt;span&gt; data[i];&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;                     &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; j = i - gap; j &amp;gt;= &lt;span&gt;0&lt;/span&gt;; j -=&lt;span&gt; gap)&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; &lt;span&gt;                    &#123;&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;                         &lt;span&gt;if&lt;/span&gt; (data[j] &amp;gt;&lt;span&gt; temp)&lt;/span&gt;&lt;span&gt;12&lt;/span&gt; &lt;span&gt;                        &#123;&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;                             data[j + gap] =&lt;span&gt; data[j];&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;                             &lt;span&gt;if&lt;/span&gt; (j == &lt;span&gt;0&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; &lt;span&gt;                            &#123;&lt;/span&gt;&lt;span&gt;16&lt;/span&gt;                                 data[j] =&lt;span&gt; temp;&lt;/span&gt;&lt;span&gt;17&lt;/span&gt;                                 &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;18&lt;/span&gt; &lt;span&gt;                            &#125;&lt;/span&gt;&lt;span&gt;19&lt;/span&gt; &lt;span&gt;                        &#125;&lt;/span&gt;&lt;span&gt;20&lt;/span&gt;                         &lt;span&gt;else&lt;/span&gt;&lt;span&gt;21&lt;/span&gt; &lt;span&gt;                        &#123;&lt;/span&gt;&lt;span&gt;22&lt;/span&gt;                             data[j + gap] =&lt;span&gt; temp;&lt;/span&gt;&lt;span&gt;23&lt;/span&gt;                             &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;24&lt;/span&gt; &lt;span&gt;                        &#125;&lt;/span&gt;&lt;span&gt;25&lt;/span&gt; &lt;span&gt;                    &#125;&lt;/span&gt;&lt;span&gt;26&lt;/span&gt; &lt;span&gt;                &#125;&lt;/span&gt;&lt;span&gt;27&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;28&lt;/span&gt;         &#125;\n\n\n过程解析：采用的步长是N&#x2F;2，每次取半，直至1。循环内部就是标准的插入排序。\n——————\n修正：修正后希尔排序才是真正牛叉的希尔啊！感谢@390218462的提出  \n\n&lt;span&gt; 1&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; ShellSortCorrect(IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&lt;span&gt; data)&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt;&lt;span&gt; temp;&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;             &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; gap = data.Count / &lt;span&gt;2&lt;/span&gt;; gap &amp;gt; &lt;span&gt;0&lt;/span&gt;; gap /= &lt;span&gt;2&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;                 &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = gap; i &amp;lt; data.Count; &lt;span&gt;i++&lt;/span&gt;&lt;span&gt;)      // &lt;span&gt;i+ = gap 改为了 i++&lt;/span&gt;&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; &lt;span&gt;                &#123;&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;                     temp =&lt;span&gt; data[i];&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;                     &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; j = i - gap; j &amp;gt;= &lt;span&gt;0&lt;/span&gt;; j -=&lt;span&gt; gap)&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; &lt;span&gt;                    &#123;&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;                         &lt;span&gt;if&lt;/span&gt; (data[j] &amp;gt;&lt;span&gt; temp)&lt;/span&gt;&lt;span&gt;12&lt;/span&gt; &lt;span&gt;                        &#123;&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;                             data[j + gap] =&lt;span&gt; data[j];&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;                             &lt;span&gt;if&lt;/span&gt; (j == &lt;span&gt;0&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; &lt;span&gt;                            &#123;&lt;/span&gt;&lt;span&gt;16&lt;/span&gt;                                 data[j] =&lt;span&gt; temp;&lt;/span&gt;&lt;span&gt;17&lt;/span&gt;                                 &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;18&lt;/span&gt; &lt;span&gt;                            &#125;&lt;/span&gt;&lt;span&gt;19&lt;/span&gt; &lt;span&gt;                        &#125;&lt;/span&gt;&lt;span&gt;20&lt;/span&gt;                         &lt;span&gt;else&lt;/span&gt;&lt;span&gt;21&lt;/span&gt; &lt;span&gt;                        &#123;&lt;/span&gt;&lt;span&gt;22&lt;/span&gt;                             data[j + gap] =&lt;span&gt; temp;&lt;/span&gt;&lt;span&gt;23&lt;/span&gt;                             &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;24&lt;/span&gt; &lt;span&gt;                        &#125;&lt;/span&gt;&lt;span&gt;25&lt;/span&gt; &lt;span&gt;                    &#125;&lt;/span&gt;&lt;span&gt;26&lt;/span&gt; &lt;span&gt;                &#125;&lt;/span&gt;&lt;span&gt;27&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;28&lt;/span&gt;         &#125;\n\n\n\n——————\n这里实现的貌似是最差的希尔排序。主要源于步长的选择。维基上有各种牛叉的“凌波微步”，极限在哪里，\n喜欢挑战的同学可以去学习学习。看维基排序算法里六种排序的测试，希尔最快，比快速排序还快！！我没实现啊！\n只是对于神奇的步长更充满了敬畏。\n基数排序基数排序是一种非比较型整数排序。\n“非比较型”是什么意思呢？因为它内部使用的是桶排序，而桶排序是非比较型排序。\n这里就要说说桶排序了。一个非常有意思的排序。\n桶排序原理：取一定数量（数列中的最大值）的编好序号的桶，将数列每个数放进编号为它的桶里，然后将不是空的桶依次倒出来，\n就组成有序数列了。  维基入口\n好吧！聪明的人一眼就看出桶排序的破绽了。假设只有两个数1,10000，岂不是要一万个桶！？这确实是个问题啊！我也\n没想出解决办法。我起初也以为桶排序就是一个通过牺牲空间来换取时间的排序算法，它不需要比较，所以是非比较型算法。\n但看了有趣的演示的桶排序后，发现世界之大，你没有解决，不代表别人没解决，睿智的人总是很多。\n1，9999的桶排序实现：new Int[2];总共有两个数，得出最大数9999的位数4，取10的4次幂即10000作为分母，\n要排序的数（1或9999）作为分子，并乘以数列总数2，即1*2&#x2F;10000,9999*2&#x2F;10000得到各自的位置0,1，完成排序。\n如果是1,10000进行排序的话，上面的做法就需要稍微加一些处理——发现最大数是10的n次幂，就将它作为分母，并\n放在数列末尾就好了。\n如果是9999,10000进行排序的话，那就需要二维数组了，两个都在位置1，位置0没数。这个时候就需要在放\n入每个位置时采用其它排序（比如插入排序）办法对这个位置的多个数排序了。\n为基数排序做个过渡，我这里实现了一个个位数桶排序涉及到了当重复的数出现的处理。\n实现如下：\n\n&lt;span&gt; 1&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; BucketSortOnlyUnitDigit(IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&lt;span&gt; data)&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt;[] indexCounter = &lt;span&gt;new&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;[&lt;span&gt;10&lt;/span&gt;&lt;span&gt;];&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;             &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;0&lt;/span&gt;; i &amp;lt; data.Count; i++&lt;span&gt;)&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;                 indexCounter[data[i]]++&lt;span&gt;;&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt;[] indexBegin = &lt;span&gt;new&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;[&lt;span&gt;10&lt;/span&gt;&lt;span&gt;];&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;             &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;1&lt;/span&gt;; i &amp;lt; &lt;span&gt;10&lt;/span&gt;; i++&lt;span&gt;)&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;                 indexBegin[i] = indexBegin[i-1]+&lt;span&gt; indexCounter[i-1];&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;16&lt;/span&gt;             IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; tempList =&lt;span&gt; NewInstance(data, data.Count);&lt;/span&gt;&lt;span&gt;17&lt;/span&gt;             &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;0&lt;/span&gt;; i &amp;lt; data.Count; i++&lt;span&gt;)&lt;/span&gt;&lt;span&gt;18&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt;19&lt;/span&gt;                 &lt;span&gt;int&lt;/span&gt; number =&lt;span&gt; data[i];&lt;/span&gt;&lt;span&gt;20&lt;/span&gt;                 tempList[indexBegin[number]++] =&lt;span&gt; data[i];&lt;/span&gt;&lt;span&gt;21&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;22&lt;/span&gt;             data =&lt;span&gt; tempList;&lt;/span&gt;&lt;span&gt;23&lt;/span&gt;         &#125;\n\n\n过程解析：indexCounter进行对每个数出现的频率的统计。indexBegin存储每个数的起始索引。\n比如 1 1 2，indexCounter统计到0个0,2个1,1个2。indexBegin计算出0,1,2的起始索引分别为\n0,0,2。当1个1已取出排序，那索引将+1,变为0,1,2。这样就通过提前给重复的数空出位置，解决了\n重复的数出现的问题。当然，你也可以考虑用二维数组来解决重复。\n下面继续基数排序。\n基数排序原理：将整数按位数切割成不同的数字，然后按每个位数分别比较。\n取得最大数的位数，从低位开始，每个位上进行桶排序。\n实现如下：\n\n&lt;span&gt; 1&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; RadixSort(IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&lt;span&gt; data)&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; max = data[&lt;span&gt;0&lt;/span&gt;&lt;span&gt;];&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;             &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;1&lt;/span&gt;; i &amp;lt; data.Count; i++&lt;span&gt;)&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (data[i] &amp;gt;&lt;span&gt; max)&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;                     max =&lt;span&gt; data[i];&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; digit = &lt;span&gt;1&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;             &lt;span&gt;while&lt;/span&gt; (max / &lt;span&gt;10&lt;/span&gt; != &lt;span&gt;0&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;11&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;                 digit++&lt;span&gt;;&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;                 max /= &lt;span&gt;10&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;14&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;15&lt;/span&gt;             &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;0&lt;/span&gt;; i &amp;lt; digit; i++&lt;span&gt;)&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt;17&lt;/span&gt;                 &lt;span&gt;int&lt;/span&gt;[] indexCounter = &lt;span&gt;new&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;[&lt;span&gt;10&lt;/span&gt;&lt;span&gt;];&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;                 IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; tempList =&lt;span&gt; NewInstance(data, data.Count);&lt;/span&gt;&lt;span&gt;19&lt;/span&gt;                 &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; j = &lt;span&gt;0&lt;/span&gt;; j &amp;lt; data.Count; j++&lt;span&gt;)&lt;/span&gt;&lt;span&gt;20&lt;/span&gt; &lt;span&gt;                &#123;&lt;/span&gt;&lt;span&gt;21&lt;/span&gt;                     &lt;span&gt;int&lt;/span&gt; number = (data[j] % Convert.ToInt32(Math.Pow(&lt;span&gt;10&lt;/span&gt;, i + &lt;span&gt;1&lt;/span&gt;))) / Convert.ToInt32(Math.Pow(&lt;span&gt;10&lt;/span&gt;, i));  &lt;span&gt;//&lt;/span&gt;&lt;span&gt;得出i+1位上的数&lt;/span&gt;&lt;span&gt;22&lt;/span&gt;                     indexCounter[number]++&lt;span&gt;;&lt;/span&gt;&lt;span&gt;23&lt;/span&gt; &lt;span&gt;                &#125;&lt;/span&gt;&lt;span&gt;24&lt;/span&gt;                 &lt;span&gt;int&lt;/span&gt;[] indexBegin = &lt;span&gt;new&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;[&lt;span&gt;10&lt;/span&gt;&lt;span&gt;];&lt;/span&gt;&lt;span&gt;25&lt;/span&gt;                 &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; k = &lt;span&gt;1&lt;/span&gt;; k &amp;lt; &lt;span&gt;10&lt;/span&gt;; k++&lt;span&gt;)&lt;/span&gt;&lt;span&gt;26&lt;/span&gt; &lt;span&gt;                &#123;&lt;/span&gt;&lt;span&gt;27&lt;/span&gt;                     indexBegin[k] = indexBegin[k - &lt;span&gt;1&lt;/span&gt;] + indexCounter[k - &lt;span&gt;1&lt;/span&gt;&lt;span&gt;];&lt;/span&gt;&lt;span&gt;28&lt;/span&gt; &lt;span&gt;                &#125;&lt;/span&gt;&lt;span&gt;29&lt;/span&gt;                 &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; k = &lt;span&gt;0&lt;/span&gt;; k &amp;lt; data.Count; k++&lt;span&gt;)&lt;/span&gt;&lt;span&gt;30&lt;/span&gt; &lt;span&gt;                &#123;&lt;/span&gt;&lt;span&gt;31&lt;/span&gt;                     &lt;span&gt;int&lt;/span&gt; number = (data[k] % Convert.ToInt32(Math.Pow(&lt;span&gt;10&lt;/span&gt;, i + &lt;span&gt;1&lt;/span&gt;))) / Convert.ToInt32(Math.Pow(&lt;span&gt;10&lt;/span&gt;&lt;span&gt;, i));&lt;/span&gt;&lt;span&gt;32&lt;/span&gt;                     tempList[indexBegin[number]++] =&lt;span&gt; data[k];&lt;/span&gt;&lt;span&gt;33&lt;/span&gt; &lt;span&gt;                &#125;&lt;/span&gt;&lt;span&gt;34&lt;/span&gt;                 data =&lt;span&gt; tempList;&lt;/span&gt;&lt;span&gt;35&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;36&lt;/span&gt;             &lt;span&gt;return&lt;/span&gt;&lt;span&gt; data;&lt;/span&gt;&lt;span&gt;37&lt;/span&gt;         &#125;\n\n\n过程解析：得出最大数的位数，从低位开始桶排序。我写的这个实现代码并不简洁，但逻辑更清晰。\n后面测试的时候我们就会发现，按理来说这个实现也还行吧！ 但并不如想象的那么快！\n循环的次数太多？（统计频率n次+9次计算+n次放到新的数组）*位数。\n创建的新实例太多？(new int[10]两次+NewInstance is反射判断创建实例+new int[n])*位数\n测试比较添加随机数组，数组有序校验，微软Linq排序\n代码如下：\n\n&lt;span&gt; 1&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;[] RandomSet(&lt;span&gt;int&lt;/span&gt; length, &lt;span&gt;int&lt;/span&gt;&lt;span&gt; max)&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt;[] result = &lt;span&gt;new&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;&lt;span&gt;[length];&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;             Random rand = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Random();&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;             &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;0&lt;/span&gt;; i &amp;lt; result.Length; i++&lt;span&gt;)&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;                 result[i] =&lt;span&gt; rand.Next(max);&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;             &lt;span&gt;return&lt;/span&gt;&lt;span&gt; result;&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; &lt;span&gt;        &#125;&lt;/span&gt;&lt;span&gt;11&lt;/span&gt; &lt;span&gt;12&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;bool&lt;/span&gt; IsAscOrdered(IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&lt;span&gt; data)&lt;/span&gt;&lt;span&gt;13&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;             &lt;span&gt;bool&lt;/span&gt; flag = &lt;span&gt;true&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;15&lt;/span&gt;             &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;0&lt;/span&gt;; i &amp;lt; data.Count - &lt;span&gt;1&lt;/span&gt;; i++&lt;span&gt;)&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt;17&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (data[i] &amp;gt; data[i + &lt;span&gt;1&lt;/span&gt;&lt;span&gt;])&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;                     flag = &lt;span&gt;false&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;19&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;20&lt;/span&gt;             &lt;span&gt;return&lt;/span&gt;&lt;span&gt; flag;&lt;/span&gt;&lt;span&gt;21&lt;/span&gt; &lt;span&gt;        &#125;&lt;/span&gt;&lt;span&gt;22&lt;/span&gt; &lt;span&gt;23&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; TestMicrosoft(IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&lt;span&gt; data)&lt;/span&gt;&lt;span&gt;24&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt;25&lt;/span&gt;             Stopwatch stopwatch = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Stopwatch();&lt;/span&gt;&lt;span&gt;26&lt;/span&gt; &lt;span&gt;            stopwatch.Start();&lt;/span&gt;&lt;span&gt;27&lt;/span&gt;             List&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; result = data.OrderBy(a =&amp;gt;&lt;span&gt; a).ToList();&lt;/span&gt;&lt;span&gt;28&lt;/span&gt; &lt;span&gt;            stopwatch.Stop();&lt;/span&gt;&lt;span&gt;29&lt;/span&gt;             &lt;span&gt;string&lt;/span&gt; methodName = &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;TestMicrosoft&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;30&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; length =&lt;span&gt; methodName.Length;&lt;/span&gt;&lt;span&gt;31&lt;/span&gt;             &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;0&lt;/span&gt;; i &amp;lt; &lt;span&gt;40&lt;/span&gt; - length; i++&lt;span&gt;)&lt;/span&gt;&lt;span&gt;32&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt;33&lt;/span&gt;                 methodName += &lt;span&gt;&quot;&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;34&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;35&lt;/span&gt;             Console.WriteLine(methodName +&lt;span&gt;36&lt;/span&gt;                 &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;  IsAscOrdered:&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; + IsAscOrdered(result) + &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;  Time:&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; +&lt;span&gt; stopwatch.Elapsed.TotalSeconds);&lt;/span&gt;&lt;span&gt;37&lt;/span&gt; &lt;span&gt;38&lt;/span&gt;         &#125;\n\n\n测试主体如下：\n\n&lt;span&gt; 1&lt;/span&gt;         &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Main(&lt;span&gt;string&lt;/span&gt;&lt;span&gt;[] args)&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt;[] aa = RandomSet(&lt;span&gt;50000&lt;/span&gt;, &lt;span&gt;99999&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;             &lt;span&gt;//&lt;/span&gt;&lt;span&gt;int[] aa = OrderedSet(5000);&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;             Console.WriteLine(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Array Length:&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; +&lt;span&gt; aa.Length);&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;             RunTheMethod((Action&amp;lt;IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&amp;gt;)SelectSort, aa.Clone() &lt;span&gt;as&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;&lt;span&gt;[]);&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;             RunTheMethod((Action&amp;lt;IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&amp;gt;)BubbleSort, aa.Clone() &lt;span&gt;as&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;&lt;span&gt;[]);&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;             RunTheMethod((Action&amp;lt;IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&amp;gt;)BubbleSortImprovedWithFlag, aa.Clone() &lt;span&gt;as&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;&lt;span&gt;[]);&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;             RunTheMethod((Action&amp;lt;IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&amp;gt;)BubbleCocktailSort, aa.Clone() &lt;span&gt;as&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;&lt;span&gt;[]);&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;             RunTheMethod((Action&amp;lt;IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&amp;gt;)InsertSort, aa.Clone() &lt;span&gt;as&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;&lt;span&gt;[]);&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;             RunTheMethod((Action&amp;lt;IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&amp;gt;)InsertSortImprovedWithBinarySearch, aa.Clone() &lt;span&gt;as&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;&lt;span&gt;[]);&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;             RunTheMethod((Action&amp;lt;IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&amp;gt;)QuickSortStrict, aa.Clone() &lt;span&gt;as&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;&lt;span&gt;[]);&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;             RunTheMethod((Action&amp;lt;IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&amp;gt;)QuickSortRelax, aa.Clone() &lt;span&gt;as&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;&lt;span&gt;[]);&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;             RunTheMethod((Action&amp;lt;IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&amp;gt;)QuickSortRelaxImproved, aa.Clone() &lt;span&gt;as&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;&lt;span&gt;[]);&lt;/span&gt;&lt;span&gt;15&lt;/span&gt;             RunTheMethod((Func&amp;lt;IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;, IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&amp;gt;)MergeSort, aa.Clone() &lt;span&gt;as&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;&lt;span&gt;[]);&lt;/span&gt;&lt;span&gt;16&lt;/span&gt;             RunTheMethod((Action&amp;lt;IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&amp;gt;)ShellSort, aa.Clone() &lt;span&gt;as&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;&lt;span&gt;[]);&lt;/span&gt;&lt;span&gt;17&lt;/span&gt;             RunTheMethod((Func&amp;lt;IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;, IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&amp;gt;)RadixSort, aa.Clone() &lt;span&gt;as&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;&lt;span&gt;[]);&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;             RunTheMethod((Action&amp;lt;IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&amp;gt;)HeapSort, aa.Clone() &lt;span&gt;as&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;&lt;span&gt;[]);&lt;/span&gt;&lt;span&gt;19&lt;/span&gt;             TestMicrosoft(aa.Clone() &lt;span&gt;as&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;&lt;span&gt;[]);&lt;/span&gt;&lt;span&gt;20&lt;/span&gt; &lt;span&gt;            Console.Read();&lt;/span&gt;&lt;span&gt;21&lt;/span&gt; &lt;span&gt;        &#125;&lt;/span&gt;&lt;span&gt;22&lt;/span&gt; &lt;span&gt;23&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; RunTheMethod(Func&amp;lt;IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;, IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&amp;gt; method, IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&lt;span&gt; data)&lt;/span&gt;&lt;span&gt;24&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt;25&lt;/span&gt;             Stopwatch stopwatch = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Stopwatch();&lt;/span&gt;&lt;span&gt;26&lt;/span&gt; &lt;span&gt;            stopwatch.Start();&lt;/span&gt;&lt;span&gt;27&lt;/span&gt;             IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; result =&lt;span&gt; method(data);&lt;/span&gt;&lt;span&gt;28&lt;/span&gt; &lt;span&gt;            stopwatch.Stop();&lt;/span&gt;&lt;span&gt;29&lt;/span&gt;             &lt;span&gt;string&lt;/span&gt; methodName =&lt;span&gt; method.Method.Name;&lt;/span&gt;&lt;span&gt;30&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; length =&lt;span&gt; methodName.Length;&lt;/span&gt;&lt;span&gt;31&lt;/span&gt;             &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;0&lt;/span&gt;; i &amp;lt; &lt;span&gt;40&lt;/span&gt; - length; i++&lt;span&gt;)&lt;/span&gt;&lt;span&gt;32&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt;33&lt;/span&gt;                 methodName += &lt;span&gt;&quot;&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;34&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;35&lt;/span&gt;             Console.WriteLine(methodName +&lt;span&gt;36&lt;/span&gt;                 &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;  IsAscOrdered:&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; + IsAscOrdered(result) + &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;  Time:&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; +&lt;span&gt; stopwatch.Elapsed.TotalSeconds);&lt;/span&gt;&lt;span&gt;37&lt;/span&gt; &lt;span&gt;        &#125;&lt;/span&gt;&lt;span&gt;38&lt;/span&gt; &lt;span&gt;39&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; RunTheMethod(Action&amp;lt;IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&amp;gt; method, IList&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt;&lt;span&gt; data)&lt;/span&gt;&lt;span&gt;40&lt;/span&gt; &lt;span&gt;        &#123;&lt;/span&gt;&lt;span&gt;41&lt;/span&gt;             Stopwatch stopwatch = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Stopwatch();&lt;/span&gt;&lt;span&gt;42&lt;/span&gt; &lt;span&gt;            stopwatch.Start();&lt;/span&gt;&lt;span&gt;43&lt;/span&gt; &lt;span&gt;            method(data);&lt;/span&gt;&lt;span&gt;44&lt;/span&gt; &lt;span&gt;            stopwatch.Stop();&lt;/span&gt;&lt;span&gt;45&lt;/span&gt;             &lt;span&gt;string&lt;/span&gt; methodName =&lt;span&gt; method.Method.Name;&lt;/span&gt;&lt;span&gt;46&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; length =&lt;span&gt; methodName.Length;&lt;/span&gt;&lt;span&gt;47&lt;/span&gt;             &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;0&lt;/span&gt;; i &amp;lt; &lt;span&gt;40&lt;/span&gt; - length; i++&lt;span&gt;)&lt;/span&gt;&lt;span&gt;48&lt;/span&gt; &lt;span&gt;            &#123;&lt;/span&gt;&lt;span&gt;49&lt;/span&gt;                 methodName += &lt;span&gt;&quot;&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;50&lt;/span&gt; &lt;span&gt;            &#125;&lt;/span&gt;&lt;span&gt;51&lt;/span&gt;             Console.WriteLine(methodName +&lt;span&gt;52&lt;/span&gt;                 &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;  IsAscOrdered:&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; + IsAscOrdered(data) + &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;  Time:&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; +&lt;span&gt; stopwatch.Elapsed.TotalSeconds);&lt;/span&gt;&lt;span&gt;53&lt;/span&gt;         &#125;\n\n\n剩余代码折叠在此处\n View Code\n测试设备：win8(64位)，i7-3630QM,8G内存，vs2012\n测试结果：\n100000,50000,10000,5000,1000,100依次是：\n\n\n结果分析：可以看出在大数组的时候，微软自带排序更接近快速排序。而当数组变小时，速度却没有明显提升，甚至变得更慢，\n比如1000和100。可以推断出在数组足够小的时候，比较已经不是影响这个方法主要因素。而根据它对大数组的表现。我们可以\n推断出它应该用的是快速排序。反编译验证下：\n\n在System.Linq.EnumerableSorter下。有兴趣的同学可以去看下详细实现。\n维基上也有个测试。硬件没我的好。时间是我测试结果时间的几百倍。有兴趣的同学可以比较下。\n在上面的测试中，我们可以看到快速最快，归并其次，冒泡最慢（维基上是希尔最快，估计使用的是某种神奇的步长）。\n在我这里，以前实现的希尔还不如二分查找优化版的快，修正后希尔快了相当多，上面测试的希尔排序是以前错误的实现。\n修正后的实现测试效果请点击右侧导航到希尔排序查看。希尔排序是一种神奇又有潜力的算法。步长不好会很挫！\n而基数排序却是比平均时间复杂度为o(nlogn)的堆排序，归并排序，快速排序还要慢的，虽然它的平均时间复杂度为o(n)。\n冒泡标识优化版对随机数列结果优化不明显，鸡尾酒版优化可以看到，但也不是很厉害。\n插入排序二分查找优化版优化比较明显。我优化的快速排序QuickSortRelaxImproved优化也不明显。\n以上是随机数列的测试结果，最大值为99999。\n而对于有序数列，这些方法表现又会如何呢？\n我这里就不演示了。本文末尾会附上demo，大家可以自行测试。\n有意思的是:\n我在测试有序数列的时候，QuickSortStrict方法栈溢出了（stack overflow exception）。这个异常\n是让我去stackoverflow搜寻答案吗？哈哈！我确信我的方法不是无限循环。跳过一堆链接。。。我是\n在测试10000个数排序的时候发生的错误。我跟踪后发现大约在9400多次递归的时候，栈溢出。找啊找\n终于找见了一个类似的问题。上面说如果一个递归9000多次而没有返回值，也会报栈溢出的。而这个方法\n对于10000个有序数列，确实每次减少一个数地递归，次数会超过限制。\n我的算法理论不怎么好，对于时间复杂度和空间复杂度，还有稳定度，搞得也不怎么清楚，只知道个大致的  \n意思。各位要笔试面试的朋友可以去维基百科这个表来了解学习。\n总结我觉得使用IList更贴近数列，更能展现基本的操作。所以我的实现中都没有将它强制转化为List\n或者int[]来调用微软封装的方法。这样说来，题目说C#实现倒快有点名不副实了。不过这样却也方便了其它语言\n朋友。比如将我这篇博文里的实现随便改改，就可以说是另一个语言版本的8种排序算法了。哈哈！在这里，\n我想说下这次学习排序对我的意义：老久不怎么动脑了，突然动起来，磨磨唧唧地得出结果，最后倒也有点成就感！\n在学习过程中，经常会脑子转不过弯，想不通的，只是走在路上或者睡觉前突然灵感一现，有点小惊喜的感觉！\n这大概就是进步的特征吧！哈哈！这次写demo+写博客花费了不少时间，倒也收获颇多，尤其在我将8种\n排序都实现之前，没进行过一次测试，全部实现完成后，测试时各种索引越界+无限循环+各种问题，没几个\n能跑通的，到后来的几乎都没有问题，也算是锻炼了思维，找出错原因的能力。本篇是自我学习的一个总结，\n要学习及锻炼的园友，还望一定自己实现一下，可以和我的比较一下，解除疑惑或者提出改进。\n主要参考：维基百科，有趣的演示Demo源码PS:我打算三月份去广州发展，主要会Asp.net mvc+jquery（不介意学习新的技术[除了webform]及语言[除了java]）。\n","categories":["学习笔记","排序算法"],"tags":["排序算法"]},{"title":"CSharp排序算法小结","url":"/2019/11/30/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/CSharp%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%B0%8F%E7%BB%93/","content":"前言\n算法这个东西其实在开发中很少用到，特别是web开发中，但是算法也很重要，因为任何的程序，任何的软件，都是由很多的算法和数据结构组成的。但是这不意味着算法对于每个软件设计人员的实际工作都是很重要的。每个项目特点和需求特殊也导致算法运用场景上不同。但是个人觉得算法运用的好的话会给自己在程序设计的时候提供比较好的思路。下面就对一些排序算法小结一下，就当做自己的一个笔记吧。\n插入排序\n 1.简介\n插入排序（Insertion Sort）的算法描述是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。插入排序在实现上，通常采用in-place排序（即只需用到O(1)的额外空间的排序），因而在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。\n2.算法描述\n一般来说，插入排序都采用in-place在数组上实现。具体算法描述如下：1.从第一个元素开始，该元素可以认为已经被排序2.取出下一个元素，在已经排序的元素序列中从后向前扫描3.如果该元素（已排序）大于新元素，将该元素移到下一位置4.重复步骤3，直到找到已排序的元素小于或者等于新元素的位置5.将新元素插入到该位置后6.重复步骤2~5如果比较操作的代价比交换操作大的话，可以采用二分查找法来减少比较操作的数目。该算法可以认为是插入排序的一个变种，称为二分查找排序。\n3.使用插入排序为一列数字进行排序的过程 \n\n\n最差时间复杂度  \n最优时间复杂度 \n平均时间复杂度\n4.C#实现\n\n    /// &lt;summary&gt;\n    /// 插入排序 /// &lt;/summary&gt;\n    public class InsertionSorter\n    &#123; public void Sort(int\\[\\] list)\n        &#123; for (int i = 1; i &lt; list.Length; ++i)\n            &#123; int t = list\\[i\\]; int j = i; while ((j &gt; 0) &amp;&amp; (list\\[j - 1\\] &gt; t))\n                &#123;\n                    list\\[j\\] \\= list\\[j - 1\\]; \\--j;\n                &#125;\n                list\\[j\\] \\= t;\n            &#125;\n\n        &#125;\n    &#125;\n\n\n数组\nint[] iArrary &#x3D; new int[] { 1, 5, 3, 6, 10, 55, 9, 2, 87, 12, 34, 75, 33, 47 };\n希尔排序\n 1.简介\n希尔排序，也称递减增量排序算法，是插入排序的一种更高效的改进版本。希尔排序是非稳定排序算法。\n2.算法实现\n原始的算法实现在最坏的情况下需要进行O(n2)的比较和交换。V. Pratt的书[1] 对算法进行了少量修改，可以使得性能提升至O(n log2 n)。这比最好的比较算法的O(n log n)要差一些。希尔排序通过将比较的全部元素分为几个区域来提升插入排序的性能。这样可以让一个元素可以一次性地朝最终位置前进一大步。然后算法再取越来越小的步长进行排序，算法的最后一步就是普通的插入排序，但是到了这步，需排序的数据几乎是已排好的了（此时插入排序较快）。假设有一个很小的数据在一个已按升序排好序的数组的末端。如果用复杂度为O(n2)的排序（冒泡排序或插入排序），可能会进行n次的比较和交换才能将该数据移至正确位置。而希尔排序会用较大的步长移动数据，所以小数据只需进行少数比较和交换即可到正确位置。一个更好理解的希尔排序实现：将数组列在一个表中并对列排序（用插入排序）。重复这过程，不过每次用更长的列来进行。最后整个表就只有一列了。将数组转换至表是为了更好地理解这算法，算法本身仅仅对原数组进行排序（通过增加索引的步长，例如是用i +&#x3D; step_size而不是i++）。\n3.排序过程\n\n最差时间复杂度 根据步长串行的不同而不同。\n最优时间复杂度 O(n)\n平均时间复杂度  根据步长串行的不同而不同。\n4.C#实现\n\n    /// &lt;summary&gt;\n    /// 希尔排序 /// &lt;/summary&gt;\n    public class ShellSorter\n    &#123; public void Sort(int\\[\\] list)\n        &#123; int inc; for (inc = 1; inc &lt;= list.Length / 9; inc = 3 \\* inc + 1) ; for (; inc &gt; 0; inc /= 3)\n            &#123; for (int i = inc + 1; i &lt;= list.Length; i += inc)\n                &#123; int t = list\\[i - 1\\]; int j = i; while ((j &gt; inc) &amp;&amp; (list\\[j - inc - 1\\] &gt; t))\n                    &#123;\n                        list\\[j \\- 1\\] = list\\[j - inc - 1\\];\n                        j \\-= inc;\n                    &#125;\n                    list\\[j \\- 1\\] = t;\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n\n\n选择排序\n 1.简介\n选择排序(Selection sort)是一种简单直观的排序算法。它的工作原理如下。首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。选择排序的主要优点与数据移动有关。如果某个元素位于正确的最终位置上，则它不会被移动。选择排序每次交换一对元素，它们当中至少有一个将被移到其最终位置上，因此对n个元素的表进行排序总共进行至多n-1次交换。在所有的完全依靠交换去移动元素的排序方法中，选择排序属于非常好的一种。\n2.实现过程\n\n最差时间复杂度 О(n²)\n最优时间复杂度 О(n²)\n平均时间复杂度 О(n²)\n3.C#实现\n\n    /// &lt;summary&gt;\n    /// 选择排序 /// &lt;/summary&gt;\n    public class SelectionSorter\n    &#123; // public enum comp &#123;COMP\\_LESS,COMP\\_EQUAL,COMP\\_GRTR&#125;;\n        private int min; // private int m=0;\n        public void Sort(int\\[\\] list)\n        &#123; for (int i = 0; i &lt; list.Length - 1; ++i)\n            &#123;\n                min \\= i; for (int j = i + 1; j &lt; list.Length; ++j)\n                &#123; if (list\\[j\\] &lt; list\\[min\\])\n                        min \\= j;\n                &#125; int t = list\\[min\\];\n                list\\[min\\] \\= list\\[i\\];\n                list\\[i\\] \\= t; // Console.WriteLine(&quot;&#123;0&#125;&quot;,list\\[i\\]);\n\n }\n        &#125;\n    &#125;\n\n\n冒泡排序\n 1.简介\n冒泡排序（Bubble Sort，台湾译为：泡沫排序或气泡排序）是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。冒泡排序对n个项目需要O(n^{2})的比较次数，且可以原地排序。尽管这个算法是最简单了解和实作的排序算法之一，但它对于少数元素之外的数列排序是很没有效率的。冒泡排序是与插入排序拥有相等的执行时间，但是两种法在需要的交换次数却很大地不同。在最坏的情况，冒泡排序需要O(n^{2})次交换，而插入排序只要最多O(n)交换。冒泡排序的实现（类似下面）通常会对已经排序好的数列拙劣地执行（O(n^{2})），而插入排序在这个例子只需要O(n)个运算。因此很多现代的算法教科书避免使用冒泡排序，而用插入排序取代之。冒泡排序如果能在内部循环第一次执行时，使用一个旗标来表示有无需要交换的可能，也有可能把最好的复杂度降低到O(n)。在这个情况，在已经排序好的数列就无交换的需要。若在每次走访数列时，把走访顺序和比较大小反过来，也可以稍微地改进效率。有时候称为往返排序，因为算法会从数列的一端到另一端之间穿梭往返。\n2.算法实现1.比较相邻的元素。如果第一个比第二个大，就交换他们两个。2.对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。在这一点，最后的元素应该会是最大的数。3.针对所有的元素重复以上的步骤，除了最后一个。4.持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。 \n3.实现过程\n\n最差时间复杂度 \n最优时间复杂度 \n平均时间复杂度 \n4.C#实现\n\n   /// &lt;summary&gt;\n    /// 冒泡排序 /// &lt;/summary&gt;\n    public class bubblesort\n    &#123; public void BubbleSort(int\\[\\] R)\n        &#123; int i, j, temp; //交换标志 \n            bool exchange; for (i = 0; i &lt; R.Length; i++) //最多做R.Length-1趟排序 \n\n {                    exchange = false; &#x2F;&#x2F;本趟排序开始前，交换标志应为假                    for (j &#x3D; R.Length - 2; j &gt;&#x3D; i; j–)                    { if (R[j + 1] &lt; R[j])　&#x2F;&#x2F;交换条件 {                            temp = R[j + 1];                            R[j + 1] &#x3D; R[j];                            R[j] = temp;                            exchange = true; &#x2F;&#x2F;发生了交换，故将交换标志置为真 }                    } if (!exchange) &#x2F;&#x2F;本趟排序未发生交换，提前终止算法 { break;                    }                }            }        }\n\n","categories":["学习笔记","排序算法"],"tags":["排序算法"]},{"title":"C#排序算法的比较","url":"/2024/09/04/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/CSharp%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83/","content":"C#排序算法的比较首先通过图表比较不同排序算法的时间复杂度和稳定性。\n排序方法平均时间最坏情况最好情况辅助空间稳定性直接插入排序O(n2)O(n2)O(n)O(1)是冒泡排序O(n2)O(n2)O(n)O(1)是简单选择排序O(n2)O(n2)O(n2)O(1)是希尔排序-O(nlog2n)~O(n2)O(nlog2n)~O(n2)O(1)否快速排序O(nlog2n)O(n2)O(nlog2n)O(log2n)否堆排序O(nlog2n)O(nlog2n)O(nlog2n)O(1)否2-路归并排序O(nlog2n)O(nlog2n)O(nlog2n)O(n)是基数排序O(d(n + rd))O(d(n + rd))O(d(n + rd))O(rd)是\n\n注：1. 算法的时间复杂度一般情况下指最坏情况下的渐近时间复杂度。\n        2. 排序算法的稳定性会对多关键字排序产生影响。\n下面通过C#代码说明不同的排序算法\n插入排序\n时间复杂度：平均情况—O(n2) 最坏情况—O(n2) 辅助空间：O(1) 稳定性：稳定\n插入排序是在一个已经有序的小序列的基础上，一次插入一个元素。当然，刚开始这个有序的小序列只有1个元素，就是第一个元素。比较是从有序序列的末尾开始，也就是想要插入的元素和已经有序的最大者开始比起，如果比它大则直接插入在其后面，否则一直往前找直到找到它该插入的位置。如果碰见一个和插入元素相等的，那么插入元素把想插入的元素放在相等元素的后面。所以，相等元素的前后顺序没有改变，从原无序序列出去的顺序就是排好序后的顺序，所以插入排序是稳定的。\n希尔排序(shell)\n时间复杂度：理想情况—O(nlog2n) 最坏情况—O(n2) 稳定性：不稳定\n希尔排序是按照不同步长对元素进行插入排序，当刚开始元素很无序的时候，步长最大，所以插入排序的元素个数很少，速度很快；当元素基本有序了，步长很小，插入排序对于有序的序列效率很高。所以，希尔排序的时间复杂度会比o(n^2)好一些。由于多次插入排序，我们知道一次插入排序是稳定的，不会改变相同元素的相对顺序，但在不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，最后其稳定性就会被打乱，所以shell排序是不稳定的。\n冒泡排序\n时间复杂度：平均情况—O(n2) 最坏情况—O(n2) 辅助空间：O(1) 稳定性：稳定\n冒泡排序就是把小的元素往前调或者把大的元素往后调。比较是相邻的两个元素比较，交换也发生在这两个元素之间。所以，如果两个元素相等，我想你是不会再无聊地把他们俩交换一下的；如果两个相等的元素没有相邻，那么即使通过前面的两两交换把两个相邻起来，这时候也不会交换，所以相同元素的前后顺序并没有改变，所以冒泡排序是一种稳定排序算法。\n快速排序\n时间复杂度：平均情况—O(nlog2n) 最坏情况—O(n2) 辅助空间：O(log2n) 稳定性：不稳定\n快速排序有两个方向，左边的i下标一直往右走，当a[i] &lt;&#x3D; a[center_index]，其中center_index是中枢元素的数组下标，一般取为数组第0个元素。而右边的j下标一直往左走，当a[j] &gt; a[center_index]。如果i和j都走不动了，i &lt;&#x3D; j, 交换a[i]和a[j],重复上面的过程，直到i&gt;j。 交换a[j]和a[center_index]，完成一趟快速排序。在中枢元素和a[j]交换的时候，很有可能把前面的元素的稳定性打乱，比如序列为 5 3 3 4 3 8 9 10 11， 现在中枢元素5和3(第5个元素，下标从1开始计)交换就会把元素3的稳定性打乱，所以快速排序是一个不稳定的排序算法，不稳定发生在中枢元素和a[j]交换的时刻。\n选择排序\n时间复杂度：平均情况—O(n2) 最坏情况—O(n2) 辅助空间：O(1) 稳定性：不稳定\n选择排序是给每个位置选择当前元素最小的，比如给第一个位置选择最小的，在剩余元素里面给第二个元素选择第二小的，依次类推，直到第n-1个元素，第n个元素不用选择了，因为只剩下它一个最大的元素了。那么，在一趟选择，如果当前元素比一个元素小，而该小的元素又出现在一个和当前元素相等的元素后面，那么交换后稳定性就被破坏了。比较拗口，举个例子，序列5 8 5 2 9， 我们知道第一遍选择第1个元素5会和2交换，那么原序列中2个5的相对前后顺序就被破坏了，所以选择排序不是一个稳定的排序算法。\n堆排序\n时间复杂度：平均情况—O(nlog2n) 最坏情况—O(nlog2n) 辅助空间：O(1) 稳定性：不稳定\n我们知道堆的结构是节点i的孩子为2*i和2*i+1节点，大顶堆要求父节点大于等于其2个子节点，小顶堆要求父节点小于等于其2个子节点。在一个长为n的序列，堆排序的过程是从第n&#x2F;2开始和其子节点共3个值选择最大(大顶堆)或者最小(小顶堆),这3个元素之间的选择当然不会破坏稳定性。但当为n&#x2F;2-1, n&#x2F;2-2, …1这些个父节点选择元素时，就会破坏稳定性。有可能第n&#x2F;2个父节点交换把后面一个元素交换过去了，而第n&#x2F;2-1个父节点把后面一个相同的元素没有交换，那么这2个相同的元素之间的稳定性就被破坏了。所以，堆排序不是稳定的排序算法\n归并排序\n时间复杂度：平均情况—O(nlog2n) 最坏情况—O(nlog2n) 辅助空间：O(n) 稳定性：稳定\n归并排序是把序列递归地分成短序列，递归出口是短序列只有1个元素(认为直接有序)或者2个序列(1次比较和交换),然后把各个有序的段序列合并成一个有序的长序列，不断合并直到原序列全部排好序。可以发现，在1个或2个元素时，1个元素不会交换，2个元素如果大小相等也没有人故意交换，这不会破坏稳定性。那么，在短的有序序列合并的过程中，稳定是是否受到破坏？没有，合并过程中我们可以保证如果两个当前元素相等时，我们把处在前面的序列的元素保存在结果序列的前面，这样就保证了稳定性。所以，归并排序也是稳定的排序算法。\n","categories":["学习笔记","排序算法"],"tags":["排序算法"]},{"title":"C#经典排序算法大全","url":"/2024/09/04/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/CSharp%E7%BB%8F%E5%85%B8%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%A4%A7%E5%85%A8/","content":"C# 经典排序算法大全\nExcerpt文章浏览阅读84次。C# 经典排序算法大全选择排序using System;using System.Collections.Generic;using System.Linq;using System.Text;namespace sorter{    public class SelectionSorter    {        private int min;       …_c# case复杂排序\n\n\nC# 经典排序算法大全选择排序using System;using System.Collections.Generic;using System.Linq;using System.Text;namespace sorter&#123;public class SelectionSorter&#123;private int min;public void Sort(int[] arr)&#123;for (int i = 0; i &lt; arr.Length - 1; ++i)&#123;min = i;for (int j = i + 1; j &lt; arr.Length; ++j)&#123;if (arr[j] &lt; arr[min])&#123;min = j;&#125;&#125;int t = arr[min];arr[min] = arr[i];arr[i] = t;&#125;&#125;&#125;class Program&#123;static void Main(string[] args)&#123;int[] arrInt = new int[] &#123; 4, 2, 7, 1, 8, 3, 9, 0, 5, 6 &#125;;SelectionSorter selSor = new SelectionSorter();selSor.Sort(arrInt);foreach (int i in arrInt)&#123;Console.WriteLine(i);&#125;Console.ReadKey();&#125;&#125;&#125;\n\n冒泡排序using System;using System.Collections.Generic;using System.Linq;using System.Text;namespace sorter&#123;public class EbullitionSorter&#123;public void Sort(int[] arr)&#123;int i, j, temp;bool done = false;j = 1;while ((j &lt; arr.Length) &amp;&amp; (!done))&#123;done = true;for (i = 0; i &lt; arr.Length - j; i++)&#123;if (arr[i] &gt; arr[i + 1])&#123;done = false;temp = arr[i];arr[i] = arr[i + 1];arr[i + 1] = temp;&#125;&#125;j++;&#125;&#125;&#125;class Program&#123;static void Main(string[] args)&#123;int[] arrInt = new int[] &#123; 4, 2, 7, 1, 8, 3, 9, 0, 5, 6 &#125;;EbullitionSorter selSor = new EbullitionSorter();selSor.Sort(arrInt);foreach (int i in arrInt)&#123;Console.WriteLine(i);&#125;Console.ReadKey();&#125;&#125;&#125;\n\n高速排序using System;using System.Collections.Generic;using System.Linq;using System.Text;namespace sorter&#123;public class QuickSorter&#123;private void swap(ref int l, ref int r)&#123;int temp;temp = l;l = r;r = temp;&#125;public void Sort(int[] list, int low, int high)&#123;int pivot;int l, r;int mid;if (high &lt;= low)&#123;return;&#125;else if (high == low + 1)&#123;if (list[low] &gt; list[high])&#123;swap(ref list[low], ref list[high]);&#125;return;&#125;mid = (low + high) &gt;&gt; 1;pivot = list[mid];swap(ref list[low], ref list[mid]);l = low + 1;r = high;do&#123;while (l &lt;= r &amp;&amp; list[l] &lt; pivot)&#123;l++;&#125;while (list[r] &gt;= pivot)&#123;r--;&#125;if (l &lt; r)&#123;swap(ref list[l], ref list[r]);&#125;&#125; while (l &lt; r);list[low] = list[r];list[r] = pivot;if (low + 1 &lt; r)&#123;Sort(list, low, r - 1);&#125;if (r + 1 &lt; high)&#123;Sort(list, r + 1, high);&#125;&#125;&#125;class Program&#123;static void Main(string[] args)&#123;int[] arrInt = new int[] &#123; 4, 2, 7, 1, 8, 3, 9, 0, 5, 6 &#125;;QuickSorter selSor = new QuickSorter();selSor.Sort(arrInt, 0, arrInt.Length - 1);foreach (int i in arrInt)&#123;Console.WriteLine(i);&#125;Console.ReadKey();&#125;&#125;&#125;\n\n插入排序using System;using System.Collections.Generic;using System.Linq;using System.Text;namespace sorter&#123;public class InsertionSorter&#123;public void Sort(int[] arr)&#123;for (int i = 1; i &lt; arr.Length; i++)&#123;int t = arr[i];int j = i;while ((j &gt; 0) &amp;&amp; (arr[j - 1] &gt; t))&#123;arr[j] = arr[j - 1];--j;&#125;arr[j] = t;&#125;&#125;&#125;class Program&#123;static void Main(string[] args)&#123;int[] arrInt = new int[] &#123; 4, 2, 7, 1, 8, 3, 9, 0, 5, 6 &#125;;InsertionSorter selSor = new InsertionSorter();selSor.Sort(arrInt);foreach (int i in arrInt)&#123;Console.WriteLine(i);&#125;Console.ReadKey();&#125;&#125;&#125;\n\n希尔排序using System;using System.Collections.Generic;using System.Linq;using System.Text;namespace sorter&#123;public class ShellSorter&#123;public void Sort(int[] arr)&#123;int inc;for (inc = 1; inc &lt;= arr.Length / 9; inc = 3 * inc + 1) ;for (; inc &gt; 0; inc /= 3)&#123;for (int i = inc + 1; i &lt;= arr.Length; i += inc)&#123;int t = arr[i - 1];int j = i;while ((j &gt; inc) &amp;&amp; (arr[j - inc - 1] &gt; t))&#123;arr[j - 1] = arr[j - inc - 1];j -= inc;&#125;arr[j - 1] = t;&#125;&#125;&#125;&#125;class Program&#123;static void Main(string[] args)&#123;int[] arrInt = new int[] &#123; 4, 2, 7, 1, 8, 3, 9, 0, 5, 6 &#125;;ShellSorter selSor = new ShellSorter();selSor.Sort(arrInt);foreach (int i in arrInt)&#123;Console.WriteLine(i);&#125;Console.ReadKey();&#125;&#125;&#125;\n\n归并排序using System;using System.Collections.Generic;using System.Linq;using System.Text;namespace Merge&#123;public class Function&#123;private int Groups;private int CopyGroups;private int mergerows;private int[] Array27;private static Random ran = new Random();public Function(int length)&#123;Array27 = new int[length];for (int i = 0; i &lt; length; i++)Array27[i] = ran.Next(1, 100);&#125;public void ToMergeSort()&#123;MergeSort(Array27);&#125;public void ToRecursiveMergeSort()&#123;RecursiveMergeSort(Array27, 0, Array27.Length - 1);&#125;public void ToNaturalMergeSort()&#123;NaturalMergeSort(Array27);&#125;public void RecursiveMergeSort(int[] Array, int left, int right)&#123;int middle = (left + right) / 2;if (left &lt; right)&#123;RecursiveMergeSort(Array, left, middle);RecursiveMergeSort(Array, middle + 1, right);MergeOne(Array, left, middle, right);&#125;&#125;public void MergeOne(int[] Array, int left, int middle, int right)&#123;int leftindex = left;int rightindex = middle + 1;int[] merge = new int[right + 1];int index = 0;while (leftindex &lt;= middle &amp;&amp; rightindex &lt;= right)merge[index++] = (Array[leftindex] - Array[rightindex]) &gt;= 0 ? Array[rightindex++] : Array[leftindex++];if (leftindex &lt;= middle)&#123;for (int i = leftindex; i &lt;= middle; i++)merge[index++] = Array[i];&#125;if (rightindex &lt;= right)&#123;for (int i = rightindex; i &lt;= right; i++)merge[index++] = Array[i];&#125;index = 0;for (int i = left; i &lt;= right; i++)Array[i] = merge[index++];&#125;public void MergeSort(int[] Array)&#123;int[] merge = new int[Array.Length];int P = 0;while (true)&#123;int index = 0;int ENumb = (int)Math.Pow(2, P);if (ENumb &lt; Array.Length)&#123;while (true)&#123;int TorFAndrightindex = index;if (TorFAndrightindex &lt;= Array.Length - 1)MergeTwo(Array, merge, index, ENumb);elsebreak;index += 2 * ENumb;&#125;&#125;elsebreak;P++;&#125;&#125;public void MergeTwo(int[] Array, int[] merge, int index, int ENumb)&#123;int left = index;int middle = left + ENumb - 1;if (middle &gt;= Array.Length)&#123;middle = index;&#125;int mergeindex = index;int right;int middleTwo = (index + ENumb - 1) + 1;right = index + ENumb + ENumb - 1;if (right &gt;= Array.Length - 1)&#123;right = Array.Length - 1;&#125;while (left &lt;= middle &amp;&amp; middleTwo &lt;= right)&#123;merge[mergeindex++] = Array[left] &gt;= Array[middleTwo] ? Array[middleTwo++] : Array[left++];&#125;if (left &lt;= middle)&#123;while (left &lt;= middle &amp;&amp; mergeindex &lt; merge.Length)merge[mergeindex++] = Array[left++];&#125;if (middleTwo &lt;= right)&#123;while (middleTwo &lt;= right)merge[mergeindex++] = Array[middleTwo++];&#125;if (right + 1 &gt;= Array.Length)Copy(Array, merge);&#125;public void NaturalMergeSort(int[] Array)&#123;int[,] PointsSymbol = LinearPoints(Array);if (PointsSymbol[0, 1] == Array.Length - 1)return;elseNaturalMerge(Array, PointsSymbol);&#125;public void NaturalMerge(int[] Array, int[,] PointsSymbol)&#123;int left;int right;int leftend;int rightend;mergerows = GNumberTwo(Groups);CopyGroups = Groups;int[] TempArray = new int[Array.Length];while (true)&#123;int[,] TempPointsSymbol = new int[mergerows, 2];int row = 0;do&#123;if (row != CopyGroups - 1)&#123;left = PointsSymbol[row, 0];leftend = PointsSymbol[row, 1];right = PointsSymbol[row + 1, 0];rightend = PointsSymbol[row + 1, 1];MergeThree(Array, TempArray, left, leftend, right, rightend);MergePointSymbol(PointsSymbol, TempPointsSymbol, row);&#125;else&#123;默认剩下的单独一个子数组已经虚拟合并。然后Copy进TempArray。int TempRow = PointsSymbol[row, 0];int TempCol = PointsSymbol[row, 1];while (TempRow &lt;= TempCol)TempArray[TempRow] = Array[TempRow++];TempPointsSymbol[row / 2, 0] = PointsSymbol[row, 0];TempPointsSymbol[row / 2, 1] = PointsSymbol[row, 1];break;&#125;row += 2;if (TempPointsSymbol[0, 1] == Array.Length - 1)break;&#125;while (row &lt;= CopyGroups - 1);Copy(Array, TempArray);UpdatePointSymbol(PointsSymbol, TempPointsSymbol, row);mergerows = GNumber(mergerows);CopyGroups = GNumberTwo(CopyGroups);if (PointsSymbol[0, 1] == Array.Length - 1)break;&#125;&#125;public int GNumber(int Value)&#123;if (Value % 2 == 0)Value /= 2;elseValue -= 1;return Value;&#125;public int GNumberTwo(int Value)&#123;if (Value % 2 == 0)mergerows = Value / 2;elsemergerows = Value / 2 + 1;return mergerows;&#125;public void MergeThree(int[] Array, int[] Temp, int left, int leftend, int right, int rightend)&#123;int index = left;while (left &lt;= leftend &amp;&amp; right &lt;= rightend)Temp[index++] = Array[left] &gt;= Array[right] ? Array[right++] : Array[left++];while (left &lt;= leftend)Temp[index++] = Array[left++];while (right &lt;= rightend)Temp[index++] = Array[right++];&#125;public void MergePointSymbol(int[,] PointsSymbol, int[,] TempPointsSymbol, int row)&#123;int rowindex = row / 2;TempPointsSymbol[rowindex, 0] = PointsSymbol[row, 0];TempPointsSymbol[rowindex, 1] = PointsSymbol[row + 1, 1];&#125;public void UpdatePointSymbol(int[,] PointsSymbol, int[,] TempPointsSymbol, int rows)&#123;int row = 0;for (; row &lt; TempPointsSymbol.GetLength(0); row++)&#123;for (int col = 0; col &lt; 2; col++)PointsSymbol[row, col] = TempPointsSymbol[row, col];&#125;for (; row &lt; PointsSymbol.GetLength(0); row++)&#123;for (int col2 = 0; col2 &lt; 2; col2++)PointsSymbol[row, col2] = 0;&#125;补剩下的index组，\n\n&#x2F;&#x2F; int row3 &#x3D; TempPointsSymbol.GetLength(0); &#x2F;&#x2F; PointsSymbol[row3, 0] &#x3D; PointsSymbol[rows, 0]; &#x2F;&#x2F; PointsSymbol[row3, 1] &#x3D; PointsSymbol[rows, 1]; &#x2F;&#x2F; &#x2F;&#x2F;后面的清零 &#x2F;&#x2F; for (int row4 &#x3D; row3 + 1; row4 &lt; PointsSymbol.GetLength(0); row4++) &#x2F;&#x2F; { &#x2F;&#x2F; for (int col4 &#x3D; 0; col4 &lt; 2; col4++) &#x2F;&#x2F; PointsSymbol[row4, col4] &#x3D; 0; &#x2F;&#x2F; } &#x2F;&#x2F;} } public int[,] LinearPoints(int[] Array) { Groups &#x3D; 1; int StartPoint &#x3D; 0; int row &#x3D; 0; int col &#x3D; 0; &#x2F;&#x2F;最糟糕的情况就是有Array.Length行。 int[,] PointsSet &#x3D; new int[Array.Length, 2]; &#x2F;&#x2F;线性扫描Array，划分数组 &#x2F;&#x2F;初始前index&#x3D;0 PointsSet[row, col] &#x3D; 0; do { &#x2F;&#x2F;推断升序子数组终于的index开关 bool Judge &#x3D; false; &#x2F;&#x2F;从Array第二个数推断是否要结束或者是否是升序子数组. while (++StartPoint &lt; Array.Length &amp;&amp; Array[StartPoint] &lt; Array[StartPoint - 1]) { &#x2F;&#x2F;打开第一个升序子数组结束的index开关 Judge &#x3D; true; &#x2F;&#x2F;又一次開始第二个升序子数组的前index PointsSet[row, col + 1] &#x3D; StartPoint - 1; &#x2F;&#x2F;计算子数组个数 Groups++; &#x2F;&#x2F;换行记录自然子数组的index row++; break; &#x2F;&#x2F;–StartPoint; } &#x2F;&#x2F;升序子数组结束index if (Judge) PointsSet[row, col] &#x3D; StartPoint; &#x2F;&#x2F;else &#x2F;&#x2F; –StartPoint; } while (StartPoint &lt; Array.Length); &#x2F;&#x2F;终于index&#x3D;StartPoint - 1，可是糟糕情况下还有剩余若干行为： 0,0 … PointsSet[row, col + 1] &#x3D; StartPoint - 1; &#x2F;&#x2F;调用展示方法 DisplaySubarray(Array, PointsSet, Groups); return PointsSet; } public void DisplaySubarray(int[] Array, int[,] PointsSet, int Groups) { Console.WriteLine(“Subarray is {0}:”, Groups); &#x2F;&#x2F;展示子数组的前后index for (int r &#x3D; 0; r &lt; Groups; r++) { for (int c &#x3D; 0; c &lt; PointsSet.GetLength(1); c++) { Console.Write(PointsSet[r, c]); if (c &lt; PointsSet.GetLength(1) - 1) Console.Write(“,”); } Console.Write(“\\t\\t”); } Console.WriteLine(); &#x2F;&#x2F;展示分出的子数组 for (int v &#x3D; 0; v &lt; Groups; v++) { int i &#x3D; 1; for (int r &#x3D; PointsSet[v, 0]; r &lt;&#x3D; PointsSet[v, 1]; r++) { Console.Write(Array[r] + “ “); i++; } if (i &lt;&#x3D; 3) Console.Write(“\\t\\t”); else Console.Write(“\\t”); if (PointsSet[v, 1] &#x3D;&#x3D; Array.Length) break; } } public void Copy(int[] Array, int[] merge) { &#x2F;&#x2F;一部分排好序的元素替换掉原来Array中的元素 for (int i &#x3D; 0; i &lt; Array.Length; i++) { Array[i] &#x3D; merge[i]; } } &#x2F;&#x2F;输出 public override string ToString() { string temporary &#x3D; string.Empty; foreach (var element in Array27) temporary +&#x3D; element + “ “; temporary +&#x3D; “\\n”; return temporary; } } class Program { static void Main(string[] args) { while (true) { Console.WriteLine(“请选择：”); Console.WriteLine(“1.归并排序（非递归）”); Console.WriteLine(“2.归并排序（递归）”); Console.WriteLine(“3.归并排序（自然合并）”); Console.WriteLine(“4.退出”); int Arraynum &#x3D; Convert.ToInt32(Console.ReadLine()); switch (Arraynum) { case 4: Environment.Exit(0); break; case 1: Console.WriteLine(“Please Input Array Length”); int Leng271 &#x3D; Convert.ToInt32(Console.ReadLine()); Function obj1 &#x3D; new Function(Leng271); Console.WriteLine(“The original sequence:”); Console.WriteLine(obj1); Console.WriteLine(“‘MergeSort’ Finaly Sorting Result:”); obj1.ToMergeSort(); Console.WriteLine(obj1); break; case 2: Console.WriteLine(“Please Input Array Length”); int Leng272 &#x3D; Convert.ToInt32(Console.ReadLine()); Function obj2 &#x3D; new Function(Leng272); Console.WriteLine(“The original sequence:”); Console.WriteLine(obj2); Console.WriteLine(“‘RecursiveMergeSort’ Finaly Sorting Result:”); obj2.ToRecursiveMergeSort(); Console.WriteLine(obj2); break; case 3: Console.WriteLine(“Please Input Array Length”); int Leng273 &#x3D; Convert.ToInt32(Console.ReadLine()); Function obj3 &#x3D; new Function(Leng273); Console.WriteLine(“The original sequence:”); Console.WriteLine(obj3); obj3.ToNaturalMergeSort(); Console.WriteLine(); Console.WriteLine(); Console.WriteLine(“‘NaturalMergeSort’ Finaly Sorting Result:”); Console.WriteLine(obj3); break; } } } } }\n基数排序using System;using System.Collections.Generic;using System.Linq;using System.Text;namespace Merge&#123;public class RadixSorter&#123;public int[] RadixSort(int[] ArrayToSort, int digit)&#123;for (int k = 1; k &lt;= digit; k++)&#123;int[] tmpArray = new int[ArrayToSort.Length];int[] tmpCountingSortArray = new int[10] &#123; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 &#125;;for (int i = 0; i &lt; ArrayToSort.Length; i++)&#123;int tmpSplitDigit = ArrayToSort[i] / (int)Math.Pow(10, k - 1) - (ArrayToSort[i] / (int)Math.Pow(10, k)) * 10;tmpCountingSortArray[tmpSplitDigit] += 1;&#125;for (int m = 1; m &lt; 10; m++)&#123;tmpCountingSortArray[m] += tmpCountingSortArray[m -1];&#125;for (int n = ArrayToSort.Length - 1; n &gt;= 0; n--)&#123;int tmpSplitDigit = ArrayToSort[n] / (int)Math.Pow(10, k - 1) -(ArrayToSort[n] / (int)Math.Pow(10, k)) * 10;tmpArray[tmpCountingSortArray[tmpSplitDigit] - 1] = ArrayToSort[n];tmpCountingSortArray[tmpSplitDigit] -= 1;&#125;for (int p = 0; p &lt; ArrayToSort.Length; p++)&#123;ArrayToSort[p] = tmpArray[p];&#125;&#125;return ArrayToSort;&#125;&#125;class Program&#123;static void Main(string[] args)&#123;int[] intArray = new int[] &#123; 5, 3, 7, 4, 8, 2, 9, 1, 0, 6 &#125;;int[] newIntArray = intArray;RadixSorter rS=new RadixSorter();newIntArray = rS.RadixSort(intArray, intArray.Length);foreach (int i in intArray)&#123;Console.Write(i + &quot; &quot;);&#125;Console.ReadKey();&#125;&#125;&#125;\n\n计数排序using System;using System.Collections.Generic;using System.Linq;using System.Text;namespace Merge&#123;class Program&#123;\n\n&#x2F;&#x2F;&#x2F; 要求: &#x2F;&#x2F;&#x2F; arrayToSort的元素必须大于等于0。或者经过一定的转换使其元素在 &#x2F;&#x2F;&#x2F; 大于等于0范围内。比如有例如以下序列(-1,-8,10,11),那么依据最小值8, &#x2F;&#x2F;&#x2F; 将各个数字加8转化为(7,0,18,19),然后进行计数排序。结果为(0,7,18,19), &#x2F;&#x2F;&#x2F; 然后再将结果个数字减8即为(-8,-1,10,11) &#x2F;&#x2F;&#x2F;  &#x2F;&#x2F;&#x2F; 要排序的数组 &#x2F;&#x2F;&#x2F; 数组的最大值加一 &#x2F;&#x2F;&#x2F; 计数排序后的结果 public static int[] CountingSort(int[] arrayToSort, int k) { &#x2F;&#x2F; 排序后的结果存储 int[] sortedArray &#x3D; new int[arrayToSort.Length]; &#x2F;&#x2F; 计数数组 int[] countingArray &#x3D; new int[k]; &#x2F;&#x2F; 计数数组初始化 for (int i &#x3D; 0; i &lt; countingArray.Length; i++) { countingArray[i] &#x3D; 0; } &#x2F;&#x2F; 单个元素计数(经过该步骤countingArray[i]的含义为数字i的个数为countingArray[i]) for (int i &#x3D; 0; i &lt; arrayToSort.Length; i++) { countingArray[arrayToSort[i]] &#x3D; countingArray[arrayToSort[i]] + 1; } &#x2F;&#x2F; 计算小于等于某数的个数(经过该步骤countingArray[i]的含义为小于等于数字i的元素个数为countingArray[i]) for (int i &#x3D; 1; i &lt; countingArray.Length; i++) { countingArray[i] +&#x3D; countingArray[i - 1]; } &#x2F;&#x2F; 得到排序后的结果 for (int i &#x3D; 0; i &lt; sortedArray.Length; i++) { int numIndex &#x3D; countingArray[arrayToSort[i]] - 1; sortedArray[numIndex] &#x3D; arrayToSort[i]; countingArray[arrayToSort[i]] &#x3D; countingArray[arrayToSort[i]] - 1; } return sortedArray; } static void Main(string[] args) { int[] intArray &#x3D; new int[] { 5, 3, 7, 4, 8, 2, 9, 1, 0, 6 }; int[] intNewArray &#x3D; intArray; intNewArray &#x3D; CountingSort(intArray, intArray.Length); foreach (int i in intNewArray) { Console.Write(i + “ “); } Console.ReadKey(); } } }\n堆排序using System;using System.Collections.Generic;using System.Linq;using System.Text;namespace Merge&#123;class Program&#123;private static void HeapSortFunction(int[] array)&#123;try&#123;BuildMaxHeap(array);for (int i = array.Length - 1; i &gt; 0; i--)&#123;Swap(ref array[0], ref array[i]);MaxHeapify(array, 0, i);&#125;&#125;catch (Exception ex)&#123;Console.Write(ex.Message);&#125;&#125;private static void BuildMaxHeap(int[] array)&#123;try&#123;for (int i = array.Length / 2 - 1; i &gt;= 0; i--)&#123;MaxHeapify(array, i, array.Length);&#125;&#125;catch (Exception ex)&#123;Console.Write(ex.Message);&#125;&#125;private static void MaxHeapify(int[] array, int currentIndex, int heapSize)&#123;try&#123;int left = 2 * currentIndex + 1;int right = 2 * currentIndex + 2;int large = currentIndex;if (left &lt; heapSize &amp;&amp; array[left] &gt; array[large])&#123;large = left;&#125;if (right &lt; heapSize &amp;&amp; array[right] &gt; array[large])&#123;large = right;&#125;if (currentIndex != large)&#123;Swap(ref array[currentIndex], ref array[large]);MaxHeapify(array, large, heapSize);&#125;&#125;catch (Exception ex)&#123;Console.Write(ex.Message);&#125;&#125;private static void Swap(ref int a, ref int b)&#123;int temp = 0;temp = a;a = b;b = temp;&#125;static void Main(string[] args)&#123;int[] intArray = new int[] &#123; 5, 3, 7, 4, 8, 2, 9, 1, 0, 6 &#125;;HeapSortFunction(intArray);foreach (int i in intArray)&#123;Console.Write(i + &quot; &quot;);&#125;Console.ReadKey();&#125;&#125;&#125;\n\n排序的分类&#x2F;稳定性&#x2F;时间复杂度和空间复杂度总结  \n版权声明：本文博客原创文章。博客，未经同意，不得转载。\n","categories":["学习笔记","排序算法"],"tags":["排序算法"]},{"title":"冒泡排序算法CSharp实现","url":"/2024/09/04/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95CSharp%E5%AE%9E%E7%8E%B0/","content":"冒泡排序算法（C#实现） - Eric Sun - 博客园\nExcerpt简单的冒泡排序算法，代码如下：&#x2F;&#x2F;冒泡排序（从数组的起始位置开始遍历，以大数为基准：大的数向下沉一位）privatestaticvoid BubbleSortFunction(int[] array) { try { int length &#x3D; array.Length; int temp; bool\n\n\n简单的冒泡排序算法，代码如下：\n\n&lt;span&gt;//&lt;/span&gt;&lt;span&gt;冒泡排序（从数组的起始位置开始遍历，以大数为基准：大的数向下沉一位）&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;private&lt;/span&gt;&lt;span&gt;static&lt;/span&gt;&lt;span&gt;void&lt;/span&gt;&lt;span&gt; BubbleSortFunction(&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt;[] array)&lt;br&gt;        &#123;&lt;br&gt;            &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt;&lt;br&gt;            &#123;&lt;br&gt;                &lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; length &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; array.Length;&lt;br&gt;                &lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; temp;&lt;br&gt;                &lt;/span&gt;&lt;span&gt;bool&lt;/span&gt;&lt;span&gt; hasExchangeAction; &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;记录此次大循环中相邻的两个数是否发生过互换（如果没有互换，则数组已经是有序的）&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;&lt;br&gt;                &lt;/span&gt;&lt;span&gt;for&lt;/span&gt;&lt;span&gt; (&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; i &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;; i &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt; length &lt;/span&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;; i&lt;/span&gt;&lt;span&gt;++&lt;/span&gt;&lt;span&gt;)    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;数组有N个数，那么用N-1次大循环就可以排完&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                &#123;&lt;br&gt;                    hasExchangeAction &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;false&lt;/span&gt;&lt;span&gt;;  &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;每次大循环都假设数组有序&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;&lt;br&gt;                    &lt;/span&gt;&lt;span&gt;for&lt;/span&gt;&lt;span&gt; (&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; j &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;; j &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt; length &lt;/span&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt; i &lt;/span&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;; j&lt;/span&gt;&lt;span&gt;++&lt;/span&gt;&lt;span&gt;)    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;从数组下标0处开始遍历，（length - i - 1 是刨除已经排好的大数）&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                    &#123;&lt;br&gt;                        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (array[j] &lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; array[j &lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;])    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;相邻两个数进行比较，如果前面的数大于后面的数，则将这相邻的两个数进行互换&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                        &#123;&lt;br&gt;                            temp &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; array[j];&lt;br&gt;                            array[j] &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; array[j &lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;];&lt;br&gt;                            array[j &lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;] &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; temp;&lt;br&gt;                            hasExchangeAction &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;true&lt;/span&gt;&lt;span&gt;;   &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;发生过互换&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                        &#125;&lt;br&gt;                    &#125;&lt;br&gt;&lt;br&gt;                    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (&lt;/span&gt;&lt;span&gt;!&lt;/span&gt;&lt;span&gt;hasExchangeAction) &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;如果没有发生过互换，则数组已经是有序的了，跳出循环&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                    &#123;&lt;br&gt;                        &lt;/span&gt;&lt;span&gt;break&lt;/span&gt;&lt;span&gt;;&lt;br&gt;                    &#125;&lt;br&gt;                &#125;&lt;br&gt;            &#125;&lt;br&gt;            &lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (Exception ex)&lt;br&gt;            &#123; &#125;&lt;br&gt;        &#125;&lt;/span&gt;\n\n\n。。。。。\nposted @ 2011-08-17 16:02  Eric Sun  阅读(7637)  评论()  编辑  收藏  举报\n","categories":["学习笔记","排序算法"],"tags":["排序算法"]},{"title":"堆排序算法CSharp实现","url":"/2024/09/04/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%A0%86%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95CSharp%E5%AE%9E%E7%8E%B0/","content":"堆排序算法（C#实现）\nExcerpt在软件设计相关领域，“堆（Heap）”的概念主要涉及到两个方面：一种是数据结构，逻辑上是一颗完全二叉树，存储上是一个数组对象（二叉堆）。另一种是垃圾收集存储区，是软件系统可以编程的内存区域。本文所说的堆指的是前者，另外，这篇文章中堆中元素的值均以整形为例堆排序的时间复杂度是O(nlog2n),与快速\n\n\n在软件设计相关领域，“堆（Heap）”的概念主要涉及到两个方面：\n一种是数据结构，逻辑上是一颗完全二叉树，存储上是一个数组对象（二叉堆）。\n另一种是垃圾收集存储区，是软件系统可以编程的内存区域。\n本文所说的堆指的是前者，另外，这篇文章中堆中元素的值均以整形为例\n堆排序的时间复杂度是O(nlog2n),与快速排序达到相同的时间复杂度. 但是在实际应用中,我们往往采用快速排序而不是堆排序. 这是因为快速排序的一个好的实现,往往比堆排序具有更好的表现. 堆排序的主要用途,是在形成和处理优先级队列方面. 另外, 如果计算要求是类优先级队列(比如, 只要返回最大或者最小元素, 只有有限的插入要求等), 堆同样是很适合的数据结构.\n**堆排序**堆排序是一种选择排序。是不稳定的排序方法。时间复杂度为O(nlog2n)。堆排序的特点是：在排序过程中，将排序数组看成是一棵完全二叉树的顺序存储结构，利用完全二叉树中双亲节点和孩子节点之间的内在关系，在当前无序区中选择关键字最大(或最小)的记录。\n基本思想1.将要排序的数组创建为一个大根堆。大根堆的堆顶元素就是这个堆中最大的元素。2.将大根堆的堆顶元素和无序区最后一个元素交换，并将无序区最后一个位置例入有序区，然后将新的无序区调整为大根堆。重复操作，无序区在递减，有序区在递增。初始时，整个数组为无序区，第一次交换后无序区减一，有序区增一。每一次交换，都是大根堆的堆顶元素插入有序区，所以有序区保持是有序的。\n大根堆和小根堆堆：是一颗完全二叉树。大根堆：所有节点的子节点比其自身小的堆小根堆：所有节点的子节点比其自身大的堆\n堆与数组的关系\n堆是一种逻辑结构（形象的表示数据的存储格式），数组则是数据的实际存储结构（对应数据的存储地址），堆中的根节点与左右子节点在存储数组中的位置关系如下：假设根节点在数组中的位置（数组下标）为 i ，那么左节点在数组中的位置（数组下标）为 i * 2 + 1 ， 右节点在数组中的位置（数组下标）为 i * 2 + 2 。\n以上是基本的知识点，具体代码如下所示：\n\n&lt;span&gt;        //&lt;/span&gt;&lt;span&gt;堆排序算法（传递待排数组名，即：数组的地址。故形参数组的各种操作反应到实参数组上）&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;　　　　 private &lt;/span&gt;&lt;span&gt;static &lt;/span&gt;&lt;span&gt;void&lt;/span&gt;&lt;span&gt; HeapSortFunction(&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt;[] array)&lt;br&gt;        &#123;&lt;br&gt;            &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt;&lt;br&gt;            &#123;&lt;br&gt;                BuildMaxHeap(array);    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;创建大顶推（初始状态看做：整体无序）&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;　　　　　　　　　for&lt;/span&gt;&lt;span&gt; (&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; i &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; array.Length &lt;/span&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;; i &lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;; i&lt;/span&gt;&lt;span&gt;--&lt;/span&gt;&lt;span&gt;)&lt;br&gt;                &#123;&lt;br&gt;                    Swap(&lt;/span&gt;&lt;span&gt;ref&lt;/span&gt;&lt;span&gt; array[&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;], &lt;/span&gt;&lt;span&gt;ref&lt;/span&gt;&lt;span&gt; array[i]); &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;将堆顶元素依次与无序区的最后一位交换（使堆顶元素进入有序区）&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                    MaxHeapify(array, &lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;, i); &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;重新将无序区调整为大顶堆&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                &#125;&lt;br&gt;            &#125;&lt;br&gt;            &lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (Exception ex)&lt;br&gt;            &#123; &#125;&lt;br&gt;        &#125;&lt;br&gt;&lt;br&gt;        &lt;/span&gt;&lt;span&gt;///&lt;/span&gt;&lt;span&gt;&amp;lt;summary&amp;gt;&lt;/span&gt;&lt;span&gt;&lt;br&gt;        &lt;/span&gt;&lt;span&gt;///&lt;/span&gt;&lt;span&gt; 创建大顶推（根节点大于左右子节点）&lt;br&gt;        &lt;/span&gt;&lt;span&gt;///&lt;/span&gt;&lt;span&gt;&amp;lt;/summary&amp;gt;&lt;/span&gt;&lt;span&gt;&lt;br&gt;        &lt;/span&gt;&lt;span&gt;///&lt;/span&gt;&lt;span&gt;&amp;lt;param name=&quot;array&quot;&amp;gt;&lt;/span&gt;&lt;span&gt;待排数组&lt;/span&gt;&lt;span&gt;&amp;lt;/param&amp;gt;&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;　　　　 private &lt;/span&gt;&lt;span&gt;static &lt;/span&gt;&lt;span&gt;void&lt;/span&gt;&lt;span&gt; BuildMaxHeap(&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt;[] array)&lt;br&gt;        &#123;&lt;br&gt;            &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt;&lt;br&gt;            &#123;&lt;br&gt;                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;根据大顶堆的性质可知：数组的前半段的元素为根节点，其余元素都为叶节点&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;　　　　　　　　　for&lt;/span&gt;&lt;span&gt; (&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; i &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; array.Length &lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;; i &lt;/span&gt;&lt;span&gt;&amp;gt;=&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;; i&lt;/span&gt;&lt;span&gt;--&lt;/span&gt;&lt;span&gt;) &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;从最底层的最后一个根节点开始进行大顶推的调整&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                &#123;&lt;br&gt;                    MaxHeapify(array, i, array.Length); &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;调整大顶堆&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                &#125;&lt;br&gt;            &#125;&lt;br&gt;            &lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (Exception ex)&lt;br&gt;            &#123; &#125;&lt;br&gt;        &#125;&lt;br&gt;&lt;br&gt;        &lt;/span&gt;&lt;span&gt;///&lt;/span&gt;&lt;span&gt;&amp;lt;summary&amp;gt;&lt;/span&gt;&lt;span&gt;&lt;br&gt;        &lt;/span&gt;&lt;span&gt;///&lt;/span&gt;&lt;span&gt; 大顶推的调整过程&lt;br&gt;        &lt;/span&gt;&lt;span&gt;///&lt;/span&gt;&lt;span&gt;&amp;lt;/summary&amp;gt;&lt;/span&gt;&lt;span&gt;&lt;br&gt;        &lt;/span&gt;&lt;span&gt;///&lt;/span&gt;&lt;span&gt;&amp;lt;param name=&quot;array&quot;&amp;gt;&lt;/span&gt;&lt;span&gt;待调整的数组&lt;/span&gt;&lt;span&gt;&amp;lt;/param&amp;gt;&lt;/span&gt;&lt;span&gt;&lt;br&gt;        &lt;/span&gt;&lt;span&gt;///&lt;/span&gt;&lt;span&gt;&amp;lt;param name=&quot;currentIndex&quot;&amp;gt;&lt;/span&gt;&lt;span&gt;待调整元素在数组中的位置（即：根节点）&lt;/span&gt;&lt;span&gt;&amp;lt;/param&amp;gt;&lt;/span&gt;&lt;span&gt;&lt;br&gt;        &lt;/span&gt;&lt;span&gt;///&lt;/span&gt;&lt;span&gt;&amp;lt;param name=&quot;heapSize&quot;&amp;gt;&lt;/span&gt;&lt;span&gt;堆中所有元素的个数&lt;/span&gt;&lt;span&gt;&amp;lt;/param&amp;gt;&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;　　　　 private &lt;/span&gt;&lt;span&gt;static &lt;/span&gt;&lt;span&gt;void&lt;/span&gt;&lt;span&gt; MaxHeapify(&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt;[] array, &lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; currentIndex, &lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; heapSize)&lt;br&gt;        &#123;&lt;br&gt;            &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt;&lt;br&gt;            &#123;&lt;br&gt;                &lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; left &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;*&lt;/span&gt;&lt;span&gt; currentIndex &lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;;    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;左子节点在数组中的位置&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;　　　　　　　　　int&lt;/span&gt;&lt;span&gt; right &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;*&lt;/span&gt;&lt;span&gt; currentIndex &lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;;   &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;右子节点在数组中的位置&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;　　　　　　　　　int&lt;/span&gt;&lt;span&gt; large &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; currentIndex;   &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;记录此根节点、左子节点、右子节点 三者中最大值的位置&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;&lt;br&gt;                &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (left &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt; heapSize &lt;/span&gt;&lt;span&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span&gt; array[left] &lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; array[large])  &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;与左子节点进行比较&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                &#123;&lt;br&gt;                    large &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; left;&lt;br&gt;                &#125;&lt;br&gt;                &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (right &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt; heapSize &lt;/span&gt;&lt;span&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span&gt; array[right] &lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; array[large])    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;与右子节点进行比较&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                &#123;&lt;br&gt;                    large &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; right;&lt;br&gt;                &#125;&lt;br&gt;                &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (currentIndex &lt;/span&gt;&lt;span&gt;!=&lt;/span&gt;&lt;span&gt; large)  &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;如果 currentIndex != large 则表明 large 发生变化（即：左右子节点中有大于根节点的情况）&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                &#123;&lt;br&gt;                    Swap(&lt;/span&gt;&lt;span&gt;ref&lt;/span&gt;&lt;span&gt; array[currentIndex], &lt;/span&gt;&lt;span&gt;ref&lt;/span&gt;&lt;span&gt; array[large]);    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;将左右节点中的大者与根节点进行交换（即：实现局部大顶堆）&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                    MaxHeapify(array, large, heapSize); &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;以上次调整动作的large位置（为此次调整的根节点位置），进行递归调整&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                &#125;&lt;br&gt;            &#125;&lt;br&gt;            &lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (Exception ex)&lt;br&gt;            &#123; &#125;&lt;br&gt;        &#125;&lt;br&gt;&lt;br&gt;        &lt;/span&gt;&lt;span&gt;///&lt;/span&gt;&lt;span&gt;&amp;lt;summary&amp;gt;&lt;/span&gt;&lt;span&gt;&lt;br&gt;        &lt;/span&gt;&lt;span&gt;///&lt;/span&gt;&lt;span&gt; 交换函数&lt;br&gt;        &lt;/span&gt;&lt;span&gt;///&lt;/span&gt;&lt;span&gt;&amp;lt;/summary&amp;gt;&lt;/span&gt;&lt;span&gt;&lt;br&gt;        &lt;/span&gt;&lt;span&gt;///&lt;/span&gt;&lt;span&gt;&amp;lt;param name=&quot;a&quot;&amp;gt;&lt;/span&gt;&lt;span&gt;元素a&lt;/span&gt;&lt;span&gt;&amp;lt;/param&amp;gt;&lt;/span&gt;&lt;span&gt;&lt;br&gt;        &lt;/span&gt;&lt;span&gt;///&lt;/span&gt;&lt;span&gt;&amp;lt;param name=&quot;b&quot;&amp;gt;&lt;/span&gt;&lt;span&gt;元素b&lt;/span&gt;&lt;span&gt;&amp;lt;/param&amp;gt;&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;　　　　　private &lt;/span&gt;&lt;span&gt;static &lt;/span&gt;&lt;span&gt;void&lt;/span&gt;&lt;span&gt; Swap(&lt;/span&gt;&lt;span&gt;ref&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; a, &lt;/span&gt;&lt;span&gt;ref&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; b)&lt;br&gt;        &#123;&lt;br&gt;            &lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; temp &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;;&lt;br&gt;            temp &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; a;&lt;br&gt;            a &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; b;&lt;br&gt;            b &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; temp;&lt;br&gt;        &#125;&lt;/span&gt;\n\n\n","categories":["学习笔记","排序算法"],"tags":["排序算法"]},{"title":"归并排序算法CSharp实现","url":"/2024/09/04/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95CSharp%E5%AE%9E%E7%8E%B0/","content":"归并排序算法（C#实现）\nExcerpt自顶向下的归并排序：是利用递归和分而治之的技术将数据序列划分成为越来越小的半子表，再对半子表排序，最后再用递归步骤将排好序的半子表合并成为越来越大的有序序列，归并排序包括两个步骤，分别为：1）划分子表  2）合并半子表\n\n\n     归并排序(Merge Sort)是利用”归并”技术来进行排序。归并是指将若干个已排序的子文件合并成一个有序的文件。归并排序有两种方式：1): 自底向上的方法 2):自顶向下的方法\n 1、 自底向上的方法（1） 自底向上的基本思想     自底向上的基本思想是：第1趟归并排序时，将待排序的文件R[1..n]看作是n个长度为1的有序子文件，将这些子文件两两归并，若n为偶数，则得到n&#x2F;2个长度为2的有序子文件；若n为奇数，则最后一个子文件轮空(不参与归并)。故本趟归并完成后，前n&#x2F;2 - 1个有序子文件长度为2，但最后一个子文件长度仍为1；第2趟归并则是将第1趟归并所得到的n&#x2F;2个有序的子文件两两归并，如此反复，直到最后得到一个长度为n的有序文件为止。     上述的每次归并操作，均是将两个有序的子文件合并成一个有序的子文件，故称其为”二路归并排序”。类似地有k(k&gt;2)路归并排序。   \n2、自顶向下的方法(本文主要介绍此种方法，下面的文字都是对此种方法的解读)\n（1） 自顶向下的基本思想     采用分治法进行自顶向下的算法设计，形式更为简洁。     自顶向下的归并排序：是利用递归和分而治之的技术将数据序列划分成为越来越小的半子表，再对半子表排序，最后再用递归步骤将排好序的半子表合并成为越来越大的有序序列，归并排序包括两个步骤，分别为：\n      1）划分子表\n      2）合并半子表\n（1）分治法的三个步骤     设归并排序的当前区间是R[low..high]，分治法的三个步骤是：①分解：将当前区间一分为二，即求分裂点②求解：递归地对两个子区间R[low..mid]和R[mid+1..high]进行归并排序；③组合：将已排序的两个子区间R[low..mid]和R[mid+1..high]归并为一个有序的区间R[low..high]。  递归的终结条件：子区间长度为1（一个记录自然有序）。\n如下演示递归的整个过程：\n递归便是深度遍历（如下由左至右进行遍历）：假设有这样的一列数组{9,8,7,6,5,4,3,2,1}进行划分的顺序如下：\n{9,8,7,6,5,4,3,2,1} –&gt; {9,8,7,6,5}，{4,3,2,1}\n{9,8,7,6,5} –&gt; {9,8,7}，{6,5}\n                        {9,8,7} –&gt; {9,8}，{7}\n                                          {9,8} –&gt; {9}，{8}\n                        {6,5} –&gt;{6}，{5}\n{4,3,2,1} –&gt; {4,3}，{2,1}\n                      {4,3} –&gt;{4}，{3}\n                      {2,1} –&gt;{2}，{1}\n当深度划分到左右数组都只剩1个元素的时候，进行上述逆序的合并：\n{9}，{8} –&gt; {8,9} 然后和 {7} –&gt; {7,8,9}\n                                {6}，{5} –&gt; {5,6}    然后 {7,8,9}和{5,6} –&gt; {5,6,7,8,9}\n                                     {2}，{1} –&gt; {1,2}\n                                     {4}，{3} –&gt; {3,4}   然后 {1,2}和 {3,4} –&gt; {1,2,3,4}\n                                                                                                                         最终{5,6,7,8,9}和{1,2,3,4} –&gt; {1,2,3,4,5,6,7,8,9}\n具体实现代码如下所示：\n\n&lt;span&gt;//&lt;/span&gt;&lt;span&gt;归并排序（目标数组，子表的起始位置，子表的终止位置）&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;        &lt;span&gt;private&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; MergeSortFunction(&lt;span&gt;int&lt;/span&gt;[] array, &lt;span&gt;int&lt;/span&gt; first, &lt;span&gt;int&lt;/span&gt; last)&lt;br&gt;        &#123;&lt;br&gt;            &lt;span&gt;try&lt;/span&gt;&lt;br&gt;            &#123;&lt;br&gt;                &lt;span&gt;if&lt;/span&gt; (first &amp;lt; last)   &lt;span&gt;//&lt;/span&gt;&lt;span&gt;子表的长度大于1，则进入下面的递归处理&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;                &#123;&lt;br&gt;                    &lt;span&gt;int&lt;/span&gt; mid = (first + last) / &lt;span&gt;2&lt;/span&gt;;   &lt;span&gt;//&lt;/span&gt;&lt;span&gt;子表划分的位置&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;                    MergeSortFunction(array, first, mid);   &lt;span&gt;//&lt;/span&gt;&lt;span&gt;对划分出来的左侧子表进行递归划分&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;                    MergeSortFunction(array, mid + &lt;span&gt;1&lt;/span&gt;, last);    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;对划分出来的右侧子表进行递归划分&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;                    MergeSortCore(array, first, mid, last); &lt;span&gt;//&lt;/span&gt;&lt;span&gt;对左右子表进行有序的整合（归并排序的核心部分）&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;                &#125;&lt;br&gt;            &#125;&lt;br&gt;            &lt;span&gt;catch&lt;/span&gt; (Exception ex)&lt;br&gt;            &#123; &#125;&lt;br&gt;        &#125;&lt;br&gt;&lt;br&gt;        &lt;span&gt;//&lt;/span&gt;&lt;span&gt;归并排序的核心部分：将两个有序的左右子表（以mid区分），合并成一个有序的表&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;        &lt;span&gt;private&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; MergeSortCore(&lt;span&gt;int&lt;/span&gt;[] array, &lt;span&gt;int&lt;/span&gt; first, &lt;span&gt;int&lt;/span&gt; mid, &lt;span&gt;int&lt;/span&gt; last)&lt;br&gt;        &#123;&lt;br&gt;            &lt;span&gt;try&lt;/span&gt;&lt;br&gt;            &#123;&lt;br&gt;                &lt;span&gt;int&lt;/span&gt; indexA = first; &lt;span&gt;//&lt;/span&gt;&lt;span&gt;左侧子表的起始位置&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;                &lt;span&gt;int&lt;/span&gt; indexB = mid + &lt;span&gt;1&lt;/span&gt;;   &lt;span&gt;//&lt;/span&gt;&lt;span&gt;右侧子表的起始位置&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;                &lt;span&gt;int&lt;/span&gt;[] temp = &lt;span&gt;new&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;[last + &lt;span&gt;1&lt;/span&gt;]; &lt;span&gt;//&lt;/span&gt;&lt;span&gt;声明数组（暂存左右子表的所有有序数列）：长度等于左右子表的长度之和。&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;                &lt;span&gt;int&lt;/span&gt; tempIndex = &lt;span&gt;0&lt;/span&gt;;&lt;br&gt;                &lt;span&gt;while&lt;/span&gt; (indexA &amp;lt;= mid &amp;amp;&amp;amp; indexB &amp;lt;= last) &lt;span&gt;//&lt;/span&gt;&lt;span&gt;进行左右子表的遍历，如果其中有一个子表遍历完，则跳出循环&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;                &#123;&lt;br&gt;                    &lt;span&gt;if&lt;/span&gt; (array[indexA] &amp;lt;= array[indexB]) &lt;span&gt;//&lt;/span&gt;&lt;span&gt;此时左子表的数 &amp;lt;= 右子表的数&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;                    &#123;&lt;br&gt;                        temp[tempIndex++] = array[indexA++];    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;将左子表的数放入暂存数组中，遍历左子表下标++&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;                    &#125;&lt;br&gt;                    &lt;span&gt;else&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;此时左子表的数 &amp;gt; 右子表的数&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;                    &#123;&lt;br&gt;                        temp[tempIndex++] = array[indexB++];    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;将右子表的数放入暂存数组中，遍历右子表下标++&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;                    &#125;&lt;br&gt;                &#125;&lt;br&gt;                &lt;span&gt;//&lt;/span&gt;&lt;span&gt;有一侧子表遍历完后，跳出循环，将另外一侧子表剩下的数一次放入暂存数组中（有序）&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;                &lt;span&gt;while&lt;/span&gt; (indexA &amp;lt;= mid)&lt;br&gt;                &#123;&lt;br&gt;                    temp[tempIndex++] = array[indexA++];&lt;br&gt;                &#125;&lt;br&gt;                &lt;span&gt;while&lt;/span&gt; (indexB &amp;lt;= last)&lt;br&gt;                &#123;&lt;br&gt;                    temp[tempIndex++] = array[indexB++];&lt;br&gt;                &#125;&lt;br&gt;&lt;br&gt;                &lt;span&gt;//&lt;/span&gt;&lt;span&gt;将暂存数组中有序的数列写入目标数组的制定位置，使进行归并的数组段有序&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;                tempIndex = &lt;span&gt;0&lt;/span&gt;;&lt;br&gt;                &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = first; i &amp;lt;= last; i++)&lt;br&gt;                &#123;&lt;br&gt;                    array[i] = temp[tempIndex++];&lt;br&gt;                &#125;&lt;br&gt;            &#125;&lt;br&gt;            &lt;span&gt;catch&lt;/span&gt; (Exception ex)&lt;br&gt;            &#123; &#125;&lt;br&gt;        &#125;\n\n\n       对于N个元素的数组来说, 如此划分需要的层数是以2为底N的对数, 每一层中, 每一个元素都要复制到结果数组中, 并复制回来, 所以复制2N次, 那么对于归并排序,它的时间复杂度为O(N*logN), 而比较次数会少得多, 最少需要N&#x2F;2次,最多为N-1次, 所以平均比较次数在两者之间. 它的主要问题还是在于在内存中需要双倍的空间.\n","categories":["学习笔记","排序算法"],"tags":["排序算法"]},{"title":"插入排序算法CSharp实现","url":"/2024/09/04/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95CSharp%E5%AE%9E%E7%8E%B0/","content":"插入排序算法C#实现\nExcerpt插入排序算法主要分为：直接插入算法，折半排序算法（二分插入算法），希尔排序算法，后两种是直接插入算法的改良。因此直接插入算法是基础，这里先进行直接插入算法的分析与编码。直接插入算法的排序思想：假设有序数组从小到大为array[0],array[1],array[2],….,array[n-2],\n\n\n插入排序算法主要分为：直接插入算法，折半排序算法（二分插入算法），希尔排序算法，后两种是直接插入算法的改良。因此直接插入算法是基础，这里先进行直接插入算法的分析与编码。\n直接插入算法的排序思想：假设有序数组从小到大为array[0],array[1],array[2],….,array[n-2],array[n-1]，那么将待排数值array[n]与前面的有序数组从后向前依次比较，直到在有序数组中找到小于待排数值array[n]的位置，将array[n]插入到此位置，并入组合成新的有序数组。\n直接插入算法--代码如下所示：\n\n&lt;span&gt;　　　　　//&lt;/span&gt;&lt;span&gt;直接插入排序算法（传递待排数组名，即：数组的地址。故形参数组的各种操作反应到实参数组上）&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;　　　　　private &lt;/span&gt;&lt;span&gt;static &lt;/span&gt;&lt;span&gt;void&lt;/span&gt;&lt;span&gt; InsertSortionFunction(&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt;[] array)&lt;br&gt;        &#123;&lt;br&gt;            &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt;&lt;br&gt;            &#123;&lt;br&gt;                &lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; temp &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;;   &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;临时变量，存储待排的数值&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;　　　　　　　　　for&lt;/span&gt;&lt;span&gt; (&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; i &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;; i &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt; array.Length; i&lt;/span&gt;&lt;span&gt;++&lt;/span&gt;&lt;span&gt;)  &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;将无序的所有数值依次插入到有序数组中，注：下标从1开始，因为操作的是同一个数组&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                &#123;&lt;br&gt;                    temp &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; array[i];    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;记录待插入前面有序数组的数值&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;　　　　　　　　　　　 int&lt;/span&gt;&lt;span&gt; index &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; i &lt;/span&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;;  &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;记录前方有序数组的末尾位置&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;　　　　　　　　　　　 while&lt;/span&gt;&lt;span&gt; (index &lt;/span&gt;&lt;span&gt;&amp;gt;=&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span&gt; array[index] &lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; temp)   &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;循环遍历前面的有序数组，并且从大到小依次与待排数值进行比较&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                    &#123;&lt;br&gt;                        array[index &lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;] &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; array[index];    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;如果index&amp;gt;=0并且此时的值大于待排数值，将此处的值向后移动一位&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                        index&lt;/span&gt;&lt;span&gt;--&lt;/span&gt;&lt;span&gt;;    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;index--向前遍历有序数组&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                    &#125;&lt;br&gt;                    array[index &lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;] &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; temp;    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;由于前面的index--，所以temp插入的位置是index+1&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                &#125;&lt;br&gt;            &#125;&lt;br&gt;            &lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (Exception ex)&lt;br&gt;            &#123; &#125;&lt;br&gt;        &#125;&lt;/span&gt;\n\n\n折半排序算法是对直接插入算法的一种优化，优化的核心是：通过折半查看有序数组中间位置的数值（a）与待插入的数值（temp）的大小，如果a&gt;&#x3D;temp，则转向折半的左区间继续折半查找； 如果a&lt;temp，则转向折半后的右区间继续折半查找。直到左右下标相同时，此时折半的下标也指向相同的位置，再做最后一次循环，最终的结果是：左右下标相差1，并且原来左侧的下标指向大于temp的位置，原来右侧的下标指向了小于temp的位置，即：array[biggerIndex] &lt; temp &lt; array[smallerIndex]。\n折半排序算法--代码如下：\n\n&lt;span&gt;  &amp;nbsp;　　　&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;折半排序算法（传递待排数组名，即：数组的地址。故形参数组的各种操作反应到实参数组上）&lt;/span&gt;\n\n&lt;span&gt;        private &lt;/span&gt;&lt;span&gt;static &lt;/span&gt;&lt;span&gt;void&lt;/span&gt;&lt;span&gt; BinaryInsertionSortFunction(&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt;[] array)&lt;br&gt;        &#123;&lt;br&gt;            &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt;&lt;br&gt;            &#123;&lt;br&gt;                &lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; smallerIndex &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;; &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;记录有序数组的起始位置&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;　　　　　　　　　 int&lt;/span&gt;&lt;span&gt; biggerIndex &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;; &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;记录有序数组的终止位置&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;　　　　　　　　　 int&lt;/span&gt;&lt;span&gt; midIndex &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;; &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;记录获取有序数组的中间位置（折半法的关键：折半的位置）&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;　　　　　　　　　 int&lt;/span&gt;&lt;span&gt; temp;  &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;记录带排的数值&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;　　　　　　　　　 for&lt;/span&gt;&lt;span&gt; (&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; i &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;; i &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt; array.Length; i&lt;/span&gt;&lt;span&gt;++&lt;/span&gt;&lt;span&gt;)  &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;循环向有序数组中插入数值（i从1开始，因为操作的是同一个数组）&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                &#123;&lt;br&gt;                    temp &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; array[i];   &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;记录待插入有序数组的数值&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                    biggerIndex &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; i &lt;/span&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;;&lt;br&gt;                    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;当smallerIndex==biggerIndex时，进入最后一次循环：smallerIndex指向大于temp的数组位置，biggerIndex指向小于temp的数组位置&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;　　　　　　　　　　　 while&lt;/span&gt;&lt;span&gt; (smallerIndex &lt;/span&gt;&lt;span&gt;&amp;lt;=&lt;/span&gt;&lt;span&gt; biggerIndex)   &lt;br&gt;                    &#123;&lt;br&gt;                        midIndex &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; (smallerIndex &lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt; biggerIndex) &lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;; &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;确定折半的位置&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;　　　　　　　　　　　　　　if&lt;/span&gt;&lt;span&gt;(array[midIndex] &lt;/span&gt;&lt;span&gt;&amp;gt;=&lt;/span&gt;&lt;span&gt; temp)  &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;折半位置的数值 &amp;gt;= temp&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                        &#123;&lt;br&gt;                            biggerIndex &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; midIndex &lt;/span&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;;    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;biggerIndex以midIndex为基础向前移动一位&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                        &#125;&lt;br&gt;                        &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;&lt;br&gt;                        &#123;&lt;br&gt;                            smallerIndex &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; midIndex &lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;;  &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;smallerIndex以midIndex为基础向后移动一位&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                        &#125;&lt;br&gt;                    &#125;&lt;br&gt;                    &lt;/span&gt;&lt;span&gt;for&lt;/span&gt;&lt;span&gt; (&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; j &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; i &lt;/span&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;; j &lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;biggerIndex; j&lt;/span&gt;&lt;span&gt;--&lt;/span&gt;&lt;span&gt;) &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;将有序数组中大于temp的数值分别向后移动一位&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                    &#123;&lt;br&gt;                        array[j &lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;] &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; array[j];  &lt;/span&gt;&lt;span&gt;//&lt;br&gt;&lt;/span&gt;&lt;span&gt;                    &#125;&lt;br&gt;                    array[biggerIndex &lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;] &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; temp;   &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;将temp插入biggerIndex + 1，因为此时array[biggerIndex]&amp;lt;temp&amp;lt;array[smallerIndex]&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                &#125;&lt;br&gt;            &#125;&lt;br&gt;            &lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (Exception ex)&lt;br&gt;            &#123; &#125;&lt;br&gt;        &#125;&lt;/span&gt;\n\n\n希尔排序同样是直接插入排序算法的一种改进，基本思想是：将无序的数列划分为若干小的子序列，然后对子序列进行直接插入排序。时间性能优于直接插入排序算法，但是一种不稳定的排序，时间复杂度为O(nlogn)。希尔排序算法主要分为3重循环：第一重循环–&gt;按照gap的大小进行分组，初始化从array.Length&#x2F;2开始，依次递减到1第二重循环–&gt;对所有分组进行排序第三重循环–&gt;组内进行直接插入排序\n希尔排序算法--代码如下：\n\n&lt;span&gt;　　　　  private &lt;/span&gt;&lt;span&gt;static &lt;/span&gt;&lt;span&gt;void&lt;/span&gt;&lt;span&gt; ShellSortFunction(&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt;[] array)&lt;br&gt;        &#123;&lt;br&gt;            &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt;&lt;br&gt;            &#123;&lt;br&gt;                &lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; length &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; array.Length;&lt;br&gt;                &lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; temp &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;;&lt;br&gt;                &lt;/span&gt;&lt;span&gt;for&lt;/span&gt;&lt;span&gt; (&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; gap &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; length &lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;; gap &lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;; gap&lt;/span&gt;&lt;span&gt;--&lt;/span&gt;&lt;span&gt;)  &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;第一重循环，按照gap的大小进行分组&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                &#123;&lt;br&gt;                    &lt;/span&gt;&lt;span&gt;for&lt;/span&gt;&lt;span&gt; (&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; i &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;; i &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt; gap; i&lt;/span&gt;&lt;span&gt;++&lt;/span&gt;&lt;span&gt;)   &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;第二重循环，对所有分组进行排序&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                    &#123;&lt;br&gt;                        &lt;/span&gt;&lt;span&gt;for&lt;/span&gt;&lt;span&gt; (&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; j &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; i; j &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt; length; j &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; j &lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt; gap)    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;第三重循环，组内进行直接插入排序&lt;/span&gt;&lt;span&gt;&lt;br&gt;&lt;/span&gt;&lt;span&gt;                        &#123;&lt;br&gt;                            temp &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; array[j];&lt;br&gt;                            &lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; index &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; j &lt;/span&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt; gap;&lt;br&gt;                            &lt;/span&gt;&lt;span&gt;while&lt;/span&gt;&lt;span&gt; (index &lt;/span&gt;&lt;span&gt;&amp;gt;=&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span&gt; array[index] &lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; temp)&lt;br&gt;                            &#123;&lt;br&gt;                                array[index &lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt; gap] &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; array[index];&lt;br&gt;                                index &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; index &lt;/span&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt; gap;&lt;br&gt;                            &#125;&lt;br&gt;                            array[index &lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt; gap] &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; temp;&lt;br&gt;                        &#125;&lt;br&gt;                    &#125;&lt;br&gt;                &#125;&lt;br&gt;            &#125;&lt;br&gt;            &lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (Exception ex)&lt;br&gt;            &#123; &#125;&lt;br&gt;        &#125;&lt;/span&gt;\n\n\n。。。。\n","categories":["学习笔记","排序算法"],"tags":["排序算法"]},{"title":"中介者模式","url":"/2019/11/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E4%B8%AD%E4%BB%8B%E8%80%85%E6%A8%A1%E5%BC%8F/","content":"","categories":["学习笔记","设计模式"],"tags":["设计模式","中介者模式"]},{"title":"享元模式","url":"/2019/11/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E4%BA%AB%E5%85%83%E6%A8%A1%E5%BC%8F/","content":"","categories":["学习笔记","设计模式"],"tags":["设计模式","享元模式"]},{"title":"代理模式","url":"/2019/11/13/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/","content":"","categories":["学习笔记","设计模式"],"tags":["设计模式","代理模式"]},{"title":"单例模式","url":"/2015/11/02/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/","content":"引言在软件开发中，单例模式（Singleton Pattern） 是一种常见的设计模式，用于确保一个类只有一个实例，并提供一个全局访问点。它适用于需要严格控制资源访问的场景，例如数据库连接池、配置管理器或任务调度器等。本文将详细介绍单例模式的核心思想，并展示其在 C#、Python、Golang、C 和 C++ 中的实现方式。\n单例模式的主要特点包括：\n\n唯一性：类只有一个实例对象\n自创建：类自行创建自己的实例\n全局访问：提供一个全局访问点来获取该实例\n\n特点\n\n唯一性：类自身负责创建和管理实例。\n延迟加载：实例通常在第一次使用时创建（懒汉式）。\n线程安全：在多线程环境中需确保实例的唯一性。\n不可克隆&#x2F;序列化：避免通过克隆或反序列化创建新实例。\n\n单例模式的实现方式C# 实现C# 中的单例模式通常通过 双重检查锁定（Double-Check Locking） 实现，以确保线程安全和延迟加载。\npublic sealed class Singleton&#123;    // 使用 volatile 保证多线程下的可见性    private static volatile Singleton _instance;    private static readonly object _lock = new object();    // 私有构造函数    private Singleton() &#123; &#125;\t    public static Singleton GetInstance()    &#123;\t    // 第一次检查，避免不必要的锁定        if (_instance == null)        &#123;\t\t\t // 锁定操作            lock (_lock)            &#123;\t\t\t\t// 第二次检查，确保多线程安全                if (_instance == null)                &#123;                    _instance = new Singleton();                &#125;            &#125;        &#125;        return _instance;    &#125;&#125;\n\n饿汉式（立即加载）public sealed class Singleton&#123;\t// 静态初始化，CLR保证线程安全    private static readonly Singleton _instance = new Singleton();\t// 私有构造函数    private Singleton() &#123; &#125;    public static Singleton GetInstance()    &#123;        return _instance;    &#125;&#125;\n\nPython 实现Python 的模块天然支持单例，但也可以通过类实现。以下是一个线程安全的懒汉式实现：\nimport threadingclass Singleton:    _instance_lock = threading.Lock()  # 线程锁    def __init__(self):        # 初始化逻辑        pass    def __new__(cls, *args, **kwargs):        if not hasattr(Singleton, &quot;_instance&quot;):            with cls._instance_lock:  # 确保线程安全                if not hasattr(Singleton, &quot;_instance&quot;):                    Singleton._instance = super().__new__(cls)        return Singleton._instance# 使用示例s1 = Singleton()s2 = Singleton()print(s1 is s2)  # 输出: True\n\n饿汉式（模块级单例）# singleton.pyclass Singleton:    def __init__(self):        passinstance = Singleton()# 使用示例from singleton import instance\n\n装饰器实现def singleton(cls): \tinstances = &#123;&#125; \tdef wrapper(*args, **kwargs): \t\tif cls not in instances: \t\t\tinstances[cls] = cls(*args, **kwargs) \t\t\treturn instances[cls]\t\treturn wrapper \t\t@singleton class MySingleton: \tpass\n\nGolang 实现package mainimport (\t&quot;sync&quot;)type Singleton struct&#123;&#125;var (\tinstance *Singleton\tonce     sync.Once)func GetInstance() *Singleton &#123;\t// sync.Once 确保代码只执行一次，线程安全\tonce.Do(func() &#123;\t\tinstance = &amp;Singleton&#123;&#125;\t&#125;)\treturn instance&#125;// 使用示例func main() &#123;\ts1 := GetInstance()\ts2 := GetInstance()\tprintln(s1 == s2) // 输出: true&#125;\n\n饿汉式package maintype Singleton struct&#123;&#125;var instance = &amp;Singleton&#123;&#125;func GetInstance() *Singleton &#123;\treturn instance&#125;\n\n单例模式的优缺点优点\n控制实例数量：确保全局唯一性，避免资源浪费。\n灵活扩展：可通过子类化或组合模式扩展功能。\n全局访问：简化了对共享资源的访问。\n\n缺点\n违反单一职责原则：类负责管理自己的实例，增加了耦合。\n测试困难：全局状态可能导致单元测试难以隔离。\n生命周期管理：实例与程序生命周期一致，可能占用过多内存。.\n\n应用场景\n资源管理器：如文件系统、数据库连接池。\n配置中心：全局配置对象，避免重复加载配置。\n缓存服务：单点缓存，减少内存开销。\n日志记录器：统一日志输出，避免多线程冲突。\n\n总结单例模式是一种简单但强大的设计模式，适用于需要严格控制实例数量的场景。不同编程语言的实现方式各有特色：\n\nC# 通过 lock 和 volatile 保证线程安全。\nPython 可利用模块的天然单例特性。\nGolang 使用 sync.Once 实现原子初始化。\nC&#x2F;C++ 通过静态局部变量或互斥锁实现线程安全。\n\n实现要点总结：\n\n私有构造函数：防止外部直接实例化\n静态实例变量：保存唯一的实例\n全局访问点：提供获取实例的静态方法\n线程安全：在多线程环境下需要考虑线程安全问题\n\n选择建议：\n\n懒汉式：适用于实例创建开销较大，且可能不被使用的场景\n饿汉式：适用于实例创建开销小，且一定会被使用的场景\n双重检查锁定：适用于需要兼顾性能和线程安全的场景\n\n在实际开发中，需根据语言特性和具体需求选择合适的实现方式，同时注意避免过度使用单例模式，以免引入全局状态带来的复杂性。\n","categories":["学习笔记","设计模式"],"tags":["设计模式","单例模式"]},{"title":"原型模式","url":"/2019/11/06/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/","content":"","categories":["学习笔记","设计模式"],"tags":["设计模式","原型模式"]},{"title":"命令模式","url":"/2019/11/15/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F/","content":"","categories":["学习笔记","设计模式"],"tags":["设计模式","命令模式"]},{"title":"备忘录模式","url":"/2019/11/23/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%A4%87%E5%BF%98%E5%BD%95%E6%A8%A1%E5%BC%8F/","content":"","categories":["学习笔记","设计模式"],"tags":["设计模式","备忘录模式"]},{"title":"外观模式","url":"/2019/11/11/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F/","content":"","categories":["学习笔记","设计模式"],"tags":["设计模式","外观模式"]},{"title":"工厂方法模式","url":"/2019/11/03/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/","content":"","categories":["学习笔记","设计模式"],"tags":["设计模式","工厂方法"]},{"title":"建造者模式","url":"/2019/11/05/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F/","content":"","categories":["学习笔记","设计模式"],"tags":["设计模式","建造者"]},{"title":"抽象工厂模式","url":"/2019/11/04/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/","content":"","categories":["学习笔记","设计模式"],"tags":["设计模式","抽象工厂"]},{"title":"桥接模式","url":"/2019/11/08/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F/","content":"","categories":["学习笔记","设计模式"],"tags":["设计模式","桥接模式"]},{"title":"模板方法","url":"/2019/11/14/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95/","content":"","categories":["学习笔记","设计模式"],"tags":["设计模式","模板方法"]},{"title":"状态模式","url":"/2019/11/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E7%8A%B6%E6%80%81%E6%A8%A1%E5%BC%8F/","content":"","categories":["学习笔记","设计模式"],"tags":["设计模式","状态模式"]},{"title":"策略模式","url":"/2019/11/20/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F/","content":"","categories":["学习笔记","设计模式"],"tags":["设计模式","策略模式"]},{"title":"组合模式","url":"/2019/11/10/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F/","content":"","categories":["学习笔记","设计模式"],"tags":["设计模式","组合模式"]},{"title":"装饰模式","url":"/2019/11/09/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A3%85%E9%A5%B0%E6%A8%A1%E5%BC%8F/","content":"","categories":["学习笔记","设计模式"],"tags":["设计模式","装饰模式"]},{"title":"观察者模式","url":"/2019/11/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F/","content":"","categories":["学习笔记","设计模式"],"tags":["设计模式","观察者模式"]},{"title":"解释器模式","url":"/2019/11/24/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A7%A3%E9%87%8A%E5%99%A8%E6%A8%A1%E5%BC%8F/","content":"","categories":["学习笔记","设计模式"],"tags":["设计模式","解释器模式"]},{"title":"设计模式系列导航","url":"/2019/11/30/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%B3%BB%E5%88%97%E5%AF%BC%E8%88%AA/","content":"面向对象的设计原则\n创建型创建型模式抽象了实例化的过程。创建性模式隐藏了这些类的实例是如何被创建和放在一起，整个系统关于这些对象所知道的是由抽象类所定义的接口。这样，创建性模式在创建了什么、谁创建它、她是怎么被创建的、以及何时创建方面提供了灵活性。创建相应数目的原型并克隆她们通常比每次用适合的状态手工实例化该类更方便。\n单例模式 (Singleton) 保证一个类仅有一个实例，并提供一个访问它的全局访问点。\n\n优点：对唯一实例的受控访问。\n缺点：饿汉式&#x2F;懒汉式  多线程同时访问时可能造成多个实例。\n工厂方法模式 (Factory Method) 定义一个用于创建对象的接口，让子类决定实例化哪一个类，工厂方法使一个类的实例化延迟到其子类。\n\n优点：是简单工厂模式的进一步抽象和推广，既保持了简单工厂模式的优点（工厂类中包含了必要的逻辑判断，根据客户端的选择条件动态实例化相关的类。对于客户端来说，去除了与具体产品的依赖），而且克服了简单工厂的缺点（违背了开放封闭原则）。\n缺点：每增加一个产品，就需要增加一个产品工厂的类，增加了额外的开发。（用反射可以解决）。\n抽象工厂模式 (Abstract Factory) 提供一个创建一系列相关或互相依赖对象的接口，而无需指定它们具体的类。\n\n优点：\na)   改变具体工厂即可使用不同的产品配置，使改变一个应用的具体工厂变得很容易。\nb)   让具体的创建实例过程与客户端分离，客户端通过抽象接口操作实例，产品的具体类名也被具体工厂的实现分离。\n缺点：如果要新增方法，改动极大。\n建造者模式 (Builder) 将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。\n\n优点：使得建造代码与表示代码分离。\n缺点：1、增加代码量；2、Builder只是一个替代构造器的选择，不能直接用于降低非构造函数方法的参数数量。\n原型模式 (Prototype) 用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。\n\n优点：隐藏了对象创建的细节，大大提升了性能。不用重新初始化对象，而是动态的获得对象运行时的状态。\n缺点：深复制 or 浅复制 。\n结构型适配器模式 (Adapter) 将一个类的接口转换成客户希望的另外一个接口。Adapter模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。\n\n在GoF的设计模式中，适配器有两种类型，类适配器模式和对象适配器模式。\na)   类适配器模式：通过多重继承对一个接口与另一个接口进行匹配，而C#，Java等语言都不支持多重继承，也就是一个类只有一个父类。\nb)   一般都指的是 对象适配器模式\n优点：能够复用现存的类，客户端统一调用同一接口，更简单、直接、紧凑。\n缺点：适配器模式有点儿“亡羊补牢”的感觉，设计阶段要避免使用。\n桥接模式 (Bridge) 将抽象部分与它的实现部分分离，使它们都可以独立的变化。\n\n优点：减少各部分的耦合。 分离抽象和实现部分，更好的扩展性，可动态地切换实现、可减少子类的个数。\n缺点：1、桥接模式的引入会增加系统的理解与设计难度，由于聚合关联关系建立在抽象层，要求开发者针对抽象进行设计与编程。 2、桥接模式要求正确识别出系统中两个独立变化的维度，因此其使用范围具有一定的局限性\n装饰模式 (Decorator) 动态地给一个对象添加一些额外的职责，就增加功能来说，装饰模式比生成子类更灵活。\n\n优点：把类中的装饰功能从类中搬移出去，简化原有的类。有效的把类的核心职责和装饰功能区分开，去除相关类中重复的装饰逻辑。\n缺点：利用装饰器模式,常常造成设计中有大量的小类,数量实在太多,可能会造成使用此API程序员的困扰。\n组合模式 (Composite) 将对象组合成树形结构以表示“部分-整体”的层次结构。\n\n优点：组合模式让客户可以一致的使用组合结构和单个对象。\n缺点：使设计变得更加抽象，对象的业务规则如果很复杂，则实现组合模式具有很大挑战性，而且不是所有的方法都与叶子对象子类都有关联。\n外观模式 (Facade) 为子系统中的一组接口提供一个一致的界面，此模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。\n\n优点：1、客户对子系统的使用变得简单了，减少了与子系统的关联对象，实现了子系统与客户之间的松耦合关系。 2、只是提供了一个访问子系统的统一入口，并不影响用户直接使用子系统类 3、降低了大型软件系统中的编译依赖性，并简化了系统在不同平台之间的移植过程。\n缺点：1、不能很好地限制客户使用子系统类，如果对客户访问子系统类做太多的限制则减少了可变性和灵活性   2、在不引入抽象外观类的情况下，增加新的子系统可能需要修改外观类或客户端的源代码，违背了“开闭原则”。\n享元模式 (Flyweight) 运用共享技术有效的支持大量细粒度的对象。\n\n优点：享元模式可以避免大量非常相似类的开销。程序中，大量细粒度的类实例来表示数据，如果它们除了几个参数外基本相同，那么把它们转移到类实例的外面，在方法调用时将它们传递进来，就可以通过共享大幅度减少单个实例的数目。\n缺点：1、由于享元模式需要区分外部状态和内部状态，使得应用程序在某种程度上来说更加复杂化了。2、为了使对象可以共享，享元模式需要将享元对象的状态外部化，而读取外部状态使得运行时间变长。\n代理模式 (Proxy) 为其他对象提供一种代理以控制对这个对象的访问。\n\n优点：1）代理模式能将代理对象与真正被调用的对象分离，在一定程度上降低了系统的耦合度。2）代理模式在客户端和目标对象之间起到一个中介作用，这样可以起到保护目标对象的作用。代理对象也可以对目标对象调用之前进行其他操作。\n缺点：1）在客户端和目标对象增加一个代理对象，会造成请求处理速度变慢。2）增加了系统的复杂度。\n行为型模板方法 (Template Method)  定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。\n\n优点：模板方法模式是通过把不变行为搬移到超类，去除子类中重复代码来实现它的优势，提供了一个代码复用平台，帮助子类摆脱重复的不变行为的纠缠。\n缺点：如果父类中可变的基本方法太多,将会导致类的个数增加,系统更加庞大。\n命令模式 (Command) 将一个请求封装为一个对象，从而使你可用不同的请求对客户进行参数化；对请求排队或记录请求日志，以及支持可撤销的操作。\n优点：\na)      命令模式把请求一个操作的对象与知道怎么执行一个操作的对象分割开。\nb)      它能较容易的设计一个命令队列。\nc)       在需要的情况下，可以较容易的将命令记入日志。\nd)      允许接收请求的一方决定是否要否决请求。\ne)      可以容易的实现对请求的撤销和重做。\nf)        由于加进新的具体命令类不影响其他类，因此增加新的具体命令类很容易。\n缺点：会增加系统的复杂性，这里的复杂性应该主要指的是类的数量。\n迭代器模式 (Iterator) 提供一种方法顺序访问一个聚合对象中各个元素，而又不暴露该对象的内部表示。\n\n优点：迭代器模式就是分离了集合对象的遍历行为，抽象出一个迭代器来负责，这样既可以做到不暴露集合的内部结构，又可以让外部代码透明的访问集合内部的数据。\n缺点：由于迭代器模式将存储数据和遍历数据的职责分离，增加新的聚合类需要对应增加新的迭代器类，类的个数成对增加，这在一定程度上增加了系统的复杂性。\n观察者模式 (Publish/Subscribe) 定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个主题对象。这个主题对象在状态发生变化时，会通知所有观察者对象，让它们能够自动更新自己。\n\n优点：解耦。\n缺点：如果在被观察者之间有循环依赖的话，被观察者会触发它们之间进行循环调用，导致系统崩溃。在使用观察者模式是要特别注意这一点。\n中介者模式 (mediator) 用一个中介对象来封装一系列的对象交互。中介者使各对象不需要显示的相互引用，从而使其耦合松散，而且可以独立的改变它们之间的交互。\n\n优点：\na)   抽象中介者类（Mediator）减少了抽象同事类（colleague）之间的耦合，是的可以独立的改变和复用各个类。\nb)   由于把对象如何协作进行了抽象，将中介作为一个独立的概念并将其封装在一个对象中，这样关注的对象就从对象各自本身的行为转移到它们之间的交互上来，也就是站在一个更宏观的角度去看待系统。\n缺点：控制集中化导致了中介者的复杂化。\n状态模式 (State)  当一个对象的内在状态改变时，允许改变其行为，这个对象看起来像是改变了其类。\n\n优点：状态模式主要解决的是当控制一个对象状态转换的条件表达式过于复杂的情况。把状态的判断逻辑转移到表示不同状态的一系列类当中，可以把复杂的判断逻辑简化。【消除庞大的条件分支语句】。\n缺点：违背开放-封闭原则\n策略模式 (strategy) 它定义了算法家族，分别封装起来，让它们之间可以互相替换，此模式让算法的变化不会影响到使用算法的用户。\n\n优点：策略模式的策略类为上下文定义了一系列可供重用的算法或行为，继承有助于析取出这些算法中的公共功能。另外，策略模式简化了单元测试，因为每一个算法都有自己的类，可以通过自己的接口单独测试。当不同的行为堆砌在一个类中，很难避免使用switch语句。但是将这些行为封装在一个一个独立的策略类中，可以在使用这些行为的类中消除条件语句\n缺点：基本的策略模式，选择权在客户端，具体实现转给策略模式的上下文对象。这并不好。使用策略模式和工厂类结合，可以减轻客户端的职责。但是还是不够完美，使用反射才能真正快乐。\n责任链模式 (chain of responsibility) 使多个对象都有机会处理请求，从而避免请求的发送者和接受者之间的耦合关系。将这个对象连成一条链，并沿着这条链传递该请求，直到有一个对象处理它为止。\n\n优点：使得接收者和发送者都没有对方的明确信息，且链中对象自己也不知道链结构，结果是职责链可以简化对象的相互连接，它们只需要保持一个指向其后继者的引用，而不需要保持它所有的候选接收者的引用。开发者可以随时的增加或者修改处理一个请求的结构，增强了给对象指派职责的灵活性。\n缺点：一个请求极有可能到了链的末端都得不到处理，或者因为没有正确配置而得不到处理。\n访问者模式 (Vistor) 表示一个作用于某对象结构中的各元素的操作，它使你可以在不改变各元素的类的前提下定义作用于这些元素的新操作。\n\n优点：增加新的操作很容易。新的操作就是新的访问者。\n缺点：很难增加新的数据结构。\n备忘录模式 (Memento) 在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，这样以后就可将该对象恢复到原先保存的状态。\n\n优点：使用备忘录模式可以把复杂的发起人内部信息对其他的对象屏蔽起来，从而可以恰当地保持封装的边界。\n缺点：如果发起人角色的状态需要完整地存储到备忘录对象中，那么在资源消耗上面备忘录对象会很昂贵。\n解释器模式 (interpreter) 给定一个语言，定义它的文法的一种表示，并定义一个解释器，这个解释器使用该表示来解释语言中的句子。\n\n优点：解释器很容易改变和扩展文法，因为该模式使用类来表示文法规则，可以使用继承来改变或扩展文法，也比较容易实现文法。因为定义抽象语法树中各个节点的类的实现大体类似，这些类都易于直接编写。\n缺点：解释器模式为文法中的每一条规则至少定义了一个类，因此包含许多规则的文法可能难以管理和维护，建议当文法非常复杂时，使用其他技术（语法分析程序、编译器生成器）。\n","categories":["学习笔记","设计模式"],"tags":["设计模式"]},{"title":"访问者模式","url":"/2019/11/22/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BF%E9%97%AE%E8%80%85%E6%A8%A1%E5%BC%8F/","content":"","categories":["学习笔记","设计模式"],"tags":["设计模式","访问者模式"]},{"title":"责任链模式","url":"/2019/11/21/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%A8%A1%E5%BC%8F/","content":"","categories":["学习笔记","设计模式"],"tags":["设计模式","责任链模式"]},{"title":"迭代器模式","url":"/2019/11/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%BF%AD%E4%BB%A3%E5%99%A8%E6%A8%A1%E5%BC%8F/","content":"","categories":["学习笔记","设计模式"],"tags":["设计模式","迭代器模式"]},{"title":"适配器模式","url":"/2019/11/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F/","content":"","categories":["学习笔记","设计模式"],"tags":["设计模式","适配器模式"]},{"title":"面向对象的设计原则","url":"/2019/11/01/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/","content":"面向对象的设计原则写代码也是有原则的，我们之所以使用设计模式，主要是为了适应变化，提高代码复用率，使软件更具有可维护性和可扩展性。如果我们能更好的理解这些设计原则，对我们理解面向对象的设计模式也是有帮助的，因为这些模式的产生是基于这些原则的。这些规则是：单一职责原则（SRP）、开放封闭原则（OCP）、里氏代替原则（LSP）、依赖倒置原则（DIP）、接口隔离原则（ISP）、合成复用原则（CRP）和迪米特原则（LoD）。下面我们就分别介绍这几种设计原则。\n\n单一职责原则(SRP)：\n\nSRP(Single Responsibilities Principle)的定义：就一个类而言，应该仅有一个引起它变化的原因。简而言之，就是功能要单一。\n如果一个类承担的职责过多，就等于把这些职责耦合在一起，一个职责的变化可能会削弱或者抑制这个类完成其它职责的能力。这种耦合会导致脆弱的设计，当变化发生时，设计会遭受到意想不到的破坏。(敏捷软件开发)\n软件设计真正要做的许多内容，就是发现职责并把那些职责相互分离。\n\n  小结：单一职责原则（SRP）可以看做是低耦合、高内聚在面向对象原则上的引申，将职责定义为引起变化的原因，以提高内聚性来减少引起变化的原因。责任过多，引起它变化的原因就越多，这样就会导致职责依赖，大大损伤其内聚性和耦合度。\n\n开放关闭原则(OCP)\n\nOCP(Open-Close Principle)的定义：就是说软件实体(类，方法等等)应该可以扩展（扩展可以理解为增加），但是不能在原来的方法或者类上修改，也可以这样说，对增加代码开放，对修改代码关闭。\nOCP的两个特征： 对于扩展（增加）是开放的，因为它不影响原来的，这是新增加的。对于修改是封闭的，如果总是修改，逻辑会越来越复杂。\n\n  小结：开放封闭原则（OCP）是面向对象设计的核心思想。遵循这个原则可以为我们面向对象的设计带来巨大的好处：可维护（维护成本小，做管理简单，影响最小）、可扩展（有新需求，增加就好）、可复用（不耦合，可以使用以前代码）、灵活性好（维护方便、简单）。开发人员应该仅对程序中出现频繁变化的那些部分做出抽象，但是不能过激，对应用程序中的每个部分都刻意地进行抽象同样也不是一个好主意。拒绝不成熟的抽象和抽象本身一样重要。\n\n里氏代替原则(LSP)\n\nLSP(Liskov Substitution Principle)的定义：子类型必须能够替换掉它们的父类型。更直白的说，LSP是实现面向接口编程的基础。\n\n  小结：任何基类可以出现的地方，子类一定可以出现，所以我们可以实现面向接口编程。 LSP是继承复用的基石，只有当子类可以替换掉基类，软件的功能不受到影响时，基类才能真正被复用，而子类也能够在基类的基础上增加新的行为。里氏代换原则是对“开-闭”原则的补充。实现“开-闭”原则的关键步骤就是抽象化。而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。\n\n依赖倒置原则（DIP）\n\nDIP(Dependence Inversion Principle)的定义：抽象不应该依赖细节，细节应该依赖于抽象。简单说就是，我们要针对接口编程，而不要针对实现编程。\n高层模块不应该依赖低层模块，两个都应该依赖抽象，因为抽象是稳定的。抽象不应该依赖具体（细节），具体（细节）应该依赖抽象。\n\n  小结：依赖倒置原则其实可以说是面向对象设计的标志，如果在我们编码的时候考虑的是面向接口编程，而不是简单的功能实现，体现了抽象的稳定性，只有这样才符合面向对象的设计。\n\n接口隔离原则（ISP）\n\n接口隔离原则（Interface Segregation Principle, ISP）指的是使用多个专门的接口比使用单一的总接口要好。也就是说不要让一个单一的接口承担过多的职责，而应把每个职责分离到多个专门的接口中，进行接口分离。过于臃肿的接口是对接口的一种污染。\n使用多个专门的接口比使用单一的总接口要好。\n一个类对另外一个类的依赖性应当是建立在最小的接口上的。\n一个接口代表一个角色，不应当将不同的角色都交给一个接口。没有关系的接口合并在一起，形成一个臃肿的大接口，这是对角色和接口的污染。\n“不应该强迫客户依赖于它们不用的方法。接口属于客户，不属于它所在的类层次结构。”这个说得很明白了，再通俗点说，不要强迫客户使用它们不用的方法，如果强迫用户使用它们不使用的方法，那么这些客户就会面临由于这些不使用的方法的改变所带来的改变。\n\n  小结：接口隔离原则（ISP）告诉我们，在做接口设计的时候，要尽量设计的接口功能单一，功能单一，使它变化的因素就少，这样就更稳定，其实这体现了高内聚，低耦合的原则，这样做也避免接口的污染。\n\n组合复用原则（CRP）\n\n组合复用原则（Composite Reuse Principle, CRP）就是在一个新的对象里面使用一些已有的对象，使之成为新对象的一部分。新对象通过向这些对象的委派达到复用已用功能的目的。简单地说，就是要尽量使用合成&#x2F;聚合，尽量不要使用继承。\n要使用好组合复用原则，首先需要区分”Has—A”和“Is—A”的关系。 “Is—A”是指一个类是另一个类的“一种”，是属于的关系，而“Has—A”则不同，它表示某一个角色具有某一项责任。导致错误的使用继承而不是聚合的常见的原因是错误地把“Has—A”当成“Is—A”.例如：鸡是动物，这就是“Is-A”的表现，某人有一个手枪，People类型里面包含一个Gun类型，这就是“Has-A”的表现。\n\n  小结：组合&#x2F;聚合复用原则可以使系统更加灵活，类与类之间的耦合度降低，一个类的变化对其他类造成的影响相对较少，因此一般首选使用组合&#x2F;聚合来实现复用；其次才考虑继承，在使用继承时，需要严格遵循里氏替换原则，有效使用继承会有助于对问题的理解，降低复杂度，而滥用继承反而会增加系统构建和维护的难度以及系统的复杂度，因此需要慎重使用继承复用。\n\n迪米特法则（Law of Demeter）\n\n迪米特法则（Law of Demeter，LoD）又叫最少知识原则（Least Knowledge Principle，LKP），指的是一个对象应当对其他对象有尽可能少的了解。也就是说，一个模块或对象应尽量少的与其他实体之间发生相互作用，使得系统功能模块相对独立，这样当一个模块修改时，影响的模块就会越少，扩展起来更加容易。\n关于迪米特法则其他的一些表述有：只与你直接的朋友们通信；不要跟“陌生人”说话。\n外观模式（Facade Pattern)和中介者模式（Mediator Pattern）就使用了迪米特法则。\n\n  小结：迪米特法则的初衷是降低类之间的耦合，实现类型之间的高内聚，低耦合，这样可以解耦。但是凡事都有度，过分的使用迪米特原则，会产生大量这样的中介和传递类，导致系统复杂度变大。所以在采用迪米特法则时要反复权衡，既做到结构清晰，又要高内聚低耦合。\n\n\n","categories":["学习笔记","设计模式"],"tags":["设计模式"]},{"title":"Windows InfluxDB 安装与配置","url":"/2019/08/03/%E6%95%B0%E6%8D%AE%E5%BA%93/InfluxDB/InfluxDB%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/","content":"一、下载链接https://portal.influxdata.com/downloads，选windows版\n二、解压到安装盘，目录如下\n\n三、修改conf文件，代码如下，直接复制粘贴（1.4.2版本），注意修改路径，带D盘的改为你的安装路径就好，一共三个，注意网上有配置admin进行web管理，但新版本配置文件里没有admin因为官方给删除了，需下载Chronograf，后文会介绍\n### Welcome to the InfluxDB configuration file.# The values in this file override the default values used by the system if# a config option is not specified. The commented out lines are the configuration# field and the default value used. Uncommenting a line and changing the value# will change the value used at runtime when the process is restarted.# Once every 24 hours InfluxDB will report usage data to usage.influxdata.com# The data includes a random ID, os, arch, version, the number of series and other# usage data. No data from user databases is ever transmitted.# Change this option to true to disable reporting.# reporting-disabled = false# Bind address to use for the RPC service for backup and restore.# bind-address = &quot;127.0.0.1:8088&quot;###### [meta]###### Controls the parameters for the Raft consensus group that stores metadata### about the InfluxDB cluster.###[meta]  # Where the metadata/raft database is stored  dir = &quot;D:/influxdb-1.4.2-1/meta&quot;  # Automatically create a default retention policy when creating a database.    retention-autocreate = true  # If log messages are printed for the meta service    logging-enabled = true###### [data]###### Controls where the actual shard data for InfluxDB lives and how it is### flushed from the WAL. &quot;dir&quot; may need to be changed to a suitable place### for your system, but the WAL settings are an advanced configuration. The### defaults should work for most systems.###[data]  # The directory where the TSM storage engine stores TSM files.  dir = &quot;D:/influxdb-1.4.2-1/data&quot;  # The directory where the TSM storage engine stores WAL files.  wal-dir = &quot;D:/influxdb-1.4.2-1/wal&quot;  # The amount of time that a write will wait before fsyncing.  A duration  # greater than 0 can be used to batch up multiple fsync calls.  This is useful for slower  # disks or when WAL write contention is seen.  A value of 0s fsyncs every write to the WAL.  # Values in the range of 0-100ms are recommended for non-SSD disks.  # wal-fsync-delay = &quot;0s&quot;  # The type of shard index to use for new shards.  The default is an in-memory index that is  # recreated at startup.  A value of &quot;tsi1&quot; will use a disk based index that supports higher  # cardinality datasets.  # index-version = &quot;inmem&quot;  # Trace logging provides more verbose output around the tsm engine. Turning  # this on can provide more useful output for debugging tsm engine issues.  # trace-logging-enabled = false  # Whether queries should be logged before execution. Very useful for troubleshooting, but will  # log any sensitive data contained within a query.    query-log-enabled = true  # Settings for the TSM engine  # CacheMaxMemorySize is the maximum size a shard&#x27;s cache can  # reach before it starts rejecting writes.  # Valid size suffixes are k, m, or g (case insensitive, 1024 = 1k).  # Vaues without a size suffix are in bytes.  # cache-max-memory-size = &quot;1g&quot;  # CacheSnapshotMemorySize is the size at which the engine will  # snapshot the cache and write it to a TSM file, freeing up memory  # Valid size suffixes are k, m, or g (case insensitive, 1024 = 1k).  # Values without a size suffix are in bytes.  # cache-snapshot-memory-size = &quot;25m&quot;  # CacheSnapshotWriteColdDuration is the length of time at  # which the engine will snapshot the cache and write it to  # a new TSM file if the shard hasn&#x27;t received writes or deletes  # cache-snapshot-write-cold-duration = &quot;10m&quot;  # CompactFullWriteColdDuration is the duration at which the engine  # will compact all TSM files in a shard if it hasn&#x27;t received a  # write or delete  # compact-full-write-cold-duration = &quot;4h&quot;  # The maximum number of concurrent full and level compactions that can run at one time.  A  # value of 0 results in 50% of runtime.GOMAXPROCS(0) used at runtime.  Any number greater  # than 0 limits compactions to that value.  This setting does not apply  # to cache snapshotting.  # max-concurrent-compactions = 0  # The maximum series allowed per database before writes are dropped.  This limit can prevent  # high cardinality issues at the database level.  This limit can be disabled by setting it to  # 0.  # max-series-per-database = 1000000  # The maximum number of tag values per tag that are allowed before writes are dropped.  This limit  # can prevent high cardinality tag values from being written to a measurement.  This limit can be  # disabled by setting it to 0.  # max-values-per-tag = 100000###### [coordinator]###### Controls the clustering service configuration.###[coordinator]  # The default time a write request will wait until a &quot;timeout&quot; error is returned to the caller.  # write-timeout = &quot;10s&quot;  # The maximum number of concurrent queries allowed to be executing at one time.  If a query is  # executed and exceeds this limit, an error is returned to the caller.  This limit can be disabled  # by setting it to 0.  # max-concurrent-queries = 0  # The maximum time a query will is allowed to execute before being killed by the system.  This limit  # can help prevent run away queries.  Setting the value to 0 disables the limit.  # query-timeout = &quot;0s&quot;  # The time threshold when a query will be logged as a slow query.  This limit can be set to help  # discover slow or resource intensive queries.  Setting the value to 0 disables the slow query logging.  # log-queries-after = &quot;0s&quot;  # The maximum number of points a SELECT can process.  A value of 0 will make  # the maximum point count unlimited.  This will only be checked every second so queries will not  # be aborted immediately when hitting the limit.  # max-select-point = 0  # The maximum number of series a SELECT can run.  A value of 0 will make the maximum series  # count unlimited.  # max-select-series = 0  # The maxium number of group by time bucket a SELECT can create.  A value of zero will max the maximum  # number of buckets unlimited.  # max-select-buckets = 0###### [retention]###### Controls the enforcement of retention policies for evicting old data.###[retention]  # Determines whether retention policy enforcement enabled.    enabled = true  # The interval of time when retention policy enforcement checks run.    check-interval = &quot;30m&quot;###### [shard-precreation]###### Controls the precreation of shards, so they are available before data arrives.### Only shards that, after creation, will have both a start- and end-time in the### future, will ever be created. Shards are never precreated that would be wholly### or partially in the past.[shard-precreation]  # Determines whether shard pre-creation service is enabled.    enabled = true  # The interval of time when the check to pre-create new shards runs.    check-interval = &quot;10m&quot;  # The default period ahead of the endtime of a shard group that its successor  # group is created.    advance-period = &quot;30m&quot;###### Controls the system self-monitoring, statistics and diagnostics.###### The internal database for monitoring data is created automatically if### if it does not already exist. The target retention within this database### is called &#x27;monitor&#x27; and is also created with a retention period of 7 days### and a replication factor of 1, if it does not exist. In all cases the### this retention policy is configured as the default for the database.[monitor]  # Whether to record statistics internally.    store-enabled = true  # The destination database for recorded statistics    store-database = &quot;_internal&quot;  # The interval at which to record statistics    store-interval = &quot;10s&quot;###### [http]###### Controls how the HTTP endpoints are configured. These are the primary### mechanism for getting data into and out of InfluxDB.###[http]  # Determines whether HTTP endpoint is enabled.    enabled = true  # The bind address used by the HTTP service.    bind-address = &quot;:8086&quot;  # Determines whether user authentication is enabled over HTTP/HTTPS.  # auth-enabled = false  # The default realm sent back when issuing a basic auth challenge.  # realm = &quot;InfluxDB&quot;  # Determines whether HTTP request logging is enabled.  # log-enabled = true  # Determines whether detailed write logging is enabled.  # write-tracing = false  # Determines whether the pprof endpoint is enabled.  This endpoint is used for  # troubleshooting and monitoring.  # pprof-enabled = true  # Determines whether HTTPS is enabled.  # https-enabled = false  # The SSL certificate to use when HTTPS is enabled.  # https-certificate = &quot;/etc/ssl/influxdb.pem&quot;  # Use a separate private key location.  # https-private-key = &quot;&quot;  # The JWT auth shared secret to validate requests using JSON web tokens.  # shared-secret = &quot;&quot;  # The default chunk size for result sets that should be chunked.  # max-row-limit = 0  # The maximum number of HTTP connections that may be open at once.  New connections that  # would exceed this limit are dropped.  Setting this value to 0 disables the limit.  # max-connection-limit = 0  # Enable http service over unix domain socket  # unix-socket-enabled = false  # The path of the unix domain socket.  # bind-socket = &quot;/var/run/influxdb.sock&quot;  # The maximum size of a client request body, in bytes. Setting this value to 0 disables the limit.  # max-body-size = 25000000###### [ifql]###### Configures the ifql RPC API.###[ifql]  # Determines whether the RPC service is enabled.  # enabled = true  # Determines whether additional logging is enabled.  # log-enabled = true  # The bind address used by the ifql RPC service.  # bind-address = &quot;:8082&quot;###### [subscriber]###### Controls the subscriptions, which can be used to fork a copy of all data### received by the InfluxDB host.###[subscriber]  # Determines whether the subscriber service is enabled.  # enabled = true  # The default timeout for HTTP writes to subscribers.  # http-timeout = &quot;30s&quot;  # Allows insecure HTTPS connections to subscribers.  This is useful when testing with self-  # signed certificates.  # insecure-skip-verify = false  # The path to the PEM encoded CA certs file. If the empty string, the default system certs will be used  # ca-certs = &quot;&quot;  # The number of writer goroutines processing the write channel.  # write-concurrency = 40  # The number of in-flight writes buffered in the write channel.  # write-buffer-size = 1000###### [[graphite]]###### Controls one or many listeners for Graphite data.###[[graphite]]  # Determines whether the graphite endpoint is enabled.  # enabled = false  # database = &quot;graphite&quot;  # retention-policy = &quot;&quot;  # bind-address = &quot;:2003&quot;  # protocol = &quot;tcp&quot;  # consistency-level = &quot;one&quot;  # These next lines control how batching works. You should have this enabled  # otherwise you could get dropped metrics or poor performance. Batching  # will buffer points in memory if you have many coming in.  # Flush if this many points get buffered  # batch-size = 5000  # number of batches that may be pending in memory  # batch-pending = 10  # Flush at least this often even if we haven&#x27;t hit buffer limit  # batch-timeout = &quot;1s&quot;  # UDP Read buffer size, 0 means OS default. UDP listener will fail if set above OS max.  # udp-read-buffer = 0  ### This string joins multiple matching &#x27;measurement&#x27; values providing more control over the final measurement name.  # separator = &quot;.&quot;  ### Default tags that will be added to all metrics.  These can be overridden at the template level  ### or by tags extracted from metric  # tags = [&quot;region=us-east&quot;, &quot;zone=1c&quot;]  ### Each template line requires a template pattern.  It can have an optional  ### filter before the template and separated by spaces.  It can also have optional extra  ### tags following the template.  Multiple tags should be separated by commas and no spaces  ### similar to the line protocol format.  There can be only one default template.  # templates = [  #   &quot;*.app env.service.resource.measurement&quot;,  #   # Default template  #   &quot;server.*&quot;,  # ]###### [collectd]###### Controls one or many listeners for collectd data.###[[collectd]]  # enabled = false  # bind-address = &quot;:25826&quot;  # database = &quot;collectd&quot;  # retention-policy = &quot;&quot;  #  # The collectd service supports either scanning a directory for multiple types  # db files, or specifying a single db file.  # typesdb = &quot;/usr/local/share/collectd&quot;  #  # security-level = &quot;none&quot;  # auth-file = &quot;/etc/collectd/auth_file&quot;  # These next lines control how batching works. You should have this enabled  # otherwise you could get dropped metrics or poor performance. Batching  # will buffer points in memory if you have many coming in.  # Flush if this many points get buffered  # batch-size = 5000  # Number of batches that may be pending in memory  # batch-pending = 10  # Flush at least this often even if we haven&#x27;t hit buffer limit  # batch-timeout = &quot;10s&quot;  # UDP Read buffer size, 0 means OS default. UDP listener will fail if set above OS max.  # read-buffer = 0  # Multi-value plugins can be handled two ways.  # &quot;split&quot; will parse and store the multi-value plugin data into separate measurements  # &quot;join&quot; will parse and store the multi-value plugin as a single multi-value measurement.  # &quot;split&quot; is the default behavior for backward compatability with previous versions of influxdb.  # parse-multivalue-plugin = &quot;split&quot;###### [opentsdb]###### Controls one or many listeners for OpenTSDB data.###[[opentsdb]]  # enabled = false  # bind-address = &quot;:4242&quot;  # database = &quot;opentsdb&quot;  # retention-policy = &quot;&quot;  # consistency-level = &quot;one&quot;  # tls-enabled = false  # certificate= &quot;/etc/ssl/influxdb.pem&quot;  # Log an error for every malformed point.  # log-point-errors = true  # These next lines control how batching works. You should have this enabled  # otherwise you could get dropped metrics or poor performance. Only points  # metrics received over the telnet protocol undergo batching.  # Flush if this many points get buffered  # batch-size = 1000  # Number of batches that may be pending in memory  # batch-pending = 5  # Flush at least this often even if we haven&#x27;t hit buffer limit  # batch-timeout = &quot;1s&quot;###### [[udp]]###### Controls the listeners for InfluxDB line protocol data via UDP.###[[udp]]  # enabled = false  # bind-address = &quot;:8089&quot;  # database = &quot;udp&quot;  # retention-policy = &quot;&quot;  # These next lines control how batching works. You should have this enabled  # otherwise you could get dropped metrics or poor performance. Batching  # will buffer points in memory if you have many coming in.  # Flush if this many points get buffered  # batch-size = 5000  # Number of batches that may be pending in memory  # batch-pending = 10  # Will flush at least this often even if we haven&#x27;t hit buffer limit  # batch-timeout = &quot;1s&quot;  # UDP Read buffer size, 0 means OS default. UDP listener will fail if set above OS max.  # read-buffer = 0###### [continuous_queries]###### Controls how continuous queries are run within InfluxDB.###[continuous_queries]  # Determines whether the continuous query service is enabled.  # enabled = true  # Controls whether queries are logged when executed by the CQ service.  # log-enabled = true  # Controls whether queries are logged to the self-monitoring data store.  # query-stats-enabled = false  # interval for how often continuous queries will be checked if they need to run  # run-interval = &quot;1s&quot;\n\n四、使配置生效并打开数据库连接，双击influxd.exe就好，然后双击influx.exe进行操作，网上有操作教程，注意操作数据库时不能关闭influxd.exe，我不知道为什么总有这么个提示：There was an error writing history file: open : The system cannot find the file specified.不过好像没啥影响\n五、要使用web管理需要下载Chronograf，https://portal.influxdata.com/downloads第三个就是，下载完直接解压，双击exe程序，在浏览器输入http://localhost:8888/，一开始登录要账户密码，我都用admin就进去了\n这个是查看建立的数据库\n这个是查看数据库的数据\n没了\n","categories":["数据库","InfluxDB"],"tags":["时序数据库","InfluxDB"]},{"title":"时序数据库InfluxDB使用详解","url":"/2019/07/20/%E6%95%B0%E6%8D%AE%E5%BA%93/InfluxDB/%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE%E5%BA%93InfluxDB%E4%BD%BF%E7%94%A8%E8%AF%A6%E8%A7%A3/","content":"\nInfluxDB是一个开源的时序数据库，使用GO语言开发，特别适合用于处理和分析资源监控数据这种时序相关数据。而InfluxDB自带的各种特殊函数如求标准差，随机取样数据，统计数据变化比等，使数据统计和实时分析变得十分方便。在我们的容器资源监控系统中，就采用了InfluxDB存储cadvisor的监控数据。本文对InfluxDB的基本概念和一些特色功能做一个详细介绍，内容主要是翻译整理自官网文档，如有错漏，请指正。\n\n这里说一下使用docker容器运行influxdb的步骤，物理机安装请参照官方文档。拉取镜像文件后运行即可，当前最新版本是1.3.5。启动容器时设置挂载的数据目录和开放端口。InfluxDB的操作语法InfluxQL与SQL基本一致，也提供了一个类似mysql-client的名为influx的CLI。InfluxDB本身是支持分布式部署多副本存储的，本文介绍都是针对的单节点单副本。\nf216e9be15bff545befecb30d1d275552026216a939cc20c042b17419e3bde31root@f216e9be15bf:/Connected to http:InfluxDB shell version: 1.3.5&gt; create database cadvisor  &gt; show databases           name: databasesname----_internalcadvisor&gt; CREATE USER testuser WITH PASSWORD &#x27;testpwd&#x27; &gt; GRANT ALL PRIVILEGES ON cadvisor TO testuser &gt; CREATE RETENTION POLICY &quot;cadvisor_retention&quot; ON &quot;cadvisor&quot; DURATION 30d REPLICATION 1 DEFAULT \n\ninfluxdb里面有一些重要概念：database，timestamp，field key， field value， field set，tag key，tag value，tag set，measurement， retention policy ，series，point。结合下面的例子数据来说明这几个概念：\nname: census-————————————time                     butterflies     honeybees     location   scientist2015-08-18T00:00:00Z      12                23           1         langstroth2015-08-18T00:00:00Z      1                 30           1         perpetua2015-08-18T00:06:00Z      11                28           1         langstroth2015-08-18T00:06:00Z      3                 28           1         perpetua2015-08-18T05:54:00Z      2                 11           2         langstroth2015-08-18T06:00:00Z      1                 10           2         langstroth2015-08-18T06:06:00Z      8                 23           2         perpetua2015-08-18T06:12:00Z      7                 22           2         perpetua\n\ntimestamp既然是时间序列数据库，influxdb的数据都有一列名为time的列，里面存储UTC时间戳。\nfield key，field value，field setbutterflies和honeybees两列数据称为字段(fields)，influxdb的字段由field key和field value组成。其中butterflies和honeybees为field key，它们为string类型，用于存储元数据。\n而butterflies这一列的数据12-7为butterflies的field value，同理，honeybees这一列的23-22为honeybees的field value。field value可以为string，float，integer或boolean类型。field value通常都是与时间关联的。\nfield key和field value对组成的集合称之为field set。如下：\nbutterflies = 12 honeybees = 23butterflies = 1 honeybees = 30butterflies = 11 honeybees = 28butterflies = 3 honeybees = 28butterflies = 2 honeybees = 11butterflies = 1 honeybees = 10butterflies = 8 honeybees = 23butterflies = 7 honeybees = 22\n\n在influxdb中，字段必须存在。注意，字段是没有索引的。如果使用字段作为查询条件，会扫描符合查询条件的所有字段值，性能不及tag。类比一下，fields相当于SQL的没有索引的列。\ntag key，tag value，tag setlocation和scientist这两列称为标签(tags)，标签由tag key和tag value组成。location这个tag key有两个tag value：1和2，scientist有两个tag value：langstroth和perpetua。tag key和tag value对组成了tag set，示例中的tag set如下：\nlocation = 1, scientist = langstrothlocation = 2, scientist = langstrothlocation = 1, scientist = perpetualocation = 2, scientist = perpetua\n\ntags是可选的，但是强烈建议你用上它，因为tag是有索引的，tags相当于SQL中的有索引的列。tag value只能是string类型 如果你的常用场景是根据butterflies和honeybees来查询，那么你可以将这两个列设置为tag，而其他两列设置为field，tag和field依据具体查询需求来定。\nmeasurementmeasurement是fields，tags以及time列的容器，measurement的名字用于描述存储在其中的字段数据，类似mysql的表名。如上面例子中的measurement为census。measurement相当于SQL中的表，本文中我在部分地方会用表来指代measurement。\nretention policyretention policy指数据保留策略，示例数据中的retention policy为默认的autogen。它表示数据一直保留永不过期，副本数量为1。你也可以指定数据的保留时间，如30天。\nseriesseries是共享同一个retention policy，measurement以及tag set的数据集合。示例中数据有4个series，如下:\nArbitrary series number\nRetention policy\nMeasurement\nTag set\nseries 1\nautogen\ncensus\nlocation &#x3D; 1,scientist &#x3D; langstroth\nseries 2\nautogen\ncensus\nlocation &#x3D; 2,scientist &#x3D; langstroth\nseries 3\nautogen\ncensus\nlocation &#x3D; 1,scientist &#x3D; perpetua\nseries 4\nautogen\ncensus\nlocation &#x3D; 2,scientist &#x3D; perpetua\npointpoint则是同一个series中具有相同时间的field set，points相当于SQL中的数据行。如下面就是一个point：\nname: census-----------------time                  butterflies    honeybees   location    scientist2015-08-18T00:00:00Z       1            30           1        perpetua\n\ndatabase上面提到的结构都存储在数据库中，示例的数据库为my_database。一个数据库可以有多个measurement，retention policy， continuous queries以及user。influxdb是一个无模式的数据库，可以很容易的添加新的measurement，tags，fields等。而它的操作却和传统的数据库一样，可以使用类SQL语言查询和修改数据。\ninfluxdb不是一个完整的CRUD数据库，它更像是一个CR-ud数据库。它优先考虑的是增加和读取数据而不是更新和删除数据的性能，而且它阻止了某些更新和删除行为使得创建和读取数据更加高效。\ninfluxdb函数分为聚合函数，选择函数，转换函数，预测函数等。除了与普通数据库一样提供了基本操作函数外，还提供了一些特色函数以方便数据统计计算，下面会一一介绍其中一些常用的特色函数。\n\n聚合函数：FILL(), INTEGRAL()，SPREAD()， STDDEV()，MEAN(), MEDIAN()等。\n选择函数: SAMPLE(), PERCENTILE(), FIRST(), LAST(), TOP(), BOTTOM()等。\n转换函数: DERIVATIVE(), DIFFERENCE()等。\n预测函数：HOLT_WINTERS()。\n\n先从官网导入测试数据（注：这里测试用的版本是1.3.1，最新版本是1.3.5）:\n$ curl https://s3.amazonaws.com/noaa.water-database/NOAA_data.txt -o NOAA_data.txt$ influx -import -path=NOAA_data.txt -precision=s -database=NOAA_water_database$ influx -precision rfc3339 -database NOAA_water_databaseConnected to http://localhost:8086 version 1.3.1InfluxDB shell 1.3.1&gt; show measurementsname: measurementsname----average_temperaturedistinctsh2o_feeth2o_pHh2o_qualityh2o_temperature&gt; show series from h2o_feet;key---h2o_feet,location=coyote_creekh2o_feet,location=santa_monica\n\n下面的例子都以官方示例数据库来测试，这里只用部分数据以方便观察。measurement为h2o_feet，tag key为location，field key有level description和water_level两个。\n&gt; SELECT * FROM &quot;h2o_feet&quot; WHERE time &gt;= &#x27;2015-08-17T23:48:00Z&#x27; AND time &lt;= &#x27;2015-08-18T00:30:00Z&#x27;name: h2o_feettime                 level description    location     water_level----                 -----------------    --------     -----------2015-08-18T00:00:00Z between 6 and 9 feet coyote_creek 8.122015-08-18T00:00:00Z below 3 feet         santa_monica 2.0642015-08-18T00:06:00Z between 6 and 9 feet coyote_creek 8.0052015-08-18T00:06:00Z below 3 feet         santa_monica 2.1162015-08-18T00:12:00Z between 6 and 9 feet coyote_creek 7.8872015-08-18T00:12:00Z below 3 feet         santa_monica 2.0282015-08-18T00:18:00Z between 6 and 9 feet coyote_creek 7.7622015-08-18T00:18:00Z below 3 feet         santa_monica 2.1262015-08-18T00:24:00Z between 6 and 9 feet coyote_creek 7.6352015-08-18T00:24:00Z below 3 feet         santa_monica 2.0412015-08-18T00:30:00Z between 6 and 9 feet coyote_creek 7.52015-08-18T00:30:00Z below 3 feet         santa_monica 2.051\n\nGROUP BY，FILL()如下语句中GROUP BY time(12m),* 表示以每12分钟和tag(location)分组(如果是GROUP BY time(12m)则表示仅每12分钟分组，GROUP BY 参数只能是time和tag)。然后fill(200)表示如果这个时间段没有数据，以200填充，mean(field_key)求该范围内数据的平均值(注意：这是依据series来计算。其他还有SUM求和，MEDIAN求中位数)。LIMIT 7表示限制返回的point(记录数)最多为7条，而SLIMIT 1则是限制返回的series为1个。\n注意这里的时间区间，起始时间为整点前包含这个区间第一个12m的时间，比如这里为 2015-08-17T:23:48:00Z，第一条为 2015-08-17T23:48:00Z &lt;= t &lt; 2015-08-18T00:00:00Z这个区间的location=coyote_creek的water_level的平均值，这里没有数据，于是填充的200。第二条为 2015-08-18T00:00:00Z &lt;= t &lt; 2015-08-18T00:12:00Z区间的location=coyote_creek的water_level平均值，这里为 （8.12+8.005）/ 2 = 8.0625，其他以此类推。\n而GROUP BY time(10m)则表示以10分钟分组，起始时间为包含这个区间的第一个10m的时间，即 2015-08-17T23:40:00Z。默认返回的是第一个series，如果要计算另外那个series，可以在SQL语句后面加上 SOFFSET 1。\n那如果时间小于数据本身采集的时间间隔呢，比如GROUP BY time(10s)呢？这样的话，就会按10s取一个点，没有数值的为空或者FILL填充，对应时间点有数据则保持不变。\n## GROUP BY time(12m)&gt; SELECT mean(&quot;water_level&quot;) FROM &quot;h2o_feet&quot; WHERE time &gt;= &#x27;2015-08-17T23:48:00Z&#x27; AND time &lt;= &#x27;2015-08-18T00:30:00Z&#x27; GROUP BY time(12m),* fill(200) LIMIT 7 SLIMIT 1name: h2o_feettags: location=coyote_creektime                 mean----                 ----2015-08-17T23:48:00Z 2002015-08-18T00:00:00Z 8.06252015-08-18T00:12:00Z 7.82452015-08-18T00:24:00Z 7.5675## GROUP BY time(10m)，SOFFSET设置为1&gt; SELECT mean(&quot;water_level&quot;) FROM &quot;h2o_feet&quot; WHERE time &gt;= &#x27;2015-08-17T23:48:00Z&#x27; AND time &lt;= &#x27;2015-08-18T00:30:00Z&#x27; GROUP BY time(10m),* fill(200) LIMIT 7 SLIMIT 1 SOFFSET 1name: h2o_feettags: location=santa_monicatime                 mean----                 ----2015-08-17T23:40:00Z 2002015-08-17T23:50:00Z 2002015-08-18T00:00:00Z 2.092015-08-18T00:10:00Z 2.0772015-08-18T00:20:00Z 2.0412015-08-18T00:30:00Z 2.051\n\nINTEGRAL(field_key, unit)计算数值字段值覆盖的曲面的面积值并得到面积之和。测试数据如下：\n&gt; SELECT &quot;water_level&quot; FROM &quot;h2o_feet&quot; WHERE &quot;location&quot; = &#x27;santa_monica&#x27; AND time &gt;= &#x27;2015-08-18T00:00:00Z&#x27; AND time &lt;= &#x27;2015-08-18T00:30:00Z&#x27;name: h2o_feettime                   water_level----                   -----------2015-08-18T00:00:00Z   2.0642015-08-18T00:06:00Z   2.1162015-08-18T00:12:00Z   2.0282015-08-18T00:18:00Z   2.1262015-08-18T00:24:00Z   2.0412015-08-18T00:30:00Z   2.051\n\n使用INTERGRAL计算面积。注意，这个面积就是这些点连接起来后与时间围成的不规则图形的面积，注意unit默认是以1秒计算，所以下面语句计算结果为3732.66=2.028*1800+分割出来的梯形和三角形面积。如果unit改为1分，则结果为3732.66/60 = 62.211。unit为2分，则结果为3732.66/120 = 31.1055。以此类推。\n# unit为默认的1秒&gt; SELECT INTEGRAL(&quot;water_level&quot;) FROM &quot;h2o_feet&quot; WHERE &quot;location&quot; = &#x27;santa_monica&#x27; AND time &gt;= &#x27;2015-08-18T00:00:00Z&#x27; AND time &lt;= &#x27;2015-08-18T00:30:00Z&#x27;name: h2o_feettime                 integral----                 --------1970-01-01T00:00:00Z 3732.66# unit为1分&gt; SELECT INTEGRAL(&quot;water_level&quot;, 1m) FROM &quot;h2o_feet&quot; WHERE &quot;location&quot; = &#x27;santa_monica&#x27; AND time &gt;= &#x27;2015-08-18T00:00:00Z&#x27; AND time &lt;= &#x27;2015-08-18T00:30:00Z&#x27;name: h2o_feettime                 integral----                 --------1970-01-01T00:00:00Z 62.211\n\nSPREAD(field_key)计算数值字段的最大值和最小值的差值。\n&gt; SELECT SPREAD(&quot;water_level&quot;) FROM &quot;h2o_feet&quot; WHERE time &gt;= &#x27;2015-08-17T23:48:00Z&#x27; AND time &lt;= &#x27;2015-08-18T00:30:00Z&#x27; GROUP BY time(12m),* fill(18) LIMIT 3 SLIMIT 1 SOFFSET 1name: h2o_feettags: location=santa_monicatime                 spread----                 ------2015-08-17T23:48:00Z 182015-08-18T00:00:00Z 0.0520000000000000462015-08-18T00:12:00Z 0.09799999999999986\n\nSTDDEV(field_key)计算字段的标准差。influxdb用的是贝塞尔修正的标准差计算公式 ，如下：\n\nmean&#x3D;(v1+v2+…+vn)&#x2F;n;\nstddev &#x3D; math.sqrt(((v1-mean)2 + (v2-mean)2 + …+(vn-mean)2)&#x2F;(n-1))\n\n&gt; SELECT STDDEV(&quot;water_level&quot;) FROM &quot;h2o_feet&quot; WHERE time &gt;= &#x27;2015-08-17T23:48:00Z&#x27; AND time &lt;= &#x27;2015-08-18T00:30:00Z&#x27; GROUP BY time(12m),* fill(18) SLIMIT 1;name: h2o_feettags: location=coyote_creektime                 stddev----                 ------2015-08-17T23:48:00Z 182015-08-18T00:00:00Z 0.081317279836451862015-08-18T00:12:00Z 0.088388347648318452015-08-18T00:24:00Z 0.09545941546018377\n\nPERCENTILE(field_key, N)选取某个字段中大于N%的这个字段值。\n如果一共有4条记录，N为10，则10%*4&#x3D;0.4，四舍五入为0，则查询结果为空。N为20，则 20% * 4 &#x3D; 0.8，四舍五入为1，选取的是4个数中最小的数。如果N为40，40% * 4 &#x3D; 1.6，四舍五入为2，则选取的是4个数中第二小的数。由此可以看出N&#x3D;100时，就跟MAX(field_key)是一样的，而当N&#x3D;50时，与MEDIAN(field_key)在字段值为奇数个时是一样的。\n&gt; SELECT PERCENTILE(&quot;water_level&quot;,20) FROM &quot;h2o_feet&quot; WHERE time &gt;= &#x27;2015-08-17T23:48:00Z&#x27; AND time &lt;= &#x27;2015-08-18T00:30:00Z&#x27; GROUP BY time(12m)name: h2o_feettime                 percentile----                 ----------2015-08-17T23:48:00Z 2015-08-18T00:00:00Z 2.0642015-08-18T00:12:00Z 2.0282015-08-18T00:24:00Z 2.041&gt; SELECT PERCENTILE(&quot;water_level&quot;,40) FROM &quot;h2o_feet&quot; WHERE time &gt;= &#x27;2015-08-17T23:48:00Z&#x27; AND time &lt;= &#x27;2015-08-18T00:30:00Z&#x27; GROUP BY time(12m)name: h2o_feettime                 percentile----                 ----------2015-08-17T23:48:00Z 2015-08-18T00:00:00Z 2.1162015-08-18T00:12:00Z 2.1262015-08-18T00:24:00Z 2.051\n\nSAMPLE(field_key, N)随机返回field key的N个值。如果语句中有GROUP BY time()，则每组数据随机返回N个值。\n&gt; SELECT SAMPLE(&quot;water_level&quot;,2) FROM &quot;h2o_feet&quot; WHERE time &gt;= &#x27;2015-08-17T23:48:00Z&#x27; AND time &lt;= &#x27;2015-08-18T00:30:00Z&#x27;;name: h2o_feettime                 sample----                 ------2015-08-18T00:00:00Z 2.0642015-08-18T00:12:00Z 2.028&gt; SELECT SAMPLE(&quot;water_level&quot;,2) FROM &quot;h2o_feet&quot; WHERE time &gt;= &#x27;2015-08-17T23:48:00Z&#x27; AND time &lt;= &#x27;2015-08-18T00:30:00Z&#x27; GROUP BY time(12m);name: h2o_feettime                 sample----                 ------2015-08-18T00:06:00Z 2.1162015-08-18T00:06:00Z 8.0052015-08-18T00:12:00Z 7.8872015-08-18T00:18:00Z 7.7622015-08-18T00:24:00Z 7.6352015-08-18T00:30:00Z 2.051\n\nCUMULATIVE_SUM(field_key)计算字段值的递增和。\n&gt; SELECT CUMULATIVE_SUM(&quot;water_level&quot;) FROM &quot;h2o_feet&quot; WHERE time &gt;= &#x27;2015-08-17T23:48:00Z&#x27; AND time &lt;= &#x27;2015-08-18T00:30:00Z&#x27;;name: h2o_feettime                 cumulative_sum----                 --------------2015-08-18T00:00:00Z 8.122015-08-18T00:00:00Z 10.1842015-08-18T00:06:00Z 18.1892015-08-18T00:06:00Z 20.3052015-08-18T00:12:00Z 28.1922015-08-18T00:12:00Z 30.222015-08-18T00:18:00Z 37.9822015-08-18T00:18:00Z 40.1082015-08-18T00:24:00Z 47.7429999999999952015-08-18T00:24:00Z 49.783999999999992015-08-18T00:30:00Z 57.283999999999992015-08-18T00:30:00Z 59.334999999999994\n\nDERIVATIVE(field_key, unit) 和 NON_NEGATIVE_DERIVATIVE(field_key, unit)计算字段值的变化比。unit默认为1s，即计算的是1秒内的变化比。\n如下面的第一个数据计算方法是 (2.116-2.064)/(6*60) = 0.00014..，其他计算方式同理。虽然原始数据是6m收集一次，但是这里的变化比默认是按秒来计算的。如果要按6m计算，则设置unit为6m即可。\n&gt; SELECT DERIVATIVE(&quot;water_level&quot;) FROM &quot;h2o_feet&quot; WHERE &quot;location&quot; = &#x27;santa_monica&#x27; AND time &gt;= &#x27;2015-08-18T00:00:00Z&#x27; AND time &lt;= &#x27;2015-08-18T00:30:00Z&#x27;name: h2o_feettime                 derivative----                 ----------2015-08-18T00:06:00Z 0.000144444444444444572015-08-18T00:12:00Z -0.000244444444444444652015-08-18T00:18:00Z 0.00027222222222222182015-08-18T00:24:00Z -0.0002361111111111112015-08-18T00:30:00Z 0.00002777777777777842&gt; SELECT DERIVATIVE(&quot;water_level&quot;, 6m) FROM &quot;h2o_feet&quot; WHERE &quot;location&quot; = &#x27;santa_monica&#x27; AND time &gt;= &#x27;2015-08-18T00:00:00Z&#x27; AND time &lt;= &#x27;2015-08-18T00:30:00Z&#x27;name: h2o_feettime                 derivative----                 ----------2015-08-18T00:06:00Z 0.0520000000000000462015-08-18T00:12:00Z -0.088000000000000082015-08-18T00:18:00Z 0.097999999999999862015-08-18T00:24:00Z -0.084999999999999962015-08-18T00:30:00Z 0.010000000000000231\n\n而DERIVATIVE结合GROUP BY time，以及mean可以构造更加复杂的查询，如下所示:\n&gt; SELECT DERIVATIVE(mean(&quot;water_level&quot;), 6m) FROM &quot;h2o_feet&quot; WHERE time &gt;= &#x27;2015-08-18T00:00:00Z&#x27; AND time &lt;= &#x27;2015-08-18T00:30:00Z&#x27; group by time(12m), *name: h2o_feettags: location=coyote_creektime                 derivative----                 ----------2015-08-18T00:12:00Z -0.119000000000000222015-08-18T00:24:00Z -0.12849999999999984name: h2o_feettags: location=santa_monicatime                 derivative----                 ----------2015-08-18T00:12:00Z -0.006499999999999952015-08-18T00:24:00Z -0.015499999999999847\n\n这个计算其实是先根据GROUP BY time求平均值，然后对这个平均值再做变化比的计算。因为数据是按12分钟分组的，而变化比的unit是6分钟，所以差值除以2(12&#x2F;6)才得到变化比。如第一个值是 (7.8245-8.0625)/2 = -0.1190。\n&gt; SELECT mean(&quot;water_level&quot;) FROM &quot;h2o_feet&quot; WHERE time &gt;= &#x27;2015-08-18T00:00:00Z&#x27; AND time &lt;= &#x27;2015-08-18T00:30:00Z&#x27; group by time(12m), *name: h2o_feettags: location=coyote_creektime                 mean----                 ----2015-08-18T00:00:00Z 8.06252015-08-18T00:12:00Z 7.82452015-08-18T00:24:00Z 7.5675name: h2o_feettags: location=santa_monicatime                 mean----                 ----2015-08-18T00:00:00Z 2.092015-08-18T00:12:00Z 2.0772015-08-18T00:24:00Z 2.0460000000000003\n\nNON_NEGATIVE_DERIVATIVE与DERIVATIVE不同的是它只返回的是非负的变化比:\n&gt; SELECT DERIVATIVE(mean(&quot;water_level&quot;), 6m) FROM &quot;h2o_feet&quot; WHERE location=&#x27;santa_monica&#x27; AND time &gt;= &#x27;2015-08-18T00:00:00Z&#x27; AND time &lt;= &#x27;2015-08-18T00:30:00Z&#x27; group by time(6m), *name: h2o_feettags: location=santa_monicatime                 derivative----                 ----------2015-08-18T00:06:00Z 0.0520000000000000462015-08-18T00:12:00Z -0.088000000000000082015-08-18T00:18:00Z 0.097999999999999862015-08-18T00:24:00Z -0.084999999999999962015-08-18T00:30:00Z 0.010000000000000231&gt; SELECT NON_NEGATIVE_DERIVATIVE(mean(&quot;water_level&quot;), 6m) FROM &quot;h2o_feet&quot; WHERE location=&#x27;santa_monica&#x27; AND time &gt;= &#x27;2015-08-18T00:00:00Z&#x27; AND time &lt;= &#x27;2015-08-18T00:30:00Z&#x27; group by time(6m), *name: h2o_feettags: location=santa_monicatime                 non_negative_derivative----                 -----------------------2015-08-18T00:06:00Z 0.0520000000000000462015-08-18T00:18:00Z 0.097999999999999862015-08-18T00:30:00Z 0.010000000000000231\n\n4.1 基本语法连续查询(CONTINUOUS QUERY，简写为CQ)是指定时自动在实时数据上进行的InfluxQL查询，查询结果可以存储到指定的measurement中。基本语法格式如下：\nCREATE CONTINUOUS QUERY &lt;cq_name&gt; ON &lt;database_name&gt;BEGIN  &lt;cq_query&gt;ENDcq_query格式：SELECT &lt;function[s]&gt; INTO &lt;destination_measurement&gt; FROM &lt;measurement&gt; [WHERE &lt;stuff&gt;] GROUP BY time(&lt;interval&gt;)[,&lt;tag_key[s]&gt;]\n\nCQ操作的是实时数据，它使用本地服务器的时间戳、GROUP BY time()时间间隔以及InfluxDB预先设置好的时间范围来确定什么时候开始查询以及查询覆盖的时间范围。注意CQ语句里面的WHERE条件是没有时间范围的，因为CQ会根据GROUP BY time()自动确定时间范围。\nCQ执行的时间间隔和GROUP BY time()的时间间隔一样，它在InfluxDB预先设置的时间范围的起始时刻执行。如果GROUP BY time(1h)，则单次查询的时间范围为 now()-GROUP BY time(1h)到 now()，也就是说，如果当前时间为17点，这次查询的时间范围为 16:00到16:59.99999。\n下面看几个示例，示例数据如下，这是数据库transportation中名为bus_data的measurement，每15分钟统计一次乘客数和投诉数。数据文件bus_data.txt如下：\n# DDLCREATE DATABASE transportation# DML# CONTEXT-DATABASE: transportation bus_data,complaints=9 passengers=5 1472367600bus_data,complaints=9 passengers=8 1472368500bus_data,complaints=9 passengers=8 1472369400bus_data,complaints=9 passengers=7 1472370300bus_data,complaints=9 passengers=8 1472371200bus_data,complaints=7 passengers=15 1472372100bus_data,complaints=7 passengers=15 1472373000bus_data,complaints=7 passengers=17 1472373900bus_data,complaints=7 passengers=20 1472374800\n\n导入数据，命令如下：\nroot@f216e9be15bf:/# influx -import -path=bus_data.txt -precision=sroot@f216e9be15bf:/# influx -precision=rfc3339 -database=transportationConnected to http://localhost:8086 version 1.3.5InfluxDB shell version: 1.3.5&gt; select * from bus_dataname: bus_datatime                 complaints passengers----                 ---------- ----------2016-08-28T07:00:00Z 9          52016-08-28T07:15:00Z 9          82016-08-28T07:30:00Z 9          82016-08-28T07:45:00Z 9          72016-08-28T08:00:00Z 9          82016-08-28T08:15:00Z 7          152016-08-28T08:30:00Z 7          152016-08-28T08:45:00Z 7          172016-08-28T09:00:00Z 7          20\n\n示例1 自动缩小取样存储到新的measurement中对单个字段自动缩小取样并存储到新的measurement中。\nCREATE CONTINUOUS QUERY &quot;cq_basic&quot; ON &quot;transportation&quot;BEGIN  SELECT mean(&quot;passengers&quot;) INTO &quot;average_passengers&quot; FROM &quot;bus_data&quot; GROUP BY time(1h)END\n\n这个CQ的意思就是对bus_data每小时自动计算取样数据的平均乘客数并存储到 average_passengers中。那么在2016-08-28这天早上会执行如下流程：\nAt 8:00 cq_basic 执行查询，查询时间范围 time &gt;= &#x27;7:00&#x27; AND time &lt; &#x27;08:00&#x27;.cq_basic写入一条记录到 average_passengers:name: average_passengers------------------------time                   mean2016-08-28T07:00:00Z   7At 9:00 cq_basic 执行查询，查询时间范围 time &gt;= &#x27;8:00&#x27; AND time &lt; &#x27;9:00&#x27;.cq_basic写入一条记录到 average_passengers:name: average_passengers------------------------time                   mean2016-08-28T08:00:00Z   13.75# Results&gt; SELECT * FROM &quot;average_passengers&quot;name: average_passengers------------------------time                   mean2016-08-28T07:00:00Z   72016-08-28T08:00:00Z   13.75\n\n示例2 自动缩小取样并存储到新的保留策略（Retention Policy）中CREATE CONTINUOUS QUERY &quot;cq_basic_rp&quot; ON &quot;transportation&quot;BEGIN  SELECT mean(&quot;passengers&quot;) INTO &quot;transportation&quot;.&quot;three_weeks&quot;.&quot;average_passengers&quot; FROM &quot;bus_data&quot; GROUP BY time(1h)END\n\n与示例1类似，不同的是保留的策略不是autogen，而是改成了three_weeks(创建保留策略语法 CREATE RETENTION POLICY &quot;three_weeks&quot; ON &quot;transportation&quot; DURATION 3w REPLICATION 1)。\n&gt; SELECT * FROM &quot;transportation&quot;.&quot;three_weeks&quot;.&quot;average_passengers&quot;name: average_passengers------------------------time                   mean2016-08-28T07:00:00Z   72016-08-28T08:00:00Z   13.75\n\n示例3 使用后向引用(backreferencing)自动缩小取样并存储到新的数据库中CREATE CONTINUOUS QUERY &quot;cq_basic_br&quot; ON &quot;transportation&quot;BEGIN  SELECT mean(*) INTO &quot;downsampled_transportation&quot;.&quot;autogen&quot;.:MEASUREMENT FROM /.*/ GROUP BY time(30m),*END\n\n使用后向引用语法自动缩小取样并存储到新的数据库中。语法 :MEASUREMENT 用来指代后面的表，而 /.*/则是分别查询所有的表。这句CQ的含义就是每30分钟自动查询transportation的所有表(这里只有bus_data一个表)，并将30分钟内数字字段(passengers和complaints)求平均值存储到新的数据库 downsampled_transportation中。\n最终结果如下：\n&gt; SELECT * FROM &quot;downsampled_transportation.&quot;autogen&quot;.&quot;bus_data&quot;name: bus_data--------------time                   mean_complaints   mean_passengers2016-08-28T07:00:00Z   9                 6.52016-08-28T07:30:00Z   9                 7.52016-08-28T08:00:00Z   8                 11.52016-08-28T08:30:00Z   7                 16\n\n示例4 自动缩小取样以及配置CQ的时间范围CREATE CONTINUOUS QUERY &quot;cq_basic_offset&quot; ON &quot;transportation&quot;BEGIN  SELECT mean(&quot;passengers&quot;) INTO &quot;average_passengers&quot; FROM &quot;bus_data&quot; GROUP BY time(1h,15m)END\n\n与前面几个示例不同的是，这里的GROUP BY time(1h, 15m)指定了一个时间偏移，也就是说 cq_basic_offset执行的时间不再是整点，而是往后偏移15分钟。执行流程如下:\nAt 8:15 cq_basic_offset 执行查询的时间范围 time &gt;= &#x27;7:15&#x27; AND time &lt; &#x27;8:15&#x27;.name: average_passengers------------------------time                   mean2016-08-28T07:15:00Z   7.75At 9:15 cq_basic_offset 执行查询的时间范围 time &gt;= &#x27;8:15&#x27; AND time &lt; &#x27;9:15&#x27;.name: average_passengers------------------------time                   mean2016-08-28T08:15:00Z   16.75\n\n最终结果:\n&gt; SELECT * FROM &quot;average_passengers&quot;name: average_passengers------------------------time                   mean2016-08-28T07:15:00Z   7.752016-08-28T08:15:00Z   16.75\n\n4.2 高级语法InfluxDB连续查询的高级语法如下：\nCREATE CONTINUOUS QUERY &lt;cq_name&gt; ON &lt;database_name&gt;RESAMPLE EVERY &lt;interval&gt; FOR &lt;interval&gt;BEGIN  &lt;cq_query&gt;END\n\n与基本语法不同的是，多了RESAMPLE关键字。高级语法里CQ的执行时间和查询时间范围则与RESAMPLE里面的两个interval有关系。\n高级语法中CQ以EVERY interval的时间间隔执行，执行时查询的时间范围则是FOR interval来确定。如果FOR interval为2h，当前时间为17:00，则查询的时间范围为15:00-16:59.999999。RESAMPLE的EVERY和FOR两个关键字可以只有一个。\n示例的数据表如下，比之前的多了几条记录为了示例3和示例4的测试:\nname: bus_data--------------time                   passengers2016-08-28T06:30:00Z   22016-08-28T06:45:00Z   42016-08-28T07:00:00Z   52016-08-28T07:15:00Z   82016-08-28T07:30:00Z   82016-08-28T07:45:00Z   72016-08-28T08:00:00Z   82016-08-28T08:15:00Z   152016-08-28T08:30:00Z   152016-08-28T08:45:00Z   172016-08-28T09:00:00Z   20\n\n示例1 只配置执行时间间隔CREATE CONTINUOUS QUERY &quot;cq_advanced_every&quot; ON &quot;transportation&quot;RESAMPLE EVERY 30mBEGIN  SELECT mean(&quot;passengers&quot;) INTO &quot;average_passengers&quot; FROM &quot;bus_data&quot; GROUP BY time(1h)END\n\n这里配置了30分钟执行一次CQ，没有指定FOR interval，于是查询的时间范围还是GROUP BY time(1h)指定的一个小时，执行流程如下：\nAt 8:00, cq_advanced_every 执行时间范围 time &gt;= &#x27;7:00&#x27; AND time &lt; &#x27;8:00&#x27;.name: average_passengers------------------------time                   mean2016-08-28T07:00:00Z   7At 8:30, cq_advanced_every 执行时间范围 time &gt;= &#x27;8:00&#x27; AND time &lt; &#x27;9:00&#x27;.name: average_passengers------------------------time                   mean2016-08-28T08:00:00Z   12.6667At 9:00, cq_advanced_every 执行时间范围 time &gt;= &#x27;8:00&#x27; AND time &lt; &#x27;9:00&#x27;.name: average_passengers------------------------time                   mean2016-08-28T08:00:00Z   13.75\n\n需要注意的是，这里的 8点到9点这个区间执行了两次，第一次执行时时8:30，平均值是 (8+15+15）/ 3 = 12.6667，而第二次执行时间是9:00，平均值是 (8+15+15+17) / 4=13.75，而且最后第二个结果覆盖了第一个结果。InfluxDB如何处理重复的记录可以参见这个文档。\n最终结果：\n&gt; SELECT * FROM &quot;average_passengers&quot;name: average_passengers------------------------time                   mean2016-08-28T07:00:00Z   72016-08-28T08:00:00Z   13.75\n\n示例2 只配置查询时间范围CREATE CONTINUOUS QUERY &quot;cq_advanced_for&quot; ON &quot;transportation&quot;RESAMPLE FOR 1hBEGIN  SELECT mean(&quot;passengers&quot;) INTO &quot;average_passengers&quot; FROM &quot;bus_data&quot; GROUP BY time(30m)END\n\n只配置了时间范围，而没有配置EVERY interval。这样，执行的时间间隔与GROUP BY time(30m)一样为30分钟，而查询的时间范围为1小时，由于是按30分钟分组，所以每次会写入两条记录。执行流程如下：\nAt 8:00 cq_advanced_for 查询时间范围：time &gt;= &#x27;7:00&#x27; AND time &lt; &#x27;8:00&#x27;.写入两条记录。name: average_passengers------------------------time                   mean2016-08-28T07:00:00Z   6.52016-08-28T07:30:00Z   7.5At 8:30 cq_advanced_for 查询时间范围：time &gt;= &#x27;7:30&#x27; AND time &lt; &#x27;8:30&#x27;.写入两条记录。name: average_passengers------------------------time                   mean2016-08-28T07:30:00Z   7.52016-08-28T08:00:00Z   11.5At 9:00 cq_advanced_for 查询时间范围：time &gt;= &#x27;8:00&#x27; AND time &lt; &#x27;9:00&#x27;.写入两条记录。name: average_passengers------------------------time                   mean2016-08-28T08:00:00Z   11.52016-08-28T08:30:00Z   16\n\n需要注意的是，cq_advanced_for每次写入了两条记录，重复的记录会被覆盖。\n最终结果：\n&gt; SELECT * FROM &quot;average_passengers&quot;name: average_passengers------------------------time                   mean2016-08-28T07:00:00Z   6.52016-08-28T07:30:00Z   7.52016-08-28T08:00:00Z   11.52016-08-28T08:30:00Z   16\n\n示例3 同时配置执行时间间隔和查询时间范围CREATE CONTINUOUS QUERY &quot;cq_advanced_every_for&quot; ON &quot;transportation&quot;RESAMPLE EVERY 1h FOR 90mBEGIN  SELECT mean(&quot;passengers&quot;) INTO &quot;average_passengers&quot; FROM &quot;bus_data&quot; GROUP BY time(30m)END\n\n这里配置了执行间隔为1小时，而查询范围90分钟，最后分组是30分钟，每次插入了三条记录。执行流程如下：\nAt 8:00 cq_advanced_every_for 查询时间范围 time &gt;= &#x27;6:30&#x27; AND time &lt; &#x27;8:00&#x27;.插入三条记录name: average_passengers------------------------time                   mean2016-08-28T06:30:00Z   32016-08-28T07:00:00Z   6.52016-08-28T07:30:00Z   7.5At 9:00 cq_advanced_every_for 查询时间范围 time &gt;= &#x27;7:30&#x27; AND time &lt; &#x27;9:00&#x27;.插入三条记录name: average_passengers------------------------time                   mean2016-08-28T07:30:00Z   7.52016-08-28T08:00:00Z   11.52016-08-28T08:30:00Z   16\n\n最终结果：\n&gt; SELECT * FROM &quot;average_passengers&quot;name: average_passengers------------------------time                   mean2016-08-28T06:30:00Z   32016-08-28T07:00:00Z   6.52016-08-28T07:30:00Z   7.52016-08-28T08:00:00Z   11.52016-08-28T08:30:00Z   16\n\n示例4 配置查询时间范围和FILL填充CREATE CONTINUOUS QUERY &quot;cq_advanced_for_fill&quot; ON &quot;transportation&quot;RESAMPLE FOR 2hBEGIN  SELECT mean(&quot;passengers&quot;) INTO &quot;average_passengers&quot; FROM &quot;bus_data&quot; GROUP BY time(1h) fill(1000)END\n\n在前面值配置查询时间范围的基础上，加上FILL填充空的记录。执行流程如下：\nAt 6:00, cq_advanced_for_fill 查询时间范围：time &gt;= &#x27;4:00&#x27; AND time &lt; &#x27;6:00&#x27;，没有数据，不填充。At 7:00, cq_advanced_for_fill 查询时间范围：time &gt;= &#x27;5:00&#x27; AND time &lt; &#x27;7:00&#x27;. 写入两条记录，没有数据的时间点填充1000。------------------------time                   mean2016-08-28T05:00:00Z   1000          &lt;------ fill(1000)2016-08-28T06:00:00Z   3             &lt;------ average of 2 and 4[…] At 11:00, cq_advanced_for_fill 查询时间范围：time &gt;= &#x27;9:00&#x27; AND time &lt; &#x27;11:00&#x27;.写入两条记录，没有数据的点填充1000。name: average_passengers------------------------2016-08-28T09:00:00Z   20            &lt;------ average of 202016-08-28T10:00:00Z   1000          &lt;------ fill(1000)     At 12:00, cq_advanced_for_fill 查询时间范围：time &gt;= &#x27;10:00&#x27; AND time &lt; &#x27;12:00&#x27;。没有数据，不填充。\n\n最终结果:\n&gt; SELECT * FROM &quot;average_passengers&quot;name: average_passengers------------------------time                   mean2016-08-28T05:00:00Z   10002016-08-28T06:00:00Z   32016-08-28T07:00:00Z   72016-08-28T08:00:00Z   13.752016-08-28T09:00:00Z   202016-08-28T10:00:00Z   1000\n\n\nhttps://docs.influxdata.com/influxdb/v1.3/\nhttps://zh.wikipedia.org/wiki/%E6%A8%99%E6%BA%96%E5%B7%AE\n\n","categories":["数据库","InfluxDB"],"tags":["时序数据库","InfluxDB"]},{"title":"MySQL权限管理","url":"/2015/01/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/","content":"MySQL root修改普通用户密码\nMySQL GRANT：用户授权\nMySQL查看用户权限\nMySQL修改用户（RENAME USER）\nMySQL创建用户（3种方式）\nMySQL允许root远程登录_小gu的博客-CSDN博客_mysql允许root远程连接\n","categories":["数据库","MySQL"],"tags":["MySQL","权限"]},{"title":"SQL Server设置开启远程连接（sa配置）","url":"/2018/02/10/%E6%95%B0%E6%8D%AE%E5%BA%93/SQL%20Server/SQL%20Server%E8%AE%BE%E7%BD%AE%E5%BC%80%E5%90%AF%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5%EF%BC%88sa%E9%85%8D%E7%BD%AE%EF%BC%89/","content":"本文方案适用于Microsoft Sql Server 2008&#x2F;2012&#x2F;2012 r2&#x2F;2014版本，以下简称MSSQLSERVER。\nMSSQL默认是不允许远程连接，并且禁用sa账户的。如果想要在本地用SSMS连接远程服务器上的MSSQLSERVER，需要做两个部分的配置：\n1. SQL SERVER MANAGEMENT STUDIO(SSMS)\n2. SQL SERVER配置管理器（SQL SERVER CONFIGURATION MANAGER - SSCM）\n并且需要注意的是，有些地方如果没有生效，请重启一下sql server（可以从SSCM里，也可以从系统服务中找），下面是详细的步骤：\nSTEP1. 打开SSMS，使用Windows身份连接数据库，登录后，右键选择“属性”\n\nSTEP 2. 选择“安全性”，选中SQL SERVER和Windows身份验证模式\n\nSTEP 3. 再选择“连接”，勾选“允许远程连接此服务器”，然后点击“确定”按钮。\n\n\nSTEP 4. 展开“安全性” -》登录名 -》sa，右键选择“属性”\n\nSTEP 5. 在“常规”中，改好你自己的密码，这是你sa登录的密码。\n\nSTEP 6. 在“状态”中，启用sa登录，点击“确定”按钮\n\nSTEP 7. 右键数据库server，选择“方面”\n\nSTEP 8. 选择“服务器配置”，找到RemoteAccessEnabled，设置为“True”\n\nSTEP 9. 重新启动SQL SERVER服务，退出当前的连接，这时候应该可以用sa进行登录了。\n\n\nSTEP 10. 配置SSCM，选中左侧的“SQL SERVER服务”，确保右侧的“SQL SERVER”以及“SQL SERVER BROWER”正在运行，选择“网络配置”，双击TCP&#x2F;IP，确保状态为“启用”\n\nSTEP 11. 在Client里也确保TCP&#x2F;IP是启用的，默认的端口都是1433，可以自己修改，非默认端口需要在连接字符串里显式指明。\n\nSTEP 12. 到这里再次重启SQL SERVER服务，应该就可以用了。不过还不能用，确认防火墙端口设置，并把SQL SERVER安装目录下，C:\\Program Files\\Microsoft SQL Server\\MSSQL10.SQLEXPRESS\\MSSQL\\Binn\\sqlservr.exe添加到允许的列表中。\n","categories":["数据库","SQL Server"]},{"title":"C#使用EmguCV实现视频读取和播放，及多个视频一起播放的问题","url":"/2015/10/24/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/C#%E4%BD%BF%E7%94%A8EmguCV%E5%AE%9E%E7%8E%B0%E8%A7%86%E9%A2%91%E8%AF%BB%E5%8F%96%E5%92%8C%E6%92%AD%E6%94%BE%EF%BC%8C%E5%8F%8A%E5%A4%9A%E4%B8%AA%E8%A7%86%E9%A2%91%E4%B8%80%E8%B5%B7%E6%92%AD%E6%94%BE%E7%9A%84%E9%97%AE%E9%A2%98/","content":"\nWinForm程序\n\n1）第一种方法，使用委托：\nprivate delegate void SetTextCallback(string text);private void SetText(string text)&#123;    // InvokeRequired需要比较调用线程ID和创建线程ID    // 如果它们不相同则返回true    if (this.txt_Name.InvokeRequired)    &#123;        SetTextCallback d = new SetTextCallback(SetText);        this.Invoke(d, new object[] &#123; text &#125;);    &#125;    else &#123;        this.txt_Name.Text = text;    &#125;&#125;\n\n2）第二种方法，使用匿名委托\nprivate void SetText(Object obj)&#123;    if (this.InvokeRequired)    &#123;        this.Invoke(new MethodInvoker(delegate &#123;            this.txt_Name.Text = obj;        &#125;));    &#125;    else &#123;        this.txt_Name.Text = obj;    &#125;&#125;\n\n这里说一下BeginInvoke和Invoke和区别：BeginInvoke会立即返回，Invoke会等执行完后再返回。\n\nWPF程序\n\n1）可以使用Dispatcher线程模型来修改\n如果是窗体本身可使用类似如下的代码：\nthis.lblState.Dispatcher.Invoke(new Action(delegate{     this.lblState.Content &#x3D; “状态：” + this._statusText;}));\n那么假如是在一个公共类中弹出一个窗口、播放声音等呢？这里我们可以使用：System.Windows.Application.Current.Dispatcher，如下所示\n\n System.Windows.Application.Current.Dispatcher.Invoke(new Action(() &#x3D;&gt; {     if (path.EndsWith(“.mp3”) || path.EndsWith(“.wma”) || path.EndsWith(“.wav”))     {        _player.Open(new Uri(path));        _player.Play();    } }));\n关键问题：多个视频同时播放，以上几种方法不足以解决，多个视频播放中主界面卡死和播放显示刷新不了的问题。\n目前笔者的解决方法是\n pinturebox.CreateGraphics().DrawImage(imgSrc.Bitmap, new System.Drawing.Rectangle(0, 0, pinturebox.Width, pinturebox.Height));\nEmguCV中的Capture类可以完成视频文件的读取，并捕捉每一帧，可以利用Capture类完成实现WinForm中视频检测跟踪环境的搭建。本文只实现最简陋的WinForm + EmguCV上的avi文件读取和播放框架，复杂的检测和跟踪算法在之后添加进去。\n        这里使用WinForm实现视频的播放，主要是PictureBox类，它是支持基于事件的异步模式的典型组件，不使用EmguCV自带的UI控件等。\n\n图1.效果图\n        直接在UI线程中完成视频的播放的话整个程序只有一个线程，由于程序只能同步执行，播放视频的时候UI将停止响应用户的输入，造成界面的假死。所以视频的播放需要实现异步模式。主要有三种方法：第一是使用异步委托；第二种是使用BackgroundWorker组件；最后一种就是使用多线程（不使用CheckForIllegalCrossThreadCalls &#x3D;false的危险做法）。\n        Windows窗体控件，唯一可以从创建它的线程之外的线程中调用的是Invoke()、BegionInvoke()、EndInvoke()方法和InvokeRequired属性。其中BegionInvoke()、EndInvoke()方法是Invoke()方法的异步版本。这些方法会切换到创建控件的线程上，以调用赋予一个委托参数的方法，该委托参数可以传递给这些方法。\n        （一）   使用多线程        首先定义监控的类及其对应的事件参数类和异常类：        判断是否继续执行的布尔型成员会被调用线程改变，因此声名为volatile，不进行优化。\n/// &lt;summary&gt;/// 红外检测子。/// &lt;/summary&gt;public class ThermalSurveillant&#123;    #region Private Fields     /// &lt;summary&gt;    /// 是否停止线程，此变量供多个线程访问。    /// &lt;/summary&gt;    private volatile bool shouldStop = false;     #endregion    #region Public Properties     #endregion    #region Public Events     /// &lt;summary&gt;    /// 帧刷新事件。    /// &lt;/summary&gt;    public EventHandler&lt;FrameRefreshEventArgs&gt; FrameRefresh;     /// &lt;summary&gt;    /// 播放完成。    /// &lt;/summary&gt;    public EventHandler&lt;CompletedEventArgs&gt; Completed;     #endregion    #region Protected Methods     /// &lt;summary&gt;    /// 处理帧刷新事件。    /// &lt;/summary&gt;    /// &lt;param name=&quot;e&quot;&gt;&lt;/param&gt;    protected virtual void OnFrameRefresh(FrameRefreshEventArgs e)    &#123;        if (this.FrameRefresh != null)        &#123;            this.FrameRefresh(this, e);        &#125;    &#125;     /// &lt;summary&gt;    /// 处理视频读完事件。    /// &lt;/summary&gt;    /// &lt;param name=&quot;e&quot;&gt;&lt;/param&gt;    protected virtual void OnCompleted(CompletedEventArgs e)    &#123;        if (this.Completed != null)        &#123;            this.Completed(this, e);        &#125;    &#125;     #endregion    #region Public Methods     /// &lt;summary&gt;    /// 视频监控。    /// &lt;/summary&gt;    /// &lt;param name=&quot;capture&quot;&gt;捕捉。&lt;/param&gt;    public void DoSurveillance(Object oCapture)    &#123;        Capture capture = oCapture as Capture;        int id = 1;        if (capture == null)        &#123;            throw new InvalidCaptureObjectException(&quot;传递的Capture类型无效。&quot;);        &#125;        while (!shouldStop)        &#123;            Image&lt;Bgr, byte&gt; frame = capture.QueryFrame();            if (frame != null)            &#123;                FrameRefreshEventArgs e = new FrameRefreshEventArgs(frame.ToBitmap(), id++);                // 触发刷新事件                this.OnFrameRefresh(e);            &#125;            else            &#123;                break;            &#125;        &#125;        // 触发完成事件        this.OnCompleted(new CompletedEventArgs(id));    &#125;     /// &lt;summary&gt;    /// 请求停止线程。    /// &lt;/summary&gt;    public void Cancel()    &#123;        this.shouldStop = true;    &#125;     #endregion&#125;\n\n\n\n        UI线程中启动播放线程：\n声明：\n/// &lt;summary&gt;/// 监控线程。 /// &lt;/summary&gt;private Thread threadSurveillance = null; /// &lt;summary&gt;/// 捕获视频帧。 /// &lt;/summary&gt;private Capture captureSurveillance; /// &lt;summary&gt;/// 监控子。 /// &lt;/summary&gt;private ThermalSurveillant surveillant = new ThermalSurveillant();\n\n\n\n\n\n\n\n读入视频文件：\ncaptureSurveillance = new Capture(this.videoFilePath);captureSurveillance.SetCaptureProperty(CAP_PROP.CV_CAP_PROP_FRAME_WIDTH, this.width);captureSurveillance.SetCaptureProperty(CAP_PROP.CV_CAP_PROP_FRAME_HEIGHT, this.height);Image&lt;Bgr, byte&gt; frame = captureSurveillance.QueryFrame();this.pictureBox.Image = frame.ToBitmap();\n\n播放视频文件：\n        UI线程中响应监控类的事件：\n定义异步调用的委托：\n添加事件委托：\nthis.surveillant.FrameRefresh += OnRefreshFrame;this.surveillant.Completed += OnCompleted;\n\n\n\n\n\n        以下方法中都是由监控线程中的事件委托方法，应该使用BeginInvoke方法，这样可以优雅的结束线程，如果使用Invoke方法，则调用方式为同步调用，此时如果使用Thread.Join()方法终止线程将引发死锁（正常播放没有问题），Thread.Join()方法的使用使调用线程阻塞等待当前线程完成，在这里即UI线程阻塞等待监控线程完成，而监控线程中又触发UI线程中pictureBox的刷新，使用Invoke方法就造成了监控线程等待UI线程刷新结果，而UI线程已经阻塞，形成了死锁。死锁时只能用Thread.Abort()方法才能结束线程。或者直接强制结束应用程序。\n        使用BeginInvoke方法时为异步调用，监控线程不等待刷新结果直接继续执行，可以正常结束。结束后UI才进行刷新，不会造成死锁。\n\n图2.线程关系\n/// &lt;summary&gt;/// 刷新UI线程的pixtureBox的方法。/// &lt;/summary&gt;/// &lt;param name=&quot;frame&quot;&gt;要刷新的帧。&lt;/param&gt;private void RefreshFrame(Bitmap frame)&#123;    this.pictureBox.Image = frame;    // 这里一定不能刷新！2012年8月2日1:50:16    //this.pictureBox.Refresh();&#125;/// &lt;summary&gt;/// 响应pictureBox刷新。/// &lt;/summary&gt;/// &lt;param name=&quot;sender&quot;&gt;&lt;/param&gt;/// &lt;param name=&quot;e&quot;&gt;&lt;/param&gt;private void OnRefreshFrame(object sender, FrameRefreshEventArgs e)&#123;    // 判断是否需要跨线程调用    if (this.pictureBox.InvokeRequired == true)    &#123;        FrameRefreshDelegate fresh = this.RefreshFrame;        this.BeginInvoke(fresh, e.Frame);    &#125;    else    &#123;        this.RefreshFrame(e.Frame);    &#125;&#125;/// &lt;summary&gt;/// 响应Label刷新信息。/// &lt;/summary&gt;/// &lt;param name=&quot;sender&quot;&gt;&lt;/param&gt;/// &lt;param name=&quot;e&quot;&gt;&lt;/param&gt;private void OnCompleted(object sender, CompletedEventArgs e)&#123;    // 判断是否需要跨线程调用    CompletedDelegate fresh = this.RefreshStatus;    string message = &quot;视频结束，共 &quot; + e.FrameCount + &quot; 帧。&quot;;    this.BeginInvoke(fresh, message);&#125;　　        关闭时需要中止播放线程之后再退出：/// &lt;summary&gt;/// 关闭窗体时发生。/// &lt;/summary&gt;/// &lt;param name=&quot;sender&quot;&gt;&lt;/param&gt;/// &lt;param name=&quot;e&quot;&gt;&lt;/param&gt;private void OnFormClosed(object sender, FormClosedEventArgs e)&#123;    // 检测子算法请求终止    surveillant.Cancel();    // 阻塞调用线程直到检测子线程终止    if (threadSurveillance != null)    &#123;        if (threadSurveillance.IsAlive == true)        &#123;            threadSurveillance.Join();        &#125;    &#125;&#125;\n\n\n\n        （二）   使用异步委托\n        创建线程的一个更简单的方法是定义一个委托，并异步调用它。委托是方法的类型安全的引用。Delegate类还支持异步地调用方法。在后台，Delegate类会创建一个执行任务的线程。\n// asynchronous by using a delegatePlayVideoDelegate play = this.PlayVideoFile;IAsyncResult status = play.BeginInvoke(null, null); /// &lt;summary&gt;/// 播放视频文件。/// &lt;/summary&gt;private void PlayVideoFile()&#123;    while (true)    &#123;        Image&lt;Bgr, byte&gt; frame = capture.QueryFrame();        if (frame != null)        &#123;            Image&lt;Gray, byte&gt; grayFrame = frame.Convert&lt;Gray, byte&gt;();            grayFrame.Resize(this.width, this.height, INTER.CV_INTER_CUBIC);            RefreshPictureBoxDelegate fresh = this.RefreshPictureBox;            try            &#123;                this.BeginInvoke(fresh, grayFrame.ToBitmap());            &#125;            catch (ObjectDisposedException ex)            &#123;                Thread.CurrentThread.Abort();            &#125;        &#125;        else        &#123;            break;        &#125;    &#125;&#125; /// &lt;summary&gt;/// 刷新UI线程的pixtureBox的方法。/// &lt;/summary&gt;/// &lt;param name=&quot;frame&quot;&gt;要刷新的帧。&lt;/param&gt;private void RefreshPictureBox(Bitmap frame)&#123;    this.pictureBox.Image = frame;&#125;\n\n\n\n        （三）   使用BackgroundWorker组件\n        BackgroundWorker类是异步事件的一种实现方案，异步组件可以选择性的支持取消操作，并提供进度信息。RunWorkerAsync()方法启动异步调用。CancelAsync()方法取消。\n\n图3.BackgroundWorker组件\n/// &lt;summary&gt;/// 播放视频文件。/// &lt;/summary&gt;/// &lt;param name=&quot;sender&quot;&gt;&lt;/param&gt;/// &lt;param name=&quot;e&quot;&gt;&lt;/param&gt;private void detectItemPlay_Click(object sender, EventArgs e)&#123;    if (this.videoFilePath != null)    &#123;        // run async        this.backgroundWorker.RunWorkerAsync(capture);    &#125;&#125; /// &lt;summary&gt;/// 异步调用。/// &lt;/summary&gt;/// &lt;param name=&quot;sender&quot;&gt;&lt;/param&gt;/// &lt;param name=&quot;e&quot;&gt;&lt;/param&gt;private void OnDoWork(object sender, DoWorkEventArgs e)&#123;    Emgu.CV.Capture capture = e.Argument as Emgu.CV.Capture;    while (!e.Cancel)    &#123;        Image&lt;Bgr, byte&gt; frame = capture.QueryFrame();        if (frame != null)        &#123;            Image&lt;Gray, byte&gt; grayFrame = frame.Convert&lt;Gray, byte&gt;();            grayFrame.Resize(this.width, this.height, INTER.CV_INTER_CUBIC);            if (this.backgroundWorker.CancellationPending == true)            &#123;                e.Cancel = true;                break;            &#125;            else            &#123;                if (this.pictureBox.InvokeRequired == true)                &#123;                    RefreshPictureBoxDelegate fresh = this.RefreshPictureBox;                    this.BeginInvoke(fresh, grayFrame.ToBitmap());                &#125;                else                &#123;                    this.RefreshPictureBox(grayFrame.ToBitmap());                &#125;            &#125;        &#125;        else        &#123;            break;        &#125;    &#125;&#125; /// &lt;summary&gt;/// 关闭窗体时发生。/// &lt;/summary&gt;/// &lt;param name=&quot;sender&quot;&gt;&lt;/param&gt;/// &lt;param name=&quot;e&quot;&gt;&lt;/param&gt;private void MainForm_FormClosed(object sender, FormClosedEventArgs e)&#123;    if (this.backgroundWorker.IsBusy)    &#123;        this.backgroundWorker.CancelAsync();    &#125;&#125;\n\n","categories":["编程技术","DotNet"],"tags":["EmguCV"]},{"title":"C#时间戳","url":"/2020/04/28/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/C#%E6%97%B6%E9%97%B4%E6%88%B3/","content":"\n来源：https://blog.guoqianfan.com/2019/11/24/timestamp-in-csharp/\n\n什么是时间戳\n时间戳默认是Unix时间戳。\n\n首先要清楚JavaScript与Unix的时间戳的区别：\nJavaScript时间戳：是指格林威治时间1970年01月01日00时00分00秒(北京时间1970年01月01日08时00分00秒)起至现在的总毫秒数。\nUnix时间戳：是指格林威治时间1970年01月01日00时00分00秒(北京时间1970年01月01日08时00分00秒)起至现在的总秒数。\n可以看出JavaScript时间戳是总毫秒数，Unix时间戳是总秒数。\n比如同样是的 2016&#x2F;11&#x2F;03 12:30:00 ，转换为JavaScript时间戳为 1478147400000；转换为Unix时间戳为 1478147400。\n从上面也可以看出时间戳与时区无关。\nUnix时间戳相互转换C# DateTime转换为Unix时间戳.NET 4.6新方法只能在 .NET 4.6及更高版本里才能使用。\nlong timeStamp = DateTimeOffset.Now.ToUnixTimeSeconds(); Console.WriteLine(timeStamp);\n\n通用的老方法System.DateTime startTime = TimeZone.CurrentTimeZone.ToLocalTime(new System.DateTime(1970, 1, 1)); long timeStamp = (long)(DateTime.Now - startTime).TotalSeconds; System.Console.WriteLine(timeStamp);\n\nUnix时间戳转换为C# DateTime.NET 4.6新方法由时间戳转换的DateTimeOffset的时区默认是+00:00，此时我们需要转为本地时区，否则后续使用可能会有问题。\n转为本地时区：DateTimeOffset.LocalDateTime。\n示例代码如下：\nDateTimeOffset dto = DateTimeOffset.FromUnixTimeMilliseconds(1573696406184);DateTime dt01 = dto.DateTime;DateTime dt02 = dto.LocalDateTime;\n\n通用的老方法long unixTimeStamp = 1478162177;System.DateTime startTime = TimeZone.CurrentTimeZone.ToLocalTime(new System.DateTime(1970, 1, 1)); DateTime dt = startTime.AddSeconds(unixTimeStamp);System.Console.WriteLine(dt.ToString(&quot;yyyy/MM/dd HH:mm:ss:ffff&quot;));\n\n备注DateTimeOffset使用Now还是UtcNow对于DateTimeOffset，发现有2个获取当前时间的属性：DateTimeOffset.Now和DateTimeOffset.UtcNow。\n如果只是获取时间戳，这2个使用哪个都可以，得到的值是一样的。\n因为DateTimeOffset里面有时区信息，获取时间戳时会使用时区进行转换的，所以获得的时间戳一样。\n而也是因为时区的原因，DateTimeOffset的其他操作可能会不一样。例如DateTimeOffset.DateTime就不一样，此时推荐使用DateTimeOffset.LocalDateTime来获得本地时区的时间。\n测试代码如下：\nConsole.WriteLine(&quot;none：&#123;0&#125;&quot;, DateTimeOffset.Now);Console.WriteLine(&quot;utc：&#123;0&#125;&quot;, DateTimeOffset.UtcNow);Console.WriteLine(&quot;none：&#123;0&#125;&quot;, DateTimeOffset.Now.ToUnixTimeSeconds());Console.WriteLine(&quot;utc：&#123;0&#125;&quot;, DateTimeOffset.UtcNow.ToUnixTimeSeconds());\n\nDateTime转换为DateTimeOffset可以直接把DateTime赋值给DateTimeOffset，内部会自动进行隐式转换。这里涉及到时区，请往下看。\nDateTime的时区信息(Kind属性)DateTime的时区信息存放在Kind属性里。Kind属性的数据类型是DateTimeKind枚举，只有3个值：\n\nUnspecified：未指定&#x2F;未规定\nUtc：UTC时间\nLocal：本地时区\n\n不同情况下得到的DateTime的Kind是不同的，具体如下：\n\nDateTime.Now：DateTime.Kind是 **Local(本地时区)**。\n\nDateTime.UtcNow：DateTime.Kind是 **Utc**。\n\nDateTime.Parse()：\n\n【默认】在未指定时区时，DateTime.Kind是 Unspecified\n\n指定时区：指定时区后DateTime.Kind就是相对应的值。\n指定时区有2种方式：\n\n【默认+优先】待转换的字符串里有时区信息。例如：2019/11/24 17:40:32 +08:00\n使用DateTimeStyles参数来指定时区。DateTimeStyles是枚举类型，更多信息自己查看定义，这里不再多说。\n\n\n\n\n\nLocal和Utc都会把相应的时区传递过去。对于 Unspecified(未指定)，会被当做本地时区来处理（结果已验证，源码没看懂）。\n测试代码DateTime dtNow = DateTime.Now;DateTime dtUtcNow = DateTime.UtcNow;DateTime dtParse = DateTime.Parse(&quot;2019-11-24 17:40:13&quot;);DateTimeOffset dtoNow = dtNow;DateTimeOffset dtoUtcNow = dtUtcNow;DateTimeOffset dtoParse = dtParse;Console.WriteLine(&quot;DateTime：&quot;);Console.WriteLine(&quot;dtNow：&#123;0&#125;(Kind：&#123;1&#125;)&quot;, dtNow, dtNow.Kind);Console.WriteLine(&quot;dtUtcNow：&#123;0&#125;(Kind：&#123;1&#125;)&quot;, dtUtcNow, dtUtcNow.Kind);Console.WriteLine(&quot;dtParse：&#123;0&#125;(Kind：&#123;1&#125;)&quot;, dtParse, dtParse.Kind);Console.WriteLine();Console.WriteLine(&quot;DateTimeOffset：&quot;);Console.WriteLine(&quot;dtoNow：&#123;0&#125;&quot;, dtoNow);Console.WriteLine(&quot;dtoUtcNow：&#123;0&#125;&quot;, dtoUtcNow);Console.WriteLine(&quot;dtoParse：&#123;0&#125;&quot;, dtoParse);\n\n输出结果如下：\nDateTime：dtNow：2019/11/24 17:40:32(Kind：Local)dtUtcNow：2019/11/24 9:40:32(Kind：Utc)dtParse：2019/11/24 17:40:13(Kind：Unspecified)DateTimeOffset：dtoNow：2019/11/24 17:40:32 +08:00dtoUtcNow：2019/11/24 9:40:32 +00:00dtoParse：2019/11/24 17:40:13 +08:00\n\nDateTimeOffset.Parse的默认时区DateTimeOffset.Parse的默认时区是当前时区。\nConsole.WriteLine(&quot;parse：&#123;0&#125;&quot;, DateTimeOffset.Parse(&quot;2019-6-14 15:38:49&quot;));\n\n参考\nC# DateTime与时间戳转换：https://www.cnblogs.com/polk6/p/6024892.html\n如何将Unix时间戳转换为DateTime，反之亦然？：https://stackoverflow.com/questions/249760/how-can-i-convert-a-unix-timestamp-to-datetime-and-vice-versa\nDateTimeOffset源码：https://source.dot.net/#System.Private.CoreLib/DateTimeOffset.cs\n\n","categories":["编程技术","DotNet"]},{"title":"DotNET中定时器的使用方法","url":"/2015/04/01/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/DotNET%E4%B8%AD%E5%AE%9A%E6%97%B6%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/","content":".NET 中定时器的使用方法在.NET 开发中，定时器是实现周期性任务的核心组件。根据是否依赖 UI 线程，可将其分为 “与 UI 无关联” 和 “与 UI 相关” 两大类，不同类型的定时器适用场景、线程模型及使用方式差异显著。本文将详细讲解各类定时器的特点、核心属性、正确用法及注意事项。\n一、与 UI 无关联的定时器此类定时器运行于非 UI 线程（默认使用线程池），适用于后台计算、数据同步等无需操作 UI 的场景，时间精度相对较高。\n1. System.Timers.Timer核心特点\n支持线程同步配置，可通过SynchronizingObject指定执行线程；\n\n事件驱动模式（通过Elapsed事件触发任务）；\n\n适用于对执行精度有一定要求的后台任务。\n\n\n关键属性修正\nAutoReset：原始描述颠倒，正确逻辑为：\n\ntrue（默认）：定时器触发后自动重置，持续周期性执行；\n\nfalse：定时器仅触发一次，执行后自动停止。\n\n\n\nSynchronizingObject：默认值为null，任务运行于线程池（CPU 自动分配线程）；若指定为 UI 控件（如 WinForms 的 Form），则任务会切换到 UI 线程执行。\n\nInterval：任务执行间隔（单位：毫秒），最小值为 1。\n\nEnabled：控制定时器是否启用（true启用，false禁用）。\n\n\n正确代码示例using System;using System.Threading;public class TimersTimerExample&#123;   // 声明定时器与线程同步锁（确保多线程安全）   private readonly System.Timers.Timer \\_timer = new System.Timers.Timer();   private readonly object \\_syncRoot = new object();   public TimersTimerExample()   &#123;       // 绑定Elapsed事件（任务执行逻辑）       \\_timer.Elapsed += OnTimerTick;       // 设置执行间隔为100毫秒       \\_timer.Interval = 100;       // 配置为持续执行（AutoReset=true）       \\_timer.AutoReset = true;       // 初始禁用，需手动启动       \\_timer.Enabled = false;   &#125;   // 启动定时器   public void StartTimer()   &#123;       \\_timer.Enabled = true;       // 或使用\\_timer.Start()（与Enabled=true等效）   &#125;   // 停止定时器   public void StopTimer()   &#123;       \\_timer.Enabled = false;       // 或使用\\_timer.Stop()   &#125;   // Elapsed事件回调（默认运行于线程池）   private void OnTimerTick(object sender, System.Timers.ElapsedEventArgs e)   &#123;       // 加锁确保多线程下任务逻辑安全（避免并发问题）       lock (\\_syncRoot)       &#123;           Console.WriteLine(\\$&quot;后台任务执行：&#123;DateTime.Now:HH:mm:ss.fff&#125;&quot;);           // TODO：添加实际业务逻辑（如数据同步、日志记录）       &#125;   &#125;&#125;\n\n注意事项\n若任务逻辑涉及共享资源，需通过lock等方式保证线程安全；\n\n若需在 UI 线程更新内容，需将SynchronizingObject指定为 UI 控件（如_timer.SynchronizingObject = this，需在 WinForms 环境中）。\n\n\n2. System.Threading.Timer核心特点\n轻量级定时器，完全基于线程池实现；\n\n无事件模型，通过回调函数（TimerCallback）执行任务；\n\n不支持直接指定同步对象，需手动处理线程切换。\n\n\n关键参数构造函数System.Threading.Timer(TimerCallback callback, object state, int dueTime, int period)参数说明：\n\ncallback：定时器触发时执行的回调函数；\n\nstate：传递给回调函数的参数（无需参数时设为null）；\n\ndueTime：定时器启动延迟时间（单位：毫秒），0表示立即启动；\n\nperiod：任务执行间隔（单位：毫秒），Timeout.Infinite表示仅执行一次。\n\n\n正确代码示例using System;using System.Threading;public class ThreadingTimerExample&#123;   // 声明线程定时器（需注意释放资源）   private System.Threading.Timer \\_timer;   public ThreadingTimerExample()   &#123;       // 初始化定时器：立即启动（dueTime=0），间隔1000毫秒执行一次       \\_timer = new System.Threading.Timer(           callback: TimerCallback,           state: null,           dueTime: 0,           period: 1000       );   &#125;   // 定时器回调函数（运行于线程池）   private void TimerCallback(object state)   &#123;       Console.WriteLine(\\$&quot;轻量级后台任务：&#123;DateTime.Now:HH:mm:ss&#125;&quot;);       // TODO：添加轻量级业务逻辑（如心跳检测、缓存清理）   &#125;   // 释放定时器资源（避免内存泄漏）   public void DisposeTimer()   &#123;       \\_timer?.Change(Timeout.Infinite, Timeout.Infinite); // 先停止定时器       \\_timer?.Dispose(); // 释放资源   &#125;&#125;\n\n注意事项\n若任务执行时间超过period，线程池会分配新线程执行下一次任务，需自行控制并发；\n\n不再使用时必须调用Dispose释放资源，避免线程泄漏；\n\n无法直接更新 UI，需通过Dispatcher（WPF）或Invoke（WinForms）切换到 UI 线程。\n\n\n二、与 UI 相关的定时器此类定时器绑定 UI 线程，适用于 WinForms、WPF 等桌面应用的 UI 更新场景，无需手动处理线程安全，但时间精度较低（受 UI 线程繁忙程度影响）。\n1. System.Windows.Forms.Timer（WinForms 专用）核心特点\n仅适用于 WinForms 应用，支持可视化拖拽（从工具箱拖到 Form 上）；\n\n任务运行于 UI 线程，可直接更新 UI 控件（如 Label、TextBox）；\n\n精度较低（约 10-55 毫秒），不适用于高时效任务。\n\n\n关键属性\nInterval：执行间隔（单位：毫秒），最小值为 1；\n\nEnabled：控制定时器启用 &#x2F; 禁用（true启用，false禁用）；\n\nTick：定时器触发时执行的事件（运行于 UI 线程）。\n\n\n正确代码示例using System;using System.Windows.Forms;public partial class TimerForm : Form&#123;   // 声明WinForms定时器（可通过设计器拖拽生成）   private readonly System.Windows.Forms.Timer \\_uiTimer;   public TimerForm()   &#123;       InitializeComponent();       // 初始化定时器（代码方式，非拖拽）       \\_uiTimer = new System.Windows.Forms.Timer();       \\_uiTimer.Interval = 1000; // 1秒更新一次UI       \\_uiTimer.Tick += UITimer\\_Tick;       \\_uiTimer.Enabled = true; // 启用定时器   &#125;   // Tick事件（运行于UI线程，可直接操作控件）   private void UITimer\\_Tick(object sender, EventArgs e)   &#123;       // 直接更新Label文本（无需线程同步）       lblTime.Text = \\$&quot;当前时间：&#123;DateTime.Now:HH:mm:ss&#125;&quot;;   &#125;   // 关闭窗体时释放定时器   private void TimerForm\\_FormClosing(object sender, FormClosingEventArgs e)   &#123;       \\_uiTimer?.Dispose();   &#125;&#125;\n\n注意事项\n仅能在 WinForms 项目中使用，无法跨框架（如 WPF）；\n\n若Tick事件中执行耗时操作（如循环计算），会导致 UI 卡顿；\n\n无需手动处理线程安全，因事件始终在 UI 线程执行。\n\n\n2. System.Windows.DispatcherTimer（WPF 专用）核心特点\n仅适用于 WPF 应用，基于Dispatcher（WPF 线程调度器）实现；\n\n任务运行于 UI 线程，支持直接更新 WPF 控件（如 TextBlock）；\n\n可通过DispatcherPriority调整任务优先级（默认Normal）。\n\n\n关键属性与方法\nInterval：执行间隔（类型：TimeSpan，支持秒、毫秒等单位）；\n\nTick：定时器触发事件（运行于 UI 线程）；\n\n**Start()&#x2F;Stop()**：启动 &#x2F; 停止定时器（替代Enabled属性）；\n\nDispatcherPriority：任务在 UI 线程中的执行优先级（如Background表示后台优先级，不阻塞 UI）。\n\n\n正确代码示例using System;using System.Windows;using System.Windows.Threading;public partial class MainWindow : Window&#123;   // 声明WPF调度定时器   private readonly DispatcherTimer \\_dispatcherTimer;   public MainWindow()   &#123;       InitializeComponent();       // 初始化定时器       \\_dispatcherTimer = new DispatcherTimer();       // 设置间隔为1秒（使用TimeSpan）       \\_dispatcherTimer.Interval = TimeSpan.FromSeconds(1);       // 绑定Tick事件       \\_dispatcherTimer.Tick += DispatcherTimer\\_Tick;       // 启动定时器       \\_dispatcherTimer.Start();   &#125;   // Tick事件（运行于UI线程，可直接更新WPF控件）   private void DispatcherTimer\\_Tick(object sender, EventArgs e)   &#123;       // 直接更新TextBlock内容       tbTime.Text = \\$&quot;当前时间：&#123;DateTime.Now:HH:mm:ss.fff&#125;&quot;;   &#125;   // 关闭窗口时停止定时器   private void MainWindow\\_Closing(object sender, System.ComponentModel.CancelEventArgs e)   &#123;       \\_dispatcherTimer?.Stop();   &#125;&#125;\n\n注意事项\n仅能在 WPF 项目中使用，依赖System.Windows程序集；\n\n若需降低任务对 UI 的影响，可设置_dispatcherTimer.DispatcherPriority = DispatcherPriority.Background；\n\n若任务耗时较长，仍会导致 UI 响应缓慢，需结合Task开启后台线程处理（处理完后通过Dispatcher.Invoke更新 UI）。\n\n\n三、定时器选择指南\n\n\n定时器类型\n适用框架\n线程模型\n精度\n核心场景\n\n\n\nSystem.Timers.Timer\n通用（非 UI）\n线程池（可指定同步对象）\n较高\n后台任务、数据同步\n\n\nSystem.Threading.Timer\n通用（非 UI）\n线程池\n高\n轻量级后台任务（如心跳检测）\n\n\nSystem.Windows.Forms.Timer\nWinForms\nUI 线程\n较低\nWinForms UI 更新\n\n\nSystem.Windows.DispatcherTimer\nWPF\nUI 线程\n较低\nWPF UI 更新\n\n\n总结：需根据项目框架（WinForms&#x2F;WPF&#x2F; 控制台）、是否操作 UI、精度要求三大因素选择定时器，避免因线程模型不匹配导致 UI 卡顿或数据安全问题。\n\n（注：文档部分内容可能由 AI 生成）\n\n","categories":["编程技术","DotNet"],"tags":["定时器"]},{"title":".NET 6.0使用Identity实现JWT身份认证与授权","url":"/2024/08/21/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/NET-6-0%E4%BD%BF%E7%94%A8Identity%E5%AE%9E%E7%8E%B0JWT%E8%BA%AB%E4%BB%BD%E8%AE%A4%E8%AF%81%E4%B8%8E%E6%8E%88%E6%9D%83/","content":"使用 Visual Studio 2022 创建 ASP.NET Core Web API可以从 Visual Studio 2022 中选择 ASP.NET Core Web API 或 ASP.NET Core gRPC模板\n安装依赖库,可以使用NuGet安装或使用DotNet CLI\ndotnet add package Microsoft.EntityFrameworkCore.SqlServer --version 6.0.33dotnet add package Microsoft.EntityFrameworkCore.Tools --version 6.0.33dotnet add package Microsoft.AspNetCore.Identity.EntityFrameworkCore --version 6.0.33dotnet add package Microsoft.AspNetCore.Authentication.JwtBearer --version 6.0.33\n\n在appsettings.json中添加配置\n&#123;    &quot;Logging&quot;: &#123;        &quot;LogLevel&quot;: &#123;            &quot;Default&quot;: &quot;Information&quot;,            &quot;Microsoft.AspNetCore&quot;: &quot;Warning&quot;        &#125;    &#125;,    &quot;AllowedHosts&quot;: &quot;*&quot;,    &quot;Database&quot;: &#123;        &quot;Driver&quot;: &quot;SqlServer&quot;,        &quot;Host&quot;: &quot;127.0.0.1&quot;,        &quot;Port&quot;: 6543,        &quot;DbName&quot;: &quot;SAMPLE&quot;,        &quot;User&quot;: &quot;postgres&quot;,        &quot;Password&quot;: &quot;postgres&quot;    &#125;,    &quot;Jwt&quot;: &#123;        &quot;Audience&quot;: &quot;&quot;,        &quot;Issuer&quot;: &quot;&quot;,        &quot;Secret&quot;: &quot;&quot;    &#125;&#125;\n\n准备Model\nusing Microsoft.AspNetCore.Identity;namespace Samples.Identity.Modelpublic class Role : IdentityRole&lt;int&gt;&#123;&#125;public class RoleClaim : IdentityRoleClaim&lt;int&gt;&#123;&#125;public class User : IdentityUser&lt;int&gt;&#123;&#125;public class UserClaim : IdentityUserClaim&lt;int&gt;&#123;&#125;public class UserLogin : IdentityUserLogin&lt;int&gt;&#123;&#125;public class UserRole : IdentityUserRole&lt;int&gt;&#123;&#125;public class UserToken : IdentityUserToken&lt;int&gt;&#123;&#125;\n\nFluent API重定义数据库表名，字段\nusing Sample.Identity.Model;using Microsoft.EntityFrameworkCore;using Microsoft.EntityFrameworkCore.Metadata.Builders;namespace Samples.Identity.Configurations;public class RoleClaimConfiguration : IEntityTypeConfiguration&lt;RoleClaim&gt;&#123;    public void Configure(EntityTypeBuilder&lt;RoleClaim&gt; builder)    &#123;        builder.ToTable(&quot;SYS_ROLE_CLAIM&quot;).HasKey(x =&gt; x.Id);        builder.Property(x =&gt; x.Id).HasColumnName(&quot;ID&quot;).ValueGeneratedOnAdd();        builder.Property(x =&gt; x.RoleId).HasColumnName(&quot;ROLE_ID&quot;);        builder.Property(x =&gt; x.ClaimType).HasColumnName(&quot;CLAIM_TYPE&quot;).HasMaxLength(50);        builder.Property(x =&gt; x.ClaimType).HasColumnName(&quot;CLAIM_VALUE&quot;).HasMaxLength(50);    &#125;&#125;public class RoleConfiguration : IEntityTypeConfiguration&lt;Role&gt;&#123;    public void Configure(EntityTypeBuilder&lt;Role&gt; builder)    &#123;        builder.ToTable(&quot;SYS_ROLE&quot;).HasKey(x =&gt; x.Id);        builder.Property(x =&gt; x.Id).HasColumnName(&quot;ID&quot;).ValueGeneratedOnAdd();        builder.Property(x =&gt; x.Name).HasColumnName(&quot;NAME&quot;).HasMaxLength(50);        builder.Property(x =&gt; x.NormalizedName).HasColumnName(&quot;NORMALIZED_NAME&quot;).HasMaxLength(50);        builder.Property(x =&gt; x.ConcurrencyStamp).HasColumnName(&quot;CONCURRENCY_STAMP&quot;).HasMaxLength(50);        builder.HasData(new Role &#123; Id = 1, Name = &quot;SuperAdmin&quot;, NormalizedName = &quot;超级管理员&quot; &#125;);        builder.HasData(new Role &#123; Id = 2, Name = &quot;Admin&quot;, NormalizedName = &quot;管理员&quot; &#125;);        builder.HasData(new Role &#123; Id = 3, Name = &quot;Operator&quot;, NormalizedName = &quot;操作员&quot; &#125;);    &#125;&#125;public class UserClaimConfiguration : IEntityTypeConfiguration&lt;UserClaim&gt;&#123;    public void Configure(EntityTypeBuilder&lt;UserClaim&gt; builder)    &#123;        builder.ToTable(&quot;SYS_USER_CLAIM&quot;).HasKey(x =&gt; x.Id);        builder.Property(x =&gt; x.Id).HasColumnName(&quot;ID&quot;).ValueGeneratedOnAdd();        builder.Property(x =&gt; x.UserId).HasColumnName(&quot;USER_ID&quot;);        builder.Property(x =&gt; x.ClaimType).HasColumnName(&quot;CLAIM_TYPE&quot;).HasMaxLength(50);        builder.Property(x =&gt; x.ClaimValue).HasColumnName(&quot;CLAIM_VALUE&quot;).HasMaxLength(50);    &#125;&#125;public class UserConfiguration : IEntityTypeConfiguration&lt;User&gt;&#123;    public void Configure(EntityTypeBuilder&lt;User&gt; builder)    &#123;        builder.ToTable(&quot;SYS_USER&quot;).HasKey(x =&gt; x.Id);        builder.Property(x =&gt; x.Id).HasColumnName(&quot;ID&quot;).ValueGeneratedOnAdd();        builder.Property(x =&gt; x.UserName).HasColumnName(&quot;USERNAME&quot;).HasMaxLength(20);        builder.Property(x =&gt; x.NormalizedUserName).HasColumnName(&quot;NORMALIZED_USERNAME&quot;).HasMaxLength(20);        builder.Property(x =&gt; x.Email).HasColumnName(&quot;EMAIL&quot;).HasMaxLength(50);        builder.Property(x =&gt; x.NormalizedEmail).HasColumnName(&quot;NORMALIZED_EMAIL&quot;).HasMaxLength(50);        builder.Property(x =&gt; x.EmailConfirmed).HasColumnName(&quot;EMAIL_CONFIRMED&quot;);        builder.Property(x =&gt; x.PasswordHash).HasColumnName(&quot;PASSWORD_HASH&quot;).HasMaxLength(256);        builder.Property(x =&gt; x.SecurityStamp).HasColumnName(&quot;SECURITY_STAMP&quot;).HasMaxLength(256);        builder.Property(x =&gt; x.ConcurrencyStamp).HasColumnName(&quot;CONCURRENCY_STAMP&quot;).HasMaxLength(256);        builder.Property(x =&gt; x.PhoneNumber).HasColumnName(&quot;PHONE_NUMBER&quot;).HasMaxLength(15);        builder.Property(x =&gt; x.PhoneNumberConfirmed).HasColumnName(&quot;PHONE_NUMBER_CONFIRMED&quot;);        builder.Property(x =&gt; x.TwoFactorEnabled).HasColumnName(&quot;TWO_FACTOR_ENABLED&quot;);        builder.Property(x =&gt; x.LockoutEnd).HasColumnName(&quot;LOCKOUT_END&quot;);        builder.Property(x =&gt; x.LockoutEnabled).HasColumnName(&quot;LOCKOUT_ENABLED&quot;);        builder.Property(x =&gt; x.AccessFailedCount).HasColumnName(&quot;ACCESS_FAILED_COUNT&quot;);        builder.HasData(new User        &#123;            Id = 1,            UserName = &quot;admin&quot;,            NormalizedUserName = &quot;ADMIN&quot;,            PasswordHash = &quot;AQAAAAEAACcQAAAAELR93lThWhjLUaJtEMPGJXUR88rGK9RjjZytUhr0Jfy3J7JaObJCZAcu5MhPl39erg==&quot;,            SecurityStamp = &quot;LA4OVIYIUDB7CB44WR4CTS6FCY4VRWSO&quot;,        &#125;);    &#125;&#125;public class UserLoginConfiguration : IEntityTypeConfiguration&lt;UserLogin&gt;&#123;    public void Configure(EntityTypeBuilder&lt;UserLogin&gt; builder)    &#123;        builder.ToTable(&quot;SYS_USER_LOGIN&quot;);        builder.Property(x =&gt; x.LoginProvider).HasColumnName(&quot;LOGIN_PROVIDER&quot;).HasMaxLength(20);        builder.Property(x =&gt; x.ProviderKey).HasColumnName(&quot;PROVIDER_KEY&quot;).HasMaxLength(20);        builder.Property(x =&gt; x.ProviderDisplayName).HasColumnName(&quot;PROVIDER_DISPLAY_NAME&quot;).HasMaxLength(20);        builder.Property(x =&gt; x.UserId).HasColumnName(&quot;USER_ID&quot;);    &#125;&#125;public class UserRoleConfiguration : IEntityTypeConfiguration&lt;UserRole&gt;&#123;    public void Configure(EntityTypeBuilder&lt;UserRole&gt; builder)    &#123;        builder.ToTable(&quot;SYS_USER_ROLE&quot;);        builder.Property(x =&gt; x.UserId).HasColumnName(&quot;USER_ID&quot;);        builder.Property(x =&gt; x.RoleId).HasColumnName(&quot;ROLE_ID&quot;);    &#125;&#125;public class UserTokenConfiguration : IEntityTypeConfiguration&lt;UserToken&gt;&#123;    public void Configure(EntityTypeBuilder&lt;UserToken&gt; builder)    &#123;        builder.ToTable(&quot;SYS_USER_TOKEN&quot;);        builder.Property(x =&gt; x.UserId).HasColumnName(&quot;USER_ID&quot;);        builder.Property(x =&gt; x.LoginProvider).HasColumnName(&quot;LOGIN_PROVIDER&quot;).HasMaxLength(20);        builder.Property(x =&gt; x.Name).HasColumnName(&quot;NAME&quot;).HasMaxLength(50);        builder.Property(x =&gt; x.Value).HasColumnName(&quot;VALUE&quot;).HasMaxLength(256);    &#125;&#125;\n\n\n\n新建DataContext\nusing Microsoft.AspNetCore.Identity.EntityFrameworkCore;using Microsoft.AspNetCore.Identity;using Microsoft.EntityFrameworkCore;namespace Samples.Identity;public class DataContext: IdentityDbContext&lt;User&gt;&#123;    public DataContext(DbContextOptions&lt;DataContext&gt; options)        : base(options)    &#123;                &#125;        protected override void OnModelCreating(ModelBuilder builder)    &#123;        base.OnModelCreating(builder);        builder.ApplyConfiguration(new UserConfiguration());        builder.ApplyConfiguration(new RoleConfiguration());        builder.ApplyConfiguration(new UserClaimConfiguration());        builder.ApplyConfiguration(new UserRoleConfiguration());        builder.ApplyConfiguration(new UserLoginConfiguration());        builder.ApplyConfiguration(new RoleClaimConfiguration());        builder.ApplyConfiguration(new UserTokenConfiguration());    &#125;&#125;\n\n添加ViewModel\nusing System.ComponentModel.DataAnnotations;namespace Sample.Identity.ViewModels;public class LoginViewModel&#123;    [Required(ErrorMessage = &quot;用户名不能为空&quot;)]    public string? Username &#123; get; set; &#125;        [Required(ErrorMessage = &quot;密码不能为空&quot;)]    public string? Password &#123; get; set; &#125;&#125;\n\n添加Controller\nusing Sample.Identity.ViewModels;using Microsoft.AspNetCore.Identity;using Microsoft.AspNetCore.Mvc;using Microsoft.AspNetCore.Tokens;using System.IdentityModel.Tokens.Jwt;using System.Security.Claims;using System.Text;namespace Sample.Identity.Controllers;[Route(&quot;api/[controller]&quot;)][ApiController]public class AuthenticateController : ControllerBase&#123;    private readonly UserManager&lt;User&gt; m_userManager;    private readonly RoleManager&lt;Role&gt; m_roleManager;    private readonly IConfiguration m_configuration;        private readonly JwtOption m_jwtOptions;        public AuthenticateController(UserManager&lt;User&gt; userManager,                                 RoleManager&lt;Role&gt; roleManager,                                 IConfiguration configuration)    &#123;    \tm_userManager = userManager;        m_roleManager = roleManager;        m_configuration = configuration;                m_jwtOptions = m_configuration.GetSection(&quot;&quot;).Get&lt;JwtOption&gt;();    &#125;        [HttpPost]    [Route(&quot;login&quot;)]    public async Task&lt;IActionResult&gt; Login([FromBody] LoginViewModel model)    &#123;        var user = await m_userManager.FindByNameAsync(model.Username);        if(user!=null &amp;&amp; await m_userManager.CheckPasswordAsync(user, model.Password))        &#123;            var roles = await m_userManager.GetRolesAsync(user);                        var claims = new List&lt;Claim&gt;            &#123;                new Claim(ClaimTypes.Name, user.Username);                new Claim(JwtRegisteredClaimNames.Jti, Guid.NewGuid().ToString())            &#125;                        foreach (var role in roles)            &#123;                claims.Add(new Claim(ClaimTypes.Role, role));            &#125;                        var token = GenerateToken(claims);                        return Ok(new &#123;               token = new JwtSecurityTokenHandler().WriteToken(token),                expiration = token.ValidTo            &#125;);        &#125;                return Unauthorized();    &#125;        private JwtSecurityToken GetToken(List&lt;Claim&gt; authClaims)    &#123;        var authSigningKey = new SymmetricSecurityKey(Encoding.UTF8.GetBytes(m_jwtOptions.Secret));        var token = new JwtSecurityToken(                issuer: _configuration[&quot;JWT:ValidIssuer&quot;],                audience: _configuration[&quot;JWT:ValidAudience&quot;],                expires: DateTime.Now.AddHours(3),                claims: authClaims,                signingCredentials: new SigningCredentials(authSigningKey, SecurityAlgorithms.HmacSha256)            );             return token;    &#125;&#125;\n\n修改Program中添加\nusing Sample.Identity;using Microsoft.AspNetCore.Authentication.JwtBearer;using Microsoft.AspNetCore.Identity;using Microsoft.EntityFrameworkCore;using Microsoft.IdentityModel.Tokens;using System.Text; var builder = WebApplication.CreateBuilder(args);ConfigurationManager configuration = builder.Configuration; // Add services to the container. // For Entity Frameworkbuilder.Services.AddDbContext&lt;ApplicationDbContext&gt;(options =&gt; options.UseSqlServer(configuration.GetConnectionString(&quot;ConnStr&quot;))); // For Identitybuilder.Services.AddIdentity&lt;User, Role&gt;() //optinos =&gt; &#123;//options.Password.RequireDigit = false;//options.Password.RequireLowercase = false;//options.Password.RequireUppercase = false;//options.Password.RequireNonAlphanumeric = false;//options.Password.RequiredLength = 8;//options.Password.RequiredUniqueChars = 1;//options.Lockout.DefaultLockoutTimeSpan = TimeSpan.FromMinutes(10);//options.Lockout.MaxFailedAccessAttempts = 5;//options.Lockout.AllowedForNewUsers = true;//&#125;    .AddEntityFrameworkStores&lt;DataContext&gt;()    .AddDefaultTokenProviders();  var jwtOptions = builder.Configuration.GetSection(&quot;JWT&quot;).Get&lt;JwtOption&gt;(); // Adding Authenticationbuilder.Services.AddAuthentication(options =&gt;&#123;    options.DefaultAuthenticateScheme = JwtBearerDefaults.AuthenticationScheme;    options.DefaultChallengeScheme = JwtBearerDefaults.AuthenticationScheme;    options.DefaultScheme = JwtBearerDefaults.AuthenticationScheme;&#125;) // Adding Jwt Bearer.AddJwtBearer(options =&gt;&#123;    options.SaveToken = true;    options.RequireHttpsMetadata = false;    options.TokenValidationParameters = new TokenValidationParameters()    &#123;        ValidateIssuer = true,        ValidateAudience = true,        ValidAudience = jwtOptions.Audience,        ValidIssuer = jwtOptions.Issuer,        IssuerSigningKey = new SymmetricSecurityKey(Encoding.UTF8.GetBytes(jwtOptions.Secret))    &#125;;&#125;); builder.Services.AddControllers();// Learn more about configuring Swagger/OpenAPI at https://aka.ms/aspnetcore/swashbucklebuilder.Services.AddEndpointsApiExplorer();builder.Services.AddSwaggerGen(); var app = builder.Build(); // Configure the HTTP request pipeline.if (app.Environment.IsDevelopment())&#123;    app.UseSwagger();    app.UseSwaggerUI();&#125; app.UseHttpsRedirection(); // Authentication &amp; Authorizationapp.UseAuthentication();app.UseAuthorization(); app.MapControllers(); app.Run();\n\n执行数据迁移\nadd-migration L0update-database\n\n","categories":["编程技术","DotNet"],"tags":["Identity","JWT"]},{"title":"Net作业调度(一) -Quartz.Net入门","url":"/2015/09/12/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/Net%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6(%E4%B8%80)%20-Quartz.Net%E5%85%A5%E9%97%A8/","content":"背景很多时候，项目需要在不同时刻，执行一个或很多个不同的作业。\nWindows执行计划这时并不能很好的满足需求了，迫切需要一个更为强大，方便管理，集群部署的作业调度框架。\n介绍Quartz 一个开源的作业调度框架，OpenSymphony的开源项目。Quartz.Net 是Quartz的C#移植版本。\n它一些很好的特性：\n1：支持集群，作业分组，作业远程管理。 \n2：自定义精细的时间触发器，使用简单，作业和触发分离。\n3：数据库支持，可以寄宿Windows服务，WebSite，winform等。\n实战Quartz框架的一些基础概念解释：\n 　　Scheduler     作业调度器。\n 　　IJob             作业接口，继承并实现Execute， 编写执行的具体作业逻辑。\n　　JobBuilder       根据设置，生成一个详细作业信息(JobDetail)。\n　　TriggerBuilder   根据规则，生产对应的Trigger\nNuget安装 \n PM&gt; Install-Package Quartz \n下面是简单使用例子，附带详细的注释：\nstatic void Main(string[] args)&#123; IScheduler scheduler = StdSchedulerFactory.GetDefaultScheduler(); scheduler.Start();  IJobDetail job1 = JobBuilder.Create&lt;HelloJob&gt;() .WithIdentity(&quot;作业名称&quot;, &quot;作业组&quot;) .Build(); ITrigger trigger1 = TriggerBuilder.Create() .WithIdentity(&quot;触发器名称&quot;, &quot;触发器组&quot;) .StartNow()  .WithSimpleSchedule(x =&gt; x  .WithIntervalInSeconds(5) .RepeatForever())  .Build(); scheduler.ScheduleJob(job1, trigger1);  IJobDetail job2= JobBuilder.Create&lt;DumbJob&gt;() .WithIdentity(&quot;myJob&quot;, &quot;group1&quot;) .UsingJobData(&quot;jobSays&quot;, &quot;Hello World!&quot;) .Build(); ITrigger trigger2 = TriggerBuilder.Create() .WithIdentity(&quot;mytrigger&quot;, &quot;group1&quot;) .StartNow() .WithCronSchedule(&quot;/5 * * ? * *&quot;)  .Build(); scheduler.ScheduleJob(job2, trigger2); &#125;\n\n声明要执行的作业，HelloJob：\n/// &lt;summary&gt;/// 作业/// &lt;/summary&gt;public class HelloJob : IJob&#123; public void Execute(IJobExecutionContext context) &#123; Console.WriteLine(&quot;作业执行!&quot;); &#125;&#125;\n\n声明要执行的作业，DumbJob：\npublic class DumbJob : IJob\n &#123;\n /// &lt;summary&gt;\n ///  context 可以获取当前Job的各种状态。\n /// &lt;/summary&gt;\n /// &lt;param name=&quot;context&quot;&gt;&lt;/param&gt;\n public void Execute(IJobExecutionContext context)\n &#123;\n JobDataMap dataMap = context.JobDetail.JobDataMap;\n string content = dataMap.GetString(``&quot;jobSays&quot;``);\n Console.WriteLine(``&quot;作业执行，jobSays:&quot; + content);\n &#125;\n &#125;\n其WithCronSchedule(“”) 拥有强大的Cron时间表达式，正常情况下_WithSimpleSchedule(x)_ 已经满足大部分对日期设置的要求了。\nQuartz.Net官方2.X教程  http://www.quartz-scheduler.net/documentation/quartz-2.x/tutorial/index.html\nQuartz.Net开源地址   https://github.com/quartznet/quartznet\n","categories":["编程技术","DotNet"],"tags":["Quartz.NET"]},{"title":"Net作业调度(三) — Quartz.Net进阶","url":"/2015/09/26/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/Net%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6(%E4%B8%89)%20%E2%80%94%20Quartz.Net%E8%BF%9B%E9%98%B6/","content":"介绍前面介绍Quartz.Net的基本用法，但在实际应用中，往往有更多的特性需求，比如记录job执行的执行历史，发邮件等。\n阅读目录\nQuartz.Net插件\nTriggerListener,JobListener\nCron表达式\nQuartz.Net线程池\n总结\n\nQuartz.Net插件     Quartz.net 自身提供了一个插件接口(ISchedulerPlugin)用来增加附加功能，看下官方定义：\n1\n2\n3\n4\n5\n6\n7\n8\npublic interface ISchedulerPlugin\n &#123;\n void Initialize(``string pluginName, IScheduler sched);\n void Shutdown();\n void Start();\n &#125;\n　继承接口，实现自己的插件。\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\npublic class MyPlugin : ISchedulerPlugin\n &#123;\n public void  Initialize(``string pluginName, IScheduler sched)\n &#123;\n Console.WriteLine(``&quot;实例化&quot;``);\n &#125;\n public  void Start()\n &#123;\n Console.WriteLine(``&quot;启动&quot;``);\n &#125;\n public  void Shutdown()\n &#123;\n Console.WriteLine(``&quot;关闭&quot;``);\n &#125;\n &#125;\n　　主函数里面配置要实现的插件，注释部分，一句话搞定。\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\nstatic void Main(``string``[] args)\n &#123;\n var properties = new NameValueCollection();\n properties[``&quot;quartz.plugin.MyPlugin.type&quot;``] = &quot;QuartzDemo3.MyPlugin,QuartzDemo3&quot;``;\n var schedulerFactory = new StdSchedulerFactory(properties);\n var scheduler = schedulerFactory.GetScheduler();\n var job = JobBuilder.Create&lt;HelloJob&gt;()\n .WithIdentity(``&quot;myJob&quot;``, &quot;group1&quot;``)\n .Build();\n var trigger = TriggerBuilder.Create()\n .WithIdentity(``&quot;mytrigger&quot;``, &quot;group1&quot;``)\n .WithCronSchedule(``&quot;/2 * * ? * *&quot;``)\n .Build();\n scheduler.ScheduleJob(job, trigger);\n scheduler.Start();\n Thread.Sleep(6000);\n scheduler.Shutdown(``true``);\n Console.ReadLine();\n &#125;\n运行结果如下：\n \nTriggerListener，JobListener这2个是对触发器和job本身的行为监听器，这样更好方便跟踪Job的状态及运行情况。  \nITriggerListener是官方定义的接口，这里我们直接继承实现。 \npublic class MyTriggerListener : ITriggerListener    { private string name; public void TriggerComplete(ITrigger trigger, IJobExecutionContext context, SchedulerInstruction triggerInstructionCode)        {            Console.WriteLine(“job完成时调用”);        } public void TriggerFired(ITrigger trigger, IJobExecutionContext context)        {            Console.WriteLine(“job执行时调用”);        } public void TriggerMisfired(ITrigger trigger)        {            Console.WriteLine(“错过触发时调用(例：线程不够用的情况下)”);        } public bool VetoJobExecution(ITrigger trigger, IJobExecutionContext context)        { &#x2F;&#x2F;Trigger触发后，job执行时调用本方法。true即否决，job后面不执行。            return false;        } public string Name { get { return name; } set { name &#x3D; value; } }    }\n主函数添加：\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n scheduler.ListenerManager.AddTriggerListener(myJobListener, KeyMatcher&lt;TriggerKey&gt;.KeyEquals(``new TriggerKey(``&quot;mytrigger&quot;``, &quot;group1&quot;``)));\n ////添加监听器到指定分类的所有监听器。\n ////添加监听器到指定分类的所有监听器。\n////添加监听器到指定的2个分组。\n ////添加监听器到所有的触发器上。\n scheduler.Start();\nJobListener同理，这里不多做描述。\nCron表达式quartz中的cron表达式和Linux下的很类似，比如 “&#x2F;5 * * ? * * *“ 这样的7位表达式，最后一位年非必选。\n表达式从左到右，依此是秒、分、时、月第几天、月、周几、年。下面表格是要遵守的规范：\n字段名\n允许的值\n允许的特殊字符\nSeconds\n0-59\n, - * &#x2F;\nMinutes\n0-59\n, - * &#x2F;\nHours\n0-23\n, - * &#x2F;\nDay of month\n1-31\n, - * ? &#x2F; L W\nMonth\n1-12 or JAN-DEC\n, - * &#x2F;\nDay of week\n1-7 or SUN-SAT\n, - * ? &#x2F; L #\nYear\n空, 1970-2099\n, - * &#x2F;\n特殊字符\n解释\n,\n或的意思。例：分钟位 5,10  即第5分钟或10分都触发。 \n&#x2F;\na&#x2F;b。 a：代表起始时间，b频率时间。 例； 分钟位  3&#x2F;5，  从第三分钟开始，每5分钟执行一次。\n*\n频率。 即每一次波动。    例；分钟位 *  即表示每分钟 \n-\n区间。  例： 分钟位   5-10 即5到10分期间。 \n?\n任意值 。   即每一次波动。只能用在DayofMonth和DayofWeek，二者冲突。指定一个另一个一个要用?\nL\n表示最后。 只能用在DayofMonth和DayofWeek，4L即最后一个星期三\nW\n工作日。  表示最后。 只能用在DayofWeek\n4#2。 只能用DayofMonth。 某月的第二个星期三  \n实例介绍”0 0 10,14,16 * * ?”    每天10点，14点，16点 触发。\n“0 0&#x2F;5 14,18 * * ?”    每天14点或18点中，每5分钟触发 。\n“0 4&#x2F;15 14-18 * * ?”       每天14点到18点期间,  从第四分钟触发，每15分钟一次。\n“0 15 10 ? * 6L”        每月的最后一个星期五上午10:15触发。\nQuartz.Net线程池线程池数量设置：\nproperties[“quartz.threadPool.threadCount”] &#x3D; “5”;  \n这个线程池的设置，是指同时间，调度器能执行Job的最大数量。\nquartz是用每个线程跑一个job。上面的设置可以解释是job并发时能执行5个job，剩下的job如果触发时间恰好到了，当前job会进入暂停状态，直到有可用的线程。\n如果在指定的时间范围依旧没有可用线程，会触发misfired时间。\nquartz 提供了IThreadPool接口，也可以用自定义线程池来实现。\n配置如下：\nproperties[“quartz.threadPool.type”] &#x3D; “Quartz.Simpl.SimpleThreadPool, Quartz”; \n一般来说作业调度很少并发触发大量job，如果有上百个JOB，可在服务器承受范围内适量增加线程数量。     \n总结官方有LoggingTriggerHistoryPlugin，LoggingJobHistoryPlugin  已实现的，触发器和job历史记录的插件。\nQuartz.Plugin 命名空间下有官方实现的其他一些插件，也可以自己增加扩展。\nquartz中监听器还有SchedulerListener，使用方法基本一样。 \n本文基于自用经验和官方文档代码来写的，部分是直接翻译的。 \nQuartz.Net官方教程http://www.quartz-scheduler.net/documentation/quartz-2.x/tutorial/index.html\n","categories":["编程技术","DotNet"],"tags":["Quartz.NET"]},{"title":"Net作业调度(五)—quartz.net动态添加job设计","url":"/2015/10/10/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/Net%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6(%E4%BA%94)%E2%80%94quartz.net%E5%8A%A8%E6%80%81%E6%B7%BB%E5%8A%A0job%E8%AE%BE%E8%AE%A1/","content":"介绍在实际项目使用中quartz.net中，都希望有一个管理界面可以动态添加job，而避免每次都要上线发布。 \n也看到有园子的同学问过。这里就介绍下实现动态添加job的几种方式， 也是二次开发的核心模块。\n阅读目录：\n传统方式\n框架反射方式\n进程方式\nURL方式\n框架配置方式\n\n传统方式 继承IJob，实现业务逻辑，添加到scheduler。\npublic class MonitorJob : IJob    { public void Execute(IJobExecutionContext context)        { &#x2F;&#x2F;do something            Console.WriteLine(“test”);        }    } &#x2F;&#x2F;var job &#x3D; JobBuilder.Create() &#x2F;&#x2F; .WithIdentity(“test”, “value”) &#x2F;&#x2F; .Build(); &#x2F;&#x2F;var trigger &#x3D; (ICronTrigger) TriggerBuilder.Create() &#x2F;&#x2F; .WithIdentity(“test”, “value”) &#x2F;&#x2F; .WithCronSchedule(“0 0&#x2F;5 * * * ?”) &#x2F;&#x2F; .Build(); &#x2F;&#x2F;scheduler.ScheduleJob(job, trigger);\n也可以使用CrystalQuartz远程管理暂停取消。之前的博客CrystalQuartz远程管理(二)。\n框架反射方式这种方式需要定义一套接口框架。 比如：\n  interface IcustomJob    { void Excute(string context); void Failed(string error); void Complete(string msg);    }\n1：当我们写job时同一实现这个框架接口，类库形式。\n2：写完后编译成DLL，上传到我们的作业执行节点。\n3：在执行节点中，通过反射拿到DLL的job信息。\n4：然后构建quartz的job，添加到scheduler。\n这种方式缺点： 耦合性太高，开发量较大。 优点：集中式管理。\n系统结构如图：\n\n进程方式这个方式和windows任务计划类似。\n1：使用方编写自己的job，无需实现任何接口，可执行应用程序形式。\n2：将程序发送到执行节点，由执行节点起进程调用job程序。\n执行节点调用，示例如下：\n public class ConsoleJob:IJob    { public void Execute(IJobExecutionContext context)        {            JobDataMap dataMap = context.JobDetail.JobDataMap; string content &#x3D; dataMap.GetString(“jobData”); var jd &#x3D; new JavaScriptSerializer().Deserialize(content);\n        Process p \\= new Process();\n        p.StartInfo.UseShellExecute \\= true;\n        p.StartInfo.FileName \\= jd.Path;\n        p.StartInfo.Arguments \\= jd.Parameters;   //空格分割\n        p.StartInfo.WindowStyle = ProcessWindowStyle.Minimized;\n        p.Start();\n    &#125;\n&#125;\n\n这种方式相对来说： 耦合性中等，执行节点和job相互不关心，没有依赖，开发量较小。\n系统结构如图：\n\nURL方式URL方式和第三种类似，不过调用的不在是执行程序，而是URL。\n1： 使用方在网页或服务中，实现业务逻辑。\n2： 然后将Url，交给执行节点post或get执行。\n执行节点调用，示例如下：\n public class HttpJob : IJob    { public void Execute(IJobExecutionContext context)        { var dataMap &#x3D; context.JobDetail.JobDataMap; var content &#x3D; dataMap.GetString(“jobData”); var jd &#x3D; new JavaScriptSerializer().Deserialize(content); if (jd.Parameters &#x3D;&#x3D; null)                jd.Parameters = string.Empty; if (jd.Timeout &#x3D;&#x3D; 0)                jd.Timeout = 5*60; var result &#x3D; RequestHelper.Post(jd.Url, jd.ContentType, jd.Timeout, jd.Parameters, jd.heads);        }    }\n这种方式耦合比较低，使用方不需要单独写应用程序了，和平常业务开发一样。\n执行节点的职权，仅仅作为一个触发器。\n有2点需要注意的是：\n1：请求URL时，注意双方约定token加密，防止非执行节点执行调用。\n2：使用方，如果有耗时操作，建议异步执行。 \n系统结构如图：\n\n框架配置方式1：使用方直接使用quartz.net框架，实现自己的job。从管理方拉取执行节点配置，然后自行管理执行节点。\n2：使用方也可以暴露端口给管理方，以实现监控，修改配置。\n这种形式，耦合性最低。是把管理方当成一个配置中心。 ps：几乎和传统方式+CrystalQuartz一样了。\n\n通过context.JobDetail.JobDataMap，可以保存job的需要的信息。\n本篇介绍主流的几种实现方案，供大家参考使用。\n","categories":["编程技术","DotNet"],"tags":["Quartz.NET"]},{"title":"Net作业调度(二) -CrystalQuartz远程管理","url":"/2015/09/19/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/Net%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6(%E4%BA%8C)%20-CrystalQuartz%E8%BF%9C%E7%A8%8B%E7%AE%A1%E7%90%86/","content":"介绍上篇已经了解Quartz.NET的基本使用方法了。但如果想方便的知道某个作业执行情况，需要暂停，启动等操作行为，这时候就需要个Job管理的界面。\n本文介绍Quartz.NET如何进行远程job管理，如图:\n\n实战一：作业服务端\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\nstatic void Main(``string``[] args)\n &#123;\n var properties = new NameValueCollection();\n properties[``&quot;quartz.scheduler.instanceName&quot;``] = &quot;RemoteServerSchedulerClient&quot;``;\n properties[``&quot;quartz.threadPool.type&quot;``] = &quot;Quartz.Simpl.SimpleThreadPool, Quartz&quot;``;\n properties[``&quot;quartz.threadPool.threadCount&quot;``] = &quot;5&quot;``;\n properties[``&quot;quartz.threadPool.threadPriority&quot;``] = &quot;Normal&quot;``;\n properties[``&quot;quartz.scheduler.exporter.type&quot;``] = &quot;Quartz.Simpl.RemotingSchedulerExporter, Quartz&quot;``;\n properties[``&quot;quartz.scheduler.exporter.port&quot;``] = &quot;556&quot;``;\n properties[``&quot;quartz.scheduler.exporter.bindName&quot;``] = &quot;QuartzScheduler&quot;``;\n properties[``&quot;quartz.scheduler.exporter.channelType&quot;``] = &quot;tcp&quot;``;\n var schedulerFactory = new StdSchedulerFactory(properties);\n var scheduler = schedulerFactory.GetScheduler();\n var job = JobBuilder.Create&lt;PrintMessageJob&gt;()\n .WithIdentity(``&quot;myJob&quot;``, &quot;group1&quot;``)\n .Build();\n var trigger = TriggerBuilder.Create()\n .WithIdentity(``&quot;myJobTrigger&quot;``, &quot;group1&quot;``)\n .StartNow()\n .WithCronSchedule(``&quot;/10 * * ? * *&quot;``)\n .Build();\n scheduler.ScheduleJob(job, trigger);\n scheduler.Start();\n &#125;\n1\n2\n3\n4\n5\n6\n7\npublic class PrintMessageJob : IJob\n &#123;\n public void Execute(IJobExecutionContext context)\n &#123;\n Console.WriteLine(``&quot;Hello!&quot;``);\n &#125;\n &#125;\n启动如下\n\n二：作业远程管理端，无需写任何代码，引用官方程序集，嵌入到已有的web网站。 \n      PM&gt; Install-Package CrystalQuartz.Remote\n      Webconfig 需要配置的地方\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n&lt;configuration&gt; \n &lt;crystalQuartz&gt;\n &lt;provider&gt;\n &lt;add property=``&quot;Type&quot; value=``&quot;CrystalQuartz.Core.SchedulerProviders.RemoteSchedulerProvider, CrystalQuartz.Core&quot; /&gt;\n &lt;add property=``&quot;SchedulerHost&quot; value=``&quot;tcp://127.0.0.1:556/QuartzScheduler&quot; /&gt; &lt;!--TCP监听的地址--&gt;\n &lt;/provider&gt;\n &lt;/crystalQuartz&gt;\n&lt;system.webServer&gt;\n &lt;!-- Handler拦截处理了，输出作业监控页面--&gt;\n &lt;handlers&gt;\n &lt;add name=``&quot;CrystalQuartzPanel&quot; verb=``&quot;*&quot; path=``&quot;CrystalQuartzPanel.axd&quot; type=``&quot;CrystalQuartz.Web.PagesHandler, CrystalQuartz.Web&quot; /&gt;\n &lt;/handlers&gt;\n &lt;/system.webServer&gt;\n&lt;/configuration&gt;\n　Web管理界面\n\n其他CrystalQuartz 提供基础功能，可以继续在此基础上进行二次开发，另外推荐使用Window服务寄宿，比较方法。\n参考资源张善友   　　　　　　　　    http://www.cnblogs.com/shanyou/archive/2012/01/15/2323011.html\nCrystalQuartz开源的地址 　　https://github.com/guryanovev/CrystalQuartz\n","categories":["编程技术","DotNet"],"tags":["Quartz.NET","任务调度"]},{"title":"Net作业调度(四)—quartz.net持久化和集群","url":"/2015/10/03/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/Net%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6(%E5%9B%9B)%E2%80%94quartz.net%E6%8C%81%E4%B9%85%E5%8C%96%E5%92%8C%E9%9B%86%E7%BE%A4/","content":"介绍在实际使用quartz.net中，持久化能保证实例重启后job不丢失、 集群能均衡服务器压力和解决单点问题。\nquartz.net在这两方面配置都比较简单。\n持久化quartz.net的持久化，是把job、trigger一些信息存储到数据库里面，以解决内存存储重启丢失。\n下载sql脚本           https://github.com/quartznet/quartznet/blob/master/database/tables/tables\\_sqlServer.sql\n创建个数据库，并执行脚本\n  QRTZ_BLOB_TRIGGERS  以Blob 类型存储的触发器。\n  QRTZ_CALENDARS   存放日历信息， quartz.net可以指定一个日历时间范围。\n  QRTZ_CRON_TRIGGERS  cron表达式触发器。\n  QRTZ_JOB_DETAILS      job详细信息。\n  QRTZ_LOCKS       集群实现同步机制的行锁表\n  QRTZ_SCHEDULER_STATE   实例信息，集群下多使用。\nquartz.net 配置  &#x2F;&#x2F;=&#x3D;&#x3D;持久化&#x3D;&#x3D;&#x3D;&#x3D; &#x2F;&#x2F;存储类型            properties[“quartz.jobStore.type”] &#x3D; “Quartz.Impl.AdoJobStore.JobStoreTX, Quartz”; &#x2F;&#x2F;表明前缀            properties[“quartz.jobStore.tablePrefix”] &#x3D; “QRTZ_“; &#x2F;&#x2F;驱动类型            properties[“quartz.jobStore.driverDelegateType”] &#x3D; “Quartz.Impl.AdoJobStore.SqlServerDelegate, Quartz”; &#x2F;&#x2F;数据源名称            properties[“quartz.jobStore.dataSource”] &#x3D; “myDS”; &#x2F;&#x2F;连接字符串            properties[“quartz.dataSource.myDS.connectionString”] &#x3D; @”Data Source&#x3D;(local);Initial Catalog&#x3D;JobScheduler;User ID&#x3D;sa;Password&#x3D;123465”; &#x2F;&#x2F;sqlserver版本            properties[“quartz.dataSource.myDS.provider”] &#x3D; “SqlServer-20”;\n启动客户端  var properties &#x3D; JobsManager.GetProperties(); var schedulerFactory &#x3D; new StdSchedulerFactory(properties);            scheduler = schedulerFactory.GetScheduler();            scheduler.Start(); &#x2F;&#x2F;var job &#x3D; JobBuilder.Create() &#x2F;&#x2F; .WithIdentity(“test”, “value”) &#x2F;&#x2F; .Build(); &#x2F;&#x2F;var trigger &#x3D; (ICronTrigger) TriggerBuilder.Create() &#x2F;&#x2F; .WithIdentity(“test”, “value”) &#x2F;&#x2F; .WithCronSchedule(“0 0&#x2F;5 * * * ?”) &#x2F;&#x2F; .Build(); &#x2F;&#x2F;scheduler.ScheduleJob(job, trigger);\n补充     1： 持久化后，job只有添加一次了(数据库已经有了)，所以不能再执行端写添加job的行为。这时候需要一个管理工具，动态添加操作。\n     2： quartz.net 支持sql server、sqlite、mysql、oracle、mongodb(非官方版)。\n部署图：\n \n如图quartz.net 的集群模式是依赖数据库表的，所以要持久化配置。  集群节点之间是不通信的，这样分布式的架构，很方便进行水平扩展。\n1: 除了线程池数量，instanceId可以不同外，各个节点的配置必须是一样的。\n2：集群中节点的系统时间一致。  \n3：多线程、集群中。quartz.net 利用数据库锁来保证job不会重复执行。\n     源码在DBSemaphore.cs、UpdateLockRowSemaphore.cs、StdRowLockSemaphore.cs\n4：集群化后，某节点失效后，剩余的节点能保证job继续执行下去。\n实例配置后启动。\n   &#x2F;&#x2F;cluster            properties[“quartz.jobStore.clustered”] &#x3D; “true”;            properties[“quartz.scheduler.instanceId”] &#x3D; “AUTO”;\n简单管理界面：\n\n","categories":["编程技术","DotNet"],"tags":["Quartz.NET"]},{"title":"Prism之Module","url":"/2015/07/25/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/Prism%E4%B9%8BModule/","content":"Prism的核心功能之一就是支持模块化应用程序开发(Modular Application Development)，并且在运行时对各个模块进行动态管理。\n使用Prism进行模块化开发首先要了解几个概念：\n1.Module: Module是一些逻辑上相关的程序集或者资源文件的集合，在Silverlight程序中通常以xap文件为单位存在。而每一个Module中都需要有一个负责进行初始化工作以及与系统进行集成的角色，它需要实现IModule接口。IModule接口中只有一个Initialize方法，一方面这个接口将这个工程标记为一个Module，另一方面你可以在Initialize方法中实现一些逻辑，比如向容器中注册一些Service，或者将视图集成到程序中等等。\n2.ModuleInfo: 在创建了一个Module之后，需要通知Prism这个Module的存在，也就是要注册一下。在Prism中，Module是以ModuleInfo的形式存在的。ModuleInfo记录了Module的信息，ModuleName属性是Module的标识符，相当于Module的ID；ModuleType是Module的AssemblyQualifiedName；DependsOn属性是该Module依赖的其它Module的ModuleName的集合，在加载该Module时，如果有依赖项没有加载的话，会先将依赖项加载；InitializationMode，有两种情况——WhenAvailable和OnDemand，当选择了WhenAvailable时，该Module会在程序启动时自动加载，如果选择了OnDemand，则会按需加载，默认情况下是WhenAvailable；Ref，存储该Module的位置，如XXX.xap；State，定义了Module从注册到加载到初始化的整个过程中的状态。\n3.ModuleCatalog: ModuleCatalog实现了IModuleCatalog接口，它是ModuleInfo的容器，保存着系统中所有Module的信息，不仅会管理哪些Module需要加载，什么时候加载以什么顺序加载等问题，还要检查各个Module之间是否存在着循环依赖、是否有重复的Module等等。ModuleCatalog提供了含参构造方法和AddModule方法，可以通过代码将Module注册进去，同时也可以在xaml文件中配置好Module，然后通过ModuleCatalog.CreateFromXaml方法来加载。\n4.ModuleManager: ModuleManager实现了IModuleManager接口。顾名思义就是管理Module的类。IModuleManager中含有两个方法和两个事件：Run方法会将所有InitializationMode为WhenAvailable的Module加载，然后进行初始化，初始化的工作委托给了IModuleInitializer来完成，它会获取到Module类(上面提到的实现了IModule接口的类)的实例，然后调用其Initialize方法。LoadModule方法用来加载InitializationMode为OnDemand的Module。两个事件分别用来通知下载Module的进度变化以及Module加载完成。\n下面用一个示例程序来说明如何在Prism中进行模块化程序开发。\n1.创建一个Silverlight Application，叫做PrismModule。\n2.在Solution中添加三个Silverlight Application，分别叫做ModuleA, ModuleB, ModuleC。然后删除这三个工程中的App文件和MainPage文件。\n3.在ModuleA工程下添加一个UserControl，叫做ViewA，然后再添加一个类，叫做ModuleA。并添加Microsoft.Practices.Prism和Microsoft.Practices.ServiceLocation引用。下面是ViewA和ModuleA的代码：\n&lt;UserControl x:Class=&quot;ModuleA.ViewA&quot;    xmlns=&quot;http://schemas.microsoft.com/winfx/2006/xaml/presentation&quot;    xmlns:x=&quot;http://schemas.microsoft.com/winfx/2006/xaml&quot;    xmlns:d=&quot;http://schemas.microsoft.com/expression/blend/2008&quot;    xmlns:mc=&quot;http://schemas.openxmlformats.org/markup-compatibility/2006&quot;    mc:Ignorable=&quot;d&quot;    d:DesignHeight=&quot;300&quot; d:DesignWidth=&quot;400&quot;&gt;         &lt;Grid x:Name=&quot;LayoutRoot&quot; Background=&quot;White&quot;&gt;        &lt;TextBlock Text=&quot;Module A&quot; FontSize=&quot;22&quot; /&gt;    &lt;/Grid&gt;&lt;/UserControl&gt;\n\n\n\npublic class ModuleA : IModule&#123;    public void Initialize()    &#123;    &#125;&#125;\n\n\n\n4.对ModuleB和ModuleC重复做步骤3的操作，只是将文本改成相应模块。\n5.在PrismModule中添加对ModuleA、ModuleB、ModuleC、Prism、UnityExtensions还有Unity for Silverlight的引用，然后创建Shell和Bootstrapper。添加一个UserControl，叫做Shell；再添加一个类，叫做Bootstrapper。\nShell代码如下：\n&lt;UserControl x:Class=&quot;PrismModule.Shell&quot;    xmlns=&quot;http://schemas.microsoft.com/winfx/2006/xaml/presentation&quot;    xmlns:x=&quot;http://schemas.microsoft.com/winfx/2006/xaml&quot;    xmlns:d=&quot;http://schemas.microsoft.com/expression/blend/2008&quot;    xmlns:mc=&quot;http://schemas.openxmlformats.org/markup-compatibility/2006&quot;    xmlns:prism=&quot;http://www.codeplex.com/prism&quot;    mc:Ignorable=&quot;d&quot;    d:DesignHeight=&quot;600&quot; d:DesignWidth=&quot;800&quot;&gt;         &lt;StackPanel Margin=&quot;50&quot;&gt;        &lt;StackPanel Orientation=&quot;Horizontal&quot; HorizontalAlignment=&quot;Center&quot;&gt;            &lt;Border VerticalAlignment=&quot;Top&quot; BorderBrush=&quot;Red&quot; BorderThickness=&quot;2&quot; Width=&quot;200&quot; Height=&quot;100&quot;&gt;                &lt;ContentControl prism:RegionManager.RegionName=&quot;RegionA&quot; /&gt;            &lt;/Border&gt;            &lt;Border VerticalAlignment=&quot;Top&quot; BorderBrush=&quot;Red&quot; BorderThickness=&quot;2&quot; Width=&quot;200&quot; Height=&quot;100&quot;&gt;                &lt;ContentControl prism:RegionManager.RegionName=&quot;RegionB&quot; /&gt;            &lt;/Border&gt;            &lt;StackPanel&gt;                &lt;Border BorderBrush=&quot;Red&quot; BorderThickness=&quot;2&quot; Width=&quot;200&quot; Height=&quot;100&quot;&gt;                    &lt;ContentControl prism:RegionManager.RegionName=&quot;RegionC&quot; /&gt;                &lt;/Border&gt;                &lt;Button Content=&quot;Load Module C&quot; Click=&quot;LoadModuleC&quot; Width=&quot;120&quot; Height=&quot;25&quot; /&gt;            &lt;/StackPanel&gt;        &lt;/StackPanel&gt;    &lt;/StackPanel&gt;&lt;/UserControl&gt;\n\n\n\nShell.xaml.cs代码如下：\n&lt;UserControl x:Class=&quot;PrismModule.Shell&quot;    xmlns=&quot;http://schemas.microsoft.com/winfx/2006/xaml/presentation&quot;    xmlns:x=&quot;http://schemas.microsoft.com/winfx/2006/xaml&quot;    xmlns:d=&quot;http://schemas.microsoft.com/expression/blend/2008&quot;    xmlns:mc=&quot;http://schemas.openxmlformats.org/markup-compatibility/2006&quot;    xmlns:prism=&quot;http://www.codeplex.com/prism&quot;    mc:Ignorable=&quot;d&quot;    d:DesignHeight=&quot;600&quot; d:DesignWidth=&quot;800&quot;&gt;         &lt;StackPanel Margin=&quot;50&quot;&gt;        &lt;StackPanel Orientation=&quot;Horizontal&quot; HorizontalAlignment=&quot;Center&quot;&gt;            &lt;Border VerticalAlignment=&quot;Top&quot; BorderBrush=&quot;Red&quot; BorderThickness=&quot;2&quot; Width=&quot;200&quot; Height=&quot;100&quot;&gt;                &lt;ContentControl prism:RegionManager.RegionName=&quot;RegionA&quot; /&gt;            &lt;/Border&gt;            &lt;Border VerticalAlignment=&quot;Top&quot; BorderBrush=&quot;Red&quot; BorderThickness=&quot;2&quot; Width=&quot;200&quot; Height=&quot;100&quot;&gt;                &lt;ContentControl prism:RegionManager.RegionName=&quot;RegionB&quot; /&gt;            &lt;/Border&gt;            &lt;StackPanel&gt;                &lt;Border BorderBrush=&quot;Red&quot; BorderThickness=&quot;2&quot; Width=&quot;200&quot; Height=&quot;100&quot;&gt;                    &lt;ContentControl prism:RegionManager.RegionName=&quot;RegionC&quot; /&gt;                &lt;/Border&gt;                &lt;Button Content=&quot;Load Module C&quot; Click=&quot;LoadModuleC&quot; Width=&quot;120&quot; Height=&quot;25&quot; /&gt;            &lt;/StackPanel&gt;        &lt;/StackPanel&gt;    &lt;/StackPanel&gt;&lt;/UserControl&gt;\n\n\n\nBootstrapper代码如下：\npublic class Bootstrapper : UnityBootstrapper&#123;    protected override DependencyObject CreateShell()    &#123;        return this.Container.TryResolve&lt;Shell&gt;();    &#125;     protected override void InitializeShell()    &#123;        App.Current.RootVisual = (UIElement)this.Shell;    &#125;     protected override IModuleCatalog CreateModuleCatalog()    &#123;        return new ModuleCatalog();    &#125;     protected override void ConfigureModuleCatalog()    &#123;        Type typeA = typeof(ModuleA.ModuleA);        ModuleInfo moduleA = new ModuleInfo        &#123;   //  ModuleA没有设置InitializationMode,默认为WhenAvailable            ModuleName = typeA.Name,            ModuleType = typeA.AssemblyQualifiedName,        &#125;;         Type typeB = typeof(ModuleB.ModuleB);        ModuleInfo moduleB = new ModuleInfo        &#123;            ModuleName = typeB.Name,            ModuleType = typeB.AssemblyQualifiedName,            InitializationMode = InitializationMode.OnDemand,        &#125;;         Type typeC = typeof(ModuleC.ModuleC);        ModuleInfo moduleC = new ModuleInfo        &#123;            ModuleName = typeC.Name,            ModuleType = typeC.AssemblyQualifiedName,            InitializationMode = InitializationMode.OnDemand,            //  ModuleC依赖于ModuleB            DependsOn = new Collection&lt;string&gt; &#123; moduleB.ModuleName &#125;,        &#125;;         this.ModuleCatalog.AddModule(moduleA);        this.ModuleCatalog.AddModule(moduleB);        this.ModuleCatalog.AddModule(moduleC);    &#125;&#125;\n\n\n\n将App.xaml.cs中的Application_Startup方法改为\nprivate void Application_Startup(object sender, StartupEventArgs e)&#123;    Bootstrapper bootstrapper = new Bootstrapper();    bootstrapper.Run();&#125;\n\n\n\n6.现在已经有了Region，需要将各个Module中的View填充到Region中。修改ModuleA,ModuleB和ModuleC的Initialize方法。\npublic void Initialize()&#123;    ServiceLocator.Current.GetInstance&lt;IRegionManager&gt;().        RegisterViewWithRegion(&quot;RegionA&quot;, typeof(ViewA));&#125;\n\n\n\n将其中的A改为相应的字母。运行程序，结果如下：\n\n我们点击按钮来加载ModuleC，因为ModuleC依赖于ModuleB，所以ModuleB也一块儿加载出来了。但是这与我们预期的效果不太一致。因为一共只load了一个xap文件，用WinRAR打开看一下，发现三个Module的程序集都在其中。\n\n在Silverlight程序中，模块化程序开发应该不仅仅体现在开发时的模块化，运行时也应该是模块化的。比如ModuleA在程序加载时就load出来，但是ModuleB和ModuleC则是在点击了按钮后才load出来的，换句话说，在没点按钮前就不应该将ModuleB和ModuleC的程序集加载进来。现在由于PrismModule项目引用了三个Module，所以程序集会被一块打包进xap文件中。我们修改一下，将对ModuleB和ModuleC的引用的Copy Local属性设置为false：\n\n重新编译一下，再次查看xap文件，发现已经没有了ModuleB和ModuleC。\n\n运行程序，报错。很简单，因为我们在Bootstrapper中用到了ModuleB和ModuleC，缺少了这两个dll，程序没法运行。为了解决这个问题，我们把初始化ModuleCatalog的过程改一下，不使用代码，而是使用配置文件。在Silverlight中，Prism支持使用xaml文件作为配置文件。下面在PrismModule工程下新建一个资源文件，ModuleCatalog.xaml。内容如下：\n&lt;Modularity:ModuleCatalog xmlns=&quot;http://schemas.microsoft.com/winfx/2006/xaml/presentation&quot;        xmlns:x=&quot;http://schemas.microsoft.com/winfx/2006/xaml&quot;        xmlns:sys=&quot;clr-namespace:System;assembly=mscorlib&quot;               xmlns:Modularity=&quot;clr-namespace:Microsoft.Practices.Prism.Modularity;assembly=Microsoft.Practices.Prism&quot;&gt;        &lt;Modularity:ModuleInfo Ref=&quot;ModuleA.xap&quot; ModuleName=&quot;ModuleA&quot;         ModuleType=&quot;ModuleA.ModuleA, ModuleA, Version=1.0.0.0, Culture=neutral, PublicKeyToken=null&quot; /&gt;     &lt;Modularity:ModuleInfo Ref=&quot;ModuleB.xap&quot; ModuleName=&quot;ModuleB&quot; InitializationMode=&quot;OnDemand&quot;        ModuleType=&quot;ModuleB.ModuleB, ModuleB, Version=1.0.0.0, Culture=neutral, PublicKeyToken=null&quot; /&gt;     &lt;Modularity:ModuleInfo Ref=&quot;ModuleC.xap&quot; ModuleName=&quot;ModuleC&quot; InitializationMode=&quot;OnDemand&quot;        ModuleType=&quot;ModuleC.ModuleC, ModuleC, Version=1.0.0.0, Culture=neutral, PublicKeyToken=null&quot;&gt;        &lt;Modularity:ModuleInfo.DependsOn&gt;            &lt;sys:String&gt;ModuleB&lt;/sys:String&gt;        &lt;/Modularity:ModuleInfo.DependsOn&gt;    &lt;/Modularity:ModuleInfo&gt;&lt;/Modularity:ModuleCatalog&gt;\n\n\n\n这里大体和用代码写一致，只不过Ref属性里要写明该Module对应的是哪个xap包。Prism在Silverlight程序中使用一个叫做XapModuleTypeLoader的类来加载Module，在将Module下载之后会获取AppManifest.xaml文件，也就是说如果你的Module是个类库工程的话，会在加载时产生错误。可以将几个类库的程序集文件包装在一个xap文件中作为一个Module来使用，或者自定义一个ModuleTypeLoader。\n定义完Module的配置文件后，要改写Bootstrapper。首先删除用代码配置Module的方法ConfigureModuleCatalog，然后在CreateModuleCatalog方法中替换成一下内容：\nprotected override IModuleCatalog CreateModuleCatalog()&#123;    return Microsoft.Practices.Prism.Modularity.ModuleCatalog.CreateFromXaml(        new Uri(&quot;/PrismModule;component/ModuleCatalog.xaml&quot;, UriKind.Relative));&#125;\n\n\n\n再次运行程序，正常运行。\n\n这样就达到了按需加载的目的。节约带宽是一个好处，如果产品是分模块往外卖的时候，可以由客户按需定制。\n不过再打开ModuleB和ModuleC的xap文件看一下，发现里面不仅有Module本身的程序集，还包括了引用的Prism的程序集等。而这些程序集其实已经在PrismModule.xap中包含了。完全没有必要重复下载。所以可以将多余的程序集的引用的Copy Local属性设置为false，这样就瘦身成功了。(想要避免重复加载相同的文件，也可以通过在项目的Properties面板中勾选Reduce XAP size by using application library caching选项)\n如果你对Module的加载到执行的整个过程感兴趣，那么Prism本身提供了一个QuickStart，既有Unity版本也有Mef版本，不要错过。\n","categories":["编程技术","DotNet"],"tags":["WPF","Prism"]},{"title":"Prism之Bootstrapper","url":"/2015/07/18/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/Prism%E4%B9%8BBootstrapper/","content":"  在程序中使用框架必然要有一个切入点，框架会在这里进行初始化，处理相关配置信息等。在Prism中扮演这一角色的就是Bootstrapper。\nPrism提供了一个抽象基类Bootstrapper，这个类里面包含了包含了许多空的虚方法，可以重写它们添加自己的逻辑。这个基类与任何容器无关，所以可以通过继承它来实现基于特定容器的Bootstrapper，不过通常我们大可不必这样做，因为Prism默认提供了两个基于特定容器的Bootstrapper——UnityBootstrapper和MefBootstrapper，分别使用Unity和Mef来实现依赖注入。而我们需要做的工作就是在这两个类之间选择一个适合自己的，稍微配置一下就可以了。当然如果你不喜欢这两个容器或者已有的程序使用了其它容器(如Spring.Net， Castle等)，也可以通过继承Boostrapper抽象基类来实现自己的SpringBootstrapper和CastleBootstrapper。虽然UnityBootstrapper的代码看起来挺简单的，但是如果仿照这个来实现CastleBootstrapper却并不是那么容易的一件事(不信你可以试试)，所以更好的办法是用现成的。\n那么Bootstrapper都做了些什么呢？\n\n\n创建Logger：\n 执行CreateLogger方法，默认创建一个EmptyLogger，不会在任何地方输出log。当然是可以扩展的，比如你可以使用Clog来做一个适配器。\n\n创建并配置ModuleCatalog\n\n\n执行CreateModuleCatalog方法，默认创建一个空的ModuleCatalog。然后执行ConfigureModuleCatalog方法，默认情况下这个方法是空的。可以重写这两个方法，加入自定义的获取ModuleCatalog的逻辑，比如在CreateModuleCatalog中可以从一个xaml文件中读取Module信息。\nprotected override IModuleCatalog CreateModuleCatalog()&#123;\treturn ModuleCatalog.CreateFromXaml(new Uri(&quot;/AssemblyName;component/ModulesCatalog.xaml&quot;,  UriKind.Relative));&#125;\n\n\n创建并配置依赖注入容器\n\n  Prism中使用依赖注入来管理各个组件，你可以使用任何你熟悉的容器，比如Castle, Unity等。Prism中内置了对Unity以及Mef的支持，所以有两种预定义好的Bootstrapper: UnityBootstrapper和MefBootstrapper，其中分别采用UnityContainer和CompositionContainer作为依赖注入容器。以UnityBootstrapper为例，在这一步中会先调用CreateContainer方法，返回一个UnityContainer；然后调用ConfigureContainer方法，在这个方法中主要是将一些常用的类注册到容器中。\n\n配置默认的Region适配器映射\n\n  为了使xaml中的UI控件可以使用Region，需要先注册一下。Prism默认支持Region的控件类型有：TabControl, Selector, ItemsControl, ContentControl。当然你也可以通过实现IRegionAdapter接口或者直接继承RegionAdapterBase来使其它控件也支持Region。\n\n配置默认的Region 行为(Behavior)\n\n  为RegionBehaviorFactory添加一些默认的行为。这样可以扩展Region的行为。可以通过实现IRegionBehavior接口或继承RegionBehavior来自定义Region的行为，并重写ConfigureDefaultRegionBehaviors方法添加到Region。\n\n注册框架异常类型\n\n  Prism提供了ExceptionExtensions类来帮助开发人员定位异常发生的根异常。在这一步通过调用RegisterFrameworkExceptionTypes方法向ExceptionExtensions中添加新的Root Exception。\n\n创建并初始化Shell\n\n  首先调用CreateShell方法来创建一个Shell，这是一个抽象方法，通常这个方法中就是返回作为整个网站容器的页面。之后会将RegionManager attach到Shell上，然后更新定义的Regions，最后调用InitializeShell方法来初始化Shell。默认情况下这是个空方法，可以通过重写这个方法加入自定义的逻辑，可以在这个方法中将Shell作为Silverlight程序的根容器页面显示出来。\nprotected override void InitializeShell()`&#123;     Application.Current.RootVisual = Shell;&#125;\n\n\n初始化Modules\n\n  调用InitializeModules方法，实际上就是调用ModuleManager.Run方法，会调用ModuleCatalog中的所有InitializationMode为WhenAvailable的Module的Initialize方法。\n  至此，整个容器的初始化过程就完毕了。\n  值得一提的还有CommonServiceLocator，这同样是Patterns &amp; Practices小组的产品。它的作用很简单，就是统一依赖注入容器的接口，使程序不必依赖于特定的容器，只需要使用ServiceLocator，然后去间接地使用其它各种各样的容器。在Prism的内部就是使用ServiceLocator来进行管理的。所以不管使用什么样的容器，都需要提供一个实现了IServiceLocator接口的适配器，如使用Unity要提供UnityServiceLocatorAdapter，使用Mef要提供MefServiceLocatorAdapter。这样不管外部使用什么容器，内部都不需要改变。所以如果要使用Prism重头开始构架一个程序，那么在整个程序中不依赖于特定的依赖注入容器接口，而是使用ServiceLocator是一个不错的选择，这样可以在需要的情况下很容易地更换容器，只需要重写一个Bootstrapper和一个ServiceLocatorAdapter就可以了。\n","categories":["编程技术","DotNet"],"tags":["WPF","Prism"]},{"title":"Prism之Region(1)","url":"/2015/08/01/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/Prism%E4%B9%8BRegion(1)/","content":"Prism可以帮助我们开发模块化程序，将程序分割成一个个独立的Module，分别进行开发。然后在程序运行的时候，将各个Module组合到一起，为程序提供各种各样的功能。通常来说，Module是一些视图和功能的集合，那么就需要一种办法来将这些视图以某种形式，在特定的时间展现出来。Prism通过Shell + Region来组织视图的布局，完成视图间的转换等。\n\n如上图所示，Shell相当于ASP.NET中的母版页，它定义了页面的布局、主题等。其中的导航区和内容区是预留出来的需要进行填充内容的部分，也就是Region，起到占位符的作用，程序会在运行时动态地向Region中填充内容。\n那么如何将一个区域定义为Region呢？\n首先在引入Prism的命名空间\nxmlns:prism=&quot;http://www.codeplex.com/prism&quot;   如果IDE无法找到这个命名空间的话，需要先注册Prism。\n然后在需要定义为Region的控件上加上Attached Property。\n&lt;ContentControl prism:RegionManager.RegionName=&quot;MainRegion&quot; /&gt;\n并不是所有的控件都可以作为Region的，需要为需要定义为Region的控件添加RegionAdapter。RegionAdapter的作用是为特定的控件创建相应的Region，并将控件与Region进行绑定，然后为Region添加一些行为。一个RegionAdapter需要实现IRegionAdapter接口，如果你需要自定义一个RegionAdapter，可以通过继承RegionAdapterBase类来省去一些工作。Prism为Silverlight提供了几个RegionAdapter：\n\nContentControlRegionAdapter： 创建一个SingleActiveRegion并将其与ContentControl绑定\nItemsControlRegionAdapter： 创建一个AllActiveRegion并将其与ItemsControl绑定\nSelectorRegionAdapter： 创建一个Region并将其与Selector绑定\nTabControlRegionAdapter： 创建一个Region并将其与TabControl绑定\n\n从图中可以看到，导航区对应的NavigationRegion中四个视图都是亮着的，而内容区对应的ContentRegion中四个视图只有一个是亮着的(橘黄色代表显示在页面中)。ItemsControl本来就是由许多个Item组成的，因此ItemsControlRegionAdapter会创建AllActiveRegion，这种类型的Region中所有Active的视图都会显示在ItemsControl中；而ContentControl只能容纳一个Content，所以ContentControlRegionAdapter创建了一个SingleActiveRegion，其中的视图只有一个是处于Active状态的，会显示在ContentControl中，其它的都是不可见的，需要将它们激活(Active)，才能使其显示。\n通常我们并不直接和Region打交道，而是通过RegionManager，它实现了IRegionManager接口。IRegionManager接口包含一个只读属性Regions，是Region的集合，还有一个CreateRegionManager方法。Prism通过RegionManagerExtensions类使用扩展方法为IRegionManager添加了更多的功能。\n\nAddToRegion： 将一个视图添加到一个Region中。\nRegisterViewWithRegion： 将一个视图和一个Region进行关联。当Region显示的时候，关联的视图才会显示，也就是说，在这个Region显示之前，关联的视图是不会被创建的。\nRequestNavigate： 进行页面切换，将指定的Region中显示的视图切换为指定的视图。\n\n本文开头说过，需要在运行时将分散在各个Module的视图显示在页面特定的位置上。那么首先就需要定义页面显示的地方，即Region。然后就是要定义创建视图的时机和方式。在Prism中有两种方式来定义视图与Region之间的映射关系——View Discovery和View Injection。\nView Discovery是以声明式的方式来建立Region和视图之间的关系。如上图中的导航区，需要在导航区显示的时候就将各个导航视图填充到其中。而内容区中也需要一个默认显示的内容视图。因此也可以这样理解View Discovery，就是指定一个Region的默认视图。我们可以使用IRegionManager.RegisterViewWithRegion方法来声明某个Region默认应该显示哪个视图。注意这里是Register，是注册，也就是说不会马上创建该视图。当Region显示在页面中的时候，它会去寻找与自己相关联的视图，并对其进行初始化。\n\n\n这样做的好处是我们不必关注在什么时候创建视图，一切都会自动完成。缺点就是默认视图是确定的，当需要进行视图转换的时候，这种方式就行不通了。这时候就需要View Injection。\nView Injection可以让我们对于Region中显示的视图有更精确的控制。通常可以通过调用IRegionManager.AddToRegion方法或者是IRegionManager.Regions[“RegionName”].Add方法来向一个Region中添加一个视图的实例。对于SingleActiveRegion(ContentControlRegionAdapter会创建这种类型的Region)，可以通过IRegion.Activate方法将一个已经添加到Region中的视图显示出来。当然也可以通过IRegion.Deactivate方法来将视图状态置为非激活或者干脆调用IRegion.Remove方法将视图移除。可以看到，因为要添加的是视图的实例，所以需要仔细地设计在什么时候使用View Injection，以免造成不必要的开销。\n在Prism 4.0中新添加了一些导航API，这套API大大地简化了View Injection的流程，它使用URI来进行Region中视图的导航，然后会根据URI来创建视图，并将其添加到Region中，然后激活该视图。导航API的出现不只是为了简化View Injection的过程，它还提供了前进、后退的功能，并且对MVVM模式下的导航有良好的支持，还能够在进行导航的时候传递参数等等。所以推荐的方式是使用新的导航API，也就是使用IRegionManager.RequestNavigate方法。\n如果一个页面相对来说不大变化，如导航区，在程序初始化的过程完成后就不会轻易地变动，这时候就较适合于使用RegisterViewWithRegion方法，通常可以在Module的Initialize方法中完成这个过程。\npublic void Initialize()&#123;    logger.Log(&quot;初始化Navigation模块&quot;, Category.Debug, Priority.Low);    _regionManager.RegisterViewWithRegion(RegionNames.NavRegion, typeof(NavigationItem));    _regionManager.RegisterViewWithRegion(RegionNames.MainRegion, // 两种方式都可以                                            () =&gt; _container.Resolve&lt;NavigationContainer&gt;() );    _regionManager.RegisterViewWithRegion(RegionNames.NavDemoActionRegion, typeof(ActionController));&#125;\n\n\n\n如果一个区域需要频繁地切换页面的话，如主内容区，可以使用View Injection的方式。\nIRegionManager regionManager = ...;IRegion mainRegion = regionManager.Regions[&quot;MainRegion&quot;];InboxView view = this.container.Resolve&lt;InboxView&gt;();mainRegion.Add(view);\n\n\n\n可以看到，这时候已经生成了视图的实例。之前提到过，一个Region可以包含多个视图，这些视图会处于不同的状态，对于ItemsControl类型的Region来说，里面会显示很多个Item，所以添加进去就可以了；但是对于ContentControl这种Region，同一时刻只能显示一个视图，所以在添加进去之后还需要有一个Activate的过程。\n使用URI来进行导航只需要提供需要切换的视图的名称就可以，并不需要了解视图的类型，从而达到解耦的目的，并且可以通过URI来进行参数传递。\npublic void Initialize()&#123;      //  因为Prism无法确定每个视图都是什么类型，所以就使用了Object，    //  因此在根据ViewName获取实例时，会使用IServiceLocator.GetInstance&lt;Object&gt;(ViewName)    _container.RegisterType&lt;object, ViewA&gt;(ViewNames.ViewA);    _container.RegisterType&lt;object, ViewB&gt;(ViewNames.ViewB);    _container.RegisterType&lt;object, ViewC&gt;(ViewNames.ViewC);&#125;\n\n\n\n首先注册一下视图的类型，其实就是将视图的名称与视图类型进行一下关联。在导航的时候调用RequestNavigate方法就可以了。\nvoid ToSpecifiedView(string viewName)&#123;              Uri uri = new Uri(viewName, UriKind.Relative);    _regionManager.RequestNavigate(RegionNames.NavDemoShowRegion, uri);    logger.Log(&quot;跳转到视图 [&quot; + viewName + &quot;]&quot;, Category.Info, Priority.Low);&#125;\n\n\n\nPrism提供了UriQuery类来帮助我们在导航的时候传递参数。\nvoid ToSpecifiedView(string viewName)&#123;    UriQuery query = new UriQuery();    if (viewName == ViewNames.ViewA)    &#123;        query.Add(&quot;Time&quot;, DateTime.Now.ToShortTimeString());    &#125;    Uri uri = new Uri(viewName + query.ToString(), UriKind.Relative);    _regionManager.RequestNavigate(RegionNames.NavDemoShowRegion, uri, CallbackHandler);   //  回调方法可加可不加&#125;\n\n\n\n上面的代码判断当跳转到ViewA时，传递一个叫做Time的参数。那么怎样在视图中获取传递的参数呢？这里就要提一下INavigationAware接口了。这个接口使视图或者其对应的ViewModel也可以参与到页面导航的过程中来。所以这个接口既可以由视图来实现，也可以由视图的DataContext——通常指的就是ViewModel，来实现。\npublic interface INavigationAware&#123;    bool IsNavigationTarget(NavigationContext navigationContext);    void OnNavigatedTo(NavigationContext navigationContext);    void OnNavigatedFrom(NavigationContext navigationContext);&#125;\n\n\n\n当从本页面转到其它页面的时候，会调用OnNavigatedFrom方法，navigationContext会包含目标页面的URI。\n当从其它页面导航至本页面的时候，首先会调用IsNavigationTarget，IsNavigationTarget返回一个bool值，简单地说这个方法的作用就是告诉Prism，是重复使用这个视图的实例还是再创建一个。然后调用OnNavigatedTo方法。在导航到本页面的时候，就可以从navigationContext中取出传递过来的参数。\n\n使用导航API的另一个优点就是可以进行页面的前进和后退，一切由Prism完成。这个功能是由IRegionNavigationJournal接口提供的。\npublic interface IRegionNavigationJournal&#123;    bool CanGoBack &#123; get; &#125;    bool CanGoForward &#123; get; &#125;    IRegionNavigationJournalEntry CurrentEntry &#123; get; &#125;    INavigateAsync NavigationTarget &#123; get; set; &#125;    void Clear();    void GoBack();    void GoForward();    void RecordNavigation(IRegionNavigationJournalEntry entry);&#125;\n\n\n\n其中CanGoBack和CanGoForward属性表示当前是否可以后退或前进。如果可以的话，可以使用GoBack和GoForward方法进行前进和后退。\npublic class ActionControllerViewModel : NotificationObject&#123;    private IRegion _demoShowRegion;    public bool CanGoBack    &#123;        get        &#123;            return _demoShowRegion.NavigationService.Journal.CanGoBack;        &#125;    &#125;     public bool CanGoForward    &#123;        get        &#123;            return _demoShowRegion.NavigationService.Journal.CanGoForward;        &#125;    &#125;     void ToPrevious()    &#123;        _demoShowRegion.NavigationService.Journal.GoBack();        ResetNavigationButtonState();    &#125;     void ToNext()    &#123;        _demoShowRegion.NavigationService.Journal.GoForward();        ResetNavigationButtonState();    &#125;     void ResetNavigationButtonState()    &#123;        RaisePropertyChanged(() =&gt; this.CanGoBack);        RaisePropertyChanged(() =&gt; this.CanGoForward);    &#125;&#125;\n\n\n\n\n导航API还可以控制视图的生命周期，在页面跳转时进行确认拦截(Confirming or Cancelling Navigation)以及其它功能，可以参考 Developer’s Guide to Microsoft Prism。\n","categories":["编程技术","DotNet"],"tags":["WPF","Prism"]},{"title":"Prism之Region(2)","url":"/2015/08/08/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/Prism%E4%B9%8BRegion(2)/","content":"在Prism之Region(1)中，介绍了一些Prism中页面组织以及切换的方式。这一篇将以一个很简单的示例程序来实践一下。\n下面是效果图：\n\n先说Log，Prism内置了ILogFacade接口，在Prism提供的QuickStart项目里的Modularity中，有一个CallbackLogger，这里我们直接拿过来使用。然后在PrismRegionShell中放一个TextBox，将log的内容显示在这个TextBox中。值得一提的是，为了让输出新log的直接显示出来，需要将TextBox的滚动条滚动到最下面。这里采用的是如下方法：\npublic void Log(string message, Category category, Priority priority)&#123;    this.LogContainer.Text += string.Format(CultureInfo.CurrentUICulture, &quot;[&#123;0&#125;][&#123;1&#125;] &#123;2&#125;\\r\\n&quot;, category, priority, message);    //  这段代码的作用是让文本框的滚动条滚动到最底部    LogContainer.Select(LogContainer.Text.Length, LogContainer.Text.Length);&#125;\n\n\n\n然后说一下左边的导航区。这里放置了一个ItemsControl，并将其设为Region。里面的两个按钮并不是直接写死到xaml里的，而是在两个Module初始化时动态添加进来的。也就是说，这个ItemsControl并不知道自己将要包含哪些项。这里我们使用IRegionManager.RegisterViewWithRegion(RegionNames.NavRegion, typeof(EmptyNavigationItem));这种方式来将视图注册到Region中。这样当该Region显示的时候两个视图才会被初始化。这里需要注意的是，一个Region里需要同时显示多个视图时，视图的顺序问题。比如ItemsControl，哪个先被注册就哪个显示在上面，但是由于Module的加载速度等原因，所以这时两个视图不一定谁在上面。现在我需要指定[导航示例]这个按钮在上，那么Prism为我们提供了ViewSortHintAttribute来解决这个问题。在需要进行排序的视图上添加上相应的attribute就可以了。\n[ViewSortHint(&quot;01&quot;)]public partial class NavigationItem : UserControl [ViewSortHint(&quot;02&quot;)]public partial class EmptyNavigationItem : UserControl\n\n\n\n在初始化导航实例的Module时，将导航示例的视图注册到内容区的Region，这时[上一个]按钮依然处于灰色状态，因为通过RegisterViewWithRegion方法显示的页面是不被记录的。当点击[ViewA][ViewB][ViewC]这三个按钮时，会采用RequestNavigate方法来进行页面的跳转，这时页面跳转的过程会被记录下来，此时就可以通过[上一个]和[下一个]按钮进行页面的前进和后退。\nvoid ToSpecifiedView(string viewName)&#123;    UriQuery query = new UriQuery();    if (viewName == ViewNames.ViewA)    &#123;        query.Add(&quot;Time&quot;, DateTime.Now.ToShortTimeString());    &#125;    Uri uri = new Uri(viewName + query.ToString(), UriKind.Relative);    _regionManager.RequestNavigate(RegionNames.NavDemoShowRegion, uri);    logger.Log(&quot;跳转到视图 [&quot; + viewName + &quot;]&quot;, Category.Info, Priority.Low);    ResetNavigationButtonState();&#125;\n\n\n\n注意这三个视图已经在初始化Module的时候使用IUnityContainer.RegisterType&lt;object, ViewA&gt;(ViewNames.ViewA)方法注册过了。\npublic void Initialize()&#123;    logger.Log(&quot;初始化Navigation模块&quot;, Category.Debug, Priority.Low);    _regionManager.RegisterViewWithRegion(RegionNames.NavRegion, typeof(NavigationItem));    _regionManager.RegisterViewWithRegion(RegionNames.MainRegion,                                             () =&gt; _container.Resolve&lt;NavigationContainer&gt;() );    _regionManager.RegisterViewWithRegion(RegionNames.NavDemoActionRegion, typeof(ActionController));     //  注意注册的类型的必须是object，因为Prism无法确定视图的类型，所以就用了object    _container.RegisterType&lt;object, ViewA&gt;(ViewNames.ViewA);    _container.RegisterType&lt;object, ViewB&gt;(ViewNames.ViewB);    _container.RegisterType&lt;object, ViewC&gt;(ViewNames.ViewC);&#125;\n\n\n\nViewA和ViewB都实现了INavigationAware接口，不同之处在于ViewA是在其对应的ViewModel ViewAViewModel类中实现的，而ViewB则直接在Code Behind中实现的。Prism对MVVM提供了良好的支持，因此既可以选择在视图中实现该接口也可以在对应的ViewModel中实现。\npublic bool IsNavigationTarget(NavigationContext navigationContext)&#123;    return false;&#125;\n\n\n\n在ViewB中，IsNavigationTarget方法返回了false，而ViewA中则返回了true。可以通过点击三个按钮进行页面跳转，观察log可以发现，ViewA只创建了一次，而ViewB则每次都要重新创建。还有就是在跳转到ViewA的时候传递了参数，可以在OnNavigatedTo方法中取出参数。\npublic void OnNavigatedTo(NavigationContext navigationContext)&#123;    UriQuery query = navigationContext.Parameters;    string time = query[&quot;Time&quot;];    logger.Log(string.Format(&quot;ViewA: 现在时间 &#123;0&#125;&quot;, time), Category.Info, Priority.Medium);&#125;\n\n","categories":["编程技术","DotNet"],"tags":["WPF","Prism"]},{"title":"Prism之使用EventAggregation进行模块间通信","url":"/2015/08/15/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/Prism%E4%B9%8B%E4%BD%BF%E7%94%A8EventAggregation%E8%BF%9B%E8%A1%8C%E6%A8%A1%E5%9D%97%E9%97%B4%E9%80%9A%E4%BF%A1/","content":"在开发Silverlight程序的时候，经常需要在不同的组件间进行通信。比如点击一个button，可能就需要改变另一个控件的内容。比较直接的办法是使用事件，当然使用MVVM的时候也可以使用command，还可以定义一些全局的变量来保存一些信息等。\nPrism提供了几种用于组件间通信的途径，可以使用RegionContext使不同的视图共享数据，也可以借助于容器的力量来使用共享的service来进行通信，或者使用command等。除此之外，Prism还提供了一种基于事件的多播发布&#x2F;订阅方式的通信机制，使不同的组件之间能够以一种松散耦合的方式来进行通信。这就是本文要介绍的事件聚合(Event Aggregation)。\n事件聚合的过程有点像收听广播，首先要有个固定的频率，然后内容就会在这个频率上广播出去，至于有没有人收听，广播电台是不知道的，它只是把内容播送了出去。而其他的人想听广播也不用跑到广播电台，只要知道频率，收听这个频率就可以了。联系广播电台和听众的就是这个频率。\n在事件聚合的过程中，事件发布方(publisher)相当于广播电台，事件接收方(Subscriber)相当于听众，而事件自然就相当于频率了。\n使用Event Aggregation很简单，只需要知道一个接口和一个类基本上就足够了。接口是IEventAggregator，类是CompositePresentationEvent。\n要想发布或订阅事件，自然得先要有事件，所以第一件工作就是要定义事件。Prism提供了一个事件基类CompositePresentationEvent，自定义的事件只需要继承这个类就可以了，泛型代表的是事件发生过程中需要传递的参数类型。如：\npublic class ReceiveNewEmailEvent : CompositePresentationEvent&lt;MailViewModel&gt;&#123;&#125;\n\n\n\n上面定义了一个事件，用于在收到新邮件时使用，传递的参数是一个邮件的ViewModel。\n使用的时候也很简单，使用IEventAggregator接口中的GetEvent方法来获取事件，然后要么发布出去，要么订阅一下就可以了。\n下面是当收到一封新的邮件的时候，发布事件的代码：\npublic class EmailReceiver&#123;    private IEventAggregator _eventAggregator;    public EmailReceiver(IEventAggregator eventAggregator)    &#123;        _eventAggregator = eventAggregator;    &#125;     public void ReceiveEmail()    &#123;        if (_email != null)        &#123;   //  当接收到新邮件时，就发布事件，所有订阅了该事件的组件都会接到通知            _eventAggregator.GetEvent&lt;ReceiveNewEmailEvent&gt;()                .Publish(_email);        &#125;    &#125;&#125;\n\n\n\n可以看到我们直接在构造函数中传递了IEventAggregator类型的参数，如果使用Prism来搭建Silverlight程序的话，那么在默认的Bootstrapper中会在容器中添加IEventAggregator的实例，所以并不需要我们做其它更多的工作。如果对Prism或Bootstrapper不太了解的话，可以参考这两篇文章(Prism简介，Bootstrapper)。\n下面是订阅ReceiveNewEmail事件的代码：\npublic class MailBox&#123;    public MailBox(IEventAggregator eventAggregator)    &#123;        eventAggregator.GetEvent&lt;ReceiveNewEmailEvent&gt;()            .Subscribe(OnReceivedNewEmail);    &#125;     //  该方法必须为public    public void OnReceivedNewEmail(MailViewModel mail)    &#123;        //  do something    &#125;&#125;\n\n\n\n这样，发布出去的事件马上就可以被接收到，而且两个组件只是依赖于事件，彼此之间是松散耦合的。\n事件可以订阅，也可以退订，甚至可以有选择地接受某些特定的事件。下面以一个模拟的简单的邮箱客户端来演示一下Event Agregation的使用场景。\n\n如图所示,左边是邮件列表，会有一个定时器每隔两秒钟接收到一封邮件，这时邮箱客户端会更新邮件列表，点击左边的列表，会在右边显示邮件的内容。如果点击’将该发信人加入黑名单’，则不会再接受来自该发件人的邮件，如果点击断开连接，则停止接受邮件，再次点击会继续接收邮件。需求大致就是这样了。\n首先在启动程序的时候开启一个定时器，每隔两秒钟会接收一封邮件，并发布事件通知有新邮件：\npublic class EmailReceiver&#123;    public void Run()    &#123;        var timer = new DispatcherTimer();        timer.Tick += (s, e) =&gt; EventAggregatorRepository.EventAggregator                                    .GetEvent&lt;ReceiveNewEmailEvent&gt;()                                    .Publish(EmailRepository.GetMail());        timer.Interval = new TimeSpan(0, 0, 0, 2);        timer.Start();    &#125; &#125;\n\n\n\nMailList组件会订阅这个事件，并对邮件列表进行更新：\npublic partial class MailList : UserControl&#123;    private readonly ObservableCollection&lt;MailViewModel&gt; _mails =         new ObservableCollection&lt;MailViewModel&gt;();     //  黑名单列表    private readonly List&lt;string&gt; _refusedSenders = new List&lt;string&gt;();             public MailList()    &#123;        InitializeComponent();         MailItems.ItemsSource = _mails;         SubscribeReceiveEmailEvent();    &#125;     private void SubscribeReceiveEmailEvent()    &#123;   //  订阅事件的Subscribe方法提供了几个重载方法，除了最简单的直接订阅之外,        //  还可以指定线程类型(比如如果直接使用System.Threading.Timer的话，        //  就必须使用ThreadOption.UIThread，否则会报错)，以及是否持有订阅者的引用,        //  或者指定一个filter来对事件进行过滤        //  本例中使用的filter是拒绝接受黑名单中包含的发件人发过来的邮件        EventAggregatorRepository.EventAggregator            .GetEvent&lt;ReceiveNewEmailEvent&gt;()            .Subscribe(OnReceiveNewEmail, ThreadOption.UIThread,            true, (mail) =&gt; !_refusedSenders.Contains(mail.From));    &#125;     public void OnReceiveNewEmail(MailViewModel mail)    &#123;        _mails.Insert(0, mail);    &#125;&#125;\n\n\n\n当点击左边的邮件列表的时候，会在右边的MailContent组件中显示该邮件的信息，这个过程也是通过Event Aggregation来完成的。\n//  NotificationObject是Prism提供的对MVVM的支持的ViewModel的基类//  可以简化INotifyPropertyChanged接口的实现方式public class MailViewModel : NotificationObject&#123;    public MailViewModel()    &#123;   //  DelegateCommand也是Prism提供的一种Command类型        ViewMailCommand = new DelegateCommand(OnViewMail);    &#125;             public ICommand ViewMailCommand &#123; get; private set; &#125;     public void OnViewMail()    &#123;        this.HasRead = true;        EventAggregatorRepository.EventAggregator            .GetEvent&lt;ViewEmailEvent&gt;()            .Publish(this);    &#125;&#125;\n\n\n\n当点击时，会进入相应的Command逻辑，而MailContent则订阅了ViewEmailEvent，并将传递过来的MailViewModel显示出来：\npublic partial class MailContent : UserControl&#123;    public MailContent()    &#123;        InitializeComponent();         EventAggregatorRepository.EventAggregator            .GetEvent&lt;ViewEmailEvent&gt;()            .Subscribe(OnViewEmail);    &#125;     public void OnViewEmail(MailViewModel mail)    &#123;        this.DataContext = mail;    &#125;&#125;\n\n\n\n当点击将该发信人加入黑名单按钮时,会发布AddRefuseSenderEvent，而接收到这一事件的MailList组件则会更新黑名单，这样filter就会过滤掉黑名单中已经存在的发件人的邮件：\npublic void OnRefusedSendersAdded(string sender)&#123;    if (!_refusedSenders.Contains(sender))    &#123;        _refusedSenders.Add(sender);    &#125;&#125;\n\n\n\n如果点击了断开连接或重新连接的话，会发布一个ConnectOrDisconnectMailServerEvent事件。Prism的事件基类并不支持不带参数的事件，也就是说没有办法创建一个不需要传参的事件。所以这里我们使用了object类型作为参数类型，在传递参数的时候直接传了个null过去。\nEventAggregatorRepository.EventAggregator    .GetEvent&lt;ConnectOrDisconnectMailServerEvent&gt;()    .Publish(null);\n\n\n\n而当MailList接收到该事件的时候，首先判断一下是否已经订阅了ReceiveNewEmailEvent事件，如果订阅了就退订，如果没有订阅就重新订阅。这样来达到开启或关闭接收邮件的目的：\npublic partial class MailList : UserControl&#123;    private readonly ObservableCollection&lt;MailViewModel&gt; _mails =         new ObservableCollection&lt;MailViewModel&gt;();     private readonly List&lt;string&gt; _refusedSenders = new List&lt;string&gt;();             public MailList()    &#123;        InitializeComponent();         SubscribeReceiveEmailEvent();         EventAggregatorRepository.EventAggregator            .GetEvent&lt;ConnectOrDisconnectMailServerEvent&gt;()            .Subscribe(OnConnectOrDisconnectMailServer);    &#125;     public void OnConnectOrDisconnectMailServer(object obj)    &#123;        //  判断是否已经订阅了该事件        bool hasSubscribed = EventAggregatorRepository.EventAggregator            .GetEvent&lt;ReceiveNewEmailEvent&gt;()            .Contains(OnReceiveNewEmail);        if (hasSubscribed)        &#123;            UnsubscribeReceiveEmailEvent();        &#125;        else        &#123;            SubscribeReceiveEmailEvent();        &#125;    &#125;     private void SubscribeReceiveEmailEvent()    &#123;        EventAggregatorRepository.EventAggregator            .GetEvent&lt;ReceiveNewEmailEvent&gt;()            .Subscribe(OnReceiveNewEmail, ThreadOption.UIThread,            true, (mail) =&gt; !_refusedSenders.Contains(mail.From));    &#125;     private void UnsubscribeReceiveEmailEvent()    &#123;   //  退订事件        EventAggregatorRepository.EventAggregator            .GetEvent&lt;ReceiveNewEmailEvent&gt;()            .Unsubscribe(OnReceiveNewEmail);    &#125;     public void OnReceiveNewEmail(MailViewModel mail)    &#123;        _mails.Insert(0, mail);    &#125;&#125;\n\n\n\n由于EventAggregation并不需要建立在Prism装配的程序上，为了操作简便，所以并没有使用Prism来管理这个程序，当然也就没有使用容器。所以我用了一个static的全局变量来保存了一个IEventAggregator的实例。\n本文为了演示，所以大量地使用了Event Aggregation，希望大家在工作中要仔细斟酌使用，虽然用起来很灵活，但是如果事件太多的话，也会让人有无从下手的感觉，增加维护的难度。\n","categories":["编程技术","DotNet"],"tags":["WPF","Prism"]},{"title":"Prism简介","url":"/2015/07/11/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/Prism%E7%AE%80%E4%BB%8B/","content":"Prism是由微软Patterns &amp; Practices团队开发的项目，目的在于帮助开发人员构建松散耦合的、更灵活、更易于维护并且更易于测试的WPF应用或是Silverlight应用以及Windows Phone 7应用。使用Prism可以使程序开发更趋于模块化，整个项目将由多个离散的、松耦合的模块组成，而各个模块又可以又不同的开发者或团队进行开发、测试和部署。目前Prism的最新版本是Prism 4，于2010年11月12日发布。Prism有很完整的文档以及丰富的示例程序。在这里我们仅针对于Silverlight程序的开发。\n在下载Prism安装包并安装完成后，会在目标文件夹中发现很多文件。\n\n推荐首先运行RegisterPrismBinaries.bat文件，这样在开发基于Prism的程序时可以更方便地添加引用程序集。\n\n使用Prism之前，需要了解一些概念，下面通过一个非常简单的小程序来了解一下Prism。\n1.打开Visual Studio 2010，新建一个Silverlight Application项目，并添加对Prism的引用。再创建三个Silverlight类库工程。\n\n2.在Contract工程下新建一个接口，叫做ITextProvider。\npublic interface ITextProvider&#123;\tstring GetText();&#125;\n3.在其它的三个项目中都引用Contract项目。\n4.在PrismStarter工程下新建一个TextProvider类并实现ITextProvider接口。\npublic class TextProvider : ITextProvider&#123; \tprivate int i = 0; \tpublic string GetText() \t&#123; \t \ti++;  \t \treturn string.Format(&quot;From TextProvider [&#123;0&#125;]&quot;, i); \t&#125;&#125;\n\n5.删除PrismStarter项目中自动生成的MainPage.xaml，创建一个新的UserControl，叫做Shell。页面代码如下：\n&lt;UserControl x:Class=&quot;PrismStarter.Shell&quot;    xmlns=&quot;http://schemas.microsoft.com/winfx/2006/xaml/presentation&quot;    xmlns:x=&quot;http://schemas.microsoft.com/winfx/2006/xaml&quot;    xmlns:d=&quot;http://schemas.microsoft.com/expression/blend/2008&quot;    xmlns:mc=&quot;http://schemas.openxmlformats.org/markup-compatibility/2006&quot;    xmlns:prism=&quot;http://www.codeplex.com/prism&quot;    mc:Ignorable=&quot;d&quot;    d:DesignHeight=&quot;300&quot; d:DesignWidth=&quot;400&quot;&gt;         &lt;Grid x:Name=&quot;LayoutRoot&quot; Background=&quot;White&quot;&gt;        &lt;Grid.RowDefinitions&gt;            &lt;RowDefinition Height=&quot;100&quot; /&gt;            &lt;RowDefinition Height=&quot;100&quot; /&gt;            &lt;RowDefinition Height=&quot;100&quot; /&gt;        &lt;/Grid.RowDefinitions&gt;                 &lt;TextBlock FontSize=&quot;30&quot; VerticalAlignment=&quot;Center&quot; HorizontalAlignment=&quot;Center&quot; Text=&quot;Prism Starter&quot; /&gt;                 &lt;ContentControl Grid.Row=&quot;1&quot; HorizontalContentAlignment=&quot;Stretch&quot; prism:RegionManager.RegionName=&quot;RegionA&quot; /&gt;         &lt;ContentControl Grid.Row=&quot;2&quot; HorizontalContentAlignment=&quot;Stretch&quot; prism:RegionManager.RegionName=&quot;RegionB&quot; /&gt;    &lt;/Grid&gt;&lt;/UserControl&gt;\n\n\n\n6.在ModuleA工程中添加对Prism程序集的引用。并添加一个UserControl叫做ViewA，页面代码为：\n&lt;Grid :Name=&quot;LayoutRoot&quot; Background=&quot;White&quot;&gt; &lt;TextBlock x:Name=&quot;textModuleA&quot; FontSize=&quot;30&quot; VerticalAlignment=&quot;Center&quot; HorizontalAlignment=&quot;Center&quot; /&gt; &lt;/Grid&gt;\n\nCodeBehind中的代码为：\npublic partial class ViewA : UserControl&#123;     public ViewA(ITextProvider textProvider)     &#123;         InitializeComponent();         this.Loaded += (s, e) =&gt;         &#123;            textModuleA.Text = string.Format(&quot;Module A &#123;0&#125;&quot;, textProvider.GetText());         &#125;;     &#125;&#125;\n\n7.在ModuleA工程中添加一个类叫做ModuleA，并实现接口IModule。\npublic class ModuleA : IModule&#123;    private IRegionManager _regionManager;     public ModuleA(IRegionManager regionManager)    &#123;        _regionManager = regionManager;    &#125;     public void Initialize()    &#123;        _regionManager.RegisterViewWithRegion(&quot;RegionA&quot;, typeof(ViewA));    &#125;&#125;\n\n\n\n\n\n注意这里的RegionA对应于Shell页面中的RegionName。\n8.在ModuleB工程中重复6、7过程，只是将A替换为B。\n9.在PrismStarter工程中添加对ModuleA和ModuleB的引用。\n10.在PrismStarter工程中添加一个PrismStarterBootstrapper类，并继承UnityBootstrapper。\npublic class PrismStarterBootstrapper : UnityBootstrapper&#123;    protected override DependencyObject CreateShell()    &#123;        return this.Container.TryResolve&lt;Shell&gt;();    &#125;     protected override void InitializeShell()    &#123;   //  控制页面在初始化时显示Shell页面        App.Current.RootVisual = (UIElement)this.Shell;    &#125;     protected override void ConfigureModuleCatalog()    &#123;   //  注册Module。在实际开发中可以使用xaml做配置文件，        //  这样就可以将PrismStarter与ModuleA和ModuleB完全解耦，也就不再需要引用这两个项目        Type moduleAType = typeof(ModuleA.ModuleA);        ModuleInfo moduleA = new ModuleInfo        &#123;            ModuleName = moduleAType.Name,            ModuleType = moduleAType.AssemblyQualifiedName,        &#125;;         Type moduleBType = typeof(ModuleB.ModuleB);        ModuleInfo moduleB = new ModuleInfo        &#123;            ModuleName = moduleBType.Name,            ModuleType = moduleBType.AssemblyQualifiedName,        &#125;;         this.ModuleCatalog.AddModule(moduleA);        this.ModuleCatalog.AddModule(moduleB);    &#125;     protected override void ConfigureContainer()    &#123;   //  注册一下TextProvider，这样在通过容器请求ITextProvider时会返回TextProvider实例        base.ConfigureContainer();        this.Container.RegisterInstance&lt;ITextProvider&gt;(new TextProvider());    &#125;&#125;\n\n\n\n11.最后一步，打开App.xaml.cs，修改Application_Startup方法\nprivate void Application_Startup(object sender, StartupEventArgs e)&#123;    PrismStarterBootstrapper bootstrapper = new PrismStarterBootstrapper();    bootstrapper.Run();&#125;\n\n\n\n运行程序，结果如下：\n\n下面简单介绍一下这个小例子中涉及到的一些概念。\nBootstrapper: 在程序中使用框架需要找到一个切入点，将框架植入进去，将一部分功能委托给框架来实现。在Silverlight中使用Prism的切入点就是App.xaml.cs中的Application_Startup方法。一般来说，这个方法中只是指定页面最先加载的页面，但是我们把默认的逻辑去掉，取而代之的是Bootstrapper(在本例中就是PrismStarterBootstrapper)。当调用Bootstrapper.Run方法时，它会完成一些准备工作，如一些配置等。因此你会发现，使用Prism后，启动程序时会比正常启动要慢一些，就是因为Bootstrapper做了许多工作。\nContainer: 依赖注入容器。在程序中使用依赖注入的好处到处都可以找的到。在Silverlight中使用容器来管理各个组件的一个很明显的好处就是使用单例来降低内存使用。否则每次加载一个页面都需要重新创建一个也很耗费资源的。当然好处不只这些，通过容器来注入一些服务(如本例中的IRegionManager和ITextProvider)显得相当方便。\nModule: Prism帮助我们把程序分解成一个个功能模块，这些功能模块就叫做Module，通常一个工程就是一个Module。由于Module彼此是独立的，但是在运行时需要将它们整合到一起，因此Prism需要知道Module的存在，这里就涉及到了ModuleCatalog, ModuleCatalog就是Module的容器，里面包含了所有Module的信息，以ModuleInfo的形式存在。ModuleInfo就是对Module的抽象，包含Module的名字，类型，依赖等一些信息。\nShell: 相当于程序的入口，初始界面，还能够提供类似ASP.Net中的母版页的功能。Shell必须由Bootstrapper创建，因为Shell需要使用的一些service，比如RegionManager等，需要在Shell显示前注册。\nRegion: 相当于ASP.Net中的ContentPlaceHolder(是这么叫的吧？)，起到占位符的作用，如本例中Shell中有两个Region——RegionA和RegionB，定义了两块区域。在Module的初始化过程中，通过IRegionManager将Module中的页面放进了定义好的Region中。IRegionManager负责管理Region，可以通过它向Region中注册View，进行导航等。\nPrism的功能当然远不止这么简单，它还提供对MVVM模式的支持，对导航的支持等，在后续文章中会逐步介绍。希望能够通过本文让大家对Prism有一定的了解。\n代码下载\n","categories":["编程技术","DotNet"],"tags":["WPF","Prism"]},{"title":"[译]RabbitMQ教程C#版 - Hello World","url":"/2018/04/14/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/RabbitMQ%E6%95%99%E7%A8%8BC#%E7%89%88%20-%20Hello%20World/","content":"\n\n先决条件本教程假定 RabbitMQ 已经安装，并运行在localhost 标准端口（5672）。如果你使用不同的主机、端口或证书，则需要调整连接设置。\n\n从哪里获得帮助如果您在阅读本教程时遇到困难，可以通过邮件列表 联系我们。\n\n介绍#RabbitMQ 是一个消息中间件：它接收并转发消息。您可以把它想象为一个邮局：当您把需要寄出的邮件投递到邮箱，邮差最终会把邮件送给您的收件人。在这个比喻中，RabbitMQ 就是一个邮箱，也可以理解成邮局和邮递员。\nRabbitMQ 和邮局的主要区别在于它不处理纸张，而是接收、存储和转发二进制数据块 - _消息_。\nRabbitMQ 和消息传递通常使用一些术语。\n生产 的意思无非就是发送。发送消息的程序就是一个 _生产者_：\n\n队列 就是 RabbitMQ 内部“邮箱”的名称。虽然消息流经 RabbitMQ 和您的应用程序，但它们只能存储在 队列 中。_队列_ 只受主机的内存和磁盘的限制，它本质上就是一个很大的消息缓冲区。多个 生产者 可以发送消息到一个队列，并且多个 消费者 可以尝试从一个 队列 接收数据。这就是我们代表队列的方式：\n\n消费 与接收有相似的含义，等待接收消息的程序就是一个 _消费者_：\n\n\n注意：生产者、消费者和中间件不是必须部署在同一主机上，实际上在大多数应用程序中它们也不是这样的。\n\n“Hello World”#使用 .NET &#x2F; C＃Client\n在教程的这一部分，我们将用 C＃ 编写两个程序：一个发送单条消息的生产者，以及接收消息并将其打印出来的消费者。我们将忽略 .NET 客户端 API 中的一些细节，专注于更简单的开始。这是一个消息传递的“Hello World”。\n在下图中，P是我们的生产者，C是我们的消费者。中间的盒子是队列 - RabbitMQ 代表消费者保存的消息缓冲区。\n\n\n.NET 客户端库\nRabbitMQ 支持多种协议，本教程使用AMQP 0-9-1，它是一种开放的、通用的消息传递协议。RabbitMQ 提供了一些针对不同 语言环境 的客户端，我们将使用 RabbitMQ 提供的 .NET 客户端。\n客户端支持 .NET Core 以及 .NET Framework 4.5.1+。本教程将使用 .NET Core，因此您需要确保客户端已 安装 并且路径添加到PATH系统变量。\n您也可以使用 .NET Framework 来完成本教程，但设置步骤会有所不同。\nRabbitMQ .NET 客户端 5.0 及更高版本通过 nuget 发布。\n本教程假定您在 Windows 上使用 PowerShell。在 MacOS 和 Linux 上，几乎所有 shell 也都可以正常工作。\n\n安装#首先让我们验证您在PATH系统变量是否有 .NET Core 工具链：\ndotnet --help\n\n应该产生帮助信息。\n现在，让我们生成两个项目，一个用于发布者，另一个用于消费者：\ndotnet new console --name Send\nmv Send/Program.cs Send/Send.cs\ndotnet new console --name Receive\nmv Receive/Program.cs Receive/Receive.cs\n\n这将创建两个名为Send和Receive的新目录。\n然后，我们添加客户端依赖项。\ncd Send\ndotnet add package RabbitMQ.Client\ndotnet restore\ncd ../Receive\ndotnet add package RabbitMQ.Client\ndotnet restore\n\n我们已经建立了 .NET 项目，现在我们可以编写一些代码。\n发送#\n我们将调用我们的消息发布者（发送者）Send.cs和我们的消息消费者（接收者）Receive.cs。发布者将连接到 RabbitMQ，发送一条消息，然后退出。\n在 Send.cs 中，我们需要使用一些命名空间：\nusing System;\nusing RabbitMQ.Client;\nusing System.Text;\n\n设置类：\nclass Send\n&#123;\n    public static void Main()\n    &#123;\n        ...\n    &#125;\n&#125;\n\n然后，我们可以创建一个连接，连接到服务器：\nclass Send\n&#123;\n    public static void Main()\n    &#123;\n        var factory = new ConnectionFactory() &#123; HostName = &quot;localhost&quot; &#125;;\n        using (var connection = factory.CreateConnection())\n        &#123;\n            using (var channel = connection.CreateModel())\n            &#123;\n                ...\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\n该连接抽象了套接字连接，并为我们处理协议版本的协商和身份验证等。在这里，我们连接的是本地机器上的代理， 因此是localhost。如果我们想连接到其他机器上的代理，我们只需在此指定其名称或 IP 地址。\n接下来，我们创建一个通道，该 API 的主要功能是把获得信息保存起来。\n想要发送消息，我们必须为需要发送的消息声明一个队列，然后我们就可以把消息发布到队列中：\nusing System;\nusing RabbitMQ.Client;\nusing System.Text;\n\nclass Send\n&#123;\n    public static void Main()\n    &#123;\n        var factory = new ConnectionFactory() &#123; HostName = &quot;localhost&quot; &#125;;\n        using(var connection = factory.CreateConnection())\n        using(var channel = connection.CreateModel())\n        &#123;\n            channel.QueueDeclare(queue: &quot;hello&quot;,\n                                 durable: false,\n                                 exclusive: false,\n                                 autoDelete: false,\n                                 arguments: null);\n\n            string message = &quot;Hello World!&quot;;\n            var body = Encoding.UTF8.GetBytes(message);\n\n            channel.BasicPublish(exchange: &quot;&quot;,\n                                 routingKey: &quot;hello&quot;,\n                                 basicProperties: null,\n                                 body: body);\n            Console.WriteLine(&quot; [x] Sent &#123;0&#125;&quot;, message);\n        &#125;\n\n        Console.WriteLine(&quot; Press [enter] to exit.&quot;);\n        Console.ReadLine();\n    &#125;\n&#125;\n\n声明队列是 幂等 的 - 只有当它不存在时才会被创建。消息内容是一个字节数组，所以您可以用喜欢的任意方式编码。\n当上面的代码完成运行时，通道和连接将被释放。这就是我们的发布者。\n（Send.cs 源码）\n\n发送不起作用！\n如果这是您第一次使用 RabbitMQ，并且您没有看到“已发送”消息，那么您可能会挠着头想知道错误出在什么地方。也许是代理程序启动时没有足够的可用磁盘空间（默认情况下，它至少需要50 MB空闲空间），因此拒绝接收消息。必要时检查代理程序日志文件来确认和减少限制。配置文件 文档 将告诉您如何设置disk_free_limit。\n\n接收#至于消费者，它是把消息从 RabbitMQ 拉取过来。因此，与发布消息的发布者不同，我们会保持消费者持续不断地运行，监听消息并将其打印出来。\n\n代码（在 Receive.cs 中）具有与Send差不多一样的using声明：\nusing RabbitMQ.Client;\nusing RabbitMQ.Client.Events;\nusing System;\nusing System.Text;\n\n设置与发布者相同；我们开启一个连接和一个通道，并声明我们将要使用的队列。请注意，这需要与Send发布到的队列相匹配。\nclass Receive\n&#123;\n    public static void Main()\n    &#123;\n        var factory = new ConnectionFactory() &#123; HostName = &quot;localhost&quot; &#125;;\n        using (var connection = factory.CreateConnection())\n        &#123;\n            using (var channel = connection.CreateModel())\n            &#123;\n                channel.QueueDeclare(queue: &quot;hello&quot;,\n                                     durable: false,\n                                     exclusive: false,\n                                     autoDelete: false,\n                                     arguments: null);\n                ...\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\n请注意，我们在这里也声明了队列。因为我们可能会在发布者之前启动消费者，所以我们希望在我们尝试从它中消费消息之前确保队列已存在。\n我们即将告诉服务器将队列中的消息传递给我们。由于它会异步推送消息，因此我们提供了一个回调。这就是EventingBasicConsumer.Received事件处理程序所做的事情。\nusing RabbitMQ.Client;\nusing RabbitMQ.Client.Events;\nusing System;\nusing System.Text;\n\nclass Receive\n&#123;\n    public static void Main()\n    &#123;\n        var factory = new ConnectionFactory() &#123; HostName = &quot;localhost&quot; &#125;;\n        using(var connection = factory.CreateConnection())\n        using(var channel = connection.CreateModel())\n        &#123;\n            channel.QueueDeclare(queue: &quot;hello&quot;,\n                                 durable: false,\n                                 exclusive: false,\n                                 autoDelete: false,\n                                 arguments: null);\n\n            var consumer = new EventingBasicConsumer(channel);\n            consumer.Received += (model, ea) =&gt;\n            &#123;\n                var body = ea.Body;\n                var message = Encoding.UTF8.GetString(body);\n                Console.WriteLine(&quot; [x] Received &#123;0&#125;&quot;, message);\n            &#125;;\n            channel.BasicConsume(queue: &quot;hello&quot;,\n                                 autoAck: true,\n                                 consumer: consumer);\n\n            Console.WriteLine(&quot; Press [enter] to exit.&quot;);\n            Console.ReadLine();\n        &#125;\n    &#125;\n&#125;\n\n（Receive.cs 源码）\n组合在一起#打开两个终端。\n运行消费者：\ncd Receive\ndotnet run\n\n运行生产者：\ncd Send\ndotnet run\n\n消费者将打印它通过 RabbitMQ 从发布者处获得的消息。消费者将继续运行、等待新消息（按Ctrl-C将其停止），可以尝试从开启另一个终端运行发布者。\n接下来可以跳转到 教程[2]，构建一个简单的工作队列。\n写在最后#本文翻译自 RabbitMQ 官方教程 C# 版本。如本文介绍内容与官方有所出入，请以官方最新内容为准。水平有限，翻译的不好请见谅，如有翻译错误还请指正。\n\n原文链接：RabbitMQ tutorial - “Hello World!”\n实验环境：RabbitMQ 3.7.4 、.NET Core 2.1.3、Visual Studio Code\n最后更新：2018-03-13\n\n","categories":["编程技术","DotNet"],"tags":["RabbitMQ"]},{"title":"[译]RabbitMQ教程C#版 - 主题","url":"/2018/04/07/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/RabbitMQ%E6%95%99%E7%A8%8BC#%E7%89%88%20-%20%E4%B8%BB%E9%A2%98/","content":"\n先决条件本教程假定 RabbitMQ 已经安装，并运行在localhost 标准端口（5672）。如果你使用不同的主机、端口或证书，则需要调整连接设置。\n从哪里获得帮助如果您在阅读本教程时遇到困难，可以通过邮件列表 联系我们。\n\n主题#（使用 .NET 客户端）\n在 教程[4] 中，我们改进了我们日志系统。我们用direct交换器替换了只能呆滞广播消息的fanout交换器，从而可以有选择性的接收日志。\n虽然使用direct交换器改进了我们的系统，但它仍然有局限性 - 不能基于多个标准进行路由。\n在我们的日志系统中，我们可能不仅要根据日志的严重性订阅日志，可能还要根据日志分发源来订阅日志。或许您可能从 unix syslog 工具中了解过这种概念，syslog 工具在路由日志的时候是可以既基于严重性（info&#x2F;warn&#x2F;crit…）又基于设备（auth&#x2F;cron&#x2F;kern…）的。\n这种机制会给我们带来极大的灵活性 - 我们可以仅监听来自cron的关键错误日志，与此同时，监听来自kern的所有日志。\n要在我们的日志系统中实现这一特性，我们需要学习更复杂的topic交换器。\nTopic交换器#发送到topic交换器的消息不能随意指定routing key，它必须是一个由点分割的单词列表，这些单词可以是任意内容，但通常会在其中指定一些与消息相关的特性。请看一些合法的路由键示例：stock.usd.nyse，nyse.vmw，quick.orange.rabbit，路由键可以包含任意数量的单词，但不能超过255个字节的上限。\nbinding key也必须是相同的形式，topic交换器的背后逻辑与direct交换器类似 - 使用指定路由键发送的消息会被分发到与其绑定键匹配的所有队列中。不过对于绑定键来说，有两个重要的特殊情况需要注意：\n\n*（星号）可以代替一个单词。\n#（哈希）可以代替零个或多个单词。\n\n下图示例是对上述内容最简单的解释：\n\n在这个示例中，我们打算发送的消息全是用来描述动物的，这些消息会使用由三个单词（两个点）组成的路由键来发送。在路由键中，第一个单词用来描述行动速度、第二个是颜色、第三个是物种，即：&lt;speed&gt;.&lt;colour&gt;.&lt;species&gt;。\n我们创建了三个绑定：Q1绑定了键.orange.，Q2绑定了键*.*.rabbit和lazy.#。\n这些绑定可以被概括为：\n\nQ1对所有橙色的动物感兴趣。\nQ2对兔子以及所有行动缓慢的动物感兴趣。\n\n路由键为quick.orange.rabbit的消息会被发送到这两个队列，消息lazy.orange.elephant也会被发送到这两个队列。另外，quick.orange.fox只会进入第一个队列，lazy.brown.fox只会进入第二个队列。lazy.pink.rabbit只会被发送到第二个队列一次，尽管它匹配了两个绑定（避免了消息重复）。quick.brown.fox没有匹配的绑定，因此它将会被丢弃。\n如果我们打破约定，发送使用一个或四个单词（例如：orange和quick.orange.male.rabbit）作路由键的消息会发生什么？答案是，这些消息因为没有匹配到任何绑定，将被丢弃。\n但是，另外，例如路由键为lazy.orange.male.rabbit的消息，尽管它有四个单词，也会匹配最后一个绑定，并将被发送到第二个队列。\n\nTopics 交换器topic交换器的功能是很强大的，它可以表现出一些其他交换器的行为。当一个队列与键＃（哈希）绑定时， 它会忽略路由键，接收所有消息，这就像fanout交换器一样。当特殊字符*（星号）和＃（哈希）未在绑定中使用时，topic交换器的行为就像direct交换器一样。\n\n组合在一起#我们将要在我们的日志系统中使用topic交换器，首先假设日志的路由键有两个单词组成：&lt;facility&gt;.&lt;severity&gt;。\n代码与上一篇 教程 中的代码几乎相同。\nEmitLogTopic.cs的代码：\nusing System;\nusing System.Linq;\nusing RabbitMQ.Client;\nusing System.Text;\n\nclass EmitLogTopic\n&#123;\n    public static void Main(string[] args)\n    &#123;\n        var factory = new ConnectionFactory() &#123; HostName = &quot;localhost&quot; &#125;;\n        using(var connection = factory.CreateConnection())\n        using(var channel = connection.CreateModel())\n        &#123;\n            channel.ExchangeDeclare(exchange: &quot;topic_logs&quot;,\n                                    type: &quot;topic&quot;);\n\n            var routingKey = (args.Length &gt; 0) ? args[0] : &quot;anonymous.info&quot;;\n            \n            var message = (args.Length &gt; 1)\n                          ? string.Join(&quot; &quot;, args.Skip(1).ToArray())\n                          : &quot;Hello World!&quot;;\n            var body = Encoding.UTF8.GetBytes(message);\n            \n            channel.BasicPublish(exchange: &quot;topic_logs&quot;,\n                                 routingKey: routingKey,\n                                 basicProperties: null,\n                                 body: body);\n                                 \n            Console.WriteLine(&quot; [x] Sent &#39;&#123;0&#125;&#39;:&#39;&#123;1&#125;&#39;&quot;, routingKey, message);\n        &#125;\n    &#125;\n&#125;\n\nReceiveLogsTopic.cs的代码：\nusing System;\nusing RabbitMQ.Client;\nusing RabbitMQ.Client.Events;\nusing System.Text;\n\nclass ReceiveLogsTopic\n&#123;\n    public static void Main(string[] args)\n    &#123;\n        var factory = new ConnectionFactory() &#123; HostName = &quot;localhost&quot; &#125;;\n        using(var connection = factory.CreateConnection())\n        using(var channel = connection.CreateModel())\n        &#123;\n            channel.ExchangeDeclare(exchange: &quot;topic_logs&quot;, type: &quot;topic&quot;);\n            var queueName = channel.QueueDeclare().QueueName;\n\n            if(args.Length &lt; 1)\n            &#123;\n                Console.Error.WriteLine(&quot;Usage: &#123;0&#125; [binding_key...]&quot;,\n                                        Environment.GetCommandLineArgs()[0]);\n                Console.WriteLine(&quot; Press [enter] to exit.&quot;);\n                Console.ReadLine();\n                Environment.ExitCode = 1;\n                return;\n            &#125;\n\n            foreach(var bindingKey in args)\n            &#123;\n                channel.QueueBind(queue: queueName,\n                                  exchange: &quot;topic_logs&quot;,\n                                  routingKey: bindingKey);\n            &#125;\n\n            Console.WriteLine(&quot; [*] Waiting for messages. To exit press CTRL+C&quot;);\n\n            var consumer = new EventingBasicConsumer(channel);\n            consumer.Received += (model, ea) =&gt;\n            &#123;\n                var body = ea.Body;\n                var message = Encoding.UTF8.GetString(body);\n                var routingKey = ea.RoutingKey;\n                Console.WriteLine(&quot; [x] Received &#39;&#123;0&#125;&#39;:&#39;&#123;1&#125;&#39;&quot;,\n                                  routingKey,\n                                  message);\n            &#125;;\n            channel.BasicConsume(queue: queueName,\n                                 autoAck: true,\n                                 consumer: consumer);\n\n            Console.WriteLine(&quot; Press [enter] to exit.&quot;);\n            Console.ReadLine();\n        &#125;\n    &#125;\n&#125;\n\n请运行以下示例：\n要接收所有日志：\ncd ReceiveLogsTopic\ndotnet run &quot;#&quot;\n\n要接收来自设备kern的所有日志：\ncd ReceiveLogsTopic\ndotnet run &quot;kern.*&quot;\n\n或者，如果您只想监听级别为critical的日志：\ncd ReceiveLogsTopic\ndotnet run &quot;*.critical&quot;\n\n您可以创建多个绑定：\ncd ReceiveLogsTopic\ndotnet run &quot;kern.*&quot; &quot;*.critical&quot;\n\n使用路由键kern.critical发出日志：\ncd EmitLogTopic\ndotnet run &quot;kern.critical&quot; &quot;A critical kernel error&quot;\n\n希望运行这些程序能让您玩得开心。要注意的是，这些代码没有针对路由键和绑定键做任何预设，您可以尝试使用两个以上的路由键参数。\n（ EmitLogTopic.cs 和 ReceiveLogsTopic.cs 的完整源码）\n接下来，在 教程[6] 中将了解如何将往返消息作为远程过程调用。\n写在最后#本文翻译自 RabbitMQ 官方教程 C# 版本。如本文介绍内容与官方有所出入，请以官方最新内容为准。水平有限，翻译的不好请见谅，如有翻译错误还请指正。\n\n原文链接：RabbitMQ tutorial - Topics\n实验环境：RabbitMQ 3.7.4 、.NET Core 2.1.3、Visual Studio Code\n最后更新：2018-09-06\n\n","categories":["编程技术","DotNet"],"tags":["RabbitMQ"]},{"title":"[译]RabbitMQ教程C#版 - 发布订阅","url":"/2018/04/21/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/RabbitMQ%E6%95%99%E7%A8%8BC#%E7%89%88%20-%20%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85/","content":"\n先决条件本教程假定 RabbitMQ 已经安装，并运行在localhost 标准端口（5672）。如果你使用不同的主机、端口或证书，则需要调整连接设置。\n从哪里获得帮助如果您在阅读本教程时遇到困难，可以通过邮件列表 联系我们。\n\n发布&#x2F;订阅#（使用 .NET Client）\n在 教程[2] 中，我们创建了一个工作队列，假设在工作队列中的每一个任务都只被分发给一个 Worker。那么在这一章节，我们要做与之完全不同的事，那就是我们将要把一条消息分发给多个消费者。这种模式被称为“发布&#x2F;订阅”。\n为了说明、体现这种模式，我们将会建一个简单的日志系统。它将会包含两个程序 - 第一个用来发送日志消息，第二个用来接收并打印它们。\n在我们建立的日志系统中，每个接收程序的运行副本都会收到消息。这样我们就可以运行一个接收程序接收消息并将日志写入磁盘；同时运行另外一个接收程序接收消息并将日志打印到屏幕上。\n实质上，发布的日志消息将会被广播给所有的接收者。\n交换器#在教程的前几部分，我们是发送消息到队列并从队列中接收消息。现在是时候介绍 Rabbit 中完整的消息传递模型了。\n让我们快速回顾一下前面教程中的内容：\n\n_生产者_是发送消息的用户应用程序。\n_队列_是存储消息的缓冲区。\n_消费者_是接收消息的用户应用程序。\n\n在 RabbitMQ 中，消息传递模型的核心理念是生产者从来不会把任何消息直接发送到队列，其实，通常生产者甚至不知道消息是否会被分发到任何队列中。\n然而，生产者只能把消息发送给_交换器_。交换器非常简单，一方面它接收来自生产者的消息，另一方面又会把接收的消息推送到队列中。交换器必须明确知道该如何处理收到的消息，应该追加到一个特定队列中？还是应该追加到多个队列中？或者应该把它丢弃？这些规则都被定义在_交换器类型_中。\n\n目前交换器类型有这几种：direct，topic，headers和fanout。我们先重点关注最后一个fanout，我们创建一个这种类型的交换器，将其命名为logs：\nchannel.ExchangeDeclare(&quot;logs&quot;, &quot;fanout&quot;);\n\nfanout类型交换器非常简单，正如您可能从名字中猜出的那样，它会把收到的所有消息广播到它已知的所有队列中。这恰巧是我们的日志系统目前所需要的。\n\n列举交换器要列举出服务器上的交换器，您可以使用非常有用的rabbitmqctl命令行工具：\nsudo rabbitmqctl list_exchanges\n\n执行上述命令后，出现的列表中将会有一些amq.*交换器和默认（未命名）交换器。这些是默认创建的，不过目前您可能用不到它们。\n默认交换器在教程的前些部分，我们对交换器这一概念还一无所知，但仍然可以把消息发送到队列。之所以这样，是因为我们使用了一个用空字符串(&quot;&quot;)标识的默认交换器。\n回顾一下我们之前如何发布消息：\nvar message = GetMessage(args);\nvar body = Encoding.UTF8.GetBytes(message);\nchannel.BasicPublish(exchange: &quot;&quot;,\n                     routingKey: &quot;hello&quot;,\n                     basicProperties: null,\n                     body: body);\n\n第一个参数就是交换器的名称，空字符串表示默认或匿名交换器：将消息路由到routingKey指定的队列（如果存在）中。\n\n现在，我们可以把消息发布到我们指定的交换器：\nvar message = GetMessage(args);\nvar body = Encoding.UTF8.GetBytes(message);\nchannel.BasicPublish(exchange: &quot;logs&quot;,\n                     routingKey: &quot;&quot;,\n                     basicProperties: null,\n                     body: body);\n\n临时队列#您是否还记得之前我们使用过的队列，它们都有一个特定的名称（记得应该是hello和task_queue吧）。给队列命名对我们来说是至关重要的 – 因为我们可能需要多个 Worker 指向同一个队列；当您想要在生产者和消费者之间共享队列时，给队列一个名称也是非常重要的。\n但是，我们创建的日志系统并不希望如此。我们希望监听所有的日志消息，而不仅仅是其中一部分。我们也只对目前流动的消息感兴趣，而不是旧消息。为解决这个问题，我们需要做好两件事。\n首先，我们无论何时连接 Rabbit，都需要一个新的、空的队列。要做到这一点，我们可以使用随机名称来创建队列，或许，甚至更好的方案是让服务器为我们选择一个随机队列名称。\n其次，一旦我们与消费者断开连接，与之相关的队列应该被自动删除。\n在 .NET 客户端中，如果不向QueueDeclare()方法提供任何参数，实际上就是创建了一个非持久化、独占、且自动删除的随机命名队列：\nvar queueName = channel.QueueDeclare().QueueName;\n\n您可以在 队列指南 中了解更多关于exclusive参数和其他队列属性的信息。\n此时，queueName包含一个随机队列名称。例如，它看起来可能像amq.gen-JzTY20BRgKO-HjmUJj0wLg。\n绑定#\n我们已经创建好了一个fanout 交换器和一个队列。现在我们需要告诉交换器把消息发送到我们的队列。而交换器和队列之间的关系就称之为_绑定_。\nchannel.QueueBind(queue: queueName,\n                  exchange: &quot;logs&quot;,\n                  routingKey: &quot;&quot;);\n\n从现在起，logs交换器会把消息追加到我们的队列中。\n\n列举绑定您可以使用（您或许已经猜到了），列举出现有的绑定。\nsudo rabbitmqctl list_bindings\n\n\n组合在一起#\n生产者程序负责分发消息，这与之前的教程看起来没有太大区别。\n最重要的变化是我们现在想把消息发布到我们的logs交换器，而不是匿名交换器。在发送时我们需要提供一个路由键routingKey，但是对于fanout交换器，它的值可以被忽略。这里是EmitLog.cs文件的代码：\nusing System;\nusing RabbitMQ.Client;\nusing System.Text;\n\nclass EmitLog\n&#123;\n    public static void Main(string[] args)\n    &#123;\n        var factory = new ConnectionFactory() &#123; HostName = &quot;localhost&quot; &#125;;\n        using(var connection = factory.CreateConnection())\n        using(var channel = connection.CreateModel())\n        &#123;\n            channel.ExchangeDeclare(exchange: &quot;logs&quot;, type: &quot;fanout&quot;);\n\n            var message = GetMessage(args);\n            var body = Encoding.UTF8.GetBytes(message);\n            channel.BasicPublish(exchange: &quot;logs&quot;,\n                                 routingKey: &quot;&quot;,\n                                 basicProperties: null,\n                                 body: body);\n            Console.WriteLine(&quot; [x] Sent &#123;0&#125;&quot;, message);\n        &#125;\n\n        Console.WriteLine(&quot; Press [enter] to exit.&quot;);\n        Console.ReadLine();\n    &#125;\n\n    private static string GetMessage(string[] args)\n    &#123;\n        return ((args.Length &gt; 0)\n               ? string.Join(&quot; &quot;, args)\n               : &quot;info: Hello World!&quot;);\n    &#125;\n&#125;\n\n（EmitLog.cs 源码）\n如你所见，在建立连接后，我们声明了交换器。这一步非常有必要，因为发布消息到一个不存在的交换器，这种情况是被禁止的。\n如果没有队列绑定到交换器上，消息将会丢失，但这对我们来说并没有什么没问题；如果没有消费者正在监听，我们是可以放心地把消息丢弃的。\nReceiveLogs.cs的代码：\nusing System;\nusing RabbitMQ.Client;\nusing RabbitMQ.Client.Events;\nusing System.Text;\n\nclass ReceiveLogs\n&#123;\n    public static void Main()\n    &#123;\n        var factory = new ConnectionFactory() &#123; HostName = &quot;localhost&quot; &#125;;\n        using(var connection = factory.CreateConnection())\n        using(var channel = connection.CreateModel())\n        &#123;\n            channel.ExchangeDeclare(exchange: &quot;logs&quot;, type: &quot;fanout&quot;);\n\n            var queueName = channel.QueueDeclare().QueueName;\n            channel.QueueBind(queue: queueName,\n                              exchange: &quot;logs&quot;,\n                              routingKey: &quot;&quot;);\n\n            Console.WriteLine(&quot; [*] Waiting for logs.&quot;);\n\n            var consumer = new EventingBasicConsumer(channel);\n            consumer.Received += (model, ea) =&gt;\n            &#123;\n                var body = ea.Body;\n                var message = Encoding.UTF8.GetString(body);\n                Console.WriteLine(&quot; [x] &#123;0&#125;&quot;, message);\n            &#125;;\n            channel.BasicConsume(queue: queueName,\n                                 autoAck: true,\n                                 consumer: consumer);\n\n            Console.WriteLine(&quot; Press [enter] to exit.&quot;);\n            Console.ReadLine();\n        &#125;\n    &#125;\n&#125;\n\n（ReceiveLogs.cs 源码）\n按照 教程[1]中的设置说明生成EmitLogs和ReceiveLogs 项目。\n如果您想把日志保存到文件中，只需打开一个控制台并输入：\ncd ReceiveLogs\ndotnet run &gt; logs_from_rabbit.log\n\n如果你想在屏幕上看到日志，我可以新开一个终端并运行：\ncd ReceiveLogs\ndotnet run\n\n当然，分发日志需要输入：\ncd EmitLog\ndotnet run\n\n使用rabbitmqctl list_bindings命令，您可以验证代码是否真正创建了我们想要的绑定和队列。当有两个ReceiveLogs.cs程序运行时，您应该看到如下所示的内容：\nsudo rabbitmqctl list_bindings\n\n​​​​    \n对执行结果的解释简洁明了：来自logs交换器的数据转发到了两个由服务器随机分配名称的队列。这正是我们期待的结果。\n想要了解如何监听消息的这一块内容，让我们继续阅读 教程[4]。\n写在最后#本文翻译自 RabbitMQ 官方教程 C# 版本。如本文介绍内容与官方有所出入，请以官方最新内容为准。水平有限，翻译的不好请见谅，如有翻译错误还请指正。\n\n原文链接：RabbitMQ tutorial - Publish&#x2F;Subscribe\n实验环境：RabbitMQ 3.7.4 、.NET Core 2.1.3、Visual Studio Code\n最后更新：2018-06-11\n\n","categories":["编程技术","DotNet"],"tags":["RabbitMQ"]},{"title":"[译]RabbitMQ教程C#版 - 工作队列","url":"/2018/04/28/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/RabbitMQ%E6%95%99%E7%A8%8BC#%E7%89%88%20-%20%E5%B7%A5%E4%BD%9C%E9%98%9F%E5%88%97/","content":"\n先决条件本教程假定 RabbitMQ 已经安装，并运行在localhost 标准端口（5672）。如果你使用不同的主机、端口或证书，则需要调整连接设置。\n从哪里获得帮助如果您在阅读本教程时遇到困难，可以通过邮件列表 联系我们。\n\n工作队列#（使用 .NET Client）\n\n在 教程[1] 中，我们编写了两个程序，用于从一个指定的队列发送和接收消息。在本文中，我们将创建一个_工作队列_，用于在多个工作线程间分发耗时的任务。\n工作队列（又名：任务队列）背后的主要想法是避免立即执行资源密集型、且必须等待其完成的任务。相反的，我们把这些任务安排在稍后完成。我们可以将任务封装为消息并把它发送到队列中，在后台运行的工作进程将从队列中取出任务并最终执行。当您运行多个工作线程，这些任务将在这些工作线程之间共享。\n这个概念在Web应用程序中特别有用，因为在一个 HTTP 请求窗口中无法处理复杂的任务。\n准备#我们将略微修改上一个示例中的_Send_程序，以其可以在命令行发送任意消息。这个程序将调度任务到我们的工作队列中，所以让我们把它命名为NewTask：\n像 教程[1]一样，我们需要生成两个项目：\ndotnet new console --name NewTask\nmv NewTask/Program.cs NewTask/NewTask.cs\n\ndotnet new console --name Worker\nmv Worker/Program.cs Worker/Worker.cs\n\ncd NewTask\ndotnet add package RabbitMQ.Client\ndotnet restore\n\ncd ../Worker\ndotnet add package RabbitMQ.Client\ndotnet restore\n\n\nvar message = GetMessage(args);\nvar body = Encoding.UTF8.GetBytes(message);\n\nvar properties = channel.CreateBasicProperties();\nproperties.Persistent = true;\n\nchannel.BasicPublish(exchange: &quot;&quot;,\n                     routingKey: &quot;task_queue&quot;,\n                     basicProperties: properties,\n                     body: body);\n\n从命令行参数获取消息的帮助方法：\nprivate static string GetMessage(string[] args)\n&#123;\n    return ((args.Length &gt; 0) ? string.Join(&quot; &quot;, args) : &quot;Hello World!&quot;);\n&#125;\n\n我们旧的Receive.cs脚本也需要进行一些更改：它需要为消息体中的每个点模拟一秒种的时间消耗。它将处理由 RabbitMQ 发布的消息，并执行任务，因此我们把它复制到Worker项目并修改：\nvar consumer = new EventingBasicConsumer(channel);\n\n​​    consumer.Received +&#x3D; (model, ea) &#x3D;&gt;​    {​        var body &#x3D; ea.Body;​        var message &#x3D; Encoding.UTF8.GetString(body);​        Console.WriteLine(“ [x] Received {0}”, message);\n​​        int dots &#x3D; message.Split(‘.’).Length - 1;​        Thread.Sleep(dots * 1000);​​        Console.WriteLine(“ [x] Done”);​    };​    channel.BasicConsume(queue: “task_queue”, autoAck: true, consumer: consumer);\n模拟虚拟任务的执行时间：\nint dots = message.Split(&#39;.&#39;).Length - 1;\nThread.Sleep(dots * 1000);\n\n循环调度#使用任务队列的优点之一是能够轻松地并行工作。如果我们正在积累积压的工作，我们仅要增加更多的工作者，并以此方式可以轻松扩展。\n首先，我们尝试同时运行两个Worker实例。他们都会从队列中获取消息，但究竟如何？让我们来看看。\n您需要打开三个控制台，两个运行Worker程序，这些控制台作为我们的两个消费者 - C1和C2。\ncd Worker\ndotnet run\n\n​    \ncd Worker\ndotnet run\n\n​    \n在第三个控制台中，我们将发布一些新的任务。一旦你已经运行了消费者，你可以尝试发布几条消息：\ncd NewTask\ndotnet run &quot;First message.&quot;\ndotnet run &quot;Second message..&quot;\ndotnet run &quot;Third message...&quot;\ndotnet run &quot;Fourth message....&quot;\ndotnet run &quot;Fifth message.....&quot;\n\n让我们看看有什么发送到了我们的Worker程序：\n# shell 1\n# =&gt; [*] Waiting for messages. To exit press CTRL+C\n# =&gt; [x] Received &#39;First message.&#39;\n# =&gt; [x] Received &#39;Third message...&#39;\n# =&gt; [x] Received &#39;Fifth message.....&#39;\n\n\n# shell 2\n# =&gt; [*] Waiting for messages. To exit press CTRL+C\n# =&gt; [x] Received &#39;Second message..&#39;\n# =&gt; [x] Received &#39;Fourth message....&#39;\n\n默认情况下，RabbitMQ 会按顺序将每条消息发送给下一个消费者。消费者数量平均的情况下，每个消费者将会获得相同数量的消息。这种分配消息的方式称为循环（Round-Robin）。请尝试开启三个或更多的Worker程序来验证。\n消息确认#处理一项任务可能会需要几秒钟的时间。如果其中一个消费者开启了一项长期的任务并且只完成了部分就挂掉了，您可能想知道会发生什么？在我们当前的代码中，一旦 RabbitMQ 把消息分发给了消费者，它会立即将这条消息标记为删除。在这种情况下，如果您停掉某一个 Worker，我们将会丢失这条正在处理的消息，也将丢失所有分发到该 Worker 但尚未处理的消息。\n但是我们不想丢失任何一个任务。如果一个 Worker 挂掉了，我们希望这个任务能被重新分发给其他 Worker。\n为了确保消息永远不会丢失，RabbitMQ 支持 消息确认 机制。消费者回发一个确认信号 Ack(nowledgement) 给 RabbitMQ，告诉它某个消息已经被接收、处理并且可以自由删除它。\n如果一个消费者在还没有回发确认信号之前就挂了（其通道关闭，连接关闭或者 TCP 连接丢失），RabbitMQ 会认为该消息未被完全处理，并将其重新排队。如果有其他消费者同时在线，该消息将会被会迅速重新分发给其他消费者。这样，即便 Worker 意外挂掉，也可以确保消息不会丢失。\n没有任何消息会超时；当消费者死亡时，RabbitMQ 将会重新分发消息。即使处理消息需要非常非常长的时间也没关系。\n默认情况下，手动消息确认 模式是开启的。在前面的例子中，我们通过将autoAck（“自动确认模式”）参数设置为true来明确地关闭手动消息确认模式。一旦完成任务，是时候删除这个标志并且从 Worker 手动发送一个恰当的确认信号给RabbitMQ。\nvar consumer = new EventingBasicConsumer(channel);\n\n​​    consumer.Received +&#x3D; (model, ea) &#x3D;&gt;​    {​        var body &#x3D; ea.Body;​        var message &#x3D; Encoding.UTF8.GetString(body);​        Console.WriteLine(“ [x] Received {0}”, message);\n​​        int dots &#x3D; message.Split(‘.’).Length - 1;​        Thread.Sleep(dots * 1000);​​        Console.WriteLine(“ [x] Done”);\n​​        channel.BasicAck(deliveryTag: ea.DeliveryTag, multiple: false);​    };\n​​​    channel.BasicConsume(queue: “task_queue”, autoAck: false, consumer: consumer);\n使用上面这段代码，我们可以确定的是，即使一个 Worker 在处理消息时，我们通过使用CTRL + C来终止它，也不会丢失任何消息。Worker 挂掉不久，所有未确认的消息将会被重新分发。\n\n忘记确认遗漏BasicAck是一个常见的错误。这是一个很简单的错误，但导致的后果却是严重的。当客户端退出时（看起来像是随机分发的），消息将会被重新分发，但是RabbitMQ会吃掉越来越多的内存，因为它不能释放未确认的消息。为了调试这种错误，您可以使用rabbitmqctl来打印messages_unacknowledged字段：\nsudo rabbitmqctl list_queues name messages_ready messages_unacknowledged\n\n在Windows上，删除sudo：\nrabbitmqctl.bat list_queues name messages_ready messages_unacknowledged\n\n\n消息持久化#我们已经学习了如何确保即使消费者挂掉，任务也不会丢失。但是如果 RabbitMQ 服务器停止，我们的任务还是会丢失。\n当 RabbitMQ 退出或崩溃时，它会忘记已存在的队列和消息，除非告诉它不要这样做。为了确保消息不会丢失，有两件事是必须的：我们需要将队列和消息标记为持久。\n首先，我们需要确保 RabbitMQ 永远不会丢失我们的队列。为了做到这一点，我们需要把队列声明是_持久的（Durable）_：\n// 声明队列，通过指定 durable 参数为 true，对消息进行持久化处理。 \nchannel.QueueDeclare(queue: &quot;hello&quot;,\n                     durable: true,\n                     exclusive: false,\n                     autoDelete: false,\n                     arguments: null);\n\n虽然这个命令本身是正确的，但是它在当前设置中不会起作用。那是因为我们已经定义过一个名为hello的队列，并且这个队列不是持久化的。RabbitMQ 不允许使用不同的参数重新定义已经存在的队列，并会向尝试执行该操作的程序返回一个错误。但有一个快速的解决办法 - 让我们用不同的名称声明一个队列，例如task_queue：\nchannel.QueueDeclare(queue: &quot;task_queue&quot;,\n                     durable: true,\n                     exclusive: false,\n                     autoDelete: false,\n                     arguments: null);\n\n注意，该声明队列QueueDeclare方法的更改需要同时应用于生产者和消费者代码。\n此时，我们可以确定的是，即使 RabbitMQ 重新启动，task_queue队列也不会丢失。现在我们需要将我们的消息标记为_持久的（Persistent）_ - 通过将IBasicProperties.Persistent设置为true。\nvar properties = channel.CreateBasicProperties();\nproperties.Persistent = true;\n\n\n关于消息持久性的说明将消息标记为Persistent并不能完全保证消息不会丢失。尽管它告诉 RabbitMQ 将消息保存到磁盘，但当 RabbitMQ 接收到消息并且尚未保存消息时仍有一段时间间隔。此外，RabbitMQ 不会为每条消息执行fsync(2) - 它可能只是保存到缓存中，并没有真正写入磁盘。消息的持久化保证并不健壮，但对于简单的任务队列来说已经足够了。如果您需要一个更加健壮的保证，可以使用 发布者确认。\n\n公平调度#您可能已经注意到调度仍然无法完全按照我们期望的方式工作。例如，在有两个 Worker 的情况下，假设所有奇数消息都很庞大、偶数消息都很轻量，那么一个 Worker 将会一直忙碌，而另一个 Worker 几乎不做任何工作。是的，RabbitMQ 并不知道存在这种情况，它仍然会平均地分发消息。\n发生这种情况是因为 RabbitMQ 只是在消息进入队列后就将其分发。它不会去检查每个消费者所拥有的未确认消息的数量。它只是盲目地将第 n 条消息分发给第 n 位消费者。\n\n为了改变上述这种行为，我们可以使用参数设置prefetchCount = 1的basicQos方法。\n这就告诉 RabbitMQ 同一时间不要给一个 Worker 发送多条消息。或者换句话说，不要向一个 Worker 发送新的消息，直到它处理并确认了前一个消息。相反，它会这个消息调度给下一个不忙碌的 Worker。\nchannel.BasicQos(0, 1, false);\n\n\n关于队列大小的说明如果所有的 Worker 都很忙，您的队列可能会被填满。请留意这一点，可以尝试添加更多的 Worker，或者使用其他策略。\n\n组合在一起#我们NewTask.cs类的最终代码：\nusing System;\nusing RabbitMQ.Client;\nusing System.Text;\n\nclass NewTask\n&#123;\n    public static void Main(string[] args)\n    &#123;\n        \n        var factory = new ConnectionFactory() &#123; HostName = &quot;localhost&quot; &#125;;\n\n​​            using(var connection &#x3D; factory.CreateConnection())​            using(var channel &#x3D; connection.CreateModel())​            {​​                channel.QueueDeclare(queue: “task_queue”,​                                     durable: true,​                                     exclusive: false,​                                     autoDelete: false,​                                     arguments: null);\n​​                var message &#x3D; GetMessage(args);​                var body &#x3D; Encoding.UTF8.GetBytes(message);\n​​                var properties &#x3D; channel.CreateBasicProperties();​                properties.Persistent &#x3D; true;\n​​                channel.BasicPublish(exchange: “”,​                                     routingKey: “task_queue”,​                                     basicProperties: properties,​                                     body: body);​​                Console.WriteLine(“ [x] Sent {0}”, message);​            }​            Console.WriteLine(“ Press [enter] to exit.”);            Console.ReadLine();        }\n    private static string GetMessage(string[] args)\n    &#123;\n        return ((args.Length &gt; 0) ? string.Join(&quot; &quot;, args) : &quot;Hello World!&quot;);\n    &#125;\n&#125;\n\n（NewTask.cs 源码）\n还有我们的Worker.cs：\nusing System;\nusing RabbitMQ.Client;\nusing RabbitMQ.Client.Events;\nusing System.Text;\nusing System.Threading;\n\nclass Worker\n&#123;\n    public static void Main()\n    &#123;\n        \n        var factory = new ConnectionFactory() &#123; HostName = &quot;localhost&quot; &#125;;\n\n​​            using(var connection &#x3D; factory.CreateConnection())​            using(var channel &#x3D; connection.CreateModel())​            {​​                channel.QueueDeclare(queue: “task_queue”,​                                     durable: true,​                                     exclusive: false,​                                     autoDelete: false,​                                     arguments: null);\n​​                channel.BasicQos(prefetchSize: 0, prefetchCount: 1, global: false);​​                Console.WriteLine(“ [*] Waiting for messages.”);\n​​                var consumer &#x3D; new EventingBasicConsumer(channel);\n​​                consumer.Received +&#x3D; (model, ea) &#x3D;&gt;​                {​                    var body &#x3D; ea.Body;​                    var message &#x3D; Encoding.UTF8.GetString(body);​                    Console.WriteLine(“ [x] Received {0}”, message);\n​​                    int dots &#x3D; message.Split(‘.’).Length - 1;​                    Thread.Sleep(dots * 1000);​​                    Console.WriteLine(“ [x] Done”);\n​​                    channel.BasicAck(deliveryTag: ea.DeliveryTag, multiple: false);​                };​​                channel.BasicConsume(queue: “task_queue”,​                                     autoAck: false,​                                     consumer: consumer);​                Console.WriteLine(“ Press [enter] to exit.”);                Console.ReadLine();            }        }    }\n（Worker.cs 源码）\n使用消息确认机制和BasicQ您可以创建一个工作队列。即使 RabbitMQ 重新启动，通过持久性选项也可让任务继续存在。\n有关IModel方法和IBasicProperties的更多信息，您可以在线浏览 RabbitMQ .NET客户端API参考。\n现在，我们可以继续阅读 教程[3]，学习如何向多个消费者发送相同的消息。\n写在最后#本文翻译自 RabbitMQ 官方教程 C# 版本。如本文介绍内容与官方有所出入，请以官方最新内容为准。水平有限，翻译的不好请见谅，如有翻译错误还请指正。\n\n原文链接：RabbitMQ tutorial - Work Queues\n实验环境：RabbitMQ 3.7.4 、.NET Core 2.1.2、Visual Studio Code\n最后更新：2018-04-03\n\n","categories":["编程技术","DotNet"],"tags":["RabbitMQ"]},{"title":"[译]RabbitMQ教程C#版 - 路由","url":"/2018/05/05/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/RabbitMQ%E6%95%99%E7%A8%8BC#%E7%89%88%20-%20%E8%B7%AF%E7%94%B1/","content":"\n先决条件本教程假定 RabbitMQ 已经安装，并运行在localhost 标准端口（5672）。如果你使用不同的主机、端口或证书，则需要调整连接设置。\n从哪里获得帮助如果您在阅读本教程时遇到困难，可以通过邮件列表 联系我们。\n\n路由#（使用.NET客户端）\n在 教程[3] 中，我们构建了一个简单的日志系统，可以向多个接收者广播消息。\n在本教程中，我们会为日志系统再添加一个特性，使其可以只订阅消息的一个子集。例如，将所有日志消息打印到控制台，同时只会将严重错误消息写入日志文件（保存到磁盘空间）。\n绑定#在前面的例子中，我们创建过_绑定_。不知道您是否还记得下面的代码：\nchannel.QueueBind(queue: queueName,\n                  exchange: &quot;logs&quot;,\n                  routingKey: &quot;&quot;);\n\n绑定是指交换器和队列之间的关联关系。可以简单地理解为：某个队列对来自此交换器的消息感兴趣。\n绑定可以采用额外的routingKey参数，为了避免与BasicPublish方法中相同参数混淆，我们将其称为binding key（这里是指路由键从声明角度的一种别称，绑定键）。下面即是如何使用绑定键 建立一个绑定：\nchannel.QueueBind(queue: queueName,\n                  exchange: &quot;direct_logs&quot;,\n                  routingKey: &quot;black&quot;);\n\n绑定键的含义取决于交换器类型。像我们前面使用的fanout 交换器，忽略了它的值（依据fanout交换器的特性，它会把消息广播到所有订阅的队列，所以就算指定routingKey也不会根据其过滤消息）。\nDirect交换器#在上篇教程中，我们的日志系统会把所有消息广播给所有消费者，现在我们想要扩展使其可以根据消息的严重性过滤消息。例如，我们希望将日志消息写入磁盘的脚本仅接收严重错误的消息，而不是在警告或者信息类型的消息上浪费磁盘空间。\n之前我们使用的是fanout交换器，它没有给我们足够的灵活性 - 它只能进行无意识的广播。\n现在我们要用direct交换器替换它，direct交换器背后的路由算法很简单 - 消息会进入其binding key恰好与routing key相匹配的队列。为了说明这一点，请参考以下设置：\n\n在上面的设置中，我们可以看到direct交换器X与两个队列绑定。第一个队列通过键orange绑定，第二个队列有两个绑定，一个通过键black绑定、另外一个通过键green绑定。\n如此设置，发布使用路由键orange的消息到交换器最终会被路由到队列Q1，路由键为black或green的消息会去向队列Q2，而其他所有的消息会被丢弃。\n多重绑定#\n使用相同的绑定键绑定多个队列是完全合法的。在示例中，我们可以在X和Q1之间添加一个键为black的绑定。这种情况下，direct交换器会像fanout交换器一样，把消息广播到所有匹配的队列，路由键为black的消息会被分别发送到队列Q1和Q2。\n发送日志#我们将在日志系统中使用上述消息模型，在发送消息时使用direct交换机来替换fanout交换器。同时我们会把日志的严重性作为路由键，这样的话，接收脚本就可以选择性地接收它期望严重性的消息。首先我们来关注如何发送日志。\n同样地，我们需要先创建一个交换器：\nchannel.ExchangeDeclare(exchange: &quot;direct_logs&quot;, type: ExchangeType.Direct);\n\n准备好发送消息：\nvar body = Encoding.UTF8.GetBytes(message);\nchannel.BasicPublish(exchange: &quot;direct_logs&quot;,\n                     routingKey: severity,\n                     basicProperties: null,\n                     body: body);\n\n简单起见，我们先假定severity可以是info、warning或error任意一值。\n订阅#马上就可以像前面的教程接收消息了，但有一点不同， 我们需要为我们感兴趣的每种日志严重性级别的消息建立一个新的绑定。\nvar queueName = channel.QueueDeclare().QueueName;\n\nforeach(var severity in args)\n&#123;\n    channel.QueueBind(queue: queueName,\n                      exchange: &quot;direct_logs&quot;,\n                      routingKey: severity);\n&#125;\n\n组合在一起#\nEmitLogDirect.cs类的代码：\nusing System;\nusing System.Linq;\nusing RabbitMQ.Client;\nusing System.Text;\n\nclass EmitLogDirect\n&#123;\n    public static void Main(string[] args)\n    &#123;\n        var factory = new ConnectionFactory() &#123; HostName = &quot;localhost&quot; &#125;;\n        using(var connection = factory.CreateConnection())\n        using(var channel = connection.CreateModel())\n        &#123;\n            channel.ExchangeDeclare(exchange: &quot;direct_logs&quot;,\n                                    type: &quot;direct&quot;);\n\n            var severity = (args.Length &gt; 0) ? args[0] : &quot;info&quot;;\n            var message = (args.Length &gt; 1)\n                          ? string.Join(&quot; &quot;, args.Skip(1).ToArray())\n                          : &quot;Hello World!&quot;;\n            var body = Encoding.UTF8.GetBytes(message);\n            channel.BasicPublish(exchange: &quot;direct_logs&quot;,\n                                 routingKey: severity,\n                                 basicProperties: null,\n                                 body: body);\n            Console.WriteLine(&quot; [x] Sent &#39;&#123;0&#125;&#39;:&#39;&#123;1&#125;&#39;&quot;, severity, message);\n        &#125;\n\n        Console.WriteLine(&quot; Press [enter] to exit.&quot;);\n        Console.ReadLine();\n    &#125;\n&#125;\n\nReceiveLogsDirect.cs类的代码：\nusing System;\nusing RabbitMQ.Client;\nusing RabbitMQ.Client.Events;\nusing System.Text;\n\nclass ReceiveLogsDirect\n&#123;\n    public static void Main(string[] args)\n    &#123;\n        var factory = new ConnectionFactory() &#123; HostName = &quot;localhost&quot; &#125;;\n        using(var connection = factory.CreateConnection())\n        using(var channel = connection.CreateModel())\n        &#123;\n            channel.ExchangeDeclare(exchange: &quot;direct_logs&quot;,\n                                    type: &quot;direct&quot;);\n            var queueName = channel.QueueDeclare().QueueName;\n\n            if(args.Length &lt; 1)\n            &#123;\n                Console.Error.WriteLine(&quot;Usage: &#123;0&#125; [info] [warning] [error]&quot;,\n                                        Environment.GetCommandLineArgs()[0]);\n                Console.WriteLine(&quot; Press [enter] to exit.&quot;);\n                Console.ReadLine();\n                Environment.ExitCode = 1;\n                return;\n            &#125;\n\n            foreach(var severity in args)\n            &#123;\n                channel.QueueBind(queue: queueName,\n                                  exchange: &quot;direct_logs&quot;,\n                                  routingKey: severity);\n            &#125;\n\n            Console.WriteLine(&quot; [*] Waiting for messages.&quot;);\n\n            var consumer = new EventingBasicConsumer(channel);\n            consumer.Received += (model, ea) =&gt;\n            &#123;\n                var body = ea.Body;\n                var message = Encoding.UTF8.GetString(body);\n                var routingKey = ea.RoutingKey;\n                Console.WriteLine(&quot; [x] Received &#39;&#123;0&#125;&#39;:&#39;&#123;1&#125;&#39;&quot;,\n                                  routingKey, message);\n            &#125;;\n            channel.BasicConsume(queue: queueName,\n                                 autoAck: true,\n                                 consumer: consumer);\n\n            Console.WriteLine(&quot; Press [enter] to exit.&quot;);\n            Console.ReadLine();\n        &#125;\n    &#125;\n&#125;\n\n请像往常一样创建项目（请参阅 教程[1]）。\n如果您想将warning和error（不包括info）日志消息保存到文件，只需打开控制台并输入：\ncd ReceiveLogsDirect\ndotnet run warning error &gt; logs_from_rabbit.log\n\n如果您想在屏幕上看到所有日志消息，请打开一个新终端并执行以下操作：\ncd ReceiveLogsDirect\ndotnet run info warning error\n\n​    \n例如，想要发出error日志消息，只需要输入：\ncd EmitLogDirect\ndotnet run error &quot;Run. Run. Or it will explode.&quot;\n\n​    \nEmitLogDirect.cs 和 ReceiveLogsDirect.cs 的完整源代码。\n跳转到 教程[5]，了解如何基于模式监听消息。\n写在最后#本文翻译自 RabbitMQ 官方教程 C# 版本。如本文介绍内容与官方有所出入，请以官方最新内容为准。水平有限，翻译的不好请见谅，如有翻译错误还请指正。\n\n原文链接：RabbitMQ tutorial - Routing\n实验环境：RabbitMQ 3.7.4 、.NET Core 2.1.3、Visual Studio Code\n最后更新：2018-08-31\n\n","categories":["编程技术","DotNet"],"tags":["RabbitMQ"]},{"title":"[译]RabbitMQ教程C#版 - 远程过程调用(RPC)","url":"/2018/05/12/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/RabbitMQ%E6%95%99%E7%A8%8BC#%E7%89%88%20-%20%E8%BF%9C%E7%A8%8B%E8%BF%87%E7%A8%8B%E8%B0%83%E7%94%A8(RPC)/","content":"\n先决条件本教程假定 RabbitMQ 已经安装，并运行在localhost 标准端口（5672）。如果你使用不同的主机、端口或证书，则需要调整连接设置。\n从哪里获得帮助如果您在阅读本教程时遇到困难，可以通过邮件列表 联系我们。\n\n在第 教程[2] 中，我们学习了如何使用工作队列在多个工作单元之间分配耗时任务。\n但是如果我们想要运行一个在远程计算机上的函数并等待其结果呢？这将是另外一回事了。这种模式通常被称为 远程过程调用 或 RPC 。\n在本篇教程中，我们将使用 RabbitMQ 构建一个 RPC 系统：一个客户端和一个可扩展的 RPC 服务器。由于我们没有什么耗时任务值得分发，那干脆就创建一个返回斐波那契数列的虚拟 RPC 服务吧。\n客户端接口#为了说明如何使用 RPC 服务，我们将创建一个简单的客户端类。该类将暴露一个名为Call的方法，用来发送 RPC 请求并且保持阻塞状态，直到接收到应答为止。\nvar rpcClient = new RPCClient();\n\nConsole.WriteLine(&quot; [x] Requesting fib(30)&quot;);\nvar response = rpcClient.Call(&quot;30&quot;);\nConsole.WriteLine(&quot; [.] Got &#39;&#123;0&#125;&#39;&quot;, response);\n\nrpcClient.Close();\n\n\n关于 RPC 的说明\n尽管 RPC 在计算机中是一种很常见的模式，但它经常受到批评。问题出现在当程序员不知道一个函数是本地调用还是一个耗时的 RPC 请求。这样的混淆，会导致系统不可预测，以及给调试增加不必要的复杂性。误用 RPC 可能会导致不可维护的混乱代码，而不是简化软件。\n牢记这些限制，请考虑如下建议：\n\n确保可以明显区分哪些函数是本地调用，哪些是远程调用。\n为您的系统编写文档，明确组件之间的依赖关系。\n捕获异常，当 RPC 服务长时间宕机时客户端该如何应对。\n\n当有疑问的时候可以先避免使用 RPC。如果可以的话，考虑使用异步管道 - 而不是类似 RPC 的阻塞，其会将结果以异步的方式推送到下一个计算阶段。\n\n回调队列#一般来讲，基于 RabbitMQ 进行 RPC 通信是非常简单的，客户端发送一个请求消息，然后服务端用一个响应消息作为应答。为了能接收到响应，我们需要在发送请求过程中指定一个’callback’队列地址。\nvar props = channel.CreateBasicProperties();\nprops.ReplyTo = replyQueueName;\n\nvar messageBytes = Encoding.UTF8.GetBytes(message);\nchannel.BasicPublish(exchange: &quot;&quot;,\n                     routingKey: &quot;rpc_queue&quot;,\n                     basicProperties: props,\n                     body: messageBytes);\n\n​​    \n\n消息属性\nAMQP 0-9-1 协议在消息中预定义了一个包含 14 个属性的集合，大多数属性很少使用，但以下情况除外：Persistent：将消息标记为持久的（值为2）或者瞬时的（其他值），可以参考 教程[2]。DeliveryMode：熟悉 AMQP 协议的人可以选择此属性而不是熟悉协议的人可以选择使用此属性而不是Persistent，它们控制的东西是一样的。ContentType：用于描述编码的 mime 类型。例如，对于经常使用的 JSON 编码，将此属性设置为：application/json是一种很好的做法。ReplyTo：通常用于命名回调队列。CorrelationId：用于将 RPC 响应与请求相关联。\n\n关联ID#在上面介绍的方法中，我们建议为每个 RPC 请求创建一个回调队列，但是这种方式效率低。幸运的是我们有一种更好的方式，那就是为每个客户端创建一个独立的回调队列。\n这种方式会引出一个新的问题，在收到响应的回调队列中，它无法区分响应属于哪一个请求，此时便是CorrelationId属性的所用之处。我们将为每个请求的CorrelationId设置一个唯一值。之后当我们在回调队列接收到响应的时候，再去检查下这个属性是否和请求中的值匹配，如此一来，我们就可以把响应和请求关联起来了。如果出现一个未知的CorrelationId值，我们可以安全的销毁这个消息，因为这个消息不属于我们的请求。\n你可能会问，为什么我们应该忽略回调队列中的未知的消息，而不是用错误来标识失败呢？这是因为于服务器端可能存在竞争条件。虽然不太可能，但是 RPC 服务器可能在仅发送了响应消息而未发送消息确认的情况下挂掉，如果出现这种情况，RPC 服务器重启之后将会重新处理该请求。这就是为什么在客户端上我们必须优雅地处理重复的响应，并且理想情况下 RPC 应该是幂等的。\n总结#\n我们的 RPC 会是这样工作：\n\n客户端启动时，会创建一个匿名的独占回调队列。\n对于 RPC 请求，客户端发送带有两个属性的消息：ReplyTo（设置为回调队列）和CorrelationId（为每个请求设置唯一值）。\n请求被发送到rpc_queue队列。\nRPC 工作线程（或者叫：服务器）正在等待该队列上的请求。当出现请求时，它会执行该作业，并使用ReplyTo属性设置的队列将带有结果的消息发送回客户端。\n客户端等待回调队列上的数据。出现消息时，它会检查CorrelationId属性。如果它与请求中的值匹配，则返回对应用程序的响应。\n\n组合在一起#斐波纳契 任务：\nprivate static int fib(int n)\n&#123;\n    if (n == 0 || n == 1) return n;\n    return fib(n - 1) + fib(n - 2);\n&#125;\n\n我们宣布我们的斐波那契函数。并假定只允许有效的正整数输入。 （不要期望这个适用于大数字，它可能是最慢的递归实现）。\n我们的 RPC 服务端代码 RPCServer.cs 看起来如下所示：\nusing System;\nusing RabbitMQ.Client;\nusing RabbitMQ.Client.Events;\nusing System.Text;\n\nclass RPCServer\n&#123;\n    public static void Main()\n    &#123;\n        var factory = new ConnectionFactory() &#123; HostName = &quot;localhost&quot; &#125;;\n        using (var connection = factory.CreateConnection())\n        using (var channel = connection.CreateModel())\n        &#123;\n            channel.QueueDeclare(queue: &quot;rpc_queue&quot;, durable: false,\n              exclusive: false, autoDelete: false, arguments: null);\n            channel.BasicQos(0, 1, false);\n            var consumer = new EventingBasicConsumer(channel);\n            channel.BasicConsume(queue: &quot;rpc_queue&quot;,\n              autoAck: false, consumer: consumer);\n            Console.WriteLine(&quot; [x] Awaiting RPC requests&quot;);\n\n            consumer.Received += (model, ea) =&gt;\n            &#123;\n                string response = null;\n\n                var body = ea.Body;\n                var props = ea.BasicProperties;\n                var replyProps = channel.CreateBasicProperties();\n                replyProps.CorrelationId = props.CorrelationId;\n\n                try\n                &#123;\n                    var message = Encoding.UTF8.GetString(body);\n                    int n = int.Parse(message);\n                    Console.WriteLine(&quot; [.] fib(&#123;0&#125;)&quot;, message);\n                    response = fib(n).ToString();\n                &#125;\n                catch (Exception e)\n                &#123;\n                    Console.WriteLine(&quot; [.] &quot; + e.Message);\n                    response = &quot;&quot;;\n                &#125;\n                finally\n                &#123;\n                    var responseBytes = Encoding.UTF8.GetBytes(response);\n                    channel.BasicPublish(exchange: &quot;&quot;, routingKey: props.ReplyTo,\n                      basicProperties: replyProps, body: responseBytes);\n                    channel.BasicAck(deliveryTag: ea.DeliveryTag,\n                      multiple: false);\n                &#125;\n            &#125;;\n\n            Console.WriteLine(&quot; Press [enter] to exit.&quot;);\n            Console.ReadLine();\n        &#125;\n    &#125;\n\n​​​​​​​        private static int fib(int n)​        {​            if (n &#x3D;&#x3D; 0 || n &#x3D;&#x3D; 1)​            {​                return n;​            }​​            return fib(n - 1) + fib(n - 2);​        }​    }\n服务端代码非常简单：\n\n像往常一样，首先建立连接，通道和声明队列。\n我们可能希望运行多个服务器进程。为了在多个服务器上平均分配负载，我们需要设置channel.BasicQos中的prefetchCount值。\n使用BasicConsume访问队列，然后注册一个交付处理程序，并在其中完成工作并发回响应。\n\n我们的 RPC 客户端 RPCClient.cs 代码：\nusing System;\nusing System.Collections.Concurrent;\nusing System.Text;\nusing RabbitMQ.Client;\nusing RabbitMQ.Client.Events;\n\npublic class RpcClient\n&#123;\n    private readonly IConnection connection;\n    private readonly IModel channel;\n    private readonly string replyQueueName;\n    private readonly EventingBasicConsumer consumer;\n    private readonly BlockingCollection&lt;string&gt; respQueue = new BlockingCollection&lt;string&gt;();\n    private readonly IBasicProperties props;\n\npublic RpcClient()\n&#123;\n        var factory = new ConnectionFactory() &#123; HostName = &quot;localhost&quot; &#125;;\n\n        connection = factory.CreateConnection();\n        channel = connection.CreateModel();\n        replyQueueName = channel.QueueDeclare().QueueName;\n        consumer = new EventingBasicConsumer(channel);\n\n        props = channel.CreateBasicProperties();\n        var correlationId = Guid.NewGuid().ToString();\n        props.CorrelationId = correlationId;\n        props.ReplyTo = replyQueueName;\n\n        consumer.Received += (model, ea) =&gt;\n        &#123;\n            var body = ea.Body;\n            var response = Encoding.UTF8.GetString(body);\n            if (ea.BasicProperties.CorrelationId == correlationId)\n            &#123;\n                respQueue.Add(response);\n            &#125;\n        &#125;;\n    &#125;\n\n    public string Call(string message)\n    &#123;\n        var messageBytes = Encoding.UTF8.GetBytes(message);\n        channel.BasicPublish(\n            exchange: &quot;&quot;,\n            routingKey: &quot;rpc_queue&quot;,\n            basicProperties: props,\n            body: messageBytes);\n\n        channel.BasicConsume(\n            consumer: consumer,\n            queue: replyQueueName,\n            autoAck: true);\n\n        return respQueue.Take(); ;\n    &#125;\n\n    public void Close()\n    &#123;\n        connection.Close();\n    &#125;\n&#125;\n\npublic class Rpc\n&#123;\n    public static void Main()\n    &#123;\n        var rpcClient = new RpcClient();\n\n        Console.WriteLine(&quot; [x] Requesting fib(30)&quot;);\n        var response = rpcClient.Call(&quot;30&quot;);\n\n        Console.WriteLine(&quot; [.] Got &#39;&#123;0&#125;&#39;&quot;, response);\n        rpcClient.Close();\n    &#125;\n&#125;\n\n客户端代码稍微复杂一些：\n\n建立连接和通道，并为响应声明一个独有的 ‘callback’ 队列。\n订阅这个 ‘callback’ 队列，以便可以接收到 RPC 响应。\nCall方法用来生成实际的 RPC 请求。\n在这里，我们首先生成一个唯一的CorrelationId编号并保存它，while 循环会使用该值来捕获匹配的响应。\n接下来，我们发布请求消息，其中包含两个属性：ReplyTo和CorrelationId。\n此时，我们可以坐下来稍微一等，直到指定的响应到来。\nwhile 循环做的工作非常简单，对于每个响应消息，它都会检查CorrelationId是否是我们正在寻找的那一个。如果是这样，它就会保存该响应。\n最后，我们将响应返回给用户。\n\n客户发出请求：\nvar rpcClient = new RPCClient();\n\nConsole.WriteLine(&quot; [x] Requesting fib(30)&quot;);\nvar response = rpcClient.Call(&quot;30&quot;);\nConsole.WriteLine(&quot; [.] Got &#39;&#123;0&#125;&#39;&quot;, response);\n\nrpcClient.Close();\n\n现在是查看 RPCClient.cs 和 RPCServer.cs 的完整示例源代码（包括基本异常处理）的好时机哦。\n像往常一样设置（请参见 教程[1]）：\n我们的 RPC 服务现已准备就绪，现在可以启动服务端：\ncd RPCServer\ndotnet run\n\n​    \n要请求斐波纳契数，请运行客户端：\ncd RPCClient\ndotnet run\n\n​    \n这里介绍的设计并不是 RPC 服务的唯一可能实现，但它仍具有一些重要优势：\n\n如果 RPC 服务器太慢，您可以通过运行另一个服务器来扩展。尝试在新开一个控制台，运行第二个 RPCServer。\n在客户端，RPC 只需要发送和接收一条消息。不需要像QueueDeclare一样同步调用。因此，对于单个 RPC 请求，RPC 客户端只需要一次网络往返。\n\n我们的代码很简单，也并没有尝试去解决更复杂（但很重要）的问题，比如就像：\n\n如果服务端没有运行，客户端应该如何反应？\n客户端是否应该为 RPC 设置某种超时机制？\n如果服务端出现故障并引发异常，是否应将其转发给客户端？\n在处理之前防止无效的传入消息（例如：检查边界、类型）。\n\n\n如果您想进行实验，您可能会发现 管理 UI 对于查看队列非常有用。\n\n写在最后#本文翻译自 RabbitMQ 官方教程 C# 版本。如本文介绍内容与官方有所出入，请以官方最新内容为准。水平有限，翻译的不好请见谅，如有翻译错误还请指正。\n\n原文链接：RabbitMQ tutorial - Remote procedure call (RPC)\n实验环境：RabbitMQ 3.7.4 、.NET Core 2.1.3、Visual Studio Code\n最后更新：2018-11-17\n\n","categories":["编程技术","DotNet"],"tags":["RabbitMQ"]},{"title":"SharpDevelop源码分析 (一、序+基本概念)","url":"/2015/08/22/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/SharpDevelop%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%20(%E4%B8%80%E3%80%81%E5%BA%8F+%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5)/","content":"石榴刺猬 2004-10-04 18:55:00 \n版权声明：本文为博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。\n序\n    最近开始学习.Net，遇到了一个比较不错的开源的IDE SharpDevelop。这个开发工具是使用C#开发的，比较吸引我的一点就是它是采用了和Eclipse类似的插件技术来实现整个系统的。而这个插件系统是我最感兴趣的地方，因此开始了一段代码的研究。在本篇之后，我会陆续把我研究的心得写下来。由于是在网吧上网，有诸多不便，因此可能会拖比较长的时间。\n一、基本概念\n    首先，我们先来对 SharpDevelop 有一个比较感性的认识。你可以从这里下载到它的可执行程序和代码包    http://www.icsharpcode.com/  ，安装的废话就不说了，先运行一下看看。感觉跟VS很像吧？不过目前的版本是1.0.0.1550，还有很多地方需要完善。关于代码和系统结构，SharpDevelop的三个作者写了一本书，各位看官可以参考一下，不过我看过之后还是有很多地方不太理解。\n    然后，让我来解释一下什么叫插件以及为什么要使用插件系统。我们以往的系统，开发人员编译发布之后，系统就不允许进行更改和扩充了，如果要进行某个功能的扩充，则必须要修改代码重新编译发布。这就给我们带来了比较大的不方便。解决的方法有很多，例如提供配置等等方法。在解决方案之中，插件是一个比较好的解决方法。大家一定知道PhotoShop、WinAmp吧，他们都有“插件”的概念，允许其他开发人员根据系统预定的接口编写扩展功能（例如PhotoShop中各种各样的滤镜）。所谓的插件就是系统的扩展功能模块，这个模块是以一个独立文件的形式出现的，与系统是相对独立。在系统设计期间并不知道插件的具体功能，仅仅是在系统中为插件留下预定的接口，系统启动的时候根据插件的配置寻找插件，根据预定的接口把插件挂接到系统中。\n    这样的方式带来什么样的优点呢？首先是系统的扩展性大大的增强了，如果我们在系统发布后需要对系统进行扩充，不必重新编译，只需要修改插件就可以了。其次有利与团队开发，各个功能模块由于是以插件的形式表现在系统中，系统的每日构造就很简单了，不会因为某个模块的错误而导致整个系统的BUILD失败。失败的仅仅是一个插件而已。\n    PhotoShop和Winamp的插件系统是比较简单的，他们首先实现了一个基本的系统，然后在这个系统的基础上挂接其他扩展的功能插件。而SharpDevelop的插件系统更加强大，它的整个系统的基础就仅仅是一个插件管理系统，而你看到的所有的界面、功能统统都是以插件的形式挂入的。在这样的一个插件系统下，我们可以不修改基本系统，仅仅使用插件就构造出各种各样不同的系统。\n    现在让我们来看看它的插件系统。进入到SharpDevelop的安装目录中，在Bin目录下的SharpDevelop.exe 和 SharpDevelop.Core.dll是这个系统的基本的插件系统。在Addins目录下有两个后缀是addin的文件，其中一个 SharpDevelopCore.addin 就是它的核心插件的定义（配置）文件，里面定义的各个功能模块存在于Bin&#x2F;Sharpdevelop.Base.dll 文件中，另外还有很多其他的插件定义在Addins目录下的addin文件中。\n    分析SharpDevelop的代码，首先要弄清楚几个基本的概念，这些概念和我以前的预想有一些区别，我深入了代码之后才发现我的困惑所在。\n1、AddInTree  插件树    SharpDevelop 中的插件被组织成一棵插件树结构，树的结构是通过 Extension（扩展点）中定义的Path(路径)来定义的，类似一个文件系统的目录结构。系统中的每一个插件都在配置文件中指定了 Extension，通过Extension中指定的 Path 挂到这棵插件树上。在系统中可以通过 AddTreeSingleton对象来访问各个插件，以实现插件之间的互动。\n2、 AddIn 插件    在 SharpDevelop 的概念中，插件是包含多个功能模块的集合（而不是我过去认为的一个功能模块）。在文件的表现形式上是一个addin配置文件，在系统中对应 AddIn 类。\n3、Extension 扩展点    SharpDevelop中的每一个插件都会被挂到 AddInTree（插件树） 中，而具体挂接到这个插件树的哪个位置，则是由插件的 Extension 对象中的 Path 指定的。在addin 配置文件中，对应于  。例如下面这个功能模块的配置\n指定了扩展点路径为 &#x2F;SharpDevelop&#x2F;Workbench&#x2F;Ambiences ，也就是在插件树中的位置。\n4、Codon    这个是一个比较不好理解的东西，在 SharpDevelop 的三个作者写的书的中译版中被翻译为密码子，真是个糟糕的翻译，可以跟Handle(句柄)有一拼了。词典中还有一个翻译叫“基码”，我觉得这个也不算好，不过还稍微有那么一点意思。（这里我原来误写为“代码子”，在评论中有位仁兄说这个翻译不错，现在我觉得也好像确实不错 ^o^）    根据我对代码的理解，Codon 的功能是描述(包装)一个功能模块（一个功能模块对应一个实现了具体功能的 Command 类）。为了方便访问各个插件中的功能模块， Codon 给各种功能定义了基本的属性，分别是 ID (功能模块的标识)，Name (功能模块的类型。别误会，这个Name 是addin文件定义中Codon的XML结点的名称，ID才是真正的名称)，其中Name可能是Class(类)、MenuItem(菜单项)、Pad(面板)等等。根据具体的功能模块，可以继承Codon定义其他的一些属性，SharpDevelop中就定义了 ClassCodon、MenuItemCodon、PadCodon等等，你可以根据需要自己定义其他类型的Codon。在addin定义文件中，Codon对应于  标签下的内容。例如下面这个定义\n&lt;Extension …&gt; 内部定义了一个Codon，&lt;**Class** …&gt;  表示该Codon是一个 Class(类)，接着定义了该Codon的 ID和具体实现该Codon的类名ICSharpCode.SharpDevelop.Services.NetAmbience。运行期间将通过反射来找到对应的类并创建出来，这一点也是我们无法在以前的语言中实现的。\n再例如这一个定义\n这个扩展点中定义了三个菜单项，以及各个菜单项的名字、标签和实现的类名。这里的Codon就对应于系统中的MenuCodon对象。\n5、Command 命令    正如前文所述，Codon描述了一个功能模块，而每个功能模块都是一个 ICommand 的实现。最基本的 Command 是  AbstractCommand，根据Codon的不同对应了不同的 Command。例如 MenuItemCodon 对应 MenuItemCommand 等等。\n6、Service 服务    插件系统中，有一些功能是整个系统都要使用的，例如文件访问、资源、消息等等。这些功能都作为插件系统的一个基本功能为整个系统提供服务，我们就叫“服务”好了。为了便于访问，这些服务都统一通过 ServiceManager 来管理。其实服务也是一种类型的插件，它们的扩展点路径在目录树中的 &#x2F;Workspace&#x2F;Services 中。\n    理解了这几个基本的概念之后，就可以看看 SharpDevelop 的代码了。从 src&#x2F;main&#x2F;startup.cs 看起吧，之后是addin.cs、addinTree.cs 等等。\n   写了两个小时了，休息一下。且听下回分解。\n","categories":["编程技术","DotNet"],"tags":["SharpDevelop"]},{"title":"SharpDevelop源码分析 (三、插件系统)","url":"/2015/09/05/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/SharpDevelop%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%20(%E4%B8%89%E3%80%81%E6%8F%92%E4%BB%B6%E7%B3%BB%E7%BB%9F)/","content":"**三、插件系统**\n   上回书说到SharpDevelop入口Main函数的结构，ServiceManager.Service在InitializeServicesSubsystem方法中首次调用了AddInTreeSingleton的AddInTree实例，AddInTree在这里进行了初始化。本回进入AddInTree着重讲述SharpDevelop的插件系统。在叙述的时候为了方便起见，对于“插件”和插件具体的“功能模块”这两个词不会特别的区分，各位看官可以从上下文分辨具体的含义（而事实上，SharpDevelop中的“插件”是指.addin配置文件，每一个“插件”都可能会包含多个“功能模块”）。\n1、插件的配置   既然说到插件系统，那么我们先来看一看SharpDevelop插件系统的组织形式。   很多时候，同一个事物从不同的角度来看会得出不一样的结论，SharpDevelop的插件系统也是如此。在看SharpDevelop的代码以前，按照我对插件的理解，我认为所谓的“插件”就是代表一个功能模块，插件的配置就是描述该插件并指定如何把这个插件挂到系统中。SharpDevelop中有插件树的思想，也就是每一个插件在系统中都有一个扩展点的路径。那么按照我最初对插件的理解，编写插件需要做的就是：   A、根据插件接口编写功能模块实现一个Command类   B、编写一个配置文件，指定Command类的扩展点(Extension)路径，挂到插件树中\n   之后按照这样的理解，我编写了一个察看插件树的插件AddinTreeView，打算挂到SharpDevelop中去。根据SharpDevelop对插件的定义，我把具体插件的AddinTreeViewCommand实现了之后，编写了一个配置文件AddinTreeView.addin如下：\n   在配置文件中，Runtime节指定了插件功能模块所在的库文件Addins.dll的具体路径，在Extension节中指定了扩展点路径&#x2F;SharpDevelop&#x2F;Workbench&#x2F;MainMenu&#x2F;Tools（我是打算把它挂到主菜单的工具菜单下），然后在Extension内指定了它的Codon为 MenuItem以及具体的ID、标签、Command类名。这样做，SharpDevelop运行的很不错，我的插件出现在了Tools菜单下。之后，我又编写了一个SharpDevelop的资源管理器（ResourceEditor）的插件类ResourceEditor.dll并把它挂到Tool菜单下。同样的，我也写了一个ResourceEditor.addin文件来对应。系统工作的很正常。\n   如果我们对于每一个插件都编写这样的一个配置文件，那么插件的库文件(.dll)、插件配置文件(.addin)是一一对应的。不过这样就带来了一个小小的问题，在这样的一个以插件为基础的系统中，每一个菜单、工具栏按钮、窗体、面板都是一个插件，那么我们需要为每一个插件编写配置文件，这样就会有很多个配置文件（似乎有点太多了，不是很好管理）。SharpDevelop也想到了这个问题，于是它允许我们把多个插件的配置合并在一个插件的配置文件中。因此，我把我的两个插件库文件合并到一个Addins工程内生成了Addins.dll，又重新编写了我的插件配置文件MyAddins.addin如下：  \n   这样，我把两个插件的功能模块使用一个插件配置文件来进行配置。同样的，我也可以把几十个功能模块合并到一个插件配置文件中。SharpDevelop把这个插件配置文件称为“Addin(插件)”，而把具体的功能模块封装为Codon，使用Command类来包装具体的功能。SharpDevelop本身的核心配置SharpDevelopCore.addin里面就包含了所有的基本菜单、工具栏、PAD的插件配置。我们回过头来看一下，现在我们有了两颗树。首先，插件树本身是一个树形的结构，这个树是根据系统所有插件的各个Codon的扩展点路径构造的，表示了各个Codon在插件树中的位置，各位看官可以通过我写的这个小小的AddinTreeView来看看SharpDevelop中实际的结构。其次，插件的配置文件本身也具有了一个树形的结构，这个树结构的根节点是系统的各个插件配置文件，其下是根据这个配置文件中的Extension节点的来构成的，描述了每个Extension节点下具有的Codon。我们可以通过SharpDevelop的Tools菜单下的AddinScout来看看这个树的结构。我为了试验，把SharpDevelop的插件精简了很多，构成了一个简单的小插件系统。下面是这个精简系统的两个树的截图。各位看官可以通过这两副图理解一下插件树和插件配置文件的关系（只是看同样问题的两个角度，一个是Codon的ExtensionPath，一个是配置文件的内容）。总结一下SharpDevelop插件的配置文件格式。首先是 节点，需要指定AddIn的名称、作者之类的属性。其次，在AddIn节点下的节点内，使用&lt;Import …&gt;来指定本插件配置中Codon所在的库文件。如果分布在多个库文件中，可以一一指明。然后，编写具体功能模块的配置。每个功能模块的配置都以扩展点开始，指定了路径(Path)属性之后，在这个节点内配置在这个扩展点下具体的Codon。每个Codon根据具体不同的实现有不同的属性。各位看官可以研究一下SharpDevelop的核心配置文件SharpDevelopCore.addin的写法，相信很容易理解的。\n2、插件系统的核心AddIn和AddInTree   前文讲到，在SharpDevelop的Main函数中，ServiceManager.Service在InitializeServicesSubsystem方法中首次调用了AddInTreeSingleton的AddInTree实例，AddinTree在这个时候进行了初始化。现在我们就来看看AddInTreeSingleton.AddInTree到底做了些什么事情，它定义在&#x2F;src&#x2F;Main&#x2F;Core&#x2F;AddIns&#x2F;AddInTreeSingleton.cs文件中。\n   AddInTreeSingleton是插件树的一个Singleton（具体的可以去看《设计模式》了），AddInTreeSingleton.AddInTree是一个属性，返回一个IAddinTree接口。这里我注意到一点，AddInTreeSingleton是从DefaultAddInTree继承下来的。既然它是一个单件模式，包含的方法全部都是静态方法，没有实例化的必要，而且外部是通过AddInTree属性来访问插件树，为什么要从DefaultAddInTree继承呢？这好像没有什么必要。这也许是重构过程中被遗漏的一个小问题吧。\n   我们先来看看IAddinTree接口的内容，它定义了这样的几个内容：      A、属性ConditionFactory ConditionFactory　返回一个构造条件的工厂类，这里的条件是指插件配置中的条件，我们以后再详细说明。      B、属性CodonFactory CodonFactory　返回一个构造Codon的工厂类。      C、属性AddInCollection AddIns 返回插件树的根节点Addin（插件）集合。      D、方法IAddInTreeNode GetTreeNode(string path) 根据扩展点路径（path）返回对应的树节点      E、方法void InsertAddIn(AddIn addIn) 根据AddIn中的扩展点路径添加一个插件到树中      F、方法void RemoveAddIn(AddIn addIn) 删除一个插件      G、方法Assembly LoadAssembly(string assemblyFile)  读入插件中Runtime节的Import指定的Assembly，并构造相应的CodonFactory和CodonFactory类。\n   AddInTreeSingleton在首次调用AddInTree的时候会调用CreateAddInTree方法来进行初始化。CreateAddInTree方法是这样实现的：  \n addInTree  =  new  DefaultAddInTree();\n      初始化插件树为DefaultAddInTree的实例，这里我感受到了一点重构的痕迹。首先，DefaultAddInTree从名称上看是默认的插件树（既然是默认，那么换句话说还可以有其他的插件树）。但是SharpDevelop并没有给外部提供使用自定义插件树的接口（除非我们修改这里的代码），也就是说这个名称并不像它本身所暗示的那样。其次，按照Singleton通常的写法以及前面提到AddInTreeSingleton是从DefaultAddInTree继承下来的疑问，我猜想DefaultAddinTree的内容本来是在AddinTreeSingleton里面实现的，后来也许为了代码的条理性，把实现IAddinTree内容的代码剥离了出去，形成了DefaultAddinTree类。至于继承DefaultAddInTree的问题，也许这里本来是一个AddInTree的基类。这是题外话，也未加证实，各位看官可以不必放在心上（有兴趣的可以去找找以前SharpDevelop的老版本的代码来看看）。这里有两个察看代码的线路，一个是DefaultAddInTree的构造函数的代码，在这个构造函数中构造了Codon和Condtion的工厂类。另外一个是CreateAddInTree后面的代码，搜索插件文件，并根据插件文件进行AddIn的构造。各位看官可以选择走分支线路，也可以选择先看主线（不过这样你会漏掉不少内容）。\n2.1 支线 （DefaultAddInTree的构造函数）   我们把CreateAddInTree的代码中断一下压栈先，跳到DefaultAddInTree的构造函数中去看一看。DefaultAddInTree定义在&#x2F;src&#x2F;Main&#x2F;Core&#x2F;AddIns&#x2F;DefaultAddInTree.cs文件中。在DefaultAddInTree的构造函数中，注意到它具有一个修饰符internal，也就是说这个类只允许Core这个程序集中的类对DefaultAddInTree进行实例化（真狠啊）。构造函数中的代码只有一句：\n  LoadCodonsAndConditions(Assembly.GetExecutingAssembly());\n   虽然只有一行代码，不过这里所包含的内容却很精巧，是全局的关键，要讲清楚我可有得写了。首先，通过全局的Assembly对象取得入口程序的Assembly，传入LoadCodonsAndConditions方法中。在该方法中，枚举传入的Assembly中的所有数据类型。如果不是抽象的，并且是AbstractCodon的子类，并且具有对应的CodonNameAttribute属性信息，那么就根据这个类的名称建立一个对应的CodonBuilder并它加入CodonFactory中（之后对Condition也进行了同样的操作，我们专注来看Codon部分，Condition跟Codon基本上是一样的）。   这里的CodonFactory类和CodonBuilder类构成了SharpDevelop插件系统灵活的基础，各位看官可要看仔细了。   我们以实例来演示，以前文我编写的AddinTreeViewCommand为例。在入口的Assembly中会搜索到MenuItemCodon，它是AbstractCodon的一个子类、包装MenuItem(菜单项)Command（命令）的Codon。符合条件，执行\n codonFactory.AddCodonBuilder( new  CodonBuilder(type.FullName, assembly));\n   首先根据类名MenuItemCodon和assembly 构造CodonBuilder。CodonBuilder定义在&#x2F;src&#x2F;Main&#x2F;Core&#x2F;AddIns&#x2F;Codons&#x2F;CodonBuilder.cs文件中。在CodonBuilder的构造函数中根据MenuItemCodon的CodonNameAttribute属性信息取得该Codon的名称MenuItem。CodonNameAttribute描述了Codon的名称，这个MenuItem也就是在.addin配置文件中对应的标签，后文会看到它的重要用途。在CodonBuilder中除了包含了该Codon的ClassName（类名）和CodonName属性之外，就只有一个方法BuildCodon了。\n   很明显，BuildCodon根据构造函数中传入的assembly和类型的ClassName，建立了具体的Codon的实例，并和具体的AddIn关联起来。   之后，codonFactory调用AddCodonBuilder方法把这个CodonBuilder加入它的Builder集合中。我们向上一层，看看codonFactory如何使用这个CodonBuilder。   在文件&#x2F;src&#x2F;Main&#x2F;Core&#x2F;AddIns&#x2F;Codons&#x2F;CodonFactory.cs中，codonFactory只有两个方法。AddCodonBuilder方法把CodonBuilder加入一个以CodonName为索引的Hashtable中。另外一个方法很重要：\n   在这里，addin是这个配置文件的描述（也就是插件），而这个XmlNode类型的CodonNode是什么东西？   还记得配置文件中在标签下的、、之类的标签吗？我曾经说过，这些就是Codon的描述，现在我们来看看到底是不是如此。以前文的AddinTreeView配置为例：\n   SharpDevelop在读入插件配置文件的标签之后，就把它的ChildNodes（XmlElement的属性）依次传入CodonFactory的CreateCodon方法中。这里它的ChildNodes[0]就是这里的节点，也就是codonNode参数了。这个XML节点的Name是MenuItem，因此CreateCodon的第一行\n CodonBuilder builder  =  codonHashtable[codonNode.Name]  as  CodonBuilder;\n   根据节点的名称(MenuItem)查找对应的CodonBuilder。记得前面的CodonBuilder根据CodonNameAttribute取得了MenuItemCodon的CodonName吗？就是这个MenuItem了。CodonFactory找到了对应的MenuItemCodon的CodonBuilder（这个是在DefaultAddInTree的构造函数中调用LoadCodonsAndConditions方法建立并加入CodonFactory中的，还记得么？），之后使用这个CodonBuilder建立了对应的Codon，并把它返回给调用者。   就这样，通过CodonNameAttribute，SharpDevelop把addin配置文件的节点、CodonBulder、MenuItemCodon三部分串起来形成了一个构造Codon的路线。\n   我们回过头来整理一下思路，SharpDevelop进行了下面这样几步工作：      A、建立各个Codon，使用CodonNameAttribute指明它在配置节点中的名称      B、DefaultAddInTree的构造函数中调用LoadCodonsAndConditions方法，搜索所有的Codon，根据Codon的CodonNameAttribute建立对应的CodonBuilder加入CodonFactory中。      C、读取配置文件，在标签下遍历所有的节点，根据节点的Name使用CodonFactory建立对应的Codon。   其中，Codon的CodonNameAttribute、CodonBuilder的CodonName以及标签下XML节点的Name是一致的。对于Condition（条件）的处理也是一样。   抱歉，我上网不是很方便也不太会在Blog里面贴图（都是为了省事的借口^o^），否则也许更好理解这里的脉络关系。\n   好了，看到这里，我们看看SharpDevelop中插件的灵活性是如何体现的。首先，addin配置中的Extension节点下的Codon节点名称并没有在代码中和具体的Codon类联系起来，而是通过CodonNameAttribute跟Codon联系起来。这样做的好处是，SharpDevelop的Codon和XML的标签一样具有无限的扩展能力。假设我们要自己定义一个Codon类SplashFormCodon作用是指定某个窗体作为系统启动时的封面窗体。要做的工作很简单：首先，在SplashFormCodon中使用CodonNameAttribute指定CodonName为Splash，并且在SplashFormCodon中定义自己需要的属性。然后，在addin配置文件使用标签这样写：\n   是不是很简单？另外，对于Condition（条件）的处理也是一样，也就是说我们也可以使用类似的方法灵活的加入自己定义的条件。\n   这里我有个小小的疑问：不知道我对于设计模式的理解是不是有点小问题，我感觉CodonBuilder类的实现似乎并不如它的类名所暗示的是《设计模式》中的Builder模式，反而似乎应该是Proxy模式，因此我觉得改叫做CodonProxy是不是比较容易理解？各位看官觉得呢？   另外，虽然稍微麻烦了一小点，不过我觉得配置如果这样写会让我们比较容易和代码中具体的类关联起来:\n2.2 主线 (AddInTreeSingleton. CreateAddInTree)   啊～我写的有点累了。不过还是让我们继续AddInTreeSingleton中CreateAddInTree的代码。   在建立了DefaultAddInTree的实例后，AddInTreeSingleton在插件目录中搜索后缀为.addin的文件。还记得在SharpDevelop的Main函数中曾经调用过AddInTreeSingleton. SetAddInDirectories吗，就是搜索这个传入的目录。看来SharpDevelop把在插件目录中所有后缀为.addin的文件都看做是插件了。\n FileUtilityService fileUtilityService  =  (FileUtilityService)ServiceManager.Services.GetService( typeof (FileUtilityService));\n   先学习一下如何从ServiceManager取得所需要的服务，在SharpDevelop中要取得一个服务全部都是通过这种方式取得的。调用GetService传入要获取的服务类的类型作为参数，返回一个IService接口，之后转换成需要的服务。\n   搜索插件目录找到一个addin文件后，调用InsertAddIns把这个addin文件中的配置加入到目录树中。\n   InsertAddIns建立一个对应的AddIn（插件），调用AddInTree的InsertAddIn方法把它挂到插件树中。在这里有一个小小的处理，由于是通过Assembly查找和插件配置中Codon的标签对应的类，而Codon类所在的Assembly是通过Import标签导入的。因此在查找配置中某个Codon标签对应的Codon类的时候，也许Codon类所在的文件是在其他的addin文件中Import的。这个时候在前面支线中讲到CodonFactory中查找CodonBuilder会失败，因此必须等到Codon类所在的addin处理之后才能正确的找到CodonBuilder。这是一个依赖关系的处理问题。   SharpDevelop在这里处理的比较简单，调用InsertAddIns方法的时候，凡是出现CodonNotFoundException的时候，都加入一个retryList列表中返回。在CreateAddinTree处理完所有的addin文件之后，再重新循环尝试处理retryList列表中的addin。如果某次循环中再也无法成功的加入retryList中的addin，那么才提示失败错误。\n   我们回头来看看对AddIn的处理。\n**2.2.1  addIn.Initialize （AddIn的初始化）**   建立了AddIn的实例后，调用Initialize 方法进行初始化。AddIn是对一个.addin文件的封装，定义在&#x2F;src&#x2F;Main&#x2F;Core&#x2F;AddIns&#x2F;AddIn.cs文件中。其中包含了.addin文件的根元素的描述，包括名称、作者、版权之类的属性。在节点下包括两种节点：一个是节点，包含了指定要导入的Assembly；另外一个是节点，指定Codon的扩展点。在AddIn.Initialize方法中，使用XmlDocument对象来读取对应的addin文件。首先读取name、author 、copyright之类的基本属性，之后遍历所有的ChildNodes（子节点）。\n   如果子节点是Runtime节点，则调用AddRuntimeLibraries方法。\n   通过AddInTreeSingleton.AddInTree.LoadAssembly方法把Assembly中所有的Codon和Condition的子类加入对应Factory类中（调用了LoadCodonsAndConditions方法，我们在DefaultAddInTree的构造函数中见过了），并且把该文件和对应的Assembly保存到RuntimeLibraries列表中。\n   如果子节点是Extension节点，则调用AddExtensions方法。\n   根据这个扩展点的XML描述建立Extension对象加入到AddIn的Extensions列表中，并通过AddCodonsToExtension方法把其中包括的Codon加入到建立的Extension对象中。Extension对象是AddIn的一个内嵌类，其中一个重要的属性就是CodonCollection这个列表。AddCodonsToExtension就是把在配置中出现的Codon都加入到这个列表中保存。\n   来看看AddCodonsToExtension方法。在代码中我略过了对Condition（条件）的处理的分析和一些无关紧要的部分，我们把注意力集中在插件的处理。首先是一个 foreach (object o in el.ChildNodes) 遍历下所有的子节点，对于每个子节点的处理如下：\n   我们看到了一个期待已久的调用\n AddInTreeSingleton.AddInTree.CodonFactory.CreateCodon( this , curEl);\n   经过了上文支线2.1代码中的铺垫，SharpDevelop使用建立好的CodonFactory，调用CreateCodon方法根据下的节点构造出实际的Codon对象，一切尽在不言中了吧。   e.CodonCollection.Add(codon);把构造出来的Codon对象加入到Extension对象的CodonCollection列表中。   之后，在形如菜单的这种允许无限嵌套的结构中，SharpDevelop对此进行了处理。如果该节点有嵌套的子节点，那么构造一个新的Extension对象，递归调用AddCodonsToExtension添加到这个Extension对象中。注意一点，这个新构造的Extension对象并不是分开保存在Codon中，而是直接保存在AddIn的扩展点列表中。这样是为了方便查找，毕竟保存在具体的Codon中也没有什么用处，我们可以通过Extension对象的Path属性得知它在插件树中的具体位置。\n2.2.2 addInTree.InsertAddIn（把AddIn添加到AddInTree中）   对AddIn的构造完成之后，需要把AddIn的实例对象添加AddInTree中管理。\n   在DefaultAddInTree中，保存了两课树。一个是根据插件文件的结构形成的树，每个插件文件作为根节点，往下依次是Extension、Codon节点。addIns.Add(addIn);就是把插件加入到这个树结构中。另外一个树是根据Extension的Path＋Codon的ID作为路径构造出来的，每一个树节点是一个AddInTreeNode类，包含了在这个路径上的Codon对象。嵌套在这个节点中的Codon在通过它子节点来访问。在DefaultAddInTree中可以通过GetTreeNode来指定一个路径获得插件树上某一个节点的内容。   AddExtensions方法很简单，遍历Extension中所有的Codon，把Extension的Path＋Codon的ID作为路径，创建这个路径上的所有节点，并把Codon连接到这个AddInTreeNode上。由于Codon的ID是全局唯一的，因此每一个AddInTreeNode都具有一个唯一的Codon。\n3、最后一公里（Codon和Command的关联）   在插件树的讨论中，我们依次把AddIn－Extension－Codon的配置和他们对应的类关联了起来。不过我们一直没有涉及到Codon和它包含的Command是如何关联的。由于这个关联调用是在插件树外部的（记得在讲述SharpDevelop程序入口Main函数中，提到ServiceManager的方法InitializeServicesSubsystem么？AddServices((IService[])AddInTreeSingleton.AddInTree.GetTreeNode(servicesPath).BuildChildItems(this).ToArray(typeof(IService))); 这里就调用了BuildChildItems），因此单独在这里说明。实现这个关联的就是AddInTreeNode的BuildChildItems和BuildChildItem方法以及Codon的BuildItem方法。   BuildChildItem方法和BuildChildItems方法仅有一字之差，BuildChildItem是根据指定的Codon的ID在所属AddInTreeNode的子节点下查找包含该Codon的节点并调用该Codon的BuildItem方法；而BuildChildItems则是首先遍历所属AddInTreeNode的所有子节点，依次调用各个子节点的Codon的BuildItem方法，之后再调用所属AddInTreeNode的Codon的BuildItem方法（也就是一个树的后根遍历）。   重点在Codon的BuildItem方法。在AbstractCodon中，这个方法是一个抽象方法，SharpDevelop的代码注释中并没有明确说清楚这个方法是做什么用的。但是我们可以找一个Codon的实例来看看。例如ClassCodon的BuildItem：\n   调用AddIn的CreateObject，传入Codon的Class（类名）作为参数，建立这个类的实例。例如这个配置\n   而Codon的中的Class（类名）属性就是ICSharpCode.SharpDevelop.Commands.InitializeWorkbenchCommand。也就是说，Codon的Class指的是实现具体功能模块的Command类的名称。在读取addin配置中的节的时候，AddInTree把Assembly保存到了RuntimeLibraries中，因此CreateObject方法可以通过它们来查找并建立类的实例。   各位看官可以再看看MenuItemCodon的实现，同样是建立了对应的SdMenuCommand。   这样，SharpDevelop本身的插件结构可以和具体的对象建立分离开来，实际的对象建立是在各个Codon的BuildItem中进行的。因此我们可以发现在SharpDevelop整个是基础插件系统部分没有任何GUI的操作，实现了很好的解耦效果。\n4、问题   好了，本文对插件树构造的分析到此告一段落。我提一个小小的问题给各位看官思考：在构造插件树的过程中，如果Codon的某一个节点路径不存在（也就是说它的依赖项不存在），那么SharpDevelop会提示失败并且终止程序运行。可是实际上可能因为部署的原因或者权限的原因，某些Codon的失败并不会影响整个系统的使用，例如试用版本仅仅提供部分插件给客户使用，而并不希望系统因此而终止运行。那么就存在一个Codon依赖项失败而允许继续运行的问题。另外，我希望各个插件不在系统启动的时候全部调入系统，而是在运行期实际调用的时候才调入系统，也就是一个缓存机制，这样就可以实现系统插件的热部署。如何修改SharpDevelop的插件系统来实现这两个功能呢？\n   下一回书，应某位网友的要求，分析一下SharpDevelop中的服务。\n","categories":["编程技术","DotNet"],"tags":["SharpDevelop"]},{"title":"SharpDevelop源码分析 (二、主程序+隐藏的初始化)","url":"/2015/08/29/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/SharpDevelop%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%20(%E4%BA%8C%E3%80%81%E4%B8%BB%E7%A8%8B%E5%BA%8F+%E9%9A%90%E8%97%8F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96)/","content":"石榴刺猬 2004-10-07 20:10:00\n版权声明：本文为博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。\n二、主程序  \n    在大学课程里面，我对于模拟电路总是搞不清楚，直到现在也是这样。我总觉得电路图很奇怪，总会问“这部分电路是做什么用的”、“为什么会有这样的效果”。在我的脑海里面，每部分的电路都应该有一定的用处，可是我总是看不明白。我妈妈说，我的思路被软件所固化的太久了，看电路图不应该总是一个个模块的看，正确的方法应该是从电源的一极顺着电路看，一直看到电源的另一极。我现在仍然不懂看电路图，可是以我看代码的经验来说，我觉得分析源代码按照这样的思路来看会比较容易把脉络理清楚。     在SharpDevelop的代码中，由于很多的接口和插件的原因，很多代码在看到某个地方会突然失去函数&#x2F;方法调用的线索。例如看某个函数的实现的时候会跳到一个接口里面去，那是因为这部分功能在运行期才会给一个实现了这个接口的对象来进行具体的执行。从这个角度来说，设计模式也给我们研究代码稍微带来了一点小小的难度。在看Linux下源代码的时候也经常遇到这种问题，在这个时候寻找代码线索比较好的方法是用一个文本搜索工具来搜索相关的关键字。在Linux下我经常会用grep，Windows下面类似UltraEdit的“批量文件查找”功能会很好用（或者“Search And Replace”之类的工具）。这个是我读代码的一点小小的经验，如果你知道有更好的方法，请告诉我让我也学习一下 ? 。     我不想大段大段的贴代码出来占地方（空间、带宽，还有各位看官的注意力），在需要的地方我会贴上主要的代码，因此最好能够找代码来对应着看。把代码包解压缩，我把它解到了“F:&#x2F;SharpDevelop”（如果没有说明，下文都是以此为代码的根目录了）。由于SharpDevelop本身对于察看代码不是很方便，没有“转到定义”之类的功能，因此我建议你把它的代码转成VS的工程来看。不过很可惜，SharpDevelop的工程导出功能现在有问题，如果导出&#x2F;src&#x2F;SharpDevelop.cmbx 这个总的复合工程的话会失败（我记得RC1版本是可以成功的，不知道为什么后来的版本反而会出问题），所以只能一个一个工程的导出。     好了，让我们来看SharpDevelop的代码吧。1、起点    在主程序的起点在&#x2F;src&#x2F;Main&#x2F;StartUp&#x2F;SharpDevelopMain.cs，找到Main函数这就是整个程序的起点了。开始的部分是显示封面窗体并加上命令行控制，其中SplashScreenForm 定义在&#x2F;src&#x2F;Main&#x2F;Base&#x2F;Gui&#x2F;Dialogs&#x2F;SplashScreen.cs文件中，这部分我就不多说了。之后是\n Application.ThreadException  +&#x3D;  new  ThreadExceptionEventHandler(ShowErrorBox);\n    SharpDevelop为了有效的进行错误报告，因此自己进行了异常的控制。系统出现异常的时候，SharpDevelop会拦截下来弹出它自己的异常提示报告对话框。这个代码就是在这一行实现的。其中 ShowErrorBox 这个方法就在类SharpDevelopMain中，ExceptionBox 定义在&#x2F;src&#x2F;Main&#x2F;StartUp&#x2F;Dialogs&#x2F;ExceptionBox.cs中。如果需要进行自己的异常控制，可以学习一下这里的技巧。\n2、充满玄机的初始化\n string  [] addInDirs  =  ICSharpCode.SharpDevelop.AddInSettingsHandler.GetAddInDirectories(  out  ignoreDefaultPath );AddInTreeSingleton.SetAddInDirectories(addInDirs, ignoreDefaultPath);\n    通过AddInSettingsHandler取得插件的目录，并告知AddInTreeSingleton。AddInSettingsHandler定义在&#x2F;src&#x2F;Main&#x2F;StartUp&#x2F;Dialogs&#x2F;AddInTreeSettingsHandler.cs中，它通过读取系统配置（App.config）文件中的AddInDirectory节点的Path属性来确定插件的目录位置，或者你也可以通过自己定义的AddInDirectories节来指定插件目录。如果你没有做这些配置，默认的目录在SharpDevelop运行目录的..&#x2F;Addins目录下。\n    通过ServiceManager(服务管理器)加入三个系统默认的服务，消息服务、资源服务、图标服务。这三个服务中，消息服务是显示各种信息提示，另外两个是属于系统的资源，SharpDevelop通过服务来进行统一调用和管理。ServiceManager.Services.InitializeServicesSubsystem(“&#x2F;Workspace&#x2F;Services”);\n    初始化其他的服务。SharpDevelop把服务定义在插件树的&#x2F;Workspace&#x2F;Services这个路径中，凡是在这个路径下的插件都被认为是服务，因此如果你自己定义了一个服务的话，也需要挂到这个路径下（这里就是系统服务的扩展点了）。\n    注意！这一步中，在我们的眼皮子底下悄悄的进行了一个重要的初始化工作。各位看官请看，ServiceManager 定义在&#x2F;src&#x2F;Main&#x2F;Core&#x2F;Services&#x2F; ServiceManager.cs文件中，察看它的InitializeServicesSubsystem方法，我们发现这样一行\nAddServices((IService[]) AddInTreeSingleton.AddInTree.GetTreeNode(servicesPath).BuildChildItems(this).ToArray(typeof(IService)));\n    在这里，AddInTreeSingleton首次调用了AddInTree（插件树）的实例。按照Singleton模式，只有在首次调用的时候才会初始化实例，这里也是同样如此。整个系统的AddInTree是在这一步中进行了初始化工作，稍候我们将详细介绍AddInTree如何进行初始化工作，先顺便看看服务的初始化。在ServiceManager的InitializeServicesSubsystem方法中，通过AddInTree检索服务插件路径下的所有配置，并通过它来读取、建立具体的对象，然后加入到服务列表中。之后通过一个循环，逐个的调用各个服务的InitializeService方法初始化服务。\n    AddInTree的初始化工作容我们稍候再看，先把主体的代码看完。  \ncommands &#x3D; AddInTreeSingleton.AddInTree.GetTreeNode(“&#x2F;Workspace&#x2F;Autostart”).BuildChildItems(null);for (int i &#x3D; 0; i &lt; commands.Count - 1; ++i){ ((ICommand)commands[i]).Run();}\n    &#x2F;Workspace&#x2F;Autostart是系统自动运行命令的扩展点路径，定义在这个路径下的插件会在系统启动的时候自动运行。在这里，通过插件树初始化建立处于这个路径下的Command（命令），并逐一执行。BuildChildItems方法的功能是建立这个扩展点下的Command列表，我会在介绍AddTree的时候具体说明它的实现。\n     主程序代码的最后，初始化完毕、关闭封面窗体，然后执行命令列表中最后一个命令（也就是系统的主界面）。在主界面退出的时候，系统卸载所有的服务。\n    在这部分代码中，我们知道了两个系统指定的扩展点路径 &#x2F;Workspace&#x2F;Services 和 &#x2F;Workspace&#x2F;Autostart ，我们实现服务和指定系统自动运行命令的时候就可以挂到这两个扩展点路径下了。     托反射的福，ServiceManager.Services可以通过类型（接口）来查找具体的实例，也就是GetServices方法。但是ServiceManager的具体实现我们可以容后再看，这里已经不是最紧要的部分了。     接下来，我们来看看整个插件系统的核心－AddinTree的代码，看看它是如何通过插件配置进行初始化并建立起整个系统的插件树骨干。\n","categories":["编程技术","DotNet"],"tags":["SharpDevelop"]},{"title":"Vsiual Studio自动生成版本号的一种方法","url":"/2017/12/30/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/Vsiual%20Studio%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%89%88%E6%9C%AC%E5%8F%B7%E7%9A%84%E4%B8%80%E7%A7%8D%E6%96%B9%E6%B3%95/","content":"1、安装nuget包MSBuildTasks\n2、编辑项目的csproj文件，找到被注释掉的target的beforebuild，去掉注释，添加如下代码。代码如下。\n&lt;Target Name=&quot;BeforeBuild&quot;&gt;    &lt;Version VersionFile=&quot;Propertiesversion.txt&quot; Major=&quot;1&quot; Minor=&quot;0&quot; BuildType=&quot;Automatic&quot; StartDate=&quot;09/01/2017&quot; RevisionType=&quot;BuildIncrement&quot;&gt;      &lt;Output TaskParameter=&quot;Major&quot; PropertyName=&quot;Major&quot; /&gt;      &lt;Output TaskParameter=&quot;Minor&quot; PropertyName=&quot;Minor&quot; /&gt;      &lt;Output TaskParameter=&quot;Build&quot; PropertyName=&quot;Build&quot; /&gt;      &lt;Output TaskParameter=&quot;Revision&quot; PropertyName=&quot;Revision&quot; /&gt;    &lt;/Version&gt;    &lt;AssemblyInfo CodeLanguage=&quot;CS&quot; OutputFile=&quot;Properties\\FileVersionInfo.cs&quot; AssemblyFileVersion=&quot;$(Major).$(Minor).$(Build).$(Revision)&quot; /&gt;  &lt;/Target&gt;     \n\n3、编译项目一次就会在项目文件夹下生成 Propertiesversion.txt\n4、在AssemblyInfo.cs文件中包含了AssemblyVersion和AssemblyFileVersion，这里把AssemblyFileVersion单独放到了FileVersionInfo.cs中，编译时会自动生成FileVersionInfo.cs文件，其内容为AssemblyFileVersion，把该文件包含到项目中即可。这里并没有让程序自动生成AssemblyVersion。\n这种方式生成版本号会在vs编译时更新版本号。\n","categories":["编程技术","DotNet"],"tags":["自动生成版本号","Visual","Studio"]},{"title":"WPF","url":"/2022/07/27/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/WPF/","content":"https://blog.csdn.net/maizi314/article/details/103979437https://blog.csdn.net/wushang923/article/details/9226529https://www.cnblogs.com/lonelyxmas/p/7979743.htmlhttps://blog.csdn.net/yangyy9611/article/details/17464133https://lindexi.oschina.io/lindexi/post/WPF-%E4%BD%BF%E7%94%A8%E5%B0%81%E8%A3%85%E7%9A%84-SharpDx-%E6%8E%A7%E4%BB%B6.htmlhttps://blog.csdn.net/weixin_34320159/article/details/86132420https://blog.csdn.net/wangsunjun/article/details/8894952https://www.codeproject.com/Articles/15610/Regex-Validation-in-WPFhttps://www.cnblogs.com/mantian/p/3816834.htmlhttps://cloud.tencent.com/developer/ask/76782/answer/132738https://blog.csdn.net/ZZZWWWPPP11199988899/article/details/77620211https://blog.csdn.net/qq_38888555/article/details/82118505https://blog.csdn.net/lwwl12/article/details/78472235https://blog.walterlv.com/post/win10/2017/10/02/wpf-transparent-blur-in-windows-10.htmlhttp://toto0668.blog.163.com/blog/static/30990252201691441716893/https://blog.csdn.net/catshitone/article/details/78522931\n","categories":["编程技术","DotNet"]},{"title":"WPF自定义窗体","url":"/2018/10/06/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/WPF%E8%87%AA%E5%AE%9A%E4%B9%89%E7%AA%97%E4%BD%93/","content":"参考链接[WPF]使用WindowChrome自定义Window Style - dino.c - 博客园 (cnblogs.com)\nWPF自定义界面WindowChrome - 丑萌气质狗 - 博客园 (cnblogs.com)\n[WPF 自定义控件]﻿使用WindowChrome自定义Window Style - dino.c - 博客园 (cnblogs.com)\n[WPF 自定义控件]使用WindowChrome的问题 - dino.c - 博客园 (cnblogs.com)\n","categories":["编程技术","DotNet"],"tags":["WPF","WindowChrome","自定义界面"]},{"title":"分布式ID生成方法生成演变","url":"/2017/01/07/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/%E5%88%86%E5%B8%83%E5%BC%8FID%E7%94%9F%E6%88%90%E6%96%B9%E6%B3%95%E7%94%9F%E6%88%90%E6%BC%94%E5%8F%98/","content":"一、需求缘起\n几乎所有的业务系统，都有生成一个记录标识的需求，例如：\n（1）消息标识：message-id\n（2）订单标识：order-id\n（3）帖子标识：tiezi-id\n这个记录标识往往就是数据库中的唯一主键，数据库上会建立聚集索引（cluster index），即在物理存储上以这个字段排序。\n这个记录标识上的查询，往往又有分页或者排序的业务需求，例如：\n（1）拉取最新的一页消息：selectmessage-id&#x2F; order by time&#x2F; limit 100\n（2）拉取最新的一页订单：selectorder-id&#x2F; order by time&#x2F; limit 100\n（3）拉取最新的一页帖子：selecttiezi-id&#x2F; order by time&#x2F; limit 100\n所以往往要有一个time字段，并且在time字段上建立普通索引（non-cluster index）。\n我们都知道普通索引存储的是实际记录的指针，其访问效率会比聚集索引慢，如果记录标识在生成时能够基本按照时间有序，则可以省去这个time字段的索引查询：\nselect message-id&#x2F; (order by message-id)&#x2F;limit 100\n再次强调，能这么做的前提是，message-id的生成基本是趋势时间递增的。\n这就引出了记录标识生成（也就是上文提到的三个XXX-id）的两大核心需求：\n（1）全局唯一\n（2）趋势有序\n这也是本文要讨论的核心问题：如何高效生成趋势有序的全局唯一ID。\n二、常见方法、不足与优化\n【常见方法一：使用数据库的 auto_increment 来生成全局唯一递增ID】\n优点：\n（1）简单，使用数据库已有的功能\n（2）能够保证唯一性\n（3）能够保证递增性\n（4）步长固定\n缺点：\n（1）可用性难以保证：数据库常见架构是一主多从+读写分离，生成自增ID是写请求，主库挂了就玩不转了\n（2）扩展性差，性能有上限：因为写入是单点，数据库主库的写性能决定ID的生成性能上限，并且难以扩展\n改进方法：\n（1）增加主库，避免写入单点\n（2）数据水平切分，保证各主库生成的ID不重复\n如上图所述，由1个写库变成3个写库，每个写库设置不同的auto_increment初始值，以及相同的增长步长，以保证每个数据库生成的ID是不同的（上图中库0生成0,3,6,9…，库1生成1,4,7,10，库2生成2,5,8,11…）\n改进后的架构保证了可用性，但缺点是：\n（1）丧失了ID生成的“绝对递增性”：先访问库0生成0,3，再访问库1生成1，可能导致在非常短的时间内，ID生成不是绝对递增的（这个问题不大，我们的目标是趋势递增，不是绝对递增）\n（2）数据库的写压力依然很大，每次生成ID都要访问数据库\n为了解决上述两个问题，引出了第二个常见的方案\n【常见方法二：单点批量ID生成服务】\n分布式系统之所以难，很重要的原因之一是“没有一个全局时钟，难以保证绝对的时序”，要想保证绝对的时序，还是只能使用单点服务，用本地时钟保证“绝对时序”。数据库写压力大，是因为每次生成ID都访问了数据库，可以使用批量的方式降低数据库写压力。\n如上图所述，数据库使用双master保证可用性，数据库中只存储当前ID的最大值，例如0。ID生成服务假设每次批量拉取6个ID，服务访问数据库，将当前ID的最大值修改为5，这样应用访问ID生成服务索要ID，ID生成服务不需要每次访问数据库，就能依次派发0,1,2,3,4,5这些ID了，当ID发完后，再将ID的最大值修改为11，就能再次派发6,7,8,9,10,11这些ID了，于是数据库的压力就降低到原来的1&#x2F;6了。\n优点：\n（1）保证了ID生成的绝对递增有序\n（2）大大的降低了数据库的压力，ID生成可以做到每秒生成几万几十万个\n缺点：\n（1）服务仍然是单点\n（2）如果服务挂了，服务重启起来之后，继续生成ID可能会不连续，中间出现空洞（服务内存是保存着0,1,2,3,4,5，数据库中max-id是5，分配到3时，服务重启了，下次会从6开始分配，4和5就成了空洞，不过这个问题也不大）\n（3）虽然每秒可以生成几万几十万个ID，但毕竟还是有性能上限，无法进行水平扩展\n改进方法：\n单点服务的常用高可用优化方案是“备用服务”，也叫“影子服务”，所以我们能用以下方法优化上述缺点（1）：\n如上图，对外提供的服务是主服务，有一个影子服务时刻处于备用状态，当主服务挂了的时候影子服务顶上。这个切换的过程对调用方是透明的，可以自动完成，常用的技术是vip+keepalived，具体就不在这里展开。\n \n【常见方法三：uuid】\n上述方案来生成ID，虽然性能大增，但由于是单点系统，总还是存在性能上限的。同时，上述两种方案，不管是数据库还是服务来生成ID，业务方Application都需要进行一次远程调用，比较耗时。有没有一种本地生成ID的方法，即高性能，又时延低呢？\nuuid是一种常见的方案：string ID &#x3D;GenUUID();\n优点：\n（1）本地生成ID，不需要进行远程调用，时延低\n（2）扩展性好，基本可以认为没有性能上限\n缺点：\n（1）无法保证趋势递增\n（2）uuid过长，往往用字符串表示，作为主键建立索引查询效率低，常见优化方案为“转化为两个uint64整数存储”或者“折半存储”（折半后不能保证唯一性）\n【常见方法四：取当前毫秒数】\nuuid是一个本地算法，生成性能高，但无法保证趋势递增，且作为字符串ID检索效率低，有没有一种能保证递增的本地算法呢？\n取当前毫秒数是一种常见方案：uint64 ID &#x3D; GenTimeMS();\n优点：\n（1）本地生成ID，不需要进行远程调用，时延低\n（2）生成的ID趋势递增\n（3）生成的ID是整数，建立索引后查询效率高\n缺点：\n（1）如果并发量超过1000，会生成重复的ID\n我去，这个缺点要了命了，不能保证ID的唯一性。当然，使用微秒可以降低冲突概率，但每秒最多只能生成1000000个ID，再多的话就一定会冲突了，所以使用微秒并不从根本上解决问题。\n【常见方法五：类snowflake算法】\nsnowflake是twitter开源的分布式ID生成算法，其核心思想是：一个long型的ID，使用其中41bit作为毫秒数，10bit作为机器编号，12bit作为毫秒内序列号。这个算法单机每秒内理论上最多可以生成1000*(2^12)，也就是400W的ID，完全能满足业务的需求。\n借鉴snowflake的思想，结合各公司的业务逻辑和并发量，可以实现自己的分布式ID生成算法。\n举例，假设某公司ID生成器服务的需求如下：\n（1）单机高峰并发量小于1W，预计未来5年单机高峰并发量小于10W\n（2）有2个机房，预计未来5年机房数量小于4个\n（3）每个机房机器数小于100台\n（4）目前有5个业务线有ID生成需求，预计未来业务线数量小于10个\n（5）…\n分析过程如下：\n（1）高位取从2016年1月1日到现在的毫秒数（假设系统ID生成器服务在这个时间之后上线），假设系统至少运行10年，那至少需要10年*365天*24小时*3600秒*1000毫秒=320*10^9，差不多预留39bit给毫秒数\n（2）每秒的单机高峰并发量小于10W，即平均每毫秒的单机高峰并发量小于100，差不多预留7bit给每毫秒内序列号\n（3）5年内机房数小于4个，预留2bit给机房标识\n（4）每个机房小于100台机器，预留7bit给每个机房内的服务器标识\n（5）业务线小于10个，预留4bit给业务线标识\n这样设计的64bit标识，可以保证：\n（1）每个业务线、每个机房、每个机器生成的ID都是不同的\n（2）同一个机器，每个毫秒内生成的ID都是不同的\n（3）同一个机器，同一个毫秒内，以序列号区区分保证生成的ID是不同的\n（4）将毫秒数放在最高位，保证生成的ID是趋势递增的\n缺点：\n（1）由于“没有一个全局时钟”，每台服务器分配的ID是绝对递增的，但从全局看，生成的ID只是趋势递增的（有些服务器的时间早，有些服务器的时间晚）\n最后一个容易忽略的问题：\n生成的ID，例如message-id&#x2F; order-id&#x2F; tiezi-id，在数据量大时往往需要分库分表，这些ID经常作为取模分库分表的依据，为了分库分表后数据均匀，ID生成往往有“取模随机性”的需求，所以我们通常把每秒内的序列号放在ID的最末位，保证生成的ID是随机的。\n又如果，我们在跨毫秒时，序列号总是归0，会使得序列号为0的ID比较多，导致生成的ID取模后不均匀。解决方法是，序列号不是每次都归0，而是归一个0到9的随机数，这个地方。\n下面附上C#.Net 实现snowflake算法实现\nusing System;using System.Collections.Generic;using System.Linq;using System.Text;using System.Threading.Tasks; namespace CommonTools&#123;   public class SnowFlake    &#123;             //机器ID        private static long workerId;\t    private static long twepoch = 687888001020L; //唯一时间，这是一个避免重复的随机量，自行设定不要大于当前时间戳\t    private static long sequence = 0L;\t    private static int workerIdBits = 4; //机器码字节数。4个字节用来保存机器码\t    public static long maxWorkerId = -1L ^ -1L &lt;&lt; workerIdBits; //最大机器ID\t    private static int sequenceBits = 10; //计数器字节数，10个字节用来保存计数码\t    private static int workerIdShift = sequenceBits; //机器码数据左移位数，就是后面计数器占用的位数\t    private static int timestampLeftShift = sequenceBits + workerIdBits; //时间戳左移动位数就是机器码和计数器总字节数        public static long sequenceMask = -1L ^ -1L &lt;&lt; sequenceBits; //一微秒内可以产生计数，如果达到该值则等到下一微妙在进行生成\t    private long lastTimestamp = -1L;         private static SnowFlake sigle = null;                private  SnowFlake(long workerId)        &#123;            if (workerId &gt; maxWorkerId || workerId &lt; 0)                throw new Exception(string.Format(&quot;worker Id can&#x27;t be greater than &#123;0&#125; or less than 0 &quot;, workerId));            SnowFlake.workerId = workerId;        &#125;         public static long NewID()        &#123;            if (sigle == null)            &#123;                sigle = new SnowFlake(4L); //此处4L应该从配置文件里读取当前机器配置             &#125;           return  sigle.nextId();          &#125;           private long nextId()        &#123;            lock (this)            &#123;                long timestamp = timeGen();                if(this.lastTimestamp == timestamp)&#123; //同一微妙中生成ID                    //用&amp;运算计算该微秒内产生的计数是否已经到达上限                    SnowFlake.sequence = (SnowFlake.sequence + 1) &amp; SnowFlake.sequenceMask;                     if (SnowFlake.sequence == 0)                    &#123;                        //一微妙内产生的ID计数已达上限，等待下一微妙                        timestamp = tillNextMillis(this.lastTimestamp);                    &#125;                &#125;                else&#123; //不同微秒生成ID                    SnowFlake.sequence = 0; //计数清0                &#125;                if(timestamp &lt; lastTimestamp)                &#123; //如果当前时间戳比上一次生成ID时时间戳还小，抛出异常，因为不能保证现在生成的ID之前没有生成过                    throw new Exception(string.Format(&quot;Clock moved backwards.  Refusing to generate id for &#123;0&#125; milliseconds&quot;,                        this.lastTimestamp - timestamp));                &#125;                this.lastTimestamp = timestamp; //把当前时间戳保存为最后生成ID的时间戳                long nextId = (timestamp - twepoch &lt;&lt; timestampLeftShift)                     | SnowFlake.workerId &lt;&lt; SnowFlake.workerIdShift | SnowFlake.sequence;                return nextId;            &#125;        &#125;         /// &lt;summary&gt;        /// 获取下一微秒时间戳        /// &lt;/summary&gt;        /// &lt;param name=&quot;lastTimestamp&quot;&gt;&lt;/param&gt;        /// &lt;returns&gt;&lt;/returns&gt;        private long tillNextMillis(long lastTimestamp)        &#123;            long timestamp = timeGen();            while(timestamp &lt;= lastTimestamp)            &#123;                timestamp = timeGen();            &#125;            return timestamp;        &#125;         /// &lt;summary&gt;        /// 生成当前时间戳        /// &lt;/summary&gt;        /// &lt;returns&gt;&lt;/returns&gt;        private long timeGen()        &#123;            return (long)(DateTime.UtcNow - new DateTime(1970, 1, 1, 0, 0, 0, DateTimeKind.Utc)).TotalMilliseconds;        &#125;     &#125;&#125;\n\n","categories":["编程技术","DotNet"],"tags":["分布式ID"]},{"title":"在 WPF 中使用 Path 路径","url":"/2015/10/17/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/%E5%9C%A8%20WPF%20%E4%B8%AD%E4%BD%BF%E7%94%A8%20Path%20%E8%B7%AF%E5%BE%84/","content":"在 WPF 中总会修改 Button 的 Style，比如一个自定义的 Close 按钮。刚入门的可能会用一张 PNG 格式的图片来做这个按钮的 Icon，但这个是不优雅的。而且你要改的时候还得去操作文件，想想都痛苦。\n但是很多人苦于不知道去哪里获取 Path，当然网上已经有不少使用 Photoshop 获取图片的 Path ，但如果图片的质量不好，获取的 Path 歪歪曲曲的也不好看，更何况在这之前你还得会使用 Photoshop。\n现在分享一个我经常使用的解决方案，阿里巴巴矢量图，这上面可以说有海量的图标可以用到。\n流程：\n　　1，进入 阿里巴巴矢量图 并搜索你想要的图标\n　　2，下载 Icon 时使用 SVG 下载\n　　3，用记事本或文本编辑器打开，标签 Path 下的 d 属性就是 Path 的 Data 数据（很多复杂一点的 Icon 可能是多个 Data 组成，使用时只要用空格把几个 Data 隔开就行）\n　　例子：\n\n\n　　&lt;svg t=“1491032725422” class=“icon” style=“” viewBox=“0 0 1024 1024” version=“1.1” xmlns=“http://www.w3.org/2000/svg“ p-id=“2372” xmlns:xlink=“http://www.w3.org/1999/xlink“ width=“248” height=“248”&gt;　　&lt;defs&gt;　　　　&lt;style type=“text&#x2F;css”&gt;&lt;&#x2F;style&gt;　　&lt;&#x2F;defs&gt;　　&lt;path d=“M503.2868 510.9903m-349.4226 0a341.233 341.233 0 1 0 698.8452 0 341.233 341.233 0 1 0-698.8452 0Z” p-id=“2373”&gt;&lt;&#x2F;path&gt;　　&lt;path d=“M106.1386 263.9677a110 100 0 1 1 121.6696 248.2668Z” p-id=“2374”&gt;&lt;&#x2F;path&gt;&lt;&#x2F;svg&gt;\n　　在WPF中使用时：\n&lt;Path Data=“M503.2868 510.9903m-349.4226 0a341.233 341.233 0 1 0 698.8452 0 341.233 341.233 0 1 0-698.8452 0Z M106.1386 263.9677a110 100 0 1 1 121.6696 248.2668Z”&#x2F;&gt;\nData 也可以作为资源放在独立的资源字典里，使用的 Geometry 标签\n&lt;Geometry x:Key=“logo”&gt;M503.2868 510.9903m-349.4226 0a341.233 341.233 0 1 0 698.8452 0 341.233 341.233 0 1 0-698.8452 0Z M106.1386 263.9677a110 100 0 1 1 121.6696 248.2668Z&lt;&#x2F;Geometry&gt;\nXAML：\n&lt;Path Data=“{StaticResource logo}” Fill=“White” Stretch=“Fill” Stroke=“White” StrokeThickness=“1.5” &#x2F;&gt;\n","categories":["编程技术","DotNet"],"tags":["WPF"]},{"title":"微软官方提供的SqlHelper类，完整版并附中文注释详解","url":"/2015/07/04/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/%E5%BE%AE%E8%BD%AF%E5%AE%98%E6%96%B9%E7%9A%84SQLHelper%E7%B1%BB(%E5%90%AB%E5%AE%8C%E6%95%B4%E4%B8%AD%E6%96%87%E6%B3%A8%E9%87%8A)/","content":"","categories":["编程技术","DotNet"],"tags":["SQL","Helper"]},{"title":"最全的Windows Azure学习教程汇总","url":"/2017/01/14/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/%E6%9C%80%E5%85%A8%E7%9A%84Windows%20Azure%E5%AD%A6%E4%B9%A0%E6%95%99%E7%A8%8B%E6%B1%87%E6%80%BB/","content":"Windows Azure 是微软基于云计算的操作系统，能够为开发者提供一个平台，帮助开发可运行在云服务器、数据中心、Web 和 PC 上的应用程序。\nAzure 是一种灵活和支持互操作的平台，能够将处于云端的开发者个人能力，同微软全球数据中心网络托管的服务，比如存储、计算和网络基础设施服务，紧密结合起来。帮助开发者在“云端”和“客户端”同时部署应用，使得企业与用户都能共享资源。\n本文整理了丰富的 Windows Azure 学习资源，帮助开发者能全面地学习 Windows Azure 知识，并将 Windows Azure 运用在项目和实际工作中。  \n通过本系列博客，先来了解一下 Windows Azure 平台的基本知识。Windows Azure，正如同桌面操作系统 Windows 和服务器操作系统 Windows Server 一样，是一个云端的操作系统。开发人员可以使用同一套技术：.NET（包括 Silverlight），或者 Win32，同时针对桌面，服务器，以及云，开发程序，而不需要针对某个平台学习专门的技术。Visual Studio 和 Expression Studio 为开发人员提供了强大的工具支持。\nWindows Azure平台简介(一)：定位与产品结构\nWindows Azure平台简介(二)：Windows Azure\nWindows Azure平台简介(三)：AppFabric\nWindows Azure平台简介(四)：SQL Azure以及其他服务\n在开始本教学之前，请确保你从 Windows Azure 平台下载下载并安装了最新的 Windows Azure 开发工具。本教学使用 Visual Studio 2010 作为开发工具。\nWindows Azure入门教学系列 (一)：创建第一个WebRole程序\nWindows Azure入门教学系列 (二)：部署第一个Web Role程序\nWindows Azure入门教学系列 (三)：创建第一个Worker Role程序\nWindows Azure入门教学系列 (四)：使用Blob Storage\nWindows Azure入门教学系列 (五)：使用Queue Storage\nWindows Azure入门教学系列 (六)：使用Table Storage\nWindows Azure入门教学系列 (七)：使用REST API访问Storage Service\nWindows Azure入门教学系列 (八)：使用Windows Azure Drive\nAzure学习笔记：Web Site（1）\nAzure学习笔记：Service Bus（2）\nAzure学习笔记：Storage（3）\nAzure学习笔记：Cloud Service（4）\nAzure Storage 是微软 Azure 云提供的云端存储解决方案，当前支持的存储类型有 Blob、Queue、File 和 Table。\n\nAzure Blob Storage 基本用法 – Azure Storage 之 Blob\nAzure Queue Storage 基本用法 – Azure Storage 之 Queue\nAzure File Storage 基本用法 – Azure Storage 之 File\nAzure Table storage 基本用法 – Azure Storage 之 Table\nWindows Azure Storage 支持三重冗余的。保存在 Azure Storage 的内容，会在同一个数据中心保留有3个副本。这样的好处显而易见：当数据中心发生一般性故障的时候，比如磁盘损坏，机架服务器损坏等，用户保存在 Azure Storage 的数据不会丢失。每次对于 Storage 的写操作，都会对三个副本进行同步写操作，等到在副本操作完毕之后，才会返回执行成功给客户端。\nWindows Azure 提供了三种不同类型的存储服务(这里的存储是非关系型数据，比如图片、文档等文件)，用来提供给 Windows Azure 上运行的应用程序存储数据使用。依据不同的存储格式会有不同的限制，因为这些存储服务都是以分散式巨量存储（Distributed Mass Storage）为核心概念所设计出来的，为了要达成快速在分散式存储空间中存储与管理数据（还包含高可用度的赘余存储管理），微软有在数据的存储上做一些限制。\n微软还提供了 REST API 来方便用户操作 Storage Service。\n（1）Windows Azure Storage Service存储服务\n（2）Windows Azure Storage Service存储服务之Blob详解(上)\n（3）Windows Azure Storage Service存储服务之Blob详解(中)\n（4）Windows Azure Storage Service存储服务之Blob Share Access Signature\n（5）Windows Azure Drive\n（6）Windows Azure Storage之Table\n（7）使用工具管理Windows Azure Storage\n（8）Windows Azure 上的托管服务CDN (上)\n（9）Windows Azure 上的托管服务CDN (中) Blob Service\n（10）Windows Azure 上的托管服务CDN (下) Hosted Service、\n（11）计算你存储的Blob的大小\n（12）本地冗余存储 vs 地理冗余存储 (上)\n（13）本地冗余存储 vs 地理冗余存储 (下)\n（14）使用Azure Blob的PutBlock方法，实现文件的分块、离线上传\n（15）使用WCF服务，将本地图片上传至Azure Storage (上) 服务器端代码\n（16）使用WCF服务，将本地图片上传至Azure Storage (上) 客户端代码\n（17）Azure Storage读取访问地域冗余(Read Access – Geo Redundant Storage, RA-GRS)\n（18）使用HTML5 Portal的Azure CDN服务\n（19）再谈Azure Block Blob和Page Blob\n（20）使用Azure File实现共享文件夹\n（21）使用AzCopy工具，加快Azure Storage传输速度\n（22）Azure Storage如何支持多级目录\n（23）计算Azure VHD实际使用容量\nPowerShell 是管理 Azure 的最好方式之一，通过使用 PowerShell 脚本可以把很多的工作自动化。比如对于 Azure 上的虚拟机，可以设置定时关机操作，并在适当的时间把它开机，这样就能减少虚拟机的运行时间，同时也能为节能减排做出贡献。\n（1）PowerShell入门\n（2）修改Azure订阅名称\n（3）上传证书\n（4）使用PowerShell管理多个订阅\n（5）使用Azure PowerShell创建简单的Azure虚拟机和Linux虚拟机\n（6）设置单个Virtual Machine Endpoint\n（7）使用CSV文件批量设置Virtual Machine Endpoint\n（8）使用PowerShell设置Azure负载均衡器规则\n（9）使用PowerShell导出订阅下所有的Azure VM的Public IP和Private IP\n（10）使用PowerShell导出订阅下所有的Azure VM和Cloud Service的高可用情况\n（11）使用自定义虚拟机镜像模板，创建Azure虚拟机并绑定公网IP(VIP)和内网IP(DIP)\n（12）通过Azure PowerShell创建SSH登录的Linux VM\nSQL Azure 是微软基于 Microsoft SQL Server Denali，也就是 SQL Server 2012 构建的云端关系型数据库服务。SQL Azure 是 SQL Server 的一个大子集，能够实现 SQL Server 的绝大部分功能，并且将它们作为云端的服务来扩展。SQL Azure Database 提供内置的高精准、可用性、功效与其他功能。\n（1）入门\n（2）SQL Azure vs SQL Server\n（3）创建一个SQL Azure 服务器\n（4）创建一个SQL Azure数据库\n（5）使用SQL Server Management Studio连接SQL Azure\n（6）使用Project Houston管理SQL Azure\n（7）在SQL Azure Database中执行的T-SQL\n（8）使用Visual Studio 2010开发应用连接SQL Azure云端数据库\n（9）把本地的SQL Server数据库迁移到SQL Azure云数据库上\n（10）SQL Azure Data Sync数据同步功能(上)\n（11）SQL Azure Data Sync数据同步功能(下)\n（12）使用新Portal 创建 SQL Azure Database\n（13）Azure的两种关系型数据库服务：SQL Azure与SQL Server VM的不同\n（14）将云端SQL Azure中的数据库备份到本地SQL Server\n（15）SQL Azure 新的规格\n（16）创建PaaS SQL Azure V12数据库\n（17）SQL Azure V12 - 跨数据中心标准地域复制(Standard Geo-Replication)\n（18）使用External Table实现垮库查询\n（19）Stretch Database 概览\n（20）使用SQL Server 2016 Upgrade Advisor\n（21）将整张表都迁移到Azure Stretch Database里\n（22）迁移部分数据到Azure Stretch Database\n1. 《Windows Azure 实战》全面深入，完整覆盖 Windows Azure 所有关键技术和理论，详细讲解云计算开发流程、云服务架构（可用性、可靠性和高性能）、云设备整合、系统整合，以及云计算项目的管理。注重实战，68个精心策划的针对特定实际应用场景的真实案例，详细呈现案例的设计思路和完整实现步骤。\n\n2. 《Windows Azure 从入门到精通》介绍了如何构建和管理云端的可扩展应用，一次一个知识点，同时辅之以适当的练习，可帮助读者轻松掌握基本的编程技能，掌握 Windows Azure 云计算平台的核心服务和特性，是一本理想的入门教程。\n\n3. 《云计算与Azure平台实战》解决了从本地转移到基于云的应用程序时，可能面临的各种问题；展示了如何将 ASP.NET 身份验证和角色管理用应用于 Azure Web 角色；揭示了迁移到 Windows Azure 时把计算服务卸载到一个或多个 WorkerWeb 角色的益处；讲解如何为共享 Azure 表选择最合适的 PartionKey 和 RowKey 值的组合；探讨了改善 Azure 表的可扩展性和性能的方法。\n\n4. 《走进云计算:Windows Azure实战手记》介绍了你必须学会的微软云开发技术，介绍目前最火爆的云计算，深入剖析微软最新的云开发平台，涵盖 Windows Azure 环境、存储服务、SQL Azure 数据库与 App Fabric 服务平台 Step by Step 递进教学，初学者可按部就班地学习云应用的开发技术。\n\n相关阅读：\nAzure Blob Storage 基本用法 – Azure Storage 之 Blob\nAzure Queue Storage 基本用法 – Azure Storage 之 Queue\nAzure File Storage 基本用法 – Azure Storage 之 File\nAzure Table storage 基本用法 – Azure Storage 之 Table\n","categories":["编程技术","DotNet"],"tags":["Azure教程"]},{"title":"解决LibVLCSharp弹出Direct3d11窗体问题","url":"/2024/06/01/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/%E8%A7%A3%E5%86%B3LibVLCSharp%E5%BC%B9%E5%87%BADirect3d11%E7%AA%97%E4%BD%93%E9%97%AE%E9%A2%98/","content":"LibVLCSharp版本\n&lt;PackageReference Include=&quot;LibVLCSharp&quot; version=&quot;3.6.6&quot; /&gt;&lt;PackageReference Include=&quot;LibVLCSharp.WPF&quot; version=&quot;3.6.6&quot; /&gt;&lt;PackageReference Include=&quot;VideoLAN.LibVLC.Windows&quot; version=&quot;3.0.16&quot; /&gt;\n\n现象播放RTSP视频流时在VideoView播放正常，但会弹出一个窗体同时播放，窗体名VLC (Direct3D11 output)\n\n代码如下\npublic partial class MainWindow : Window&#123;    private LibVLC m_libVLC;        public MainWindow()    &#123;        InitializeComponent();                this.Loaded += MainWindow_Loaded;                m_libVLC = new LibVLC();    &#125;        private void MainWindow_Loaded(object sender, RoutedEventArgs e)    &#123;        VideoView.MediaPlayer = new LibVLCSharp.Shared.MediaPlayer(m_libVLC);        VideoView.MediaPlayer.Play(new Media(m_libVLC, new Uri(uri)));    &#125;&#125;\n\n故障原因\n打断点调试发现，Loaded时间执行两次，第一次执行在VideoView播放正常，第二次执行弹出VLC (Direct3D11 output)窗\n解决方法: 控制只初始化和播放一次\npublic partial class MainWindow : Window&#123;    private LibVLC m_libVLC;        public MainWindow()    &#123;        InitializeComponent();                this.Loaded += MainWindow_Loaded;                m_libVLC = new LibVLC();    &#125;        private void MainWindow_Loaded(object sender, RoutedEventArgs e)    &#123;        VideoView.MediaPlayer ??= new LibVLCSharp.Shared.MediaPlayer(m_libVLC)        &#123;            Media = new Media(m_libVLC, new Uri(uri))        &#125;;                if (!VideoView.MediaPlayer.IsPlaying)            VideoView.MediaPlayer.Play();    &#125;&#125;\n\n","categories":["编程技术","DotNet"],"tags":["LibVLCSharp","Direct3d11"]},{"title":"Go MVC框架对比","url":"/2022/11/03/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Golang/Go-MVC%E6%A1%86%E6%9E%B6%E5%AF%B9%E6%AF%94/","content":"Beego官网 https://beego.me\ngithub https://github.com/astaxie/beego\n优点：\n\n很全很简单\n不仅追求性能，同样追求开发效率，解放程序员的生产力\n社区良好，中文开发者很多，找资料很方便\n代码文档化做的很优秀\n\n缺点：\n\n比较臃肿，因为提供了很多支持，当遇到坑时需要花很多时间查源码解决问题\n模块众多，这既是优点也是缺点\n\nEcho官网 https://echo.labstack.com\ngithub https://github.com/labstack/echo\n优点：\n\n路由性能高\n更轻量级的web开发框架\n\n缺点：\n\n调试不方便，报错信息不友好\n路由性能虽高，但是路由实现的算法底层不支持路由排序，会引起路由冲突\n\nGin官网 https://gin-gonic.github.io/gin\ngithub https://github.com/gin-gonic/gin\n优点：\n\n封装比较好，API友好，源码注释比较明确，具有快速灵活，容错方便等特点\n运行速度快，分组的路由器，良好的崩溃捕获和错误处理，非常好的支持中间件和 json\n\n缺点：\n\n封装比较好，API友好，源码注释比较明确，具有快速灵活，容错方便等特点\n运行速度快，分组的路由器，良好的崩溃捕获和错误处理，非常好的支持中间件和 json\n\nIris官网 https://iris-go.com\ngithub https://github.com/kataras/iris\n优点：\n\n是社区驱动的Go语言Web 框架，支持http2，完备 MVC 支持。\n极简主义风格\n社区活跃度和文档支持都非常到位\n\n缺点：\n\n不够稳定，社区里有人反馈：最新的release版本是alpha版非常不稳定\n支持Iris的人很多，但是目前仍然不如Gin和Echo多\n\n","categories":["编程技术","Golang"],"tags":["MVC"]},{"url":"/2022/09/09/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Golang/Go-Websocket/","content":"golang.org/x/net/websocket示例package mainimport (\t&quot;fmt&quot;\t&quot;log&quot;\t&quot;net/http&quot;\t&quot;code.google.com/p/go.net/websocket&quot;)func echo(ws *websocket.Conn) &#123;\tvar err error\tvar i int\tfor &#123;\t\tvar reply string\t\t//建立连接后接收来自客户端的信息reply\t\tif err == websocket.Message.Receive(ws, &amp;reply); err != nil &#123;\t\t\tfmt.Println(&quot;error, can&#x27;t receive message ...&quot;)\t\t\tbreak\t\t&#125;\t\tfmt.Println(&quot;recevied from client: &quot; + reply)\t\ti++\t\t// 把收到的信息进行处理，可以做过滤也可以返回国定信息\t\tmsg := &quot;received: &quot; + reply\t\tfmt.Println(&quot;send to client: &quot; + msg)\t\tfmt.Println(i)\t\t// 返回消息给客户端\t\tif err = websocket.Message.Send(ws, msg); err != nil &#123;\t\t\tfmt.Println(&quot;error,can&#x27;t send message ...&quot;)\t\t\tbreak\t\t&#125;\t&#125;&#125;func main() &#123;\thttp.Handle(&quot;/&quot;, websocket.Handle(echo))\t// 访问服务器地址，ws://127.0.0.1:8088\tif err := http.ListenAndServe(&quot;:8088&quot;, nil); err != nil &#123;\t\tlog.Fatal(&quot;listen and serve: &quot;, err)\t&#125;&#125;\n\ngithub.com/gorilla/websocket示例package mainimport (\t&quot;log&quot;\t&quot;net/http&quot;\t&quot;github.com/gorilla/websocket&quot;)var (\tupgrader = websocket.Upgrader&#123;\t\t// 读取缓冲区空间大小\t\tReadBufferSize: 1024,\t\t// 写入缓冲区空间大小\t\tWriteBufferSize: 1024,\t\tCheckOrigin: func(r *http.Request) bool &#123;\t\t\treturn true\t\t&#125;,\t&#125;)func wsHandler(w http.ResponseWriter, r *http.Request) &#123;\t//完成握手升级为websocket长连接，使用conn发送和接收消息\tconn, err := upgrader.Upgrade(w, r, nil)\tif err != nil &#123;\t\tlog.Println(&quot;upgrade: &quot;, err)\t\treturn\t&#125;\tdefer conn.Close()\tfor &#123;\t\tmessageType, msg, err := conn.ReadMessage()\t\tif err != nil &#123;\t\t\tlog.Println(&quot;reading error ...&quot;, err)\t\t\treturn\t\t&#125;\t\tlog.Printf(&quot;read from client msg: %s \\n&quot;, msg)\t\tif err := conn.WriteMessage(messageType, msg); err != nil &#123;\t\t\tlog.Println(&quot;writing error ...&quot;, err)\t\t\treturn\t\t&#125;\t\tlog.Printf(&quot;write msg to client: %s \\n&quot;, msg)\t&#125;&#125;func main() &#123;\t// 监听地址 ws://127.0.0.1:8088\thttp.HandleFunc(&quot;/&quot;, wsHandler)\terr := http.ListenAndServe(&quot;:8088&quot;, nil)\tif err != nil &#123;\t\tlog.Fatal(&quot;listen and serve &quot;, err.Error())\t&#125;&#125;\n\n","categories":["编程技术","Golang"],"tags":["Websocket"]},{"title":"GoLang搭建WebAPI","url":"/2022/11/03/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Golang/GoLang%E6%90%AD%E5%BB%BAWebAPI/","content":"","categories":["编程技术","Golang"],"tags":["MVC","WebAPI","Gin","Gorm"]},{"title":"Golang使用JWT","url":"/2024/07/11/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Golang/Golang%E4%BD%BF%E7%94%A8JWT/","content":"GO语言Gin包（JWT使用） - 码农后生 - 博客园 (cnblogs.com)\n在Gin中使用JWT做认证以及JWT的续签方案 - 掘金 (juejin.cn)\n使用 Go 添加 JWT 认证 - 知乎 (zhihu.com)\ngin框架教程三：JWT的使用 - 九卷 - 博客园 (cnblogs.com)\n","categories":["编程技术","Golang"],"tags":["JWT"]},{"title":"Golang国内镜像源","url":"/2024/07/11/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Golang/Golang%E5%9B%BD%E5%86%85%E9%95%9C%E5%83%8F%E6%BA%90/","content":"Golang 国内的镜像源_golang 国内镜像-CSDN博客\n","categories":["编程技术","Golang"]},{"title":"Golang实现Async/Await模式","url":"/2024/07/11/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Golang/Golang%E5%AE%9E%E7%8E%B0Async-Await%E6%A8%A1%E5%BC%8F/","content":"使用 Go 实现 Async&#x2F;Await 模式 - 知乎 (zhihu.com)\n","categories":["编程技术","Golang"]},{"title":"Golang实现SM4","url":"/2025/03/26/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Golang/Golang%E5%AE%9E%E7%8E%B0SM4/","content":"ECB模式，PKCS5填充\npackage sm4 import (\t&quot;bytes&quot;\t&quot;encoding/hex&quot;\t&quot;github.com/tjfoc/gmsm/sm4&quot;) func SM4EcbEncrypt(key, plaintext []byte) (string, error) &#123;\tblock, err := sm4.NewCipher(key)\tif err != nil &#123;\t\treturn &quot;&quot;, err\t&#125; \tplaintext = PKCS5Padding(plaintext, block.BlockSize())\tciphertext := make([]byte, len(plaintext)) \tfor start := 0; start &lt; len(plaintext); start += block.BlockSize() &#123;\t\tblock.Encrypt(ciphertext[start:start+block.BlockSize()], plaintext[start:start+block.BlockSize()])\t&#125; \treturn hex.EncodeToString(ciphertext), nil&#125; func SM4EcbDecrypt(key []byte, data string) ([]byte, error) &#123;\tplaintext, _ := hex.DecodeString(data)\tblock, err := sm4.NewCipher(key)\tif err != nil &#123;\t\treturn nil, err\t&#125; \tciphertext := make([]byte, len(plaintext)) \tfor start := 0; start &lt; len(plaintext); start += block.BlockSize() &#123;\t\tblock.Decrypt(ciphertext[start:start+block.BlockSize()], plaintext[start:start+block.BlockSize()])\t&#125;\tciphertext = PKCS5Unpadding(ciphertext)\treturn ciphertext, nil&#125; func PKCS5Padding(ciphertext []byte, blockSize int) []byte &#123;\tpadding := blockSize - len(ciphertext)%blockSize\tpadtext := bytes.Repeat([]byte&#123;byte(padding)&#125;, padding)\treturn append(ciphertext, padtext...)&#125; func PKCS5Unpadding(origData []byte) []byte &#123;\tlength := len(origData)\tunpadding := int(origData[length-1])\treturn origData[:(length - unpadding)]&#125;\n\n","categories":["编程技术","Golang"],"tags":["Golang","国密","SM4"]},{"title":"Golang日志组件logrus使用","url":"/2024/07/11/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Golang/Golang%E6%97%A5%E5%BF%97%E7%BB%84%E4%BB%B6logrus%E4%BD%BF%E7%94%A8/","content":"Golang日志之logrus的使用 - 知乎 (zhihu.com)\n","categories":["编程技术","Golang"],"tags":["logrus","日志组件"]},{"title":"Golang环境配置","url":"/2025/03/19/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Golang/Golang%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","content":"安装GolangWindows版本下载安装程序安装即可，Ubuntu下有两种安装方式第一种方式\nsudo apt updatesudo apt install golang\n此种方式安装的版本并不是最新版，或者下载 [官方包]执行\nsudo tar -zxvf go1.24.2.linux-amd64.tar.gz -C  /usr/local # 解压缩到/usr/localsudo chmod 755 -R /usr/local/go # 修改权限，一般解压后就有权限，此步可以省略\n\n配置环境变量Windows打开 系统设置-&gt;关于-&gt;高级系统设置-&gt;环境变量，注意如果只给当前用户使用添加到用户的环境变量即可，全部用户可用需配置系统环境变量。\nGOROOT\n![[Golang环境配置&#x2F;IMG-20250804110742705.png]]\nGOPATH![[Golang环境配置&#x2F;IMG-20250804110742880.png]]\nGOPROXY\n![[Golang环境配置&#x2F;IMG-20250804110743185.png]]\nUbuntu如果只给当前用户使用编辑用户目录下.bashrc文件，全部用户可用需配置/etc/profile。\nexport GOROOT=/usr/local/go # Golang根目录export GOPATH=/home/go-project # 项目根目录export PATH=$GOROOT/bin:$GOPATH/bin:$PATH\n\n\n进阶配置GOPROXY可在环境变量中配置也可使用go env -w命令配置\ngo env -w GOPROXY=https://goproxy.cn # 七牛go env -w GOPROXY=https://mirrors.aliyun.com/goproxy/ # 阿里go env -w GOPROXY=https://goproxy.io # 官方\n\nGO111MODULE从go 1.11版本开始，推荐使用Go Modules进行包管理。\ngo env -w GO111MODULE=on\n\n在项目目录下初始化模块\ngo mod init ","categories":["编程技术","Golang"],"tags":["环境配置","Golang"]},{"title":"Golang检查目录是否存在","url":"/2025/03/26/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Golang/Golang%E6%A3%80%E6%9F%A5%E7%9B%AE%E5%BD%95%E6%98%AF%E5%90%A6%E5%AD%98%E5%9C%A8/","content":"使用os.stat()package mainimport (   &quot;fmt&quot;   &quot;os&quot;)func main() &#123;   dir := &quot;new&quot;   if _, err := os.Stat(dir); os.IsNotExist(err) &#123;      fmt.Println(dir, &quot;does not exist&quot;)   &#125; else &#123;      fmt.Println(&quot;The provided directory named&quot;, dir, &quot;exists&quot;)   &#125;&#125;\n\n使用os.open()package mainimport (   &quot;fmt&quot;   &quot;os&quot;)func main() &#123;   dir := &quot;go&quot;   if _, err := os.Open(dir); os.IsNotExist(err) &#123;      fmt.Println(&quot;The directory named&quot;, dir, &quot;does not exist&quot;)   &#125; else &#123;      fmt.Println(&quot;The directory namend&quot;, dir, &quot;exists&quot;)   &#125;&#125;\n使用mkdir()package mainimport (   &quot;fmt&quot;   &quot;os&quot;)func main() &#123;   dir := &quot;new&quot;   if err := os.Mkdir(dir, 0755); os.IsExist(err) &#123;      fmt.Println(&quot;The directory named&quot;, dir, &quot;exists&quot;)   &#125; else &#123;      fmt.Println(&quot;The directory named&quot;, dir, &quot;does not exist&quot;)   &#125;&#125;","categories":["编程技术","Golang"],"tags":["Golang"]},{"title":"Gorm使用","url":"/2024/07/11/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Golang/Gorm%E4%BD%BF%E7%94%A8/","content":"Golang下的ORM框架gorm的介绍和使用 - 知乎 (zhihu.com)\n","categories":["编程技术","Golang"],"tags":["Gorm"]},{"title":"Java&Quartz实现任务调度","url":"/2015/10/31/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Java/Java&Quartz%E5%AE%9E%E7%8E%B0%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6/","content":"1.Quartz的作用定时自动执行任务\n2.预备相关包官方网站\nquartz2.2.1quartz-jobs2.2.1\n\nPOM文件\n&lt;dependency&gt;    &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt;    &lt;artifactId&gt;quartz&lt;/artifactId&gt;    &lt;version&gt;2.2.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;     &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt;     &lt;artifactId&gt;quartz-jobs&lt;/artifactId&gt;     &lt;version&gt;2.2.1&lt;/version&gt; &lt;/dependency&gt;   \n\n3.Quartz核心3.1.Job接口被调度的任务,只有一个方法execute(JobExecutionContext xontext),Job运行时的信息保存在JobDataMap中\n3.2.JobDetail类实现Job接口,用来描述Job的相关信息,包含Name,Group,JobDataMap等\n3.3 JobExecutionContext类定时程序执行的run-time的上下文环境,用于得到Job的名字、配置的参数等\n3.3 JobDataMap类用来描述一个作业的参数,参数可以为金和基本类型或者某个对象的引用\n3.3 JobListener接口监听作业状态\n3.3 TriggaerListener接口监听触发器状态\n3.3 JobStore3.3.Tigger抽象类触发器,描述执行Job的触发规则,有SimpleTrigger和CronTrigger两个子类\n3.3.1.SimpleTrigger类继承自Trigger类,每隔xx毫秒&#x2F;秒执行一次,主要实现固定一次或者固定时间周期类任务的触发\n3.3.2.CronTrigger类继承自Trigger类,使用Cron表达式,实现各种复杂时间规则调度方案,如每天的某个时间,或每周的某几天触发执行之类\n3.4.Calendar包一些日历特定时间点的集合,包内包含以下几个类\n3.4.1 BaseCalendar类3.4.2 AnnualCalendar类排除每一年中指定的一天或者多天\n3.4.3 CalendarComparator类3.4.4 CronCalendar类使用表达式排除某时间段不执行\n3.4.5 DailyCalendar类指定的时间范围内每天不执行\n3.4.6 HolidayCalendar类排除节假日\n3.4.7 MonthlyCalendar类配出月份中的数天\n3.4.8 WeeklyCalendar类排除没周中的一天或者多天\n3.5.Scheduler类任务调度器,代表一个Quartz独立容器。\nScheduler可以将JobDetail和Trigger绑定,当Trigger触发时,对应的Job就会被执行,Job和Trigger是1:n(一对多)的关系\n3.6Misfire类错误的任务,本该执行单没有执行的任务调度\n4.实现1.单任务实现1.定义一个任务,新建任务类继承自Job类\npackage com;import java.text.SimpleDateFormat;import java.util.Date;import org.quartz.Job;import org.quartz.JobExecutionContext;import org.quartz.JobExecutionException;public class DemoJob implements Job &#123;@Overridepublic void execute(JobExecutionContext arg0) throws JobExecutionException &#123;System.out.println(new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date()));&#125;&#125;\n\n2.新建类执行这个任务(SimpleTrigger)\npackage com;import java.util.Date;import org.quartz.DateBuilder;import org.quartz.JobBuilder;import org.quartz.JobDetail;import org.quartz.Scheduler;import org.quartz.SchedulerException;import org.quartz.SchedulerFactory;import org.quartz.SimpleScheduleBuilder;import org.quartz.Trigger;import org.quartz.TriggerBuilder;import org.quartz.impl.StdSchedulerFactory;public class QuartzDemo &#123;public void simpleRun() throws SchedulerException &#123;SchedulerFactory factory = new StdSchedulerFactory();     Date runTime = DateBuilder.evenSecondDateAfterNow();  JobDetail jobDetail = JobBuilder.newJob(DemoJob.class).withIdentity(&quot;demo_job&quot;, &quot;demo_group&quot;).build();Trigger trigger = TriggerBuilder.newTrigger().withIdentity(&quot;demo_trigger&quot;, &quot;demo_group&quot;).startAt(new Date()).withSchedule(SimpleScheduleBuilder.simpleSchedule().withIntervalInSeconds(1).withRepeatCount(5)).build();Scheduler scheduler = factory.getScheduler();scheduler.scheduleJob(jobDetail,trigger);System.out.println(jobDetail.getKey() + &quot; 运行在: &quot; + runTime);   scheduler.start();  &#125;public static void main(String[] args) &#123;QuartzDemo demo = new QuartzDemo();try &#123;demo.simpleRun();&#125; catch (SchedulerException e) &#123;e.printStackTrace();&#125;&#125;&#125;\n\n2.多任务实现\n测试任务类新建两个DemoJonOne和DemoJobTwo,都实现Job接口,内容如下\n\n@Overridepublic void execute(JobExecutionContext arg0) throws JobExecutionException &#123;System.out.println(new SimpleDateFormat(&quot;HH:mm:ss&quot;).format(new Date())+&quot; Runed &quot;+getClass().getName());&#125;\n\n2.新建QuartzUtil类,内容如下\npackage com;import org.quartz.Job;import org.quartz.JobBuilder;import org.quartz.JobDetail;import org.quartz.Scheduler;import org.quartz.SchedulerException;import org.quartz.SchedulerFactory;import org.quartz.SimpleScheduleBuilder;import org.quartz.Trigger;import org.quartz.TriggerBuilder;import org.quartz.impl.StdSchedulerFactory;public class QuartzUtil &#123;private final static String JOB_GROUP_NAME = &quot;QUARTZ_JOBGROUP_NAME&quot;;private final static String TRIGGER_GROUP_NAME = &quot;QUARTZ_TRIGGERGROUP_NAME&quot;;public static void addJob(String jobName, String triggerName, Class&lt;? extends Job&gt; jobClass, int seconds)throws SchedulerException &#123;SchedulerFactory sf = new StdSchedulerFactory();Scheduler sche = sf.getScheduler();JobDetail jobDetail = JobBuilder.newJob(jobClass).withIdentity(jobName, JOB_GROUP_NAME).build();Trigger trigger = TriggerBuilder.newTrigger().withIdentity(triggerName, TRIGGER_GROUP_NAME).startNow().withSchedule(SimpleScheduleBuilder.simpleSchedule().withIntervalInSeconds(seconds).repeatForever()).build();sche.scheduleJob(jobDetail, trigger);sche.start();&#125;public static void main(String[] args) &#123;try &#123;QuartzUtil.addJob(&quot;job1&quot;, &quot;trigger1&quot;, DemoJobOne.class, 2);QuartzUtil.addJob(&quot;Job2&quot;, &quot;trigger2&quot;, DemoJobTwo.class, 5);&#125; catch (SchedulerException e) &#123;e.printStackTrace();&#125;&#125;&#125;\n\n以上方法属于手动调用,如果是web项目中就不同了添加POM\n&lt;dependency&gt;  &lt;groupId&gt;javax.servlet&lt;/groupId&gt;  &lt;artifactId&gt;servlet-api&lt;/artifactId&gt;  &lt;version&gt;2.5&lt;/version&gt;&lt;/dependency&gt;\n\npackage servlet;import javax.servlet.ServletException;import javax.servlet.http.HttpServlet;import org.quartz.SchedulerException;import com.DemoJobOne;import com.DemoJobTwo;import com.QuartzUtil;public class InitServlet extends HttpServlet &#123;private static final long serialVersionUID = 8507188690597926975L;public void init() throws ServletException &#123;try &#123;QuartzUtil.addJob(&quot;job1&quot;, &quot;trigger1&quot;, DemoJobOne.class, 2);QuartzUtil.addJob(&quot;Job2&quot;, &quot;trigger2&quot;, DemoJobTwo.class, 5);&#125; catch (SchedulerException e) &#123;e.printStackTrace();&#125;&#125;&#125;\n\n2.注册servlet\n&lt;servlet&gt;  &lt;servlet-name&gt;InitServlet&lt;/servlet-name&gt;  &lt;servlet-class&gt;servlet.InitServlet&lt;/servlet-class&gt;    &lt;load-on-startup&gt;0&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt;  &lt;servlet-name&gt;InitServlet&lt;/servlet-name&gt;  &lt;url-pattern&gt;/InitServlet&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;\n\n3.复杂规则任务调度(CronTrigger)在每分钟的1-30秒执行示例\npackage com;import org.quartz.CronScheduleBuilder;import org.quartz.JobBuilder;import org.quartz.JobDetail;import org.quartz.Scheduler;import org.quartz.SchedulerException;import org.quartz.SchedulerFactory;import org.quartz.Trigger;import org.quartz.TriggerBuilder;import org.quartz.impl.StdSchedulerFactory;public class CronTriggerDemo &#123;public static void main(String[] args) throws SchedulerException &#123;SchedulerFactory factory = new StdSchedulerFactory();Scheduler scheduler = factory.getScheduler();JobDetail job = JobBuilder.newJob(DemoJobOne.class).withIdentity(&quot;job&quot;,&quot;group&quot;).build();Trigger trigger = TriggerBuilder.newTrigger().withIdentity(&quot;trigger&quot;, &quot;group&quot;).startNow().withSchedule(CronScheduleBuilder.cronSchedule(&quot;1-30 * * * * ?&quot;)).build();scheduler.scheduleJob(job,trigger);scheduler.start();&#125;&#125;\n\n5.Cron表达式规则格式\ns M h d m w [y]\n\ns:seconds,取值0-59,允许- * &#x2F;;\nM:minutes,取值0-59,允许- * &#x2F;;\nh:hour,取值0-23,允许- * &#x2F;;\nd:day of month,取值1-31,允许- * ? &#x2F; L W;\nm:month,取值1-12&#x2F;JAN-DEC,允许- * &#x2F;;\nw:day of week,取值1-7&#x2F;SUN-SAT,允许- * ? &#x2F; L #;\ny:year,可选,取值empty、1970-2099,允许- * &#x2F;;\n符号解释、 指定枚举值,如在秒字段使用10、12,则表示只有第10秒和第12秒执行- 指定区间范围,配合使用,如在小时字段使用10-12,表示在10、11、12时都会触发\n* 代表所有值,单独使用,如在秒字段使用,表示每秒触发\n? 代表不确定值,单独使用,不用关心的值\n&#x2F; 用于递增触发,配合使用,n&#x2F;m,从n开始,每次增加m,如在秒字段设置5&#x2F;15,表示从第5秒开始,每15秒触发一次\nL 表示最后,单独使用,如在秒字段使用,代表第59秒触发,如果在前面加上数字,则表示该数据的最后一个,如在周字段使用6L,则表示本月最后一个周五W 表示最近的工作日,不会跨月,比如30W，30号是周六，则不会顺延至下周一来执行,如在月字段使用15W,则表示到本月15日最近的工作日(周一到周五)# 用来指定x的第n个工作日,如在周字段使用6#3则表示该月的第三个星期五\n月取值一月:JAN&#x2F;0二月:FEB&#x2F;1三月:MAR&#x2F;2四月:APR&#x2F;3五月:MAY&#x2F;4六月:JUN&#x2F;5七月:JUL&#x2F;6八月:AUG&#x2F;7九月:SEP&#x2F;8十月:OCT&#x2F;9十一月:NOV&#x2F;10十二月:DEC&#x2F;11\n周取值周日:SUN&#x2F;1周一:MON&#x2F;2周二:TUE&#x2F;3周三:WED&#x2F;4周四:THU&#x2F;5周五:FRI&#x2F;6周六:SAT&#x2F;7\n示例0/20 * * * * ? 每20秒执行一次1-30 * * * * ? 在1-30秒执行15 0/2 * * * ? 偶数分钟的第15秒执行0 0/2 8-17 * * ? 从8时到17时 ,每个偶数分钟执行一次0 0/3 17-23 * * ? 从17时到23时,每3分钟运行一次0 0 10am 1,15 * ? 每个月的1号和15号的上午10点 运行0,30 * * ? * MON-FRI 周一至周五,每30秒运行一次0,30 * * ? * SAT,SUN 周六、周日,每30秒运行一次0 0 12 * * ? 每天12点触发0 15 10 ? * * 每天10点15分触发0 15 10 * * ? 每天10点15分触发0 15 10 * * ? * 每天10点15分触发0 15 10 * * ? 2005 2005年每天10点15分触发0 * 14 * * ? 每天下午的 2点到2点59分每分触发0 0/5 14 * * ? 每天下午的 2点到2点59分(整点开始，每隔5分触发)0 0/5 14,18 * * ? 每天下午的 2点到2点59分(整点开始，每隔5分触发) 每天下午的 18点到18点59分(整点开始，每隔5分触发)0 0-5 14 * * ?  每天下午的 2点到2点05分每分触发0 10,44 14 ? 3 WED 3月分每周三下午的 2点10分和2点44分触发0 15 10 ? * MON-FRI 从周一到周五每天上午的10点15分触发0 15 10 15 * ? 每月15号上午10点15分触发0 15 10 L * ? 每月最后一天的10点15分触发0 15 10 ? * 6L 每月最后一周的星期五的10点15分触发0 15 10 ? * 6L 2002-2005 从2002年到2005年每月最后一周的星期五的10点15分触发0 15 10 ? * 6#3 每月的第三周的星期五开始触发0 0 12 1/5 * ? 每月的第一个中午开始每隔5天触发一次0 11 11 11 11 ? 每年的11月11号 11点11分触发(光棍节)\n\n6.Spring整合Quartz需要Spring-context-support包支持,POM如下\n&lt;dependency&gt;    &lt;groupId&gt;org.springframework&lt;/groupId&gt;    &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt;    &lt;version&gt;4.3.5.RELEASE&lt;/version&gt;&lt;/dependency&gt;\n\n新建两种Job测试类–&gt;DemoSimpleJob类和DemoCronJob类,并继承自QuartzJobBean,代码如下\npackage com;import java.text.SimpleDateFormat;import java.util.Date;import org.quartz.JobExecutionContext;import org.quartz.JobExecutionException;import org.springframework.scheduling.quartz.QuartzJobBean;public class DemoJob extends QuartzJobBean &#123;    @Override    protected void executeInternal(JobExecutionContext arg0) throws JobExecutionException &#123;        System.out.println(new SimpleDateFormat(&quot;hh:mm:ss&quot;).format(new Date()) + &quot; 输出自:&quot; + getClass().getName());    &#125;&#125;\n\n配置spring bean如下\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot;    xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot;    xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans       http://www.springframework.org/schema/beans/spring-beans-4.3.xsd       http://www.springframework.org/schema/context       http://www.springframework.org/schema/context/spring-context-4.3.xsd       http://www.springframework.org/schema/aop       http://www.springframework.org/schema/aop/spring-aop-4.3.xsd       http://www.springframework.org/schema/tx       http://www.springframework.org/schema/tx/spring-tx-4.3.xsd&quot;&gt;                &lt;bean id=&quot;demoCronJob&quot;        class=&quot;org.springframework.scheduling.quartz.JobDetailFactoryBean&quot;&gt;        &lt;property name=&quot;jobClass&quot; value=&quot;com.DemoCronJob&quot; /&gt;    &lt;/bean&gt;    &lt;bean id=&quot;demoSimpleJob&quot;        class=&quot;org.springframework.scheduling.quartz.JobDetailFactoryBean&quot;&gt;        &lt;property name=&quot;jobClass&quot; value=&quot;com.DemoSimpleJob&quot; /&gt;    &lt;/bean&gt;            &lt;bean id=&quot;simpleTrigger&quot;        class=&quot;org.springframework.scheduling.quartz.SimpleTriggerFactoryBean&quot;&gt;        &lt;property name=&quot;jobDetail&quot; ref=&quot;demoSimpleJob&quot; /&gt;        &lt;property name=&quot;startDelay&quot; value=&quot;1000&quot; /&gt;          &lt;property name=&quot;repeatInterval&quot; value=&quot;2000&quot; /&gt;      &lt;/bean&gt;    &lt;bean id=&quot;cornTrigger&quot;        class=&quot;org.springframework.scheduling.quartz.CronTriggerFactoryBean&quot;&gt;        &lt;property name=&quot;jobDetail&quot; ref=&quot;demoCronJob&quot; /&gt;        &lt;property name=&quot;cronExpression&quot; value=&quot;1-30 * * * * ?&quot; /&gt;    &lt;/bean&gt;        &lt;bean class=&quot;org.springframework.scheduling.quartz.SchedulerFactoryBean&quot;&gt;        &lt;property name=&quot;triggers&quot;&gt;            &lt;list&gt;                &lt;ref bean=&quot;cornTrigger&quot; /&gt;                &lt;ref bean=&quot;simpleTrigger&quot; /&gt;            &lt;/list&gt;        &lt;/property&gt;    &lt;/bean&gt;\n\n启动\npackage com;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class Demo &#123;    public static void main(String[] args) &#123;        ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;);    &#125;&#125;\n\n有待补充\n","categories":["编程技术","Java"],"tags":["任务调度","Quartz"]},{"title":"Mybatis Generator最完整配置详解","url":"/2015/11/07/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Java/Mybatis%20Generator%E6%9C%80%E5%AE%8C%E6%95%B4%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/","content":"同学们有福了，花了一些时间，重新整理了一个最完整的Mybatis Generator（简称MBG）的最完整配置文件，带详解，再也不用去看EN的User Guide了；\n\n\n\n\n&lt;generatorConfiguration&gt;\n\n\n \n\n\n&lt;context id=“mysql” defaultModelType=“hierarchical” targetRuntime=“MyBatis3Simple” &gt;\n&lt;!-- 自动识别数据库关键字，默认false，如果设置为true，根据SqlReservedWords中定义的关键字列表；\n    一般保留默认值，遇到数据库关键字（Java关键字），使用columnOverride覆盖 \\--&gt;\n&lt;property name\\=&quot;autoDelimitKeywords&quot; value\\=&quot;false&quot;/&gt;\n&lt;!-- 生成的Java文件的编码 \\--&gt;\n&lt;property name\\=&quot;javaFileEncoding&quot; value\\=&quot;UTF-8&quot;/&gt;\n&lt;!-- 格式化java代码 \\--&gt;\n&lt;property name\\=&quot;javaFormatter&quot; value\\=&quot;org.mybatis.generator.api.dom.DefaultJavaFormatter&quot;/&gt;\n&lt;!-- 格式化XML代码 \\--&gt;\n&lt;property name\\=&quot;xmlFormatter&quot; value\\=&quot;org.mybatis.generator.api.dom.DefaultXmlFormatter&quot;/&gt;\n\n&lt;!-- beginningDelimiter和endingDelimiter：指明数据库的用于标记数据库对象名的符号，比如ORACLE就是双引号，MYSQL默认是\\`反引号； \\--&gt;\n&lt;property name\\=&quot;beginningDelimiter&quot; value\\=&quot;\\`&quot;/&gt;\n&lt;property name\\=&quot;endingDelimiter&quot; value\\=&quot;\\`&quot;/&gt;\n\n&lt;!-- 必须要有的，使用这个配置链接数据库\n    @TODO:是否可以扩展 \\--&gt;\n&lt;jdbcConnection driverClass\\=&quot;com.mysql.jdbc.Driver&quot; connectionURL\\=&quot;jdbc:mysql:///pss&quot; userId\\=&quot;root&quot; password\\=&quot;admin&quot;\\&gt;\n    &lt;!-- 这里面可以设置property属性，每一个property属性都设置到配置的Driver上 \\--&gt;\n&lt;/jdbcConnection\\&gt;\n\n&lt;!-- java类型处理器 \n    用于处理DB中的类型到Java中的类型，默认使用JavaTypeResolverDefaultImpl；\n    注意一点，默认会先尝试使用Integer，Long，Short等来对应DECIMAL和 NUMERIC数据类型； \\--&gt;\n&lt;javaTypeResolver type\\=&quot;org.mybatis.generator.internal.types.JavaTypeResolverDefaultImpl&quot;\\&gt;\n    &lt;!-- true：使用BigDecimal对应DECIMAL和 NUMERIC数据类型\n        false：默认,\n            scale&gt;0;length&gt;18：使用BigDecimal;\n            scale=0;length\\[10,18\\]：使用Long；\n            scale=0;length\\[5,9\\]：使用Integer；\n            scale=0;length&lt;5：使用Short； \\--&gt;\n    &lt;property name\\=&quot;forceBigDecimals&quot; value\\=&quot;false&quot;/&gt;\n&lt;/javaTypeResolver\\&gt;\n\n&lt;!-- java模型创建器，是必须要的元素\n    负责：1，key类（见context的defaultModelType）；2，java类；3，查询类\n    targetPackage：生成的类要放的包，真实的包受enableSubPackages属性控制；\n    targetProject：目标项目，指定一个存在的目录下，生成的内容会放到指定目录中，如果目录不存在，MBG不会自动建目录 \\--&gt;\n&lt;javaModelGenerator targetPackage\\=&quot;com.\\_520it.mybatis.domain&quot; targetProject\\=&quot;src/main/java&quot;\\&gt;\n    &lt;!-- for MyBatis3/MyBatis3Simple\n        自动为每一个生成的类创建一个构造方法，构造方法包含了所有的field；而不是使用setter； \\--&gt;\n    &lt;property name\\=&quot;constructorBased&quot; value\\=&quot;false&quot;/&gt;\n\n    &lt;!-- 在targetPackage的基础上，根据数据库的schema再生成一层package，最终生成的类放在这个package下，默认为false \\--&gt;\n    &lt;property name\\=&quot;enableSubPackages&quot; value\\=&quot;true&quot;/&gt;\n\n    &lt;!-- for MyBatis3 / MyBatis3Simple\n        是否创建一个不可变的类，如果为true，\n        那么MBG会创建一个没有setter方法的类，取而代之的是类似constructorBased的类 \\--&gt;\n    &lt;property name\\=&quot;immutable&quot; value\\=&quot;false&quot;/&gt;\n\n    &lt;!-- 设置一个根对象，\n        如果设置了这个根对象，那么生成的keyClass或者recordClass会继承这个类；在Table的rootClass属性中可以覆盖该选项\n        注意：如果在key class或者record class中有root class相同的属性，MBG就不会重新生成这些属性了，包括：\n            1，属性名相同，类型相同，有相同的getter/setter方法； \\--&gt;\n    &lt;property name\\=&quot;rootClass&quot; value\\=&quot;com.\\_520it.mybatis.domain.BaseDomain&quot;/&gt;\n\n    &lt;!-- 设置是否在getter方法中，对String类型字段调用trim()方法 \\--&gt;\n    &lt;property name\\=&quot;trimStrings&quot; value\\=&quot;true&quot;/&gt;\n&lt;/javaModelGenerator\\&gt;\n\n&lt;!-- 生成SQL map的XML文件生成器，\n    注意，在Mybatis3之后，我们可以使用mapper.xml文件+Mapper接口（或者不用mapper接口），\n        或者只使用Mapper接口+Annotation，所以，如果 javaClientGenerator配置中配置了需要生成XML的话，这个元素就必须配置\n    targetPackage/targetProject:同javaModelGenerator \\--&gt;\n&lt;sqlMapGenerator targetPackage\\=&quot;com.\\_520it.mybatis.mapper&quot; targetProject\\=&quot;src/main/resources&quot;\\&gt;\n    &lt;!-- 在targetPackage的基础上，根据数据库的schema再生成一层package，最终生成的类放在这个package下，默认为false \\--&gt;\n    &lt;property name\\=&quot;enableSubPackages&quot; value\\=&quot;true&quot;/&gt;\n&lt;/sqlMapGenerator\\&gt;\n\n&lt;!-- 对于mybatis来说，即生成Mapper接口，注意，如果没有配置该元素，那么默认不会生成Mapper接口 \n    targetPackage/targetProject:同javaModelGenerator\n    type：选择怎么生成mapper接口（在MyBatis3/MyBatis3Simple下）：\n        1，ANNOTATEDMAPPER：会生成使用Mapper接口+Annotation的方式创建（SQL生成在annotation中），不会生成对应的XML；\n        2，MIXEDMAPPER：使用混合配置，会生成Mapper接口，并适当添加合适的Annotation，但是XML会生成在XML中；\n        3，XMLMAPPER：会生成Mapper接口，接口完全依赖XML；\n    注意，如果context是MyBatis3Simple：只支持ANNOTATEDMAPPER和XMLMAPPER \\--&gt;\n&lt;javaClientGenerator targetPackage\\=&quot;com.\\_520it.mybatis.mapper&quot; type\\=&quot;ANNOTATEDMAPPER&quot; targetProject\\=&quot;src/main/java&quot;\\&gt;\n    &lt;!-- 在targetPackage的基础上，根据数据库的schema再生成一层package，最终生成的类放在这个package下，默认为false \\--&gt;\n    &lt;property name\\=&quot;enableSubPackages&quot; value\\=&quot;true&quot;/&gt;\n\n    &lt;!-- 可以为所有生成的接口添加一个父接口，但是MBG只负责生成，不负责检查\n    &lt;property name=&quot;rootInterface&quot; value=&quot;&quot;/&gt; \\--&gt;\n&lt;/javaClientGenerator\\&gt;\n\n&lt;!-- 选择一个table来生成相关文件，可以有一个或多个table，必须要有table元素\n    选择的table会生成一下文件：\n    1，SQL map文件\n    2，生成一个主键类；\n    3，除了BLOB和主键的其他字段的类；\n    4，包含BLOB的类；\n    5，一个用户生成动态查询的条件类（selectByExample, deleteByExample），可选；\n    6，Mapper接口（可选）\n\n    tableName（必要）：要生成对象的表名；\n    注意：大小写敏感问题。正常情况下，MBG会自动的去识别数据库标识符的大小写敏感度，在一般情况下，MBG会\n        根据设置的schema，catalog或tablename去查询数据表，按照下面的流程：\n        1，如果schema，catalog或tablename中有空格，那么设置的是什么格式，就精确的使用指定的大小写格式去查询；\n        2，否则，如果数据库的标识符使用大写的，那么MBG自动把表名变成大写再查找；\n        3，否则，如果数据库的标识符使用小写的，那么MBG自动把表名变成小写再查找；\n        4，否则，使用指定的大小写格式查询；\n    另外的，如果在创建表的时候，使用的&quot;&quot;把数据库对象规定大小写，就算数据库标识符是使用的大写，在这种情况下也会使用给定的大小写来创建表名；\n    这个时候，请设置delimitIdentifiers=&quot;true&quot;即可保留大小写格式；\n\n    可选：\n    1，schema：数据库的schema；\n    2，catalog：数据库的catalog；\n    3，alias：为数据表设置的别名，如果设置了alias，那么生成的所有的SELECT SQL语句中，列名会变成：alias\\_actualColumnName\n    4，domainObjectName：生成的domain类的名字，如果不设置，直接使用表名作为domain类的名字；可以设置为somepck.domainName，那么会自动把domainName类再放到somepck包里面；\n    5，enableInsert（默认true）：指定是否生成insert语句；\n    6，enableSelectByPrimaryKey（默认true）：指定是否生成按照主键查询对象的语句（就是getById或get）；\n    7，enableSelectByExample（默认true）：MyBatis3Simple为false，指定是否生成动态查询语句；\n    8，enableUpdateByPrimaryKey（默认true）：指定是否生成按照主键修改对象的语句（即update)；\n    9，enableDeleteByPrimaryKey（默认true）：指定是否生成按照主键删除对象的语句（即delete）；\n    10，enableDeleteByExample（默认true）：MyBatis3Simple为false，指定是否生成动态删除语句；\n    11，enableCountByExample（默认true）：MyBatis3Simple为false，指定是否生成动态查询总条数语句（用于分页的总条数查询）；\n    12，enableUpdateByExample（默认true）：MyBatis3Simple为false，指定是否生成动态修改语句（只修改对象中不为空的属性）；\n    13，modelType：参考context元素的defaultModelType，相当于覆盖；\n    14，delimitIdentifiers：参考tableName的解释，注意，默认的delimitIdentifiers是双引号，如果类似MYSQL这样的数据库，使用的是\\`（反引号，那么还需要设置context的beginningDelimiter和endingDelimiter属性）\n    15，delimitAllColumns：设置是否所有生成的SQL中的列名都使用标识符引起来。默认为false，delimitIdentifiers参考context的属性\n\n    注意，table里面很多参数都是对javaModelGenerator，context等元素的默认属性的一个复写； \\--&gt;\n&lt;table tableName\\=&quot;userinfo&quot; \\&gt;\n\n    &lt;!-- 参考 javaModelGenerator 的 constructorBased属性\\--&gt;\n    &lt;property name\\=&quot;constructorBased&quot; value\\=&quot;false&quot;/&gt;\n\n    &lt;!-- 默认为false，如果设置为true，在生成的SQL中，table名字不会加上catalog或schema； \\--&gt;\n    &lt;property name\\=&quot;ignoreQualifiersAtRuntime&quot; value\\=&quot;false&quot;/&gt;\n\n    &lt;!-- 参考 javaModelGenerator 的 immutable 属性 \\--&gt;\n    &lt;property name\\=&quot;immutable&quot; value\\=&quot;false&quot;/&gt;\n\n    &lt;!-- 指定是否只生成domain类，如果设置为true，只生成domain类，如果还配置了sqlMapGenerator，那么在mapper XML文件中，只生成resultMap元素 \\--&gt;\n    &lt;property name\\=&quot;modelOnly&quot; value\\=&quot;false&quot;/&gt;\n\n    &lt;!-- 参考 javaModelGenerator 的 rootClass 属性 \n    &lt;property name=&quot;rootClass&quot; value=&quot;&quot;/&gt; \\--&gt;\n\n    &lt;!-- 参考javaClientGenerator 的  rootInterface 属性\n    &lt;property name=&quot;rootInterface&quot; value=&quot;&quot;/&gt; \\--&gt;\n\n    &lt;!-- 如果设置了runtimeCatalog，那么在生成的SQL中，使用该指定的catalog，而不是table元素上的catalog \n    &lt;property name=&quot;runtimeCatalog&quot; value=&quot;&quot;/&gt; \\--&gt;\n\n    &lt;!-- 如果设置了runtimeSchema，那么在生成的SQL中，使用该指定的schema，而不是table元素上的schema \n    &lt;property name=&quot;runtimeSchema&quot; value=&quot;&quot;/&gt; \\--&gt;\n\n    &lt;!-- 如果设置了runtimeTableName，那么在生成的SQL中，使用该指定的tablename，而不是table元素上的tablename \n    &lt;property name=&quot;runtimeTableName&quot; value=&quot;&quot;/&gt; \\--&gt;\n\n    &lt;!-- 注意，该属性只针对MyBatis3Simple有用；\n        如果选择的runtime是MyBatis3Simple，那么会生成一个SelectAll方法，如果指定了selectAllOrderByClause，那么会在该SQL中添加指定的这个order条件； \\--&gt;\n    &lt;property name\\=&quot;selectAllOrderByClause&quot; value\\=&quot;age desc,username asc&quot;/&gt;\n\n    &lt;!-- 如果设置为true，生成的model类会直接使用column本身的名字，而不会再使用驼峰命名方法，比如BORN\\_DATE，生成的属性名字就是BORN\\_DATE,而不会是bornDate \\--&gt;\n    &lt;property name\\=&quot;useActualColumnNames&quot; value\\=&quot;false&quot;/&gt;\n\n    &lt;!-- generatedKey用于生成生成主键的方法，\n        如果设置了该元素，MBG会在生成的&lt;insert&gt;元素中生成一条正确的&lt;selectKey&gt;元素，该元素可选\n        column:主键的列名；\n        sqlStatement：要生成的selectKey语句，有以下可选项：\n            Cloudscape:相当于selectKey的SQL为： VALUES IDENTITY\\_VAL\\_LOCAL()\n            DB2       :相当于selectKey的SQL为： VALUES IDENTITY\\_VAL\\_LOCAL()\n            DB2\\_MF    :相当于selectKey的SQL为：SELECT IDENTITY\\_VAL\\_LOCAL() FROM SYSIBM.SYSDUMMY1\n            Derby      :相当于selectKey的SQL为：VALUES IDENTITY\\_VAL\\_LOCAL()\n            HSQLDB      :相当于selectKey的SQL为：CALL IDENTITY()\n            Informix  :相当于selectKey的SQL为：select dbinfo(&#39;sqlca.sqlerrd1&#39;) from systables where tabid=1\n            MySql      :相当于selectKey的SQL为：SELECT LAST\\_INSERT\\_ID()\n            SqlServer :相当于selectKey的SQL为：SELECT SCOPE\\_IDENTITY()\n            SYBASE      :相当于selectKey的SQL为：SELECT @@IDENTITY\n            JDBC      :相当于在生成的insert元素上添加useGeneratedKeys=&quot;true&quot;和keyProperty属性\n    &lt;generatedKey column=&quot;&quot; sqlStatement=&quot;&quot;/&gt; \\--&gt;\n\n    &lt;!-- 该元素会在根据表中列名计算对象属性名之前先重命名列名，非常适合用于表中的列都有公用的前缀字符串的时候，\n        比如列名为：CUST\\_ID,CUST\\_NAME,CUST\\_EMAIL,CUST\\_ADDRESS等；\n        那么就可以设置searchString为&quot;^CUST\\_&quot;，并使用空白替换，那么生成的Customer对象中的属性名称就不是\n        custId,custName等，而是先被替换为ID,NAME,EMAIL,然后变成属性：id，name，email；\n\n        注意，MBG是使用java.util.regex.Matcher.replaceAll来替换searchString和replaceString的，\n        如果使用了columnOverride元素，该属性无效；\n\n    &lt;columnRenamingRule searchString=&quot;&quot; replaceString=&quot;&quot;/&gt; \\--&gt;\n\n     &lt;!-- 用来修改表中某个列的属性，MBG会使用修改后的列来生成domain的属性；\n         column:要重新设置的列名；\n         注意，一个table元素中可以有多个columnOverride元素哈~ \\--&gt;\n     &lt;columnOverride column\\=&quot;username&quot;\\&gt;\n         &lt;!-- 使用property属性来指定列要生成的属性名称 \\--&gt;\n         &lt;property name\\=&quot;property&quot; value\\=&quot;userName&quot;/&gt;\n\n         &lt;!-- javaType用于指定生成的domain的属性类型，使用类型的全限定名\n         &lt;property name=&quot;javaType&quot; value=&quot;&quot;/&gt; \\--&gt;\n\n         &lt;!-- jdbcType用于指定该列的JDBC类型 \n         &lt;property name=&quot;jdbcType&quot; value=&quot;&quot;/&gt; \\--&gt;\n\n         &lt;!-- typeHandler 用于指定该列使用到的TypeHandler，如果要指定，配置类型处理器的全限定名\n             注意，mybatis中，不会生成到mybatis-config.xml中的typeHandler\n             只会生成类似：where id = #&#123;id,jdbcType=BIGINT,typeHandler=com.\\_520it.mybatis.MyTypeHandler&#125;的参数描述\n         &lt;property name=&quot;jdbcType&quot; value=&quot;&quot;/&gt; \\--&gt;\n\n         &lt;!-- 参考table元素的delimitAllColumns配置，默认为false\n         &lt;property name=&quot;delimitedColumnName&quot; value=&quot;&quot;/&gt; \\--&gt;\n     &lt;/columnOverride\\&gt;\n\n     &lt;!-- ignoreColumn设置一个MGB忽略的列，如果设置了改列，那么在生成的domain中，生成的SQL中，都不会有该列出现 \n         column:指定要忽略的列的名字；\n         delimitedColumnName：参考table元素的delimitAllColumns配置，默认为false\n\n         注意，一个table元素中可以有多个ignoreColumn元素\n     &lt;ignoreColumn column=&quot;deptId&quot; delimitedColumnName=&quot;&quot;/&gt; \\--&gt;\n&lt;/table\\&gt;\n\n&lt;&#x2F;context&gt;\n&lt;&#x2F;generatorConfiguration&gt;\n\n","categories":["编程技术","Java"],"tags":["MyBatis"]},{"title":"Shiro","url":"/2015/11/14/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Java/Shiro%20%E8%87%AA%E5%AE%9A%E4%B9%89%E7%99%BB%E9%99%86%E3%80%81%E6%8E%88%E6%9D%83%E3%80%81%E6%8B%A6%E6%88%AA%E5%99%A8/","content":"Shiro\n登陆、授权、拦截\n按钮权限控制\n\n一、目标\nMaven+Spring+shiro\n自定义登陆、授权\n自定义拦截器\n加载数据库资源构建拦截链\n\n使用总结：\n1、需要设计的数据库：用户、角色、权限、资源\n2、可以通过，角色，权限，两个拦截器同时确定是否能访问\n3、角色与权限的关系，role1&#x3D;permission1,permission2，多级的权限：sys:permission1,拥有高级权限同时用于低级权限。\n4、perms[“permission1”] 为权限\n5、拦截器机制介绍了拦截角色还是权限\n6、角色与权限 是两个概念\n7、权限-资源，一对一。资源分为上下级，因此权限分为父权限，子权限。创建资源的时候，创建权限。权限里资源的别名\n8、角色-权限，一对多。角色里权限的别名\n9、按钮是通过权限来控制的\n10、防止有父级资源可以访问，子级资源不能访问的情况，不适用 sys:add 权限写法\n二、代码1、Pom.xml\n 1     &lt;properties&gt; 2         &lt;spring.version&gt;4.3.4.RELEASE&lt;&#x2F;spring.version&gt; 3     &lt;&#x2F;properties&gt; 4         &lt;dependency&gt; 5             &lt;groupId&gt;junit&lt;&#x2F;groupId&gt; 6             &lt;artifactId&gt;junit&lt;&#x2F;artifactId&gt; 7             &lt;version&gt;4.9&lt;&#x2F;version&gt; 8         &lt;&#x2F;dependency&gt; 9         &lt;dependency&gt;10             &lt;groupId&gt;commons-logging&lt;&#x2F;groupId&gt;11             &lt;artifactId&gt;commons-logging&lt;&#x2F;artifactId&gt;12             &lt;version&gt;1.1.3&lt;&#x2F;version&gt;13         &lt;&#x2F;dependency&gt;14         &lt;dependency&gt;15             &lt;groupId&gt;org.apache.shiro&lt;&#x2F;groupId&gt;16             &lt;artifactId&gt;shiro-core&lt;&#x2F;artifactId&gt;17             &lt;version&gt;1.2.2&lt;&#x2F;version&gt;18         &lt;&#x2F;dependency&gt;19         &lt;dependency&gt;20             &lt;groupId&gt;org.apache.shiro&lt;&#x2F;groupId&gt;21             &lt;artifactId&gt;shiro-spring&lt;&#x2F;artifactId&gt;22             &lt;version&gt;1.2.2&lt;&#x2F;version&gt;23         &lt;&#x2F;dependency&gt;24         &lt;dependency&gt;25             &lt;groupId&gt;javax.servlet&lt;&#x2F;groupId&gt;26             &lt;artifactId&gt;javax.servlet-api&lt;&#x2F;artifactId&gt;27             &lt;version&gt;3.0.1&lt;&#x2F;version&gt;28             &lt;scope&gt;provided&lt;&#x2F;scope&gt;29         &lt;&#x2F;dependency&gt;30         &lt;dependency&gt;31             &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt;32             &lt;artifactId&gt;spring-web&lt;&#x2F;artifactId&gt;33             &lt;version&gt;${spring.version}&lt;&#x2F;version&gt;34         &lt;&#x2F;dependency&gt;35         36             org.apache.shiro37             shiro-ehcache38             1.2.239         40         41             org.springframework42             spring-context43             ${spring.version}44         45         46             org.apache.shiro47             shiro-web48             1.2.249         50         51             net.sf.ehcache52             ehcache53             2.10.154      \n\n2、web.xml　　Servlet拦截访问，使用注解更方便，需要删除项目中的servlet使用javax.servlet-api 3.0 包\n\n 1 package com.cyd.shiro; 2 3 import java.io.IOException; 4 5 import javax.servlet.ServletException; 6 import javax.servlet.annotation.WebServlet; 7 import javax.servlet.http.HttpServlet; 8 import javax.servlet.http.HttpServletRequest; 9 import javax.servlet.http.HttpServletResponse;1011 import org.apache.shiro.SecurityUtils;12 import org.apache.shiro.authc.AuthenticationException;13 import org.apache.shiro.authc.IncorrectCredentialsException;14 import org.apache.shiro.authc.UnknownAccountException;15 import org.apache.shiro.authc.UsernamePasswordToken;16 import org.apache.shiro.subject.Subject;17 import org.apache.shiro.web.util.SavedRequest;18 import org.apache.shiro.web.util.WebUtils;19 import org.junit.Test;2021 @WebServlet(name &#x3D; “loginServlet”, urlPatterns &#x3D; “&#x2F;loginController”)22 public class LoginServlet extends HttpServlet {23     @Override24     protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {25         req.getRequestDispatcher(“login.jsp”).forward(req, resp);26     }2728     @Override29     protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {30         System.out.println(LoginServlet.class.toString());31         String error &#x3D; null;32         String username &#x3D; req.getParameter(“username”);33         String password &#x3D; req.getParameter(“password”);34         Subject subject &#x3D; SecurityUtils.getSubject();35         UsernamePasswordToken token &#x3D; new UsernamePasswordToken(username, password);36         try {37             subject.login(token);38         } catch (UnknownAccountException e) {39             error &#x3D; “用户名&#x2F;密码错误”;40         } catch (IncorrectCredentialsException e) {41             error &#x3D; “用户名&#x2F;密码错误”;42         } catch (AuthenticationException e) {43             &#x2F;&#x2F; 其他错误，比如锁定，如果想单独处理请单独catch处理44             error &#x3D; “其他错误：” + e.getMessage();45         }46         if (error !&#x3D; null) {&#x2F;&#x2F; 出错了，返回登录页面47             req.setAttribute(“error”, error);48             req.getRequestDispatcher(“login.jsp”).forward(req, resp);49         } else {&#x2F;&#x2F; 登录成功50             &#x2F;&#x2F;跳转到拦截登陆前的地址51             SavedRequest request&#x3D;WebUtils.getSavedRequest(req);52             String url &#x3D;request.getRequestURI();53             req.getRequestDispatcher(url.substring(url.lastIndexOf(‘&#x2F;‘))).forward(req, resp);54         }55     }5657 }\n\n3、Spring-shiro.xml\n\n&lt;beans xmlns=“http://www.springframework.org/schema/beans“ xmlns:xsi=“http://www.w3.org/2001/XMLSchema-instance“ xmlns:context=“http://www.springframework.org/schema/context“ xmlns:util=“http://www.springframework.org/schema/util“ xsi:schemaLocation=“http://www.springframework.org/schema/beans    http://www.springframework.org/schema/beans/spring-beans.xsd    http://www.springframework.org/schema/context    http://www.springframework.org/schema/context/spring-context.xsd    http://www.springframework.org/schema/util    http://www.springframework.org/schema/util/spring-util-4.2.xsd&quot;\\&gt;\n&lt;context:component-scan base-package\\=&quot;com.cyd.shiro.\\*&quot;\\&gt;&lt;/context:component-scan\\&gt;\n\n&lt;!-- Shiro的Web过滤器 \\--&gt;\n&lt;bean id\\=&quot;shiroFilter&quot; class\\=&quot;com.cyd.shiro.ExtendShiroFilterFactoryBean&quot;\\&gt;\n    &lt;property name\\=&quot;securityManager&quot; ref\\=&quot;securityManager&quot; /&gt;\n    &lt;property name\\=&quot;loginUrl&quot; value\\=&quot;/login.jsp&quot; /&gt;\n    &lt;!-- &lt;property name=&quot;successUrl&quot; value=&quot;/index.jsp&quot; /&gt; \\--&gt;\n    &lt;property name\\=&quot;unauthorizedUrl&quot; value\\=&quot;/unauthorized.jsp&quot; /&gt;\n    &lt;property name\\=&quot;filters&quot;\\&gt;\n        &lt;util:map\\&gt;\n            &lt;!-- &lt;entry key=&quot;onperms&quot; value-ref=&quot;URLPermissionsFilter&quot; /&gt; \\--&gt;\n            &lt;entry key\\=&quot;onrole&quot; value-ref\\=&quot;ExtendRolesAuthorizationFilter&quot; /&gt;\n        &lt;/util:map\\&gt;\n    &lt;/property\\&gt; \n    &lt;property name\\=&quot;filterChainDefinitions&quot;\\&gt;\n        &lt;value\\&gt; /unauthorized.jsp = anon\n            /logoutController=anon\n            /login.jsp=authc\n        &lt;/value\\&gt;\n    &lt;/property\\&gt;\n&lt;/bean\\&gt;\n\n&lt;!-- 安全管理器 \\--&gt;\n&lt;bean id\\=&quot;securityManager&quot; class\\=&quot;org.apache.shiro.web.mgt.DefaultWebSecurityManager&quot;\\&gt;\n    &lt;property name\\=&quot;realm&quot; ref\\=&quot;myRealm&quot; /&gt;\n    &lt;property name\\=&quot;cacheManager&quot; ref\\=&quot;cacheManager&quot; /&gt;\n&lt;/bean\\&gt;\n&lt;!-- 自定义认证，授权 \\--&gt;\n&lt;bean id\\=&quot;myRealm&quot; class\\=&quot;com.cyd.shiro.AdminRealm&quot;\\&gt;&lt;/bean\\&gt;\n\n&lt;!-- 注册ehcache，不然每次访问都要登陆 \\--&gt;\n&lt;bean id\\=&quot;cacheManager&quot; class\\=&quot;org.apache.shiro.cache.ehcache.EhCacheManager&quot;\\&gt;\n    &lt;property name\\=&quot;cacheManagerConfigFile&quot; value\\=&quot;classpath:ehcache.xml&quot; /&gt;\n&lt;/bean\\&gt;\n&lt;!-- 自定义鉴权拦截器 \\--&gt;\n&lt;bean id\\=&quot;URLPermissionsFilter&quot; class\\=&quot;com.cyd.shiro.URLPermissionsFilter&quot; /&gt;\n&lt;bean id\\=&quot;ExtendRolesAuthorizationFilter&quot; class\\=&quot;com.cyd.shiro.ExtendRolesAuthorizationFilter&quot; /&gt;\n\n&lt;&#x2F;beans&gt;\n\n4、Ehcache.xml 缓存\n\n&lt;ehcache xmlns:xsi=“http://www.w3.org/2001/XMLSchema-instance“ xsi:noNamespaceSchemaLocation=“..&#x2F;config&#x2F;ehcache.xsd”&gt;&lt;diskStore path=“java.io.tmpdir”&#x2F;&gt;&lt;defaultCache        maxElementsInMemory=“10000” eternal=“false” timeToIdleSeconds=“600” timeToLiveSeconds=“600” overflowToDisk=“true” maxElementsOnDisk=“10000000” diskPersistent=“false” diskExpiryThreadIntervalSeconds=“120” memoryStoreEvictionPolicy=“LRU”        &#x2F;&gt;\n  \n&lt;&#x2F;ehcache&gt;\n\n5、登陆Servlet\npackage com.cyd.shiro;\nimport java.io.IOException;\nimport javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;\nimport org.apache.shiro.SecurityUtils;import org.apache.shiro.authc.AuthenticationException;import org.apache.shiro.authc.IncorrectCredentialsException;import org.apache.shiro.authc.UnknownAccountException;import org.apache.shiro.authc.UsernamePasswordToken;import org.apache.shiro.subject.Subject;import org.apache.shiro.web.util.SavedRequest;import org.apache.shiro.web.util.WebUtils;\n@WebServlet(name &#x3D; “loginServlet”, urlPatterns &#x3D; “&#x2F;loginController”)public class LoginServlet extends HttpServlet {    @Override    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {        req.getRequestDispatcher(“login.jsp”).forward(req, resp);    }\n@Override\nprotected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;\n    System.out.println(LoginServlet.class.toString());\n    String error = null;\n    String username = req.getParameter(&quot;username&quot;);\n    String password = req.getParameter(&quot;password&quot;);\n    Subject subject = SecurityUtils.getSubject();\n    UsernamePasswordToken token = new UsernamePasswordToken(username, password);\n    try &#123;\n        subject.login(token); \n    &#125; catch (UnknownAccountException e) &#123; \n        error = &quot;用户名/密码错误&quot;;\n    &#125; catch (IncorrectCredentialsException e) &#123;\n        error = &quot;用户名/密码错误&quot;;\n    &#125; catch (AuthenticationException e) &#123;\n        // 其他错误，比如锁定，如果想单独处理请单独catch处理\n        error = &quot;其他错误：&quot; + e.getMessage();\n    &#125;\n    if (error != null) &#123;// 出错了，返回登录页面\n        req.setAttribute(&quot;error&quot;, error);\n        req.getRequestDispatcher(&quot;login.jsp&quot;).forward(req, resp);\n    &#125; else &#123;// 登录成功\n        //跳转到拦截登陆前的地址\n        SavedRequest request=WebUtils.getSavedRequest(req);\n        String url =request.getRequestURI();\n        req.getRequestDispatcher(url.substring(url.lastIndexOf(&#39;/&#39;))).forward(req, resp);\n    &#125;\n&#125;\n\n}\n\n6、自定义登陆、授权。　　根据需求自定义登陆异常。从数据库查询出当前用户拥有的权限并授权\n\n 1 package com.cyd.shiro; 2 3 import java.util.HashSet; 4 import java.util.LinkedList; 5 import java.util.List; 6 import java.util.Set; 7 8 import org.apache.shiro.authc.AuthenticationException; 9 import org.apache.shiro.authc.AuthenticationInfo;10 import org.apache.shiro.authc.AuthenticationToken;11 import org.apache.shiro.authc.SimpleAuthenticationInfo;12 import org.apache.shiro.authc.UnknownAccountException;13 import org.apache.shiro.authz.AuthorizationInfo;14 import org.apache.shiro.authz.SimpleAuthorizationInfo;15 import org.apache.shiro.realm.AuthorizingRealm;16 import org.apache.shiro.subject.PrincipalCollection;17 import org.springframework.beans.factory.annotation.Autowired;1819 import com.cyd.helloworld.SysRoles;20 import com.cyd.helloworld.SysUsers;21 import com.cyd.shiro.admin.SysUsersService;2223 public class AdminRealm extends AuthorizingRealm {2425     @Autowired26     private SysUsersService    sysusersservice;27     &#x2F;&#x2F; 认证登陆28     @Override29     protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException {30         System.out.println(“do doGetAuthenticationInfo”);31         String username &#x3D; (String) token.getPrincipal();32         SysUsers user &#x3D; sysusersservice.getSysUsers(username);33         if (user &#x3D;&#x3D; null) {34             throw new UnknownAccountException();&#x2F;&#x2F; 没找到帐号35         }36         SimpleAuthenticationInfo authenticationInfo &#x3D; new SimpleAuthenticationInfo(user.getUserName(), &#x2F;&#x2F; 用户名37                 user.getPassWorld(), &#x2F;&#x2F; 密码38                 getName() &#x2F;&#x2F; realm name39         );40         return authenticationInfo;41     }4243     &#x2F;&#x2F; 用户授权44     @Override45     protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) {46         System.out.println(“do doGetAuthorizationInfo”);47         String username &#x3D; (String)principals.getPrimaryPrincipal();48         SimpleAuthorizationInfo authorizationInfo &#x3D; new SimpleAuthorizationInfo();49         &#x2F;&#x2F;从数据库加载当前用户的角色，例如：[admin]50         authorizationInfo.setRoles(new HashSet(sysusersservice.getSysRoles(username)));51         &#x2F;&#x2F;从数据库加载当前用户可以访问的资源，例如：[index.jsp, abc.jsp]52         authorizationInfo.setStringPermissions(new HashSet(sysusersservice.getSysResource(username)));5354         return authorizationInfo;55     }56 }\n\n7、自定义拦截器。　　重写拦截器是因为shiro 验证是否有权限访问是需要当前用户拥有拦截器链的所有权限。一般需求只需要拥有部分权限即可。\n       角色验证拦截，hasRole和hasAllRoles 验证是否有权限。\n\n 1 package com.cyd.shiro; 2 3 import java.io.IOException; 4 import java.util.Set; 5 6 import javax.servlet.ServletRequest; 7 import javax.servlet.ServletResponse; 8 9 import org.apache.shiro.subject.Subject;10 import org.apache.shiro.util.CollectionUtils;11 import org.apache.shiro.web.filter.authz.RolesAuthorizationFilter;1213 &#x2F;**14  * 通过角色验证权限15  * @author chenyd16  * 2017年11月21日17  *&#x2F;18 public class ExtendRolesAuthorizationFilter extends RolesAuthorizationFilter{1920     @Override21     public boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) throws IOException {2223         System.out.println(ExtendRolesAuthorizationFilter.class.toString());24         Subject subject &#x3D; getSubject(request, response);25         String[] rolesArray &#x3D; (String[]) mappedValue;2627         if (rolesArray &#x3D;&#x3D; null || rolesArray.length &#x3D;&#x3D; 0) {28             &#x2F;&#x2F;no roles specified, so nothing to check - allow access.29             return true;30         }31         &#x2F;&#x2F;AbstractFilter32         Set roles &#x3D; CollectionUtils.asSet(rolesArray);3334         boolean flag&#x3D;false;35         for(String role: roles){36             if(subject.hasRole(role)){37                 flag&#x3D;true;38                 break;39             }40         }41         return flag;42     }43 }\n\n       url拦截校验，isPermitted和isPermittedAll验证是否有权限访问，\n\n 1 package com.cyd.shiro; 2 3 import java.io.IOException; 4 5 import javax.servlet.ServletRequest; 6 import javax.servlet.ServletResponse; 7 import javax.servlet.http.HttpServletRequest; 8 9 import org.apache.shiro.subject.Subject;10 import org.apache.shiro.web.filter.authz.PermissionsAuthorizationFilter;11 &#x2F;**12  * 通过字符串验证权限13  * @author chenyd14  * 2017年11月21日15  *&#x2F;16 public class URLPermissionsFilter extends PermissionsAuthorizationFilter {1718     &#x2F;**19      * mappedValue 访问该url时需要的权限20      * subject.isPermitted 判断访问的用户是否拥有mappedValue权限21      * 重写拦截器，只要符合配置的一个权限，即可通过22      *&#x2F;23     @Override24     public boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue)25             throws IOException {26         System.out.println(URLPermissionsFilter.class.toString());27         Subject subject &#x3D; getSubject(request, response);28         &#x2F;&#x2F; DefaultFilterChainManager29         &#x2F;&#x2F; PathMatchingFilterChainResolver30         String[] perms &#x3D; (String[]) mappedValue;31         boolean isPermitted &#x3D; false;32         if (perms !&#x3D; null &amp;&amp; perms.length &gt; 0) {33             for (String str : perms) {34                 if (subject.isPermitted(str)) {35                     isPermitted &#x3D; true;36                 }37             }38         }3940         return isPermitted;41     }42 }\n\n8、加载数据库资源构建拦截器链\n 1 package com.cyd.shiro; 2 3 import java.util.Map; 4 5 import org.apache.shiro.config.Ini; 6 import org.apache.shiro.spring.web.ShiroFilterFactoryBean; 7 import org.apache.shiro.util.CollectionUtils; 8 import org.apache.shiro.web.config.IniFilterChainResolverFactory; 9 import org.springframework.beans.factory.annotation.Autowired;1011 import com.cyd.shiro.admin.SysUsersService;1213 public class ExtendShiroFilterFactoryBean extends ShiroFilterFactoryBean{1415     @Autowired16     private SysUsersService    sysusersservice;17     &#x2F;&#x2F;PathMatchingFilter18     @Override19     public void setFilterChainDefinitions(String definitions) {20         &#x2F;&#x2F;数据库中获取权限，{&#x2F;index.jsp&#x3D;authc,onrole[“admin2”,”admin”], &#x2F;abc.jsp&#x3D;authc,onrole[“admin2”,”admin”]}21         Map&lt;String, String&gt; otherChains &#x3D; sysusersservice.getFilterChain();22         Ini ini &#x3D; new Ini();23         ini.load(definitions);24         Ini.Section section &#x3D; ini.getSection(IniFilterChainResolverFactory.URLS);25         if (CollectionUtils.isEmpty(section)) {26             section &#x3D; ini.getSection(Ini.DEFAULT_SECTION_NAME);27         }28         section.putAll(otherChains);29         setFilterChainDefinitionMap(section);30     }3132 }\n\n三、  学习笔记1、INI文件配置\n[users]  #提供了对用户&#x2F;密码及其角色的配置，用户名&#x3D;密码，角色1，角色2  \nzhang&#x3D;123,admin\n[roles]  #提供了角色及权限之间关系的配置，角色&#x3D;权限1，权限2  \nadmin&#x3D;index.jsp\n[urls] #配置拦截器链，&#x2F;** 为拦截器链名称（filterChain），authc,roles[admin],perms[“index.jsp”]拦截器列表名\n&#x2F;login.jsp&#x3D;anon\n&#x2F;loginController&#x3D;anon\n&#x2F;unauthorized.jsp&#x3D;anon\n&#x2F;**&#x3D;authc,roles[admin],perms[“index.jsp”] \n\n2、拦截器链　　Shiro的所有拦截器链名定义在源码DefaultFilter中。\nanon            \n例子&#x2F;admins&#x2F;**&#x3D;anon 没有参数，表示可以匿名使用。 \nauthc\n例如&#x2F;admins&#x2F;user&#x2F;**&#x3D;authc表示需要认证(登录)才能使用，没有参数  \nroles\n 例子&#x2F;admins&#x2F;user&#x2F;**&#x3D;roles[admin],参数可以写多个，多个时必须加上引号，  \n 并且参数之间用逗号分割，当有多个参数时，例如admins&#x2F;user&#x2F;**&#x3D;roles[“admin,guest”],  \n 每个参数通过才算通过，相当于hasAllRoles()方法。  \nperms\n例子&#x2F;admins&#x2F;user&#x2F;**&#x3D;perms[user:add:*],参数可以写多个，多个时必须加上引号，并且参数之间用逗号分割，  \n例如&#x2F;admins&#x2F;user&#x2F;**&#x3D;perms[“user:add:*,user:modify:*“]，当有多个参数时必须每个参数都通过才通过，  \n想当于isPermitedAll()方法。\nrest\n例子&#x2F;admins&#x2F;user&#x2F;**&#x3D;rest[user],根据请求的方法，相当于&#x2F;admins&#x2F;user&#x2F;**&#x3D;perms[user:method] ,  \n 其中method为post，get，delete等。\nport\n例子&#x2F;admins&#x2F;user&#x2F;**&#x3D;port[8081],当请求的url的端口不是8081是跳转到schemal:&#x2F;&#x2F;serverName:8081?queryString,  其中schmal是协议http或https等，serverName是你访问的host,8081是url配置里port的端口，queryString是你访问的url里的？后面的参数。\nauthcBasic                                 \n例如&#x2F;admins&#x2F;user&#x2F;**&#x3D;authcBasic没有参数表示httpBasic认证\nssl\n例子&#x2F;admins&#x2F;user&#x2F;**&#x3D;ssl没有参数，表示安全的url请求，协议为https\nuser\n例如&#x2F;admins&#x2F;user&#x2F;**&#x3D;user没有参数表示必须存在用户，当登入操作时不做检查  \n注：anon，authcBasic，auchc，user是认证过滤器， \n perms，roles，ssl，rest，port是授权过滤器 \n3、拦截器链源码类关系图  \n①   NameableFilter有一个name属性，定义每一个filter的名字。\n②   OncePerRequestFilter保证客户端请求后该filter的doFilter只会执行一次。\n　　doFilterInternal非常重要，在shiro整个filter体系中的核心方法及实质入口。另外，shiro是通过在request中设置一个该filter特定的属性值来保证该filter只会执行一次的。\n③   AdviceFilter中主要是对doFilterInternal做了更细致的切分。\n　　springmvc中的Interceptor，doFilterInternal会先调用preHandle做一些前置判断，如果返回false则filter链不继续往下执行，\n④   AccessControlFilter中的对onPreHandle方法做了进一步细化。\n　　isAccessAllowed方法和onAccessDenied方法达到控制效果。这两个方法都是抽象方法，由子类去实现。到这一层应该明白。isAccessAllowed和onAccessDenied方法会影响到onPreHandle方法，而onPreHandle方法会影响到preHandle方法，而preHandle方法会达到控制filter链是否执行下去的效果。所以如果正在执行的filter中isAccessAllowed和onAccessDenied都返回false，则整个filter控制链都将结束，不会到达目标方法（客户端请求的接口），而是直接跳转到某个页面（由filter定义的，将会在authc中看到）。\n⑤   FormAuthenticationFiltershiro提供的登录的filter，\n　　saveRequestAndRedirectToLogin保存request并拦截到登陆页面，登陆成功后可从WebUtils.getSavedRequest(req);中取出。\n四、未实现的功能\n动态URL权限控制。当修改权限时，重新加载拦截器链。\n密码加密\n记住我\n在线人数控制\n集成验证码\n\n　\n五、参考链接\n\n spring mvc整合shiro登录 权限验证 　　http://blog.csdn.net/rongku/article/details/51336424\nShiro（4）默认鉴权与自定义鉴权 　　http://blog.csdn.net/zhengwei223/article/details/9981741\n拦截器机制-跟我学shiro 　　　　http://jinnianshilongnian.iteye.com/blog/2025656\nshiro Filter–拦截器源码解释　　 https://www.cnblogs.com/yoohot/p/6085830.html\n动态URL　　 http://blog.csdn.net/shadowsick/article/details/39001273\n重写shirofilterbean方式加载数据库资源权限　　 http://blog.csdn.net/qq_18333833&#x2F;article&#x2F;details&#x2F;70243620\n\n\n","categories":["编程技术","Java"],"tags":["Shiro","权限管理"]},{"title":"Nodejs清理无用依赖包","url":"/2019/05/11/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Javascript/Nodejs%E6%B8%85%E7%90%86%E6%97%A0%E7%94%A8%E4%BE%9D%E8%B5%96%E5%8C%85/","content":"npm-check\n npm-check 是一个检查依赖包是否存在过期、不正确、未使用等情况的工具。\n 全局安装：\n\nnpm  install  -g  npm-check\n\n 使用：\n\nnpm-check\n\n上述指令会自动检查当前目录下的依赖包情况。\n 这里我们重点关注下未使用的依赖包。npm-check 在检查依赖包是否使用时判断的依据是文件中是否存在 require（package） 这条语句，例如：\n\nconst lodash &#x3D; require(‘lodash’);\n\n只要存在这条语句，即使我并未在其它任何地方使用（也就是说这是个无用的包），但是 npm-check 是不会将其判定为未使用的。\n ESLint\n为了解决上述存在的这种情况，我们可以借助 ESLint 先去检查代码是否存在未使用的变量（no-unused-vars），这样就可以检查某个包 require 了但并未在后续使用的情况。\n全局安装：\n\nnpm install -g eslint\n\n编写 .eslintrc.js 配置文件：\n \n\neslint  –config  .eslintrc.js  .&#x2F;\n\n执行上述指令便会检查当前目录下的所有代码是否存在定义了但未使用的变量。删除掉未使用的变量（包含对依赖包的引用）之后，再运行 npm-check 便能正确的找出那些在项目中已不再使用的依赖包了。\n","categories":["编程技术","Javascript"],"tags":["NodeJS"]},{"title":"npm修改全局包安装路径","url":"/2024/12/17/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Javascript/npm%E4%BF%AE%E6%94%B9%E5%85%A8%E5%B1%80%E5%8C%85%E5%AE%89%E8%A3%85%E8%B7%AF%E5%BE%84/","content":"默认配置默认安装路径：%AppData%\\Roaming\\npm全局缓存路径：%AppData%\\Roaming\\npm_cache\n安装全局包命令: npm install -g &lt;包名&gt;\n修改方法# 设置全局包安装路径npm config set prefix &quot;&lt;目标路径&gt;&quot;# 修改缓存包安装路径npm config set cache &quot;&lt;目标路径&gt;&quot;# 查看全局包安装路径npm config get prefix # 查看缓存包安装路径npm config get cache # 查看所有配置npm config ls\n\n添加环境变量\nNODE_PATH=&quot;&lt;全局安装包路径&gt;\\node_modules\\&quot;","categories":["编程技术","Javascript"],"tags":["NodeJS","npm"]},{"title":"npm修改国内源","url":"/2024/12/17/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Javascript/npm%E4%BF%AE%E6%94%B9%E5%9B%BD%E5%86%85%E6%BA%90/","content":"npm镜像源地址# 官方源https://registry.npmjs.org# 淘宝npm镜像https://registry.npmmirror.com# 阿里云npm镜像https://npm.aliyun.com# 腾讯云npm镜像https://mirrors.cloud.tencent.com/npm# 华为云npm镜像https://mirrors.huaweicloud.com/repository/npm# 网易npm镜像https:/mirrors.163.com/npm\n\n修改镜像源# 修改镜像源npm config set registry https://registry.npmmirror.org# 查看镜像源npm config get registry","categories":["编程技术","Javascript"],"tags":["NodeJS","npm"]},{"title":"基于.NET6和VUE3搭建SPA应用","url":"/2024/12/17/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Javascript/%E5%9F%BA%E4%BA%8E.NET6%E5%92%8CVue3%E6%90%AD%E5%BB%BASPA%E5%BA%94%E7%94%A8/","content":".NET 出到 6 之后，原本官方的 [SPA 套件]被弃用(https://github.com/dotnet/aspnetcore/issues/12890)，新版改成使用 Vue-CLI + SPA Proxy。\n环境# 确认.NET版本,此处为 6.0.200dotnet --version# 确认Node版本,此处为 v16.4.0node --version\n\n新建.NET项目# 新建react模板项目dotnet new react\n\n前端文件放在ClientApp目录,清空此目录下所有文件并使用Vue-CLI新建Vue项目并修改对应参数即可\n新建Vue项目# 安装Vue CLI, 此处使用版本 v5.0.1npm install -g @vue/cli# Vue CLI 不允许大写字母，此处使用 client-app作为项目名vue create client-app# 安装依赖npm install# 运行测试npm run dev \n\n配置打开项目.csproj文件,修改SpaRoot节点值为client-app所在目录，并注意这里的SpaProxyServerUrl 节点的值是前端的访问地址，SpaProxyLaunchCommand是npm start是前端的启动命令。\n[^注意]若SpaProxyServerUrl是HTTPS需要改成http。[^注意]每次新建.NET项目时对应的端口都不一样，前端需要改成对应的端口。\n...&lt;PropertyGroup&gt;  ...  &lt;SpaRoot&gt;client-app\\&lt;/SpaRoot&gt;  &lt;SpaProxyServerUrl&gt;http://localhost:44405&lt;/SpaProxyServerUrl&gt;  &lt;SpaProxyLaunchCommand&gt;npm start&lt;/SpaProxyLaunchCommand&gt;  ...&lt;/PropertyGroup&gt;...\n\n修改package.json,在scripts中添加启动命令\n&quot;scripts&quot;: &#123;  &quot;start&quot;: &quot;vue-cli-service serve&quot;,  &quot;build&quot;: &quot;vue-cli-service build&quot;,  &quot;lint&quot;: &quot;vue-cli-service lint&quot;&#125;\n修改vue.config.js,将devServer port换成44405。\nconst &#123; defineConfig &#125;  = require(&#x27;@vue/cli-service&#x27;)module.exports = defineConfig(&#123;  devServer: &#123;    port: 44405,  &#125;,  transplieDependencies: [    &#x27;vuetify&#x27;  ]&#125;)","categories":["编程技术","Javascript"],"tags":["SPA","VUE"]},{"title":"Conda环境配置","url":"/2025/03/26/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Python/Anaconda%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","content":"安装Anacondawget https://repo.anaconda.com/archive/Anaconda3-2024.10-1-Linux-x86_64.shsudo chmod +x Anaconda3-2024.10-1-Linux-x86_64.sh # 文件添加执行权限sudo sh Anaconda3-2024.10-1-Linux-x86_64.sh # 执行安装# Please, press ENTER to continue -&gt; 回车继续# 阅读协议，同意按回车（跳过ctrl+c）# Do you accept the license terms? [yes|no] -&gt; 同意协议输入yes回车# Anaconda3 will now be installed into this location -&gt; 选择安装路径（本文安装/usr/local/anaconda3），等待安装# by running conda init? [yes|no] -&gt; 是否添加系统环境，输入yes回车# 待安装结束# 刷新当前用户环境（激活环境）source /usr/local/anaconda3/bin\n\n如果是否添加环境变量选择no的话，安装完成需要手动添加环境变量\nexport ANACONDA3_ROOT=/usr/local/anaconda3export PATH=$ANACONDA3_ROOT/bin:$ANACONDA3_ROOT/condabin:$PATH\n如果安装时选择了no但安装完成还想初始化可以执行\nsource /usr/local/anaconda3/bin/activateconda init\n![[Anaconda环境配置&#x2F;IMG-20250804110742705.png]]\n安装完成后查看.bashrc 中变更内容如下\n# &gt;&gt;&gt; conda initialize &gt;&gt;&gt;# !! Contents within this block are managed by &#x27;conda init&#x27; !!__conda_setup=&quot;$(&#x27;/usr/local/anaconda3/bin/conda&#x27; &#x27;shell.bash&#x27; &#x27;hook&#x27; 2&gt; /dev/null)&quot;if [ $? -eq 0 ]; then    eval &quot;$__conda_setup&quot;else    if [ -f &quot;/usr/local/anaconda3/etc/profile.d/conda.sh&quot; ]; then        . &quot;/usr/local/anaconda3/etc/profile.d/conda.sh&quot;    else        export PATH=&quot;/usr/local/anaconda3/bin:$PATH&quot;    fifiunset __conda_setup# &lt;&lt;&lt; conda initialize &lt;&lt;&lt;\n\n解决打开终端Anaconda自启动问题conda config --set auto_activate_base false\n镜像源北京外国语大学\nchannels:  - defaultsshow_channel_urls: truechannel_alias: https://mirrors.bfsu.edu.cn/anacondadefault_channels:  - https://mirrors.bfsu.edu.cn/anaconda/pkgs/main  - https://mirrors.bfsu.edu.cn/anaconda/pkgs/free  - https://mirrors.bfsu.edu.cn/anaconda/pkgs/r  - https://mirrors.bfsu.edu.cn/anaconda/pkgs/pro  - https://mirrors.bfsu.edu.cn/anaconda/pkgs/msys2custom_channels:  conda-forge: https://mirrors.bfsu.edu.cn/anaconda/cloud  msys2: https://mirrors.bfsu.edu.cn/anaconda/cloud  bioconda: https://mirrors.bfsu.edu.cn/anaconda/cloud  menpo: https://mirrors.bfsu.edu.cn/anaconda/cloud  pytorch: https://mirrors.bfsu.edu.cn/anaconda/cloud  simpleitk: https://mirrors.bfsu.edu.cn/anaconda/cloud\n\n上海交通大学\ndefault_channels:  - https://anaconda.mirrors.sjtug.sjtu.edu.cn/pkgs/r  - https://anaconda.mirrors.sjtug.sjtu.edu.cn/pkgs/maincustom_channels:  conda-forge: https://anaconda.mirrors.sjtug.sjtu.edu.cn/cloud/  pytorch: https://anaconda.mirrors.sjtug.sjtu.edu.cn/cloud/channels:  - defaultsshow_channel_urls: true\n\nAnaconda添加删除虚拟环境# 新建虚拟环境 -n 为新建虚拟环境命名conda create -n python310 python=3.10# 删除虚拟环境conda remove -n python310 --all\n\nAnaconda切换虚拟环境# 查看所有虚拟环境conda env list # 激活虚拟环境conda activate python310# 退出虚拟环境conda deactivate python310","categories":["编程技术","Python"],"tags":["Python","Anaconda"]},{"title":"Python使用国内源","url":"/2024/04/07/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Python/Python%E4%BD%BF%E7%94%A8%E5%9B%BD%E5%86%85%E6%BA%90/","content":"常用国内源https://pypi.tuna.tsinghua.edu.cn/simplehttps://mirrors.ustc.edu.cn/pypi/web/simple # 已暂时移除并重定向到 BFSU PyPIhttps://mirrors.aliyun.com/pypi/simple/http://mirrors.cloud.tencent.com/pypi/simple\n\n查看当前镜像地址\npip config list# 查看数据中对应路径global.index-url = &#x27;https://pypi.tuna.tsinghua.edu.cn/simple&#x27;install.trusted-host = &#x27;https://pypi.tuna.tsinghua.edu.cn&#x27;\n\n临时使用pip install numpy -i https://pypi.tuna.tsinghua.edu.cn/simple\n\n全局修改pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n\n换回默认pip config unset global.index-url","categories":["编程技术","Python"],"tags":["Python"]},{"title":"Python判断当前运行系统环境","url":"/2025/03/26/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Python/Python%E5%88%A4%E6%96%AD%E5%BD%93%E5%89%8D%E8%BF%90%E8%A1%8C%E7%B3%BB%E7%BB%9F%E7%8E%AF%E5%A2%83/","content":"使用sys模块import sysif sys.platform.startwith(&quot;win&quot;):\tprint(&quot;当前系统是Windows&quot;)elif sys.platform.startwith(&quot;linux&quot;):\tprint(&quot;当前系统是Linux&quot;)elif sys.platform.startwith(&quot;darwin&quot;):\tprint(&quot;当前系统是MAC OS&quot;)else:\tprint(&quot;当前系统是其他操作系统&quot;)\n\n使用platform模块import platformsystem=platform.system()if system==&quot;Windows&quot;:\tprint(&quot;当前系统是Windows&quot;)elif system==&quot;Linux&quot;:\tprint(&quot;当前系统是Linux&quot;)elif system==&quot;Darwin&quot;:\tprint(&quot;当前系统是MAC OS&quot;)else:\tprint(&quot;当前系统是其他操作系统&quot;)\t\n\n使用os模块import ossystem = os.nameif system == &quot;nt&quot;:\tprint(&quot;当前系统是Windows&quot;)elif system == &quot;posix&quot;:\tprint(&quot;当前系统是Linux或Mac OS&quot;)else\tprint(&quot;当前系统是其他操作系统&quot;)\n\n","categories":["编程技术","Python"],"tags":["Python","运行环境"]},{"title":"Python对接C库","url":"/2025/03/27/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Python/Python%E5%AF%B9%E6%8E%A5C%E5%BA%93/","content":"1. 准备环境\n准备开发包：包含头文件(.h)、库文件（.dll或.so）及对接文档\n安装依赖：确保Python环境已安装ctypes库或第三方库例如Cython(用于复杂场景)\n配置路径：将SDK的库路径添加到环境变量或直接在代码中指定路径(推荐方式，不会因为换电脑导致无法编译，例如sdk/windows/sdk.dll)\n\n2.  封装接口加载SDK\nimport sysfrom ctypes import *from ctypes import wintypes# 区分Windows和Linux环境，加载不同SDKif sys.platform.startwith(&quot;win&quot;):\tsdk = WinDLL(&quot;sdk/windows/sdk.dll&quot;)elif sys.platform.startwith(&quot;linux&quot;):\tsdk = CDLL(&quot;sdk/linux/sdk.so&quot;)\n\n定义结构体\n# 定义结构体，需要与SDK头文件一致class DEMO：\t_fields_ = [\t\t(&quot;fieldname-1&quot;, c_int),   # int 类型\t\t(&quot;fieldname-2&quot;, c_int_p), # int 指针\t\t# 其他字段参考SDK文档\t]\n![[Python对接C库&#x2F;IMG-20250804110742707.png]]定义函数原型，需严格对齐SDK中的数据类型和函数参数顺序\nsdk.Init.restype = c_bool # 映射返回值，Init为C/C++中的函数名sdk.Init.argtypes = [     # 映射参数列表\tc_int, c_int_p, c_char_p]\n3. 接口调用函数调用\nsdk.Init(c_int(0), c_int_p(0), c_char_p(b&quot;this is a test&quot;))\n\n带有回调函数的函数调用回调函数例如\nint (*Callback) (int, char*);\nPython中定义回调函数类型\nCallbackType = CFUNCTYPE(c_int, c_int, c_char_p) # 返回类型在前，参数在后\n若C函数使用__stdcall（常见于Windows API）,需要WINFUNCTYPE替代CFUNCTYPE，若为__cdecl（默认）,则使用CFUNCTYPEPython实现回调函数（参数和返回值需与C定义严格一致）\ndef py_callback(num, text) -&gt; int:\tprint(f&quot;Received： &#123;num&#125;, &#123;text.decode(&quot;utf-8&quot;)&#125;&quot;)\treturn 0 # 返回值需与C定义匹配\n\n处理指针参数\n若回调参数包含指针，例如void*，需要使用c_void_p类型，并通过cast解析\ndef py_callback(data_ptr): \tdata = cast(data_ptr, POINTER(c_int)).contents.value \treturn data\n\n注册回调函数\nc_callback = CallbackType(py_callback) # 使用定义的回调类型包装Python函数global_keep_alive = c_callback # 关键！ 将回调对象保存为全局变量或类属性，防止被回收sdk.register_callback.argtypes = [c_int, CallbackType]sdk.register_callback.restype = None\n4. 资源释放退出时需要调用SDK中的清理函数释放资源\nsdk.Cleanup()\n\n5. 注意事项\n结构体指针和缓冲区需要手动分配&#x2F;释放，避免内存泄漏\n不同版本SDK接口可能有差异，建议统一开发与部署环境\n映射Windows中特有的类型例如WORD,DWORD在wintypes包中\nC调用Python回调时，若Python函数抛出异常可能导致程序崩溃。需要在回调内部处理异常。\n若C函数在子线程中调用回调，需确保Python的GIL（全局解释锁）已获取from ctypes import py_object, pythonapi PyGILState_Ensure = pythonapi.PyGILState_Ensure PyGILState_Release = pythonapi.PyGILState_Release def thread_safe_callback(): \tstate = PyGILState_Ensure() \t# 执行Python操作 \tPyGILState_Release(state)\n\n","categories":["编程技术","Python"]},{"title":"Python虚拟环境使用","url":"/2024/07/11/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Python/Python%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E4%BD%BF%E7%94%A8/","content":"Python：虚拟隔离环境的创建和基本使用_激活虚拟隔离环境的代码-CSDN博客\n你学Python 虚拟环境 看这一篇就够了 - 知乎 (zhihu.com)\n","categories":["编程技术","Python"]},{"title":"基于OpenCV的视频流处理","url":"/2025/02/24/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Python/%E5%9F%BA%E4%BA%8EOpenCV%E7%9A%84%E8%A7%86%E9%A2%91%E6%B5%81%E5%A4%84%E7%90%86/","content":"获取VideoCapture实例# 读取视频流strem_capture = cv2.VideoCapture(&quot;rtst://192.168.0.0/live/demo&quot;)# 读取视频文件file_capture = cv2.VideoCapture(&#x27;demo.mp4&#x27;)# 读取摄像头capture = cv2.VideoCapture(0)\n\n获取摄像头编号可使用ls -al /dev/ |grep video,输出信息以video开头其后缀为数字即为可能的摄像头编号。\n检查获取VideoCapture实例是否成功# 校验获取VideoCapture类实例if not capture.isOpened():\treturn\n\n获取视频流信息# 获取视频帧的宽width = capture.get(cv2.CAP_PROP_FRAME_WIDTH)# 获取视频帧的高height = cpature.get(cv2.CAP_PROP_FRAME_HEIGHT)# 获取视频帧率fps = capture.get(cv2.CAP_PROP_FPS)\n\n获取帧画面success, frame = capture.read()\n\n当需要同时处理多路摄像头时一般使用grab()和retrieve()代替\nsuccess_1 = capture.grab()success_2 = stream_capture.grab()if success_1 and success_2:\tframe_1 = capture.retrieve()\tframe_2 = stream_capture.retrieve()\n\n设置分辨率# 设置摄像头分辨率的宽capture.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)# 设置摄像头分辨率的高capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n\n保存视频文件无论是视频文件存储还是摄像头画面保存都是用VideoWriter类,初始化时需要传入文件名（包含文件格式）、视频编解码器、视频保存帧率 、分辨率，保存视频的帧率最好和读入的帧率一致，分辨率可以更改，只是要求写入的帧大小要与分辨率保持一致。若指定的文件名已存在则会覆盖文件。\nwriter = cv2.VideoWriter(&#x27;output.mp4&#x27;, \tcv2.VideoWriter_fourcc(*&#x27;MP4V&#x27;), 30, (1080,1920))writer.write(frame)\n\n释放资源不管是VideoCapture还是VideoWriter类，使用完都应该释放资源\n# 释放VideoCapture资源capture.release()# 释放VideoWriter资源writer.release()\n\n\n完整示例# -*- coding: utf-8 -*-# /usr/bin/env/python3import cv2import timecapture = cv2.VideoCapture(&#x27;rtsp://192.168.0.0/live/demo)fourcc = cv2.VideoWriter_fourcc(*&#x27;MP$v&#x27;) # 或H264,H265fps = capture.get(cv2.CAP_PROP_FPS)width = capture.get(cv2.CAP_PROP_FRAME_WIDTH)height = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)writer = cv2.VideoWriter(&#x27;demo.mp4&#x27;, fourcd, fps, (height, width))while True:\tif not capture.isOpened():\t\ttime.sleep(0.5)\t\tcontinue\tsuccess, frame = capture.read()\tif success:\t\tcv2.imshow(&#x27;DEMO&#x27;, frame) # 显示画面\t\twriter.write(frame) # 保存视频文件\tif (cv2.waitKey(20) &amp; 0xff) == ord(&#x27;q&#x27;): # 等待20ms并判断是否按下&#x27;q&#x27;退出,waitkey只能传入整数，\t\tbreakcapture.release() # 释放VideoCapturewriter.release() # 释放VideoWritercv2.destroyAllWindows() # 销毁所有opencv显示窗口","categories":["编程技术","Python"],"tags":["Python","OpenCV"]},{"title":"我如何使用 Django + Vue.js 快速构建项目","url":"/2019/05/18/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Python/%E5%9F%BA%E4%BA%8EVue%E5%92%8CDjango%E6%90%AD%E5%BB%BA%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E9%A1%B9%E7%9B%AE/","content":"\n写在开头：1看这里的时候，请确保你已将熟悉JavaScript以及了解Vue的语法， Django的语法也略懂一二。如果不是很了解，请点击这里查看学习文档Vue、Django，否则下文可能有些不好理解。2文章有点长 ，因为包含了一个Index.vue页面。3第一次写长文章，所以排版很尴尬，请指正。\n\n\n安装Vue环境\n安装element-ui组件 使用其组件美化界面\n\nnpm i element-ui -S ||  npm install element-ui --save\n\nmain.js     import ElementUI from &#x27;element-ui&#x27;;    import &#x27;element-ui/lib/theme-chalk/index.css&#x27;;    Vue.use(ElementUI)\n\n\n安装axios 使用其完成前端到后端的请求\n\n\n由于axios 使用Vue.use(无效)，所以要将其绑定在Vue原型上\n\nnpm install axios --save |  brew install axios --save\n\nimport axios from &#x27;axios&#x27;axios.defaults.baseURL = &#x27;http://localhost:8000&#x27;  Vue.prototype.$axios = axios\n\n\n安装Django及配置环境\n配置mysql数据库，使用sqlite3的 跳过此步骤无需配置\n\nsettings.py  DATABASES = &#123;    &#x27;default&#x27;: &#123;  #        &#x27;ENGINE&#x27;: &#x27;django.db.backends.mysql&#x27;,  # 不同库有不同的殷勤        &#x27;NAME&#x27;: &#x27;python_use&#x27;,  # 使用的库名        &#x27;USER&#x27;: &#x27;root&#x27;,        &#x27;PASSWORD&#x27;: &#x27;&#x27;,        &#x27;HOST&#x27;: &#x27;127.0.0.1&#x27;,        &#x27;PORT&#x27;: &#x27;3306&#x27;,    &#125;  &#125;\n\n配置完成后请查看django是否报错，不报错即连接成功\n\n安装 pip 及 django-cors-headers\n\npip install django-cors-headers\n\nsettings.py    INSTALLED_APPS = &#123;    ...    &#x27;corsheaders&#x27;,    ...  &#125;      MIDDLEWARE = [      ...        &#x27;corsheaders.middleware.CorsMiddleware&#x27;,    &#x27;django.middleware.common.CommonMiddleware&#x27;,    ...  ]    CORS_ORIGIN_ALLOW_ALL = True         \n\n\n至此，已将Vue和Django安装并配置好，接下来写一个简单的CRUD操作。请确认你的整个项目目录与此类似\n![](Vue + Django&#x2F;2064404-d3a828d4530715b4.png)\n项目目录结构\n以下使用的目录均为此图所示\n\n\n配置路由\n\nfirst/urls.py   urlpatterns = [    url(r&#x27;^admin/&#x27;, admin.site.urls),    url(r&#x27;&#x27;, include(&#x27;crud.urls&#x27;)),  ]\n\ncrud/urls.py        from django.conf.urls import url  from . import views  urlpatterns = [    url(&#x27;create/&#x27;, views.create, name = &#x27;create&#x27;),    url(&#x27;read&#x27;, views.read, name = &#x27;read&#x27;),    url(&#x27;update/&#x27;, views.update, name = &#x27;update&#x27;),    url(&#x27;delete/&#x27;, views.delete, name = &#x27;delete&#x27;),    url(&#x27;search&#x27;, views.search, name = &#x27;search&#x27;)  ]\n\n\n创建models，即在数据库中创建表\n\nfrom django.db import modelsclass Books ( models.Model ):  book_name = models.CharField( max_length = 255 )  book_price = models.DecimalField( max_digits = 5, decimal_places = 2 )  book_time = models.DateTimeField( &#x27;保存日期&#x27;, auto_now_add = True )\n\nModels创建完成后运行命令 将其应用到数据库中并创建表如果不懂 请返回顶部阅读Django文档\npython manage.py makemigrationspython manage.py migrate\n\n\n编写views.py 完成增删改查的逻辑\n\n# 1 获取前端传递来的参数# 1.1 get方法发送的参数  request.GET[&#x27;content&#x27;]# 1.2 post方法发送的参数  obj = json.loads(request.body)  name = obj[&#x27;name&#x27;]# 2 由于使用Books.objects下的方法，获取到的数据为Query Set类型， #   所以需要使用serializers.serialize(&quot;json&quot;, books)# 将查询到的数据进行序列化，变成可读的对象。# 3 向前端返回处理结果 return HttpResponse(json.dumps(res), content_type=&quot;application/json&quot;) # 将res变成json字符串返回给前端。\n\nfrom __future__ import unicode_literalsfrom django.shortcuts import renderfrom django.http import HttpResponseimport jsonfrom django.core import serializersfrom django.utils import timezonefrom crud.models import Booksdef search(request):    content = request.GET[&#x27;content&#x27;]    try:        books = serializers.serialize(&quot;json&quot;,Books.objects.filter(book_name__contains=content))        res = &#123;            &quot;code&quot;: 200,            &quot;data&quot;: books        &#125;        print(books)    except Exception,e:        res = &#123;            &quot;code&quot;: 0,            &quot;errMsg&quot;: e        &#125;    return HttpResponse(json.dumps(res), content_type=&quot;application/json&quot;)def create(request):    print(&#x27;create&#x27;)    obj = json.loads(request.body)    name = obj[&#x27;name&#x27;]    price = obj[&#x27;price&#x27;]    try:        book = Books(book_name=name, book_price=price, book_time=timezone.now())        book.save()        res = &#123;            &quot;code&quot;: 200,        &#125;    except Exception,e:        res = &#123;            &quot;code&quot;: 0,            &quot;errMsg&quot;: e        &#125;    return HttpResponse(json.dumps(res), content_type=&quot;application/json&quot;)def read(request):    print(&#x27;read&#x27;)    try:        res = &#123;            &quot;code&quot;: 200,            &quot;data&quot;: serializers.serialize(&quot;json&quot;,Books.objects.filter())        &#125;    except Exception,e:        res = &#123;            &quot;code&quot;: 0,            &quot;errMsg&quot;: e        &#125;    return HttpResponse(json.dumps(res), content_type=&quot;application/json&quot;)def update(request):    print(&#x27;update&#x27;)    obj = json.loads(request.body)    pid = obj[&#x27;id&#x27;]    name = obj[&#x27;name&#x27;]    price = obj[&#x27;price&#x27;]    try:        Books.objects.filter(id=pid).update(book_price=price, book_name=name)        res = &#123;            &quot;code&quot;: 200        &#125;    except Exception,e:        res = &#123;            &quot;code&quot;: 0,            &quot;errMsg&quot;: e        &#125;    return HttpResponse(json.dumps(res), content_type=&quot;application/json&quot;)def delete(request):    print(&#x27;delete&#x27;)    obj = json.loads(request.body)    print(obj)    pid = obj[&#x27;id&#x27;]    try:        Books.objects.filter(id=pid).delete()        res = &#123;            &quot;code&quot;: 200        &#125;    except Exception,e:        res = &#123;            &quot;code&quot;: 0,            &quot;errMsg&quot;: e        &#125;    return HttpResponse(json.dumps(res), content_type=&quot;application/json&quot;)\n\n\n\n配置路由\n\nfrontend/src/router/index.js    import Vue from &#x27;vue&#x27;  import Router from &#x27;vue-router&#x27;  import Index from &#x27;@/components/Index&#x27;  Vue.use(Router)  export default new Router(&#123;    routes: [      &#123;        path: &#x27;/&#x27;,        name: &#x27;index&#x27;,        component: Index      &#125;    ]  &#125;)\n\n\n编写路由中使用到的组件 与上面import所用名称和路径需要一致，请耐心看完注释。\n\n     this.$axios.get(&#x27;/search&#x27;, &#123;  params: &#123;       content: this.search     &#125;&#125;).then(res =&gt; &#123;  console.log(res)&#125;)this.$axios.post(&#x27;/delete/&#x27;, JSON.stringify(row)).then(res =&gt; &#123;    console.log(res)    &#125;)\n\n以下为Index.vue的全部页面，包含增删改查的基本操作，以及更改和新增时的弹出框：\nfrontend/src/components/Index.vue  &lt;template&gt;    &lt;div&gt;      &lt;el-button type=&quot;primary&quot; round @click=&quot;handleShowCreate&quot;&gt;增加书籍&lt;/el-button&gt;      &lt;el-input v-model=&quot;search&quot; placeholder=&quot;请输入内容&quot; style=&quot;width: 200px&quot;  @keyup.enter.native=&quot;handleSearch&quot;/&gt;      &lt;el-button type=&quot;primary&quot; round @click=&quot;handleSearch&quot;&gt;搜索&lt;/el-button&gt;      &lt;el-table :data=&quot;booksData&quot; height=&quot;250&quot; border style=&quot;width: 600px; margin: 40px auto;&quot;  v-loading=&quot;loading&quot;&gt;        &lt;el-table-column          prop=&quot;book_name&quot;          label=&quot;书名&quot;          align=&quot;center&quot;          width=&quot;200&quot;&gt;        &lt;/el-table-column&gt;        &lt;el-table-column          prop=&quot;book_price&quot;          label=&quot;价格&quot;          align=&quot;center&quot;          width=&quot;200&quot;&gt;        &lt;/el-table-column&gt;        &lt;el-table-column label=&quot;操作&quot; align=&quot;center&quot;&gt;          &lt;template slot-scope=&quot;scope&quot;&gt;            &lt;el-button              size=&quot;mini&quot;              @click=&quot;handleUpdate(scope.$index, scope.row)&quot;&gt;编辑&lt;/el-button&gt;            &lt;el-button              size=&quot;mini&quot;              type=&quot;danger&quot;              @click=&quot;handleDelete(scope.$index, scope.row)&quot;&gt;删除&lt;/el-button&gt;          &lt;/template&gt;        &lt;/el-table-column&gt;      &lt;/el-table&gt;      &lt;el-dialog title=&quot;修改书籍&quot; :visible.sync=&quot;dialogUpdateVisible&quot;&gt;        &lt;el-form :model=&quot;updateData&quot;&gt;          &lt;el-form-item label=&quot;书籍名称&quot;&gt;            &lt;el-input auto-complete=&quot;off&quot; v-model=&quot;updateData.name&quot;&gt;&lt;/el-input&gt;          &lt;/el-form-item&gt;          &lt;el-form-item label=&quot;书籍价格&quot;&gt;            &lt;el-input-number v-model=&quot;updateData.price&quot; :precision=&quot;2&quot; :step=&quot;0.01&quot; :max=&quot;9999&quot;&gt;&lt;/el-input-number&gt;          &lt;/el-form-item&gt;        &lt;/el-form&gt;        &lt;div slot=&quot;footer&quot; class=&quot;dialog-footer&quot;&gt;          &lt;el-button @click=&quot;handleCancel(&#x27;dialogUpdateVisible&#x27;)&quot;&gt;Cancel&lt;/el-button&gt;          &lt;el-button type=&quot;primary&quot; @click=&quot;handleConfirm(&#x27;dialogUpdateVisible&#x27;)&quot;&gt;Submit&lt;/el-button&gt;        &lt;/div&gt;      &lt;/el-dialog&gt;      &lt;el-dialog title=&quot;增加书籍&quot; :visible.sync=&quot;dialogCreateVisible&quot;&gt;        &lt;el-form :model=&quot;createData&quot;&gt;          &lt;el-form-item label=&quot;书籍名称&quot;&gt;            &lt;el-input auto-complete=&quot;off&quot; v-model=&quot;createData.name&quot;&gt;&lt;/el-input&gt;          &lt;/el-form-item&gt;          &lt;el-form-item label=&quot;书籍价格&quot;&gt;            &lt;el-input-number v-model=&quot;createData.price&quot; :precision=&quot;2&quot; :step=&quot;0.01&quot; :max=&quot;9999&quot;&gt;&lt;/el-input-number&gt;          &lt;/el-form-item&gt;        &lt;/el-form&gt;        &lt;div slot=&quot;footer&quot; class=&quot;dialog-footer&quot;&gt;          &lt;el-button @click=&quot;handleCancel(&#x27;dialogCreateVisible&#x27;)&quot;&gt;Cancel&lt;/el-button&gt;          &lt;el-button type=&quot;primary&quot; @click=&quot;handleCreate(&#x27;dialogCreateVisible&#x27;)&quot;&gt;Submit&lt;/el-button&gt;        &lt;/div&gt;      &lt;/el-dialog&gt;    &lt;/div&gt;  &lt;/template&gt;  &lt;script&gt;  export default &#123;    name: &#x27;index&#x27;,    data () &#123;      return &#123;        search: &#x27;&#x27;,        booksData: [],        oldData: &#123;&#125;,        updateData: &#123;&#125;,        createData: &#123;          name: &#x27;&#x27;,          price: 0        &#125;,        dialogUpdateVisible: false,        dialogCreateVisible: false,        loading: true      &#125;    &#125;,    methods: &#123;      handleShowCreate () &#123;        this.dialogCreateVisible = true      &#125;,      handleCreate () &#123;        if (this.createData.name === &#x27;&#x27;) &#123;          this.$message.error(&#x27;please input book name&#x27;)          return        &#125;        if (this.createData.price === 0) &#123;          this.$message.error(&#x27;please input book price&#x27;)          return        &#125;        this.$axios.post(&#x27;/create/&#x27;, JSON.stringify(this.createData)).then(res =&gt; &#123;          if (res.data.code === 200) &#123;            this.$message.success(`create $&#123;this.createData.name&#125; success`)            this.dialogCreateVisible = false            this.handleRead()          &#125; else &#123;            this.$message.error(&quot;can&#x27;t read books database&quot;)          &#125;        &#125;)        console.log(this.createData)      &#125;,      handleRead () &#123;        this.booksData = []        this.$axios.get(&#x27;/read&#x27;).then(res =&gt; &#123;          this.loading = false          if (res.data.code === 200) &#123;            let books = JSON.parse(res.data.data)            for (let i in books) &#123;              books[i].fields.id = books[i].pk              books[i].fields.book_price = Number(books[i].fields.book_price)              this.booksData.push(books[i].fields)            &#125;            console.log(this.booksData)          &#125; else &#123;            this.$message.console.error(&quot;can&#x27;t read books database&quot;)          &#125;        &#125;).catch((res) =&gt; &#123;          console.log(res)        &#125;)      &#125;,      handleUpdate (index, row) &#123;        this.dialogUpdateVisible = true        this.updateData = Object.assign(&#123;&#125;, &#123;          id: row.id,          name: row.book_name,          price: row.book_price,          time: row.book_time        &#125;)        this.oldData = Object.assign(&#123;&#125;, &#123;          id: row.id,          name: row.book_name,          price: row.book_price,          time: row.book_time        &#125;)      &#125;,      handleDelete (index, row) &#123;        this.$confirm(`are you sure to delete $&#123;this.updateData.name&#125; ?`, &#x27;&#x27;, &#123;          confirmButtonText: &#x27;submit&#x27;,          cancelButtonText: &#x27;cancel&#x27;,          type: &#x27;warning&#x27;        &#125;).then(() =&gt; &#123;          this.$axios.post(&#x27;/delete/&#x27;, JSON.stringify(row)).then(res =&gt; &#123;            if (res.data.code === 200) &#123;              this.$message.success(`delete $&#123;this.updateData.name&#125; success`)              this.handleRead()            &#125; else &#123;              this.$message.error(&quot;can&#x27;t read books database&quot;)            &#125;          &#125;)        &#125;).catch(() =&gt; &#123;          this.$message.info(&#x27;cancel delete&#x27;)        &#125;)      &#125;,      handleCancel (arg) &#123;        this.$message.info(&#x27;cancel&#x27;)        this[arg] = false      &#125;,      handleConfirm (arg) &#123;        if (this.updateData.name === this.oldData.name &amp;&amp; this.updateData.price === this.oldData.price) &#123;          this.$message.error(&#x27;please update something or cancel&#x27;)          return        &#125;        this[arg] = false        this.$axios.post(&#x27;/update/&#x27;, JSON.stringify(this.updateData)).then(res =&gt; &#123;          if (res.data.code === 200) &#123;            this.$message.success(`update $&#123;this.updateData.name&#125; success`)            this.handleRead()          &#125; else &#123;            this.$message.error(&quot;can&#x27;t read books database&quot;)          &#125;        &#125;)      &#125;,      handleSearch () &#123;        this.$axios.get(&#x27;search&#x27;, &#123;          params: &#123;            content: this.search          &#125;        &#125;).then(res =&gt; &#123;          if (res.data.code === 200) &#123;            if (res.data.data &amp;&amp; JSON.parse(res.data.data).length &gt; 0) &#123;              this.booksData = []              let books = JSON.parse(res.data.data)              for (let i in books) &#123;                let obj = &#123;                  id: books[i].pk,                  book_name: books[i].fields.book_name,                  book_price: Number(books[i].fields.book_price),                  book_time: books[i].fields.book_time                &#125;                this.booksData.push(obj)              &#125;            &#125; else &#123;              this.$message.error(`can&#x27;t search contains of &#x27;$&#123;this.search&#125;&#x27; in database`)            &#125;          &#125; else &#123;            this.$message.error(`can&#x27;t search books in database`)          &#125;        &#125;)      &#125;    &#125;,    mounted () &#123;      this.handleRead()    &#125;  &#125;  &lt;/script&gt;\n\n到这里，一个增删改查基本操作的页面就写完了，如果哪里有问题可以留言指正。 git源码以上传， 没事可以star&#x2F;fork 更新将在以下附注后增加。\n\nhttps://github.com/RogersLei/django-vue\n\n\n附注 ：\n\nVue添加事件所用到的修饰符：\n![](Vue + Django&#x2F;2064404-1aa984b701bf3e11.png)\nVue事件绑定修饰符\n\nDjango中模糊查询用到的语法：\n\n\n\nYourModels.objects.filter(headline__contains&#x3D;str)字段名__contains &#x2F; __icontains 忽略大小写\n\n更多精彩内容，就在简书APP\n“小礼物走一走，来简书关注我”\n还没有人赞赏，支持一下\n总资产23共写了2.2W字获得33个赞共22个粉丝\n推荐阅读更多精彩内容\n一.前言 最近接手了一个项目，后端是django，前端是django自带的模板，用的是jinja2，写了一段时间发…\n\n\n组织文章借鉴 ——培训师的21项修炼 书籍结构：错误的案例情景重现-抛出问题，传道受业解惑也 我们假设一个场景，大…\n\n每天总是忙忙碌碌，感觉时间完全不够用，更不要说是学习了，可是忙忙碌碌到最后感觉收获也很小，就像大家说的，瞎忙活。…\n\n和姑姑聊起当时借钱给已故父亲治病时的场景，我依稀记得当时我和涛古，妈妈给厂里老板下跪借那三万块的场景。这辈子希望以…\n\n\n本文整合Django和Vue.js  并引入elementUi 实现前后端分离项目环境\n最终的成品是设计出一个ElementUi风格的页面可以添加和显示学生信息.\n\nDjango作为Python 三大Web框架之一,因其集成了大量的组件(例如: Models Admin Form 等等)而大受欢迎,但是他本身自带的template模板实在是有点弱.于是考虑整合Vue.js同时引入ElementUI 组件,可以更加快速高效的开发出美观实用的Web页面.\nPython本文版本:Python 3.5\n安装教程: https://www.runoob.com/python3/python3-install.html\nPycharm本文版本:2019.1.3 \nPyCharm 2019.1.3 (Community Edition)\n安装教程:https://www.runoob.com/w3cnote/pycharm-windows-install.html\n\nDjango本文版本:2.2.3 \n安装教程:https://www.runoob.com/django/django-install.html\nnode.js本文版本:10.16.3\n安装教程:https://www.runoob.com/nodejs/nodejs-install-setup.html\nMySQL本文版本: 8.0.13 for Win64 \n安装教程:https://www.runoob.com/mysql/mysql-install.html\n本文的Pycharm为社区版,如果为专业版则字段Django项目的创建选项,创建项目将更加简单.\n1.创建django项目:DjangoElementUI创建文件夹E:\\PycharmProjects:\n在项目文件夹目录输入Windows 命令行如下\ndjango-admin.py startproject DjangoElementUI\n\n成功创建项目完成后文件夹结构如下图:\n\n进入项目文件夹目录,在目录中输入命令\npython manage.py runserver 0.0.0.0:8000\n\n看到如下提示则为项目创建成功\n\n在浏览器输入你服务器的 ip（这里我们输入本机 IP 地址： 127.0.0.1:8000） 及端口号，如果正常启动，输出结果如下：\n\n2.数据库配置Django 对各种数据库提供了很好的支持，包括：PostgreSQL、MySQL、SQLite、Oracle。\nDjango 为这些数据库提供了统一的调用API。 我们可以根据自己业务需求选择不同的数据库。\nMySQL 是 Web 应用中最常用的数据库。\n本文采用MySQL\n第一次使用MySQL需要安装 MySQL驱动,在项目文件夹目录下执行以下命令安装：\npip install pymysql\n\nDjango无法直接创建数据库(只能操作到数据表层),我们需要手工创建MySQL数据库.\n以下通过命令行创建 MySQL 数据库:Django_ElementUI\n登录数据库:数据库安装文件夹bin文件夹下输入命令\nmysql -u root -p \n\n\n创建数据库:create DATABASE Django_ElementUI DEFAULT CHARSET utf8;\n\n\nDjango配置数据库在项目的 settings.py 文件中找到 DATABASES 配置项，将其信息修改为：\n&#x27;ENGINE&#x27;: &#x27;django.db.backends.mysql&#x27;,  &#x27;NAME&#x27;: &#x27;Django_ElementUI&#x27;,  \n\n在与 settings.py 同级目录下的 __init__.py 中引入模块和进行配置 (告诉 Django 使用 pymysql 模块连接 mysql 数据库)\npymysql.install_as_MySQLdb()\n\n3.利用Django模型设计数据库表Django 规定，如果要使用模型，必须要创建一个 app。\n创建Django APP:myApp我们使用以下命令创建一个Django app:myApp\ndjango-admin.py startapp myApp\n\n成功后的项目文件夹目录如下:\n\n设计数据库表在myApp下的models.py设计表:\n这里我们设计一个Student表,用来存储学生信息.\n表字段\n字段类型\n含义\nstudent_name\nVarchar类型\n学生姓名\nstudent_sex\nVarchar类型\n学生性别\ncreate_time\nDatetime类型\n创建日期时间\nfrom django.db import modelsclass Student(models.Model):    student_name = models.CharField(max_length=64)    student_sex = models.CharField(max_length=3)    create_time = models.DateTimeField(auto_now=True)\n\n在 settings.py 中找到INSTALLED_APPS这一项，如下：\n&#x27;django.contrib.contenttypes&#x27;,&#x27;django.contrib.sessions&#x27;,&#x27;django.contrib.messages&#x27;,&#x27;django.contrib.staticfiles&#x27;,\n\n生成数据库迁移文件在命令行中运行：\npython manage.py makemigrations myApp\n\n执行成功后结果:\n\n执行迁移文件来完成数据库表的创建在命令行中运行：\npython manage.py migrate myApp\n\n执行成功后结果:\n\n查看数据库中数据库表已经生成成功\n(django默认在makemigrations会为表对象创建主键id,id &#x3D; models.AutoField(primary_key&#x3D;True))\n\n4.Django创建新增和查询学生信息接口在myApp目录下的views.py中创建两个视图函数\nfrom __future__ import unicode_literalsfrom django.http import JsonResponsefrom django.core import serializersfrom django.shortcuts import renderfrom django.views.decorators.http import require_http_methodsfrom myApp.models import Student@require_http_methods([&quot;GET&quot;])def add_student(request):        student = Student(student_name=request.GET.get(&#x27;student_name&#x27;))        response[&#x27;msg&#x27;] = &#x27;success&#x27;        response[&#x27;error_num&#x27;] = 0        response[&#x27;error_num&#x27;] = 1return JsonResponse(response)@require_http_methods([&quot;GET&quot;])def show_students(request):        students = Student.objects.filter()        response[&#x27;list&#x27;] = json.loads(serializers.serialize(&quot;json&quot;, students))        response[&#x27;msg&#x27;] = &#x27;success&#x27;        response[&#x27;error_num&#x27;] = 0        response[&#x27;error_num&#x27;] = 1return JsonResponse(response)\n\n5.配置路由1.在myApp目录下，新增一个urls.py文件,用于创建此APP下的分支路由，把新增的两个视图函数添加到路由里面.\nfrom django.conf.urls import url    url(r&#x27;^add_book/&#x27;, views.add_book),    url(r&#x27;^show_books/&#x27;, views.show_books),\n\n\n2.把上面创建的myApp下的分支路由加到DjangoElementUI下的主路由中urls.py.\nfrom django.contrib import adminfrom django.urls import pathfrom django.conf.urls import urlfrom django.conf.urls import include    url(r&#x27;^admin/&#x27;, admin.site.urls),    url(r&#x27;^api/&#x27;, include(urls)),\n\n\n至此Django部分已经完成,总结下我们利用Django完成了数据库的创建,并创建了两个视图函数作为接口给前端调用.\n1.安装vue-cli脚手架\n在DjangoElementUI根目录下输入命令:\nnpm install -g vue-cli\n\n2.安装好后，新建一个前端工程目录：appfront\n在DjangoElementUI项目根目录下输入命令:\nvue-init webpack appfront\n\n\n3.进入appfront目录安装vue所需要的依赖\nnpm install\n\n\n4.安装ElementUI\nnpm i element-ui -S\n\n\n5.创建新vue页面\n在src&#x2F;component文件夹下新建一个名为Studengt.vue的组件，通过调用之前在Django上写好的api，实现添加学生和展示学生信息的功能.\n&lt;el-row display=&quot;margin-top:10px&quot;&gt;&lt;el-input v-model=&quot;input&quot; placeholder=&quot;请输入学生姓名&quot; style=&quot;display:inline-table; width: 30%; float:left&quot;&gt;&lt;/el-input&gt;&lt;el-button type=&quot;primary&quot; @click=&quot;addStudent()&quot; style=&quot;float:left; margin: 2px;&quot;&gt;新增&lt;/el-button&gt;&lt;el-table :data=&quot;studentList&quot; style=&quot;width: 100%&quot; border&gt;&lt;el-table-column prop=&quot;id&quot; label=&quot;编号&quot; min-width=&quot;100&quot;&gt;&lt;template scope=&quot;scope&quot;&gt; &#123;&#123; scope.row.pk &#125;&#125; &lt;/template&gt;&lt;el-table-column prop=&quot;student_name&quot; label=&quot;姓名&quot; min-width=&quot;100&quot;&gt;&lt;template scope=&quot;scope&quot;&gt; &#123;&#123; scope.row.fields.student_name &#125;&#125; &lt;/template&gt;&lt;el-table-column prop=&quot;student_sex&quot; label=&quot;性别&quot; min-width=&quot;100&quot;&gt;&lt;template scope=&quot;scope&quot;&gt; &#123;&#123; scope.row.fields.student_sex &#125;&#125; &lt;/template&gt;&lt;el-table-column prop=&quot;add_time&quot; label=&quot;添加时间&quot; min-width=&quot;100&quot;&gt;&lt;template scope=&quot;scope&quot;&gt; &#123;&#123; scope.row.fields.create_time &#125;&#125; &lt;/template&gt;this.$http.get(&#x27;http://127.0.0.1:8000/api/add_student?student_name=&#x27; + this.input)var res = JSON.parse(response.bodyText)if (res.error_num === 0) &#123;this.$message.error(&#x27;新增学生失败，请重试&#x27;)this.$http.get(&#x27;http://127.0.0.1:8000/api/show_students&#x27;)var res = JSON.parse(response.bodyText)if (res.error_num === 0) &#123;this.studentList = res[&#x27;list&#x27;]this.$message.error(&#x27;查询学生失败&#x27;)&lt;!-- Add &quot;scoped&quot; attribute to limit CSS to this component only --&gt;\n\n6.配置路由\nappfront&#x2F;router文件夹下的index.js中增加页面路由.\nimport Router from &#x27;vue-router&#x27;import HelloWorld from &#x27;@/components/HelloWorld&#x27;import Student from &#x27;@/components/Student&#x27;export default new Router(&#123;\n\nappfront文件夹下的main.js中引入ElementUI并注册.\nimport router from &#x27;./router&#x27;import &#x27;../node_modules/element-ui/lib/theme-chalk/index.css&#x27;import ElementUI from &#x27;element-ui&#x27;Vue.config.productionTip = false\n\n7.打包并启动前端项目\n 打包vue项目\nnpm run build\n\n启动前端项目\nnpm run dev\n\n出现下面信息则说明我们前端项目已经构建成功.\n\n去浏览器访问页面地址:http://localhost:8080/#/student\n出现如下页面说明我们的页面已经成功.\n\n截止到目前,我们已经成功通过Django创建了一个后端服务,通过Vue.js + ElementUI 实现了前端页面的构建,但是他们运行在各自的服务器,而且前端页面还无法调用后端的接口.\n接下来我们需要将两个项目真正的整合到一个成一个项目.\n1.引入用于HTTP解析的vue-resource\n前端vue项目调用后端需要引入vue-resource\n在appfront文件下运行命令:\nnpm install \n\n安装完成后在main.js中引入vue-resource\nimport router from &#x27;./router&#x27;import &#x27;../node_modules/element-ui/lib/theme-chalk/index.css&#x27;import ElementUI from &#x27;element-ui&#x27;import VueResource from &#x27;vue-resource&#x27;Vue.config.productionTip = false\n\n2.在Django层注入header\n为了让后端可以识别前端需求,我们须要在Django层注入header，用Django的第三方包django-cors-headers来解决跨域问题：\n在DjangoElementUI根目录下输入命令:\npip install django-cors-headers\n\n在settings.py中增加相关中间件代码\n&#x27;django.middleware.security.SecurityMiddleware&#x27;,&#x27;django.contrib.sessions.middleware.SessionMiddleware&#x27;,&#x27;corsheaders.middleware.CorsMiddleware&#x27;,     &#x27;django.middleware.common.CommonMiddleware&#x27;,&#x27;django.middleware.csrf.CsrfViewMiddleware&#x27;,&#x27;django.contrib.auth.middleware.AuthenticationMiddleware&#x27;,&#x27;django.contrib.messages.middleware.MessageMiddleware&#x27;,&#x27;django.middleware.clickjacking.XFrameOptionsMiddleware&#x27;,CORS_ORIGIN_ALLOW_ALL = True   \n\n3.修改Django路由\n这一步我们通过Django路由配置连接前后端资源.\n首先我们把Django的TemplateView指向我们刚才生成的前端dist文件\n在DjangoElementUI目录下的urls.py中增加代码:\nfrom django.conf.urls import urlfrom django.contrib import adminfrom django.conf.urls import includefrom django.views.generic import TemplateView    url(r&#x27;^admin/&#x27;, admin.site.urls),    url(r&#x27;^api/&#x27;, include(urls)),    url( r&#x27;^vue/&#x27;, TemplateView.as_view( template_name=&quot;index.html&quot; ) )\n\n\n接着修改静态资源文件路径也指向前端appfront 相关文件\n在DjangoElementUI目录下的setting.py中增加代码:\n&#x27;BACKEND&#x27;: &#x27;django.template.backends.django.DjangoTemplates&#x27;,&#x27;DIRS&#x27;: [os.path.join(BASE_DIR, &#x27;appfront/dist&#x27;)],  &#x27;django.template.context_processors.debug&#x27;,&#x27;django.template.context_processors.request&#x27;,&#x27;django.contrib.auth.context_processors.auth&#x27;,&#x27;django.contrib.messages.context_processors.messages&#x27;,    os.path.join(BASE_DIR, &quot;appfront/dist/static&quot;)\n\n\n3.重新构建前端项目\nappfront目录下输入命令:\nnpm run build\n\n重新启动Django项目\npython manage.py runserver\n\n输入地址:http://localhost:8000/vue/#/student\n\n添加一条记录\n\n至此,大功告成!\n此份指南在配置的过程踩过不少坑,以下是踩的印象较深的坑.\n1.数据库创建的过程中务必注意大小写的问题,数据库字段和Django的Models页面,View页面和Vue中的组件页面都有关联.很容易一个大小写不注意,导致整个接口无法使用.\n2.连接MySQL需要按照对应的包,同时需要在根目录的_ini_.py中引入pymysql\n3.在整个环境的搭建过程中VUE环境的搭建需要耗费较长的npm安装时间,需要耐心等待.\n4.前后台连接需要在前端引入vue-resource,Django需要引入django-cors-headers\n\n引言大U的技术课堂 的新年第一课，祝大家新的一年好好学习，天天向上：）\n本篇将手把手教你如何快速而优雅的构建前后端分离的项目，想直接上手请往后翻！\n\n目录：\n\n我为什么要选择Django与VueJS？\n\nDjango和VueJS是如何结合起来的？\n\n实操\n\n创建 Django 项目\n\n创建 Django App 做为后端\n\n创建 VueJS 项目作为前端\n\n使用 Webpack 处理前端代码\n\n配置 Django 模板的搜索路径\n\n配置 Django 静态文件搜索路径\n\n开发环境\n\n生产环境（部署到 UCloud）\n\n\n正文：\n我为什么要选择Django与VueJS？首先介绍一下我看重的点：\nDjango (MVC框架) - The Web framework for perfectionists with deadlines\n\nPython  \n\nORM\n\n简单、清晰的配置\n\nAdmin app\n\n\nDjango 仅因为 Python 的血统，就已经站在了巨人的肩膀上，配置管理( SaltStack、Ansible )，数据分析( Pandas )，任务队列( Celery )，Restful API( Django REST framework )，HTTP请求( requests )，再加上高度抽象的ORM，功能强大的 Query Expressions，简单清晰的配置，着重提一下堪称神器的自带App: Admin，有了它你再也不用将一些经常变化的配置写在文件里面，每次增删改都重新发布一次，你只需要定义出配置的 data scheme ，只需要几行代码，Django Admin便为你提供美观，并带有权限控制的增删改查界面，而且可以通过ORM为它生成的API来做到定制化的更新，比如直接读某个wiki上的配置，自动的写入数据库，伪代码如下：\nimport pandas as pdsettings = pd.read_html(&#x27;http://某个gitlab的README 或者 某个redmine wiki&#x27;)settings = clean(settings)update(settings)\n\n最后还可以使用 django-celery 的 celery-beat 按 Interval&#x2F;crontab 的方式扔更新配置的任务到 celery 队列里面，最最重要的是，这些都可以在Django Admin后台直接配置哦，还不够优雅？请联系我\nVueJS (MVVM框架) - Vue.js\n\n数据双向绑定\n单文件组件\n清晰的生命周期\n学习曲线平滑\nvue-cli\n\n\n前端是DevOps的弱项，我需要一个 MVVM 框架来提升交互和节约时间，在试过 AngularJS ，ReactJS，VueJS之后我选择了VueJS，因为我觉得写 VueJS 代码的感觉最接近写 Python\n\n着重提一下单文件组件：\n\n特别清晰，一个文件包含且仅包含三块\n\n 前端渲染的模板\n专为此模板写渲染逻辑的 \n专为此模板写样式的 \n\n这样可以达到什么效果呢？一个文件一个组件，每个组件有它自己的逻辑与样式，你不用关心什么 local 什么 global ，CSS样式加载先后、覆盖问题，因为它是『闭包』的，而且『自给自足』，不知道这样说好不好理解\n当然组件之间也是可以通信的，举个例子，我有一个组件叫 ListULB ，使用表格展示了我拥有的所有 ULB (负载均衡)，ListULB 做了一件事，从 API 获取 ULB 对象列表并 for 循环展现出来， ListULB 可以放到某个页面里，可以放到弹框里，放到模态框里，任何地方都可以，因为这个组件对外交互的只有API\n如果我现在要写一个组件叫 AddVServer ，功能是可以为任意一个 ULB 对象添加VServer，我的写法是将在 AddVServer 组件创建的时候，将 ULB 对象传给 AddVServer 组件，这样AddVServer 组件拿到这个对象，就可以直接根据对象的ID等，创建出当前行的ULB的VServer了，伪代码如下：\n&lt;ListULB&gt;  for **ulb_object** in ulbs_list:    &#123;&#123; ulb_object.name &#125;&#125;    &#123;&#123; ulb_object.id &#125;&#125;    &lt;AddVServer :current_ulb=&#x27;**ulb_object**&#x27;&gt;&lt;/AddVServer&gt;&lt;/ListULB&gt;\n\n注意双星号包着的对象，在 ListULB 组件里面是每行的ULB，传给AddServer组件之后，变成了 current_ulb 对象，拿到id为 current_ulb.id 尽情的为它创建 VServer 吧\n如果我要为指定 VServer 创建 RServer 呢，一样的\n\n看出来了吧，进行开发之前，前端组件的结构与数据的结构对应起来可以省好多时间，数据驱动前端组件，棒吗？\n\n谁不喜欢优雅的代码呢， 『Data drive everything』 多么的省脑细胞\n以上就是我选择Python与VueJS的原因\nDjango与VueJS是如何结合起来？\n首先我选择了VueJS的前端渲染，自然放弃了Django的后端模板引擎渲染\n然后业务逻辑放到了前端，放弃了Django的View（其实也就是前后端分离必要的条件）\n保留了Django的 Controller (URLconf) 来实现前端路由的父级路由，可以达到不同页面使用不同的前端框架， 页面内部使用各自独有的前端路由的效果，万一老大给你配了前端呢，万一前端只想写 ReactJS 呢\n保留了Django的 Model ，前面说了Django的ORM太好用了，而且可以配合Django Admin\n\n所以综合来说就是:\n\nM(Django) + C(Django) + MVVM (VueJS) &#x3D; M + MVVM + C &#x3D; MMVVMC\n\n（为了容易理解，并没有使用Django自称的MTV模式理解，感兴趣看看我画的图）\n\n总结：作为以改变世界为己任的 DevOps ，MVC框架后端渲染的柔弱表现力与繁杂的交互已经不能满足我们了，…..省略1000子…..，所以我选择这样构建项目，嗯…\n好吧，也该开始了\n代码块中的修改都会用爽星号括起来，比如: **changed**\n本文为了精简篇幅，默认您已经安装了必要的 命令行界面（CLI），比如 vue-cli等\n1. 创建Django项目\n命令：\ndjango-admin startproject ulb_manager\n\n结构：\n.├── manage.py└── ulb_manager    ├── __init__.py    ├── settings.py    ├── urls.py    └── wsgi.py\n\n2. 进入项目根目录，创建一个 app 作为项目后端命令：\ncd ulb_managerpython manage.py startapp backend\n\n即：app 名叫做 backend\n结构：\n.├── backend│   ├── __init__.py│   ├── admin.py│   ├── migrations│   │   └── __init__.py│   ├── models.py│   ├── tests.py│   └── views.py├── manage.py└── ulb_manager    ├── __init__.py    ├── settings.py    ├── urls.py    └── wsgi.py\n\n3. 使用vue-cli创建一个vuejs项目作为项目前端\n命令：\nvue-init webpack frontend\n\n即：项目名叫 frontend\n结构：\n.├── backend│   ├── __init__.py│   ├── admin.py│   ├── migrations│   │   └── __init__.py│   ├── models.py│   ├── tests.py│   └── views.py├── frontend│   ├── README.md│   ├── build│   │   └── ....│   ├── config│   │   ├── dev.env.js│   │   ├── index.js│   │   ├── prod.env.js│   │   └── test.env.js│   ├── index.html│   ├── package.json│   ├── src│   │   ├── App.vue│   │   ├── assets│   │   │   └── logo.png│   │   ├── components│   │   │   └── Hello.vue│   │   └── main.js│   ├── static│   └── test│       └── ...├── manage.py└── ulb_manager    ├── __init__.py    ├── settings.py    ├── urls.py    └── wsgi.py\n\n结构总结：\n可以看到项目根目录有两个新文件夹，一个叫 backend ，一个叫 frontend，分别是：\n\nbackend Django的一个app\nfrontend Vuejs项目\n\n4. 接下来我们使用 webpack 打包Vusjs项目\n命令：\ncd frontendnpm installnpm run build\n\n结构：\n我引入了一些包，比如element-ui等，你的static里面的内容会不同，没关系 index.html 和 static 文件夹相同就够了\ndist├── index.html└── static    ├── css    │   ├── app.42b821a6fd065652cb86e2af5bf3b5d2.css    │   └── app.42b821a6fd065652cb86e2af5bf3b5d2.css.map    ├── fonts    │   ├── element-icons.a61be9c.eot    │   └── element-icons.b02bdc1.ttf    ├── img    │   └── element-icons.09162bc.svg    └── js        ├── 0.8750b01fa7ffd70f7ba6.js        ├── vendor.804853a3a7c622c4cb5b.js        └── vendor.804853a3a7c622c4cb5b.js.map\n\n构建完成会生成一个 文件夹名字叫dist，里面有一个 index.html 和一个 文件夹static ，\n5. 使用Django的通用视图 TemplateView找到项目根 urls.py (即ulb_manager&#x2F;urls.py)，使用通用视图创建最简单的模板控制器，访问 『&#x2F;』时直接返回 index.html\nurlpatterns = [    url(r&#x27;^admin/&#x27;, admin.site.urls),    **url(r&#x27;^$&#x27;, TemplateView.as_view(template_name=&quot;index.html&quot;)),**    url(r&#x27;^api/&#x27;, include(&#x27;backend.urls&#x27;, namespace=&#x27;api&#x27;))]\n\n6. 配置Django项目的模板搜索路径上一步使用了Django的模板系统，所以需要配置一下模板使Django知道从哪里找到index.html\n打开 settings.py (ulb_manager&#x2F;settings.py)，找到TEMPLATES配置项，修改如下:\nTEMPLATES = [    &#123;        &#x27;BACKEND&#x27;: &#x27;django.template.backends.django.DjangoTemplates&#x27;,        # &#x27;DIRS&#x27;: [],        **&#x27;DIRS&#x27;: [&#x27;frontend/dist&#x27;]**,        &#x27;APP_DIRS&#x27;: True,        &#x27;OPTIONS&#x27;: &#123;            &#x27;context_processors&#x27;: [                &#x27;django.template.context_processors.debug&#x27;,                &#x27;django.template.context_processors.request&#x27;,                &#x27;django.contrib.auth.context_processors.auth&#x27;,                &#x27;django.contrib.messages.context_processors.messages&#x27;,            ],        &#125;,    &#125;,]\n\n注意这里的 frontend 是VueJS项目目录，dist则是运行 npm run build 构建出的index.html与静态文件夹 static 的父级目录\n这时启动Django项目，访问 &#x2F; 则可以访问index.html，但是还有问题，静态文件都是404错误，下一步我们解决这个问题\n7. 配置静态文件搜索路径打开 settings.py (ulb_manager&#x2F;settings.py)，找到 STATICFILES_DIRS 配置项，配置如下:  \n# Add for vuejsSTATICFILES_DIRS = [    os.path.join(BASE_DIR, &quot;frontend/dist/static&quot;),]\n\n这样Django不仅可以将&#x2F;ulb 映射到index.html，而且还可以顺利找到静态文件  \n此时访问 &#x2F;ulb 我们可以看到使用Django作为后端的VueJS helloworld\nALL DONE.\n8. 开发环境因为我们使用了Django作为后端，每次修改了前端之后都要重新构建（你可以理解为不编译不能运行）\n除了使用Django作为后端，我们还可以在dist目录下面运行以下命令来看效果：\n\n但是问题依然没有解决，我想过检测文件变化来自动构建，但是构建是秒级的，太慢了，所以我直接使用VueJS的开发环境来调试\n\n毫秒，但是有个新问题，使用VueJS的开发环境脱离了Django环境，访问Django写的API，出现了跨域问题，有两种方法解决，一种是在VueJS层上做转发（proxyTable），另一种是在Django层注入header，这里我使用后者，用Django的第三方包 django-cors-headers 来解决跨域问题\n安装\npip install django-cors-headers\n\n配置（两步）\n1. settings.py 修改\nMIDDLEWARE = [    &#x27;django.middleware.security.SecurityMiddleware&#x27;,    &#x27;django.contrib.sessions.middleware.SessionMiddleware&#x27;,    **&#x27;corsheaders.middleware.CorsMiddleware&#x27;,**    &#x27;django.middleware.common.CommonMiddleware&#x27;,    &#x27;django.middleware.csrf.CsrfViewMiddleware&#x27;,    &#x27;django.contrib.auth.middleware.AuthenticationMiddleware&#x27;,    &#x27;django.contrib.messages.middleware.MessageMiddleware&#x27;,    &#x27;django.middleware.clickjacking.XFrameOptionsMiddleware&#x27;,]\n\n这里要注意中间件加载顺序，列表是有序的哦\n2. settings.py 添加\nCORS_ORIGIN_ALLOW_ALL = True\n\n至此，我的开发环境就搭建完成了\n9. 生产环境部署（部署到 UCloud ）9.1 创建主机\n\n注册 UCloud - 专业云计算服务商\n点击左侧的 云主机，然后点击 创建主机\n右侧选择 付费方式，点击 立即购买\n在支付确认页面，点击 确认支付\n\n购买成功后回到主机管理列表，如下所示：  \n\n\n这里注意记住你的外网IP，下面的ip替换成你的  \n\n9.2 环境搭建与部署\n登录主机，用你刚填写的密码：\n\nssh &#114;&#111;&#111;&#116;&#64;&#49;&#50;&#48;&#x2e;&#49;&#51;&#50;.**.75\n\nCentOS 系统可以使用 yum 安装必要的包\n# 如果你使用git来托管代码的话yum install git# 如果你要在服务器上构建前端yum install nodejsyum install npmyum install nginx\n\n\n我们使用 uwsgi 来处理 Django 请求，使用 nginx 处理 static 文件（即之前 build 之后 dist 里面的static，这里默认前端已经打包好了，如果在服务端打包前端需要安装nodejs，npm等）\n\n安装uWsgi\nyum install uwsgi# 或者pip install uwsgi\n\n我们使用配置文件启动uwsgi，比较清楚\nuwsgi配置文件：\n[uwsgi]socket = 127.0.0.1:9292stats = 127.0.0.1:9293workers = 4# 项目根目录chdir = /opt/inner_ulb_managertouch-reload = /opt/inner_ulb_managerpy-auto-reload = 1# 在项目跟目录和项目同名的文件夹里面的一个文件module= inner_ulb_manager.wsgipidfile = /var/run/inner_ulb_manager.piddaemonize = /var/log/inner_ulb_manager.log\n\nnginx 配置文件：\nserver &#123;    listen 8888;    server_name 120.132.**.75;    root /opt/inner_ulb_manager;    access_log /var/log/nginx/access_narwhals.log;    error_log /var/log/nginx/error_narwhals.log;    location / &#123;            uwsgi_pass 127.0.0.1:9292;            include /etc/nginx/uwsgi_params;    &#125;    location /static/ &#123;            root  /opt/inner_ulb_manager/;            access_log off;    &#125;    location ^~ /admin/ &#123;            uwsgi_pass 127.0.0.1:9292;            include /etc/nginx/uwsgi_params;    &#125;&#125;\n\n&#x2F;opt&#x2F;inner_ulb_manager&#x2F;static 即为静态文件目录，那么现在我们静态文件还在 frontend&#x2F;dist 怎么办，不怕，Django给我们提供了命令：\n先去settings里面配置：\nSTATIC_ROOT = os.path.join(BASE_DIR, &quot;static&quot;)\n\n然后在存在manage.py的目录，即项目跟目录执行：\npython manage.py collectstatic\n\n这样frontend&#x2F;dist&#x2F;static里面的东西就到了项目根目录的static文件夹里面了\n那么为什么不直接手动把构建好的dist&#x2F;static拷过来呢，因为开始提过Django自带的App：admin 也有一些静态文件（css,js等），它会一并collect过来，毕竟nginx只认项目跟目录的静态文件，它不知道django把它自己的需求文件放到哪了\n开头说过Django配置灵活，那么我们专门为Django创建一个生产环境的配置 prod.py  \nprod.py 与 默认 settings.py 同目录\n# 导入公共配置from .settings import *# 生产环境关闭DEBUG模式DEBUG = False# 生产环境开启跨域CORS_ORIGIN_ALLOW_ALL = False# 特别说明，下面这个不需要，因为前端是VueJS构建的，它默认使用static作为静态文件入口，我们nginx配置static为入口即可，保持一致，没Django什么事STATIC_URL = &#x27;/static/&#x27;\n\n如何使用这个配置呢，进入 wisg.py 即uwsgi配置里面的module配置修改为：\nimport osfrom django.core.wsgi import get_wsgi_applicationos.environ.setdefault(&quot;DJANGO_SETTINGS_MODULE&quot;, &quot;**inner_ulb_manager.prod**&quot;)application = get_wsgi_application()\n\n启动uwsgi\nuwsgi --ini inner_ulb_manager.ini\n\n启动ngingx\n至此，部署就完成了\n10. 效果图List 组件：\n\n\n传单个 ULB 对象给 Detail 组件使用即可\n\nDetail 组件：\n\n\n当然里面还实现了前面提到的 ULB 的 VServer 创建，VServer 的 RServer 的创建等。\n\n————————\n本文由『UCloud平台产品研发团队』提供。\n项目源码文件戳下面链接查看，大家可以马上拿源码上手试起来，操作过程中遇到问题也可直接在github上留言：）https://github.com/tmpbook/django-with-vuejs\n现在注册使用UCloud，还免费试用 及 首充返现优惠，最高可返3000元代金券！活动传送门：用UCloud！3000元限量版礼盒等你来拆！\n另，欢迎添加UCloud运营小妹个人微信号：Surdur，陪聊很专业：）\n\n\n关于作者：\n星辰（@星辰）， UCloud平台产品研发工程师，DevOps一枚。你也可以去他的知乎专栏 《随心DevOps》 上逛逛，干货满满，带你更优雅的改变世界。\n\n相关阅读推荐：机器学习进阶笔记之八 | TensorFlow与中文手写汉字识别\n机器学习进阶笔记之七 | MXnet初体验机器学习进阶笔记之六 | 深入理解Fast Neural Style机器学习进阶笔记之五 | 深入理解VGG\\Residual Network机器学习进阶笔记之四 | 深入理解GoogLeNet机器学习进阶笔记之三 | 深入理解Alexnet机器学习进阶笔记之二 | 深入理解Neural Style机器学习进阶笔记之一 | TensorFlow安装与入门\n「UCloud机构号」将独家分享云计算领域的技术洞见、行业资讯以及一切你想知道的相关讯息。\n欢迎提问&amp;求关注 o(*&#x2F;&#x2F;&#x2F;&#x2F;▽&#x2F;&#x2F;&#x2F;&#x2F;*)q～\n以上。\n","categories":["编程技术","Python"],"tags":["Django","Vue","前后端分离"]},{"title":"搭建Qt4.8.7-armv7交叉编译环境","url":"/2025/12/01/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Qt/%E6%90%AD%E5%BB%BAQt4.8.7-armv7%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91%E7%8E%AF%E5%A2%83/","content":"基于MSYS2搭建\n基于WSL(Linux)搭建","categories":["编程技术","Qt"],"tags":["Qt","交叉编译","ARMv7","ARM32"]},{"title":"DotNetty完全教程（一）","url":"/2019/10/31/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/DotNetty%E6%95%99%E7%A8%8B/DotNetty%E5%AE%8C%E5%85%A8%E6%95%99%E7%A8%8B%EF%BC%88%E4%B8%80%EF%BC%89/","content":"DotNetty完全教程（一）\nExcerpt写本系列文章的目的我一直以来都在从事.NET相关的工作，做过工控，做过网站，工作初期维护过别人写的网络库，后来自己写网络库，我发现在使用C#编程的程序员中，能否写出高性能的网络库一直都是考验一个程序员能力的标杆。为了写出高性能的网络库，我查阅了很多资料，发现Java的Netty有着得天独厚的设计以及实现优势，Java也因为Netty的存在，在开发大吞吐量的应用程序中得心应手。我想，.NET程序…\n\n\n版权声明：本文为博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。\n写本系列文章的目的我一直以来都在从事.NET相关的工作，做过工控，做过网站，工作初期维护过别人写的网络库，后来自己写网络库，我发现在使用C#编程的程序员中，能否写出高性能的网络库一直都是考验一个程序员能力的标杆。为了写出高性能的网络库，我查阅了很多资料，发现Java的Netty有着得天独厚的设计以及实现优势，Java也因为Netty的存在，在开发大吞吐量的应用程序中得心应手。\n我想，.NET程序员为什么不能使用这么好的应用程序框架。好在，Azure团队写出了DotNetty，使得.NET程序员也可以迅速的，便捷的搭建一个高性能的网络应用程序，但是，DotNetty并没有多少资料，项目代码中也没有多少注释，这对我们的学习以及使用带来了极大的障碍。\n我通过对于Netty的研究，一步步的使用DotNetty来创建应用程序，分析DotNetty实现了哪些，没有实现哪些，实现的有何不同，希望通过最简单的描述，让读者能够了解DotNetty，无论是在工作学习中快速搭建网络应用程序还是通过分析Netty的思想，为自己写的网络库添砖加瓦都是十分有意义的。\n本系列文章参考了《Netty实战》，感兴趣的同学可以去看看这本书。\nNetty是什么Netty 是一款用于创建高性能网络应用程序的高级框架。\nNetty 是一款异步的事件驱动的网络应用程序框架，支持快速地开发可维护的高性能的面向协议的服务器和客户端\nDotNetty是什么DotNetty是微软的Azure团队仿造Netty编写的网络应用程序框架。\n优点\n关注点分离——业务和网络逻辑解耦；\n模块化和可复用性；\n可测试性作为首要的要求\n\n历史\n阻塞Socket通信特点：\n建立连接要阻塞线程，读取数据要阻塞线程\n如果要管理多个客户端，就需要为每个客户端建立不同的线程\n会有大量的线程在休眠状态，等待接收数据，资源浪费\n每个线程都要占用系统资源\n线程的切换很耗费系统资源\n\n\n非阻塞Socket（NIO）特点：\n\n如图，每个Socket如果需要读写操作，都通过事件通知的方式通知选择器，这样就实现了一个线程管理多个Socket的目的。\n选择器甚至可以在所有的Socket空闲的时候允许线程先去干别的事情\n减少了线程数量导致的资源占用，减少了线程切换导致的资源消耗\n\n\nNetty特点\n\nNetty设计的关键点异步和事件驱动是Netty设计的关键\n核心组件\nChannel：一个连接就是一个Channel\n回调：通知的基础\n\npublic class ConnectHandler : SimpleChannelInboundHandler&lt;string&gt;&#123;    public override void ChannelActive(IChannelHandlerContext context)    &#123;        // 新的连接建立的时候会触发这个回调        base.ChannelActive(context);    &#125;    protected override void ChannelRead0(IChannelHandlerContext ctx, string msg)    &#123;        throw new NotImplementedException();    &#125;&#125;\n\n\nFuture：通知的另一种方式，可以认为ChannelFuture是包装了一系列Channel事件的对象。回调和Future相互补充，相互结合同时也可以理解Future是一种更加精细的回调。\n但是ChannelFuture在DotNetty中被Task取代\n\n事件和ChannelHandlerChannelHandler是事件处理器，负责处理入站事件和出站事件。通常每一个事件都由一系列的Handler处理。\n\n\n\n本文参考资料以及截图来自《Netty实战》\n\n","categories":["编程技术","DotNet","DotNetty教程"],"tags":["DotNetty"]},{"title":"DotNetty完全教程（七）","url":"/2019/10/31/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/DotNetty%E6%95%99%E7%A8%8B/DotNetty%E5%AE%8C%E5%85%A8%E6%95%99%E7%A8%8B%EF%BC%88%E4%B8%83%EF%BC%89/","content":"DotNetty完全教程（七）\nExcerptChannelPipeline和ChannelHandleContext介绍ChannelPipeline是一系列ChannelHandler连接的实例链，这个实例链构成了应用程序逻辑处理的核心。下图反映了这种关联：ChannelHandlerContext提供了一个ChannelPipeline的上下文，用于ChannelHandler在Pipeline中的交互，这种交互十分的灵活，不仅…\n\n\n版权声明：本文为博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。\nChannelPipeline和ChannelHandleContext介绍ChannelPipeline是一系列ChannelHandler连接的实例链，这个实例链构成了应用程序逻辑处理的核心。下图反映了这种关联：\nChannelHandlerContext提供了一个ChannelPipeline的上下文，用于ChannelHandler在Pipeline中的交互，这种交互十分的灵活，不仅是信息可以交互，甚至可以改变其他Handler在Pipeline中的位置。\n特性\n每一个Channel都会被分配到一个ChannelPipeline，这种关联是永久性的。在Netty中是关联，在DotNetty中这种关联被进一步的强绑定，变成了一个Channel中存在一个Pipeline。\n对于Pipeline来说，入站口被当作Pipeline的头部，出站口被当作尾部。虽然我们看到有两条线，但是在Pipeline中其实是线性的，在事件传播的时候，如果Pipeline发现这个事件的属性（入站出站）跟下一个Handler不匹配，就会跳过这个Handler，前进到下一个。\n一个Handler可以既作为入站处理器也作为出站处理器。\n修改Pipeline\n为了保证ChannelHandler处理事件的高效性，在Handler中不能有阻塞代码，但是如果遇到了一些阻塞API，就需要用到DefaultEventExecutorGroup，其功能是把这个事件的处理从原先的EventLoop中移除，送到一个专门的执行事件处理器中进行处理，从而不阻塞Pipeline。\n\nChanelPipeline的事件我们可以看到fire方法都是调用下一个Handler中的方法，我们可以在合适的时机调用下一个Handler中的方法以实现数据的流动。这里我们注意一下，Write方法并不会将消息写入Socket中，而是写入消息队列中，等待Flush将数据冲刷下去。\nContext的API支持\nPipeline和Context我们可以发现，Pipeline上也有fire–的方法，Context也有类似的方法，他们的差别在于，Pipeline或者Channel上的这些方法引发的事件流将从Pipeline的头部开始移动，而Context上的方法会让事件从当前Handler开始移动，所以为了更短的事件流，我们应该尽可能的使用Context的方法。\n使用ChannelHandlerContext\n获取当前Channel\nIChannelHandlerContext ctx = ...;IChannel channel = ctx.Channel\n\n获取当前pipeline\n// 注意一下在Netty中可以直接通过context获取pipeline，在DotNetty中需要从Channel中获取// NettyIChannelHandlerContext ctx = ...;IChannel channel = ctx.pipeline// DotNettyIChannel channel = ctx.Channel;IChannelPipeline pipeline = channel.Pipeline;\n\n写入pipeline让事件从尾端开始移动\nIChannel channel = ctx.Channel;IChannelPipeline pipeline = channel.Pipeline;channel.WriteAndFlushAsync(&quot;Hello World!&quot;);pipeline.WriteAndFlushAsync(&quot;Hello World!&quot;);\n\n注意，Write是出站事件，他的流动方向是从末尾到头部，这个一定要注意。在pipeline或者channel中写入事件，都是从最末尾开始流动，在Context中写入是从当前Handler中开始移动，这个我们已经在很多地方都说明了这样的不同。\n应用\n协议切换因为我们可以通过Context获取Pipeline的引用，获取了pipeline之后又可以动态的加载和删除Handler，利用这个特性我们可以实现协议的切换，\n随时随地使用Context这里我们补充一个知识，Context和Handler的关系是一对一的，而不是一个Context对应多个Handler，这就让我们可以缓存下Context的引用，在任何时候进行使用，这里的任何时候可以是不同的线程。举个例子就是我们之前写的回声程序是在收到信息之后发送，但是复杂一点我们需要在按下按钮的时候发送一条数据，这时候我们可以在连接之后缓存Context的引用，在按下按钮的时候使用Ctx.Write()；方法来发送一条数据。\n\n线程安全在Netty中，如果想要将一个Handler用于多个Pipeline中，需要标注Shared，同时需要保证线程安全，因为这里可能有多线程的重入问题。\n异常处理\n入站异常无论在何时引发，都会顺着Pipeline继续向下流动，如果最后的Handler没有处理，则会被标记为未处理。所以为了处理所有的入站异常，我们可以在pipeline的尾端通过复写ExceptionCaught来处理所有pipeline上的异常。\n在出站Handler中获取异常在Netty中需要使用ChannelFuture以及ChannelPromise这里先不做叙述\n\n","categories":["编程技术","DotNet","DotNetty教程"],"tags":["DotNetty"]},{"title":"DotNetty完全教程（三）","url":"/2019/10/31/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/DotNetty%E6%95%99%E7%A8%8B/DotNetty%E5%AE%8C%E5%85%A8%E6%95%99%E7%A8%8B%EF%BC%88%E4%B8%89%EF%BC%89/","content":"DotNetty完全教程（三）\nExcerpt组件介绍ChannelChannel是Socket的封装，提供绑定，读，写等操作，降低了直接使用Socket的复杂性。EventLoop我们之前就讲过EventLoop这里回顾一下：一个 EventLoopGroup 包含一个或者多个 EventLoop；一个 EventLoop 在它的生命周期内只和一个 Thread 绑定；所有由 EventLoop 处理的 I&#x2F;O 事件都将在它…\n\n版权声明：本文为博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。\n组件介绍ChannelChannel是Socket的封装，提供绑定，读，写等操作，降低了直接使用Socket的复杂性。\nEventLoop我们之前就讲过EventLoop这里回顾一下：\n\n一个 EventLoopGroup 包含一个或者多个 EventLoop；\n一个 EventLoop 在它的生命周期内只和一个 Thread 绑定；\n所有由 EventLoop 处理的 I&#x2F;O 事件都将在它专有的 Thread 上被处理；\n一个 Channel 在它的生命周期内只注册于一个 EventLoop；\n一个 EventLoop 可能会被分配给一个或多个 Channel。\n\nChannelFuture本身是Channel中消息的回调，在DotNetty中被Task取代。\nChannelHandlerChannelHandler是处理数据的逻辑容器\nChannelInboundHandler是接收并处理入站事件的逻辑容器，可以处理入站数据以及给客户端以回复。\nChannelPipelineChannelPipeline是将ChannelHandler穿成一串的的容器。需要说明的是：\n\nChannelInboundHandler只处理入站事件，ChannelOutboundHandler只处理出站事件\nChannelInboundHandler和ChannelOutboundHandler可以注册在同一个ChannelPipeline中\n\n（尝试一下）在 Netty 中，有两种发送消息的方式。你可以直接写到 Channel 中，也可以 写到和 ChannelHandler相关联的ChannelHandlerContext对象中。前一种方式将会导致消息从ChannelPipeline 的尾端开始流动，而后者将导致消息从 ChannelPipeline 中的下一个 ChannelHandler 开始流动。\n编码器和解码器Netty中内置了一些编码器和解码器，用来进行处理字节流数据，编码器用来将消息编码为字节流，解码器用来将字节流解码为另一种格式（字符串或一个对象）。\n需要注意的是，编码器和解码器都实现了ChannelInboundHandler和 ChannelOutboundHandler接口用于处理入站或出站数据。\nBootstrap引导类\nBootstrap用于引导客户端，ServerBootstrap用于引导服务器\n客户端引导类只需要一个EventLoopGroup服务器引导类需要两个EventLoopGroup。但是在简单使用中，也可以公用一个EventLoopGroup。为什么服务器需要两个EventLoopGroup呢？是因为服务器的第一个EventLoopGroup只有一个EventLoop，只含有一个SeverChannel用于监听本地端口，一旦连接建立，这个EventLoop就将Channel控制权移交给另一个EventLoopGroup，这个EventLoopGroup分配一个EventLoop给Channel用于管理这个Channel。\n\n","categories":["编程技术","DotNet","DotNetty教程"],"tags":["DotNetty"]},{"title":"DotNetty完全教程（九）","url":"/2019/10/31/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/DotNetty%E6%95%99%E7%A8%8B/DotNetty%E5%AE%8C%E5%85%A8%E6%95%99%E7%A8%8B%EF%BC%88%E4%B9%9D%EF%BC%89/","content":"DotNetty完全教程（九）\nExcerpt引导Bootstrap引导一个应用程序是指对他进行配置并且使他运行的过程。体系结构注意，DotNetty没有实现Cloneable的接口，而是直接实现了一个Clone方法。Netty实现这个接口是为了创建两个有着相同配置的应用程序，可以把一个配置整体应用到另一个上面，需要注意的是EventLoopGroup是一个浅拷贝，这就导致了拷贝的Bootstrap都会使用同一个EventLoopGr…\n\n\n引导Bootstrap引导一个应用程序是指对他进行配置并且使他运行的过程。\n体系结构注意，DotNetty没有实现Cloneable的接口，而是直接实现了一个Clone方法。Netty实现这个接口是为了创建两个有着相同配置的应用程序，可以把一个配置整体应用到另一个上面，需要注意的是EventLoopGroup是一个浅拷贝，这就导致了拷贝的Bootstrap都会使用同一个EventLoopGroup，这在每个Channel生命周期很短的时候是没有太大影响的。\n服务器引导和普通引导有什么区别呢？区别在于，服务器接收到客户端的连接请求，会用一个Channel接受连接，然后用另一个Channel与客户端进行交流，但是客户端只需要一个Channel就可以与服务器进行交互。\n关于链式调用我们发现Bootstrap类可以通过流式语法进行链式调用，这要归功于Bootstrap类的特殊定义。下面我们来看一下：\n// 定义public abstract class AbstractBootstrap&lt;TBootstrap, TChannel&gt;    where TBootstrap : AbstractBootstrap&lt;TBootstrap, TChannel&gt;    where TChannel : IChannel// 定义子类public class Bootstrap : AbstractBootstrap&lt;Bootstrap, IChannel&gt;// 方法实现public virtual TBootstrap Group(IEventLoopGroup group)&#123;    Contract.Requires(group != null);    if (this.group != null)    &#123;        throw new InvalidOperationException(&quot;group has already been set.&quot;);    &#125;    this.group = group;    return (TBootstrap)this;&#125;// 使用var bootstrap = new Bootstrap();bootstrap    .Group(group)    .Channel&lt;TcpSocketChannel&gt;()    .Handler(new ActionChannelInitializer&lt;ISocketChannel&gt;(channel =&gt;    &#123;        IChannelPipeline pipeline = channel.Pipeline;        pipeline.AddLast(new EchoClientHandler());    &#125;));\n\nAPI\n客户端引导var group = new MultithreadEventLoopGroup();var bootstrap = new Bootstrap();bootstrap    .Group(group)    .Channel&lt;TcpSocketChannel&gt;()    .Handler(new ActionChannelInitializer&lt;ISocketChannel&gt;(channel =&gt;    &#123;        IChannelPipeline pipeline = channel.Pipeline;        pipeline.AddLast(new EchoClientHandler());    &#125;));IChannel clientChannel = await bootstrap.ConnectAsync(new IPEndPoint(IPAddress.Parse(&quot;10.10.10.158&quot;), 3000));Console.ReadLine();await clientChannel.CloseAsync();\n\n服务器引导API：注意上面箭头指示的是与Bootstrap不一样的方法。为什么会有子Channel的概念呢，我们看下面这个图：因为服务器是一对多的，所以有子Channel的概念。\nIEventLoopGroup eventLoop;eventLoop = new MultithreadEventLoopGroup();try&#123;    // 服务器引导程序    var bootstrap = new ServerBootstrap();    bootstrap.Group(eventLoop);    bootstrap.Channel&lt;TcpServerSocketChannel&gt;();    bootstrap.ChildHandler(new ActionChannelInitializer&lt;IChannel&gt;(channel =&gt;    &#123;        IChannelPipeline pipeline = channel.Pipeline;        pipeline.AddLast(new EchoServerHandler());    &#125;));    IChannel boundChannel = await bootstrap.BindAsync(3000);    Console.ReadLine();    await boundChannel.CloseAsync();&#125;catch (Exception ex)&#123;    Console.WriteLine(ex);&#125;finally&#123;    await eventLoop.ShutdownGracefullyAsync();&#125;\n\n从Channel中引导客户端\n场景\n如果我们的服务器需要去第三方获取数据，这时候服务器就需要充当客户端去第三方取数据，这时候就需要在Channel中再开一个客户端获取数据。\n\n方式\n我们最好是从Channel中获取当前EventLoop，这样新开的客户端就跟当前Channel在一个线程中，减少了线程切换带来的开销，尽可能的重用了EventLoop\n\n实现\n// 从Context创建客户端引导var bootstrap = new Bootstrap();bootstrap.Group(ctx.Channel.EventLoop);\n\n初始化Pipeline如果要添加的Handler不止一个，我们就需要用到ChannelInitializer，在DotNetty中，我们有十分简单的方法可以初始化一个pipeline\nvar bootstrap = new Bootstrap();bootstrap    .Group(group)    .Channel&lt;TcpSocketChannel&gt;()    .Option(ChannelOption.TcpNodelay, true)    .Handler(new ActionChannelInitializer&lt;ISocketChannel&gt;(channel =&gt;    &#123;        IChannelPipeline pipeline = channel.Pipeline;        if (cert != null)        &#123;            pipeline.AddLast(&quot;tls&quot;, new TlsHandler(stream =&gt; new SslStream(stream, true, (sender, certificate, chain, errors) =&gt; true), new ClientTlsSettings(targetHost)));        &#125;        pipeline.AddLast(new LoggingHandler());        pipeline.AddLast(&quot;framing-enc&quot;, new LengthFieldPrepender(2));        pipeline.AddLast(&quot;framing-dec&quot;, new LengthFieldBasedFrameDecoder(ushort.MaxValue, 0, 2, 0, 2));        pipeline.AddLast(&quot;echo&quot;, new EchoClientHandler());    &#125;));\n\nChannelOptionChannelOption可以在引导的时候将设置批量的设置到所有Channel上，而不必要在每一个Channel建立的时候手动的去指定它的配置，应用场景是比如设置KeepAlive或者设置超时时间。\nbootstrap.Option(ChannelOption.SoKeepalive, true)    .Option(ChannelOption.ConnectTimeout, new TimeSpan(5000));\n\n面向无连接的用户数据报文UDP的全称是“User Datagram Protocol”，在DotNetty中实现了SocketDatagramChannel来创建无连接的引导，需要注意的是无连接的引导不需要Connect只需要bind即可，代码如下：\nvar bootstrap = new Bootstrap();bootstrap    .Group(group)    .Channel&lt;SocketDatagramChannel&gt;()    .Option(ChannelOption.SoBroadcast, true)    .Handler(new ActionChannelInitializer&lt;IChannel&gt;(channel =&gt;    &#123;        channel.Pipeline.AddLast(&quot;Quote&quot;, new QuoteOfTheMomentClientHandler());    &#125;));IChannel clientChannel = await bootstrap.BindAsync(IPEndPoint.MinPort);\n\n关闭Channel的关闭：\nawait clientChannel.CloseAsync();\n\nEventLoopGroup的关闭：\nawait group.ShutdownGracefullyAsync();\n","categories":["编程技术","DotNet","DotNetty教程"],"tags":["DotNetty"]},{"title":"DotNetty完全教程（二）","url":"/2019/10/31/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/DotNetty%E6%95%99%E7%A8%8B/DotNetty%E5%AE%8C%E5%85%A8%E6%95%99%E7%A8%8B%EF%BC%88%E4%BA%8C%EF%BC%89/","content":"DotNetty完全教程（二）\nExcerpt第一个DotNetty应用程序准备工作NuGet包介绍DotNetty由九个项目构成，在NuGet中都是单独的包，可以按需引用，其中比较重要的几个是以下几个：DotNetty.Common 是公共的类库项目，包装线程池，并行任务和常用帮助类的封装DotNetty.Transport 是DotNetty核心的实现DotNetty.Buffers 是对内存缓冲区管理的封装DotNett…\n\n\n\n版权声明：本文为博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。\n第一个DotNetty应用程序准备工作NuGet包介绍DotNetty由九个项目构成，在NuGet中都是单独的包，可以按需引用，其中比较重要的几个是以下几个：\n\nDotNetty.Common 是公共的类库项目，包装线程池，并行任务和常用帮助类的封装\nDotNetty.Transport 是DotNetty核心的实现\nDotNetty.Buffers 是对内存缓冲区管理的封装\nDotNetty.Codes 是对编码器解码器的封装，包括一些基础基类的实现，我们在项目中自定义的协议，都要继承该项目的特定基类和实现\nDotNetty.Handlers 封装了常用的管道处理器，比如Tls编解码，超时机制，心跳检查，日志等，如果项目中没有用到可以不引用，不过一般都会用到\n\n开始一个项目\n新建一个解决方案\n新建一个项目\n到NuGet中引用 DotNetty.Common DotNetty.Transport DotNetty.Buffers\n开始编写实例代码\n\n编写测试程序回声测试应用程序编写 源码下载\n新建一个解决方案 名字叫NettyTest\n\n新建一个项目 名字叫EchoServer\n\n到NuGet中引用 DotNetty.Common DotNetty.Transport DotNetty.Buffers\n\n新建一个类 EchoServerHandler\nusing DotNetty.Buffers;using DotNetty.Transport.Channels;using System;using System.Text;namespace EchoServer&#123;    /// &lt;summary&gt;    /// 因为服务器只需要响应传入的消息，所以只需要实现ChannelHandlerAdapter就可以了    /// &lt;/summary&gt;    public class EchoServerHandler : ChannelHandlerAdapter    &#123;        /// &lt;summary&gt;        /// 每个传入消息都会调用        /// 处理传入的消息需要复写这个方法        /// &lt;/summary&gt;        /// &lt;param name=&quot;ctx&quot;&gt;&lt;/param&gt;        /// &lt;param name=&quot;msg&quot;&gt;&lt;/param&gt;        public override void ChannelRead(IChannelHandlerContext ctx, object msg)        &#123;            IByteBuffer message = msg as IByteBuffer;            Console.WriteLine(&quot;收到信息：&quot; + message.ToString(Encoding.UTF8));            ctx.WriteAsync(message);        &#125;        /// &lt;summary&gt;        /// 批量读取中的最后一条消息已经读取完成        /// &lt;/summary&gt;        /// &lt;param name=&quot;context&quot;&gt;&lt;/param&gt;        public override void ChannelReadComplete(IChannelHandlerContext context)        &#123;            context.Flush();        &#125;        /// &lt;summary&gt;        /// 发生异常        /// &lt;/summary&gt;        /// &lt;param name=&quot;context&quot;&gt;&lt;/param&gt;        /// &lt;param name=&quot;exception&quot;&gt;&lt;/param&gt;        public override void ExceptionCaught(IChannelHandlerContext context, Exception exception)        &#123;            Console.WriteLine(exception);            context.CloseAsync();        &#125;    &#125;&#125;\n\n上面的代码注释已经非常详细了，相信看注释你就能明白这个类大致干了些什么，但是突如其来的一个类还是有点难以理解，那么本着认真负责的精神我会再详细解释一下没有学过Netty的同学难以理解的点：\n\n问：EchoServerHandler 是干什么用的？回答：Netty帮我们封装了底层的通信过程让我们不需要再关心套接字等网络底层的问题，更加专注于处理业务，何为业务？就是数据来了之后我要怎么办，Handler就是一个处理数据的工厂，那么上面的Handler中我们做了什么事情呢？稍加分析就能发现，我们在接到消息之后打印在了控制台上，之后将消息再发送回去。\n问：WriteAsync 是在干什么？Flush 又是在干什么？答：由于是初学，不灌输太多，大家现在只需要知道数据写入之后并不会直接发出去，Flush的时候才会发出去。\n\n\n在自动生成的Program.cs中写入服务器引导程序。\nusing DotNetty.Transport.Bootstrapping;using DotNetty.Transport.Channels;using DotNetty.Transport.Channels.Sockets;using System;using System.Threading.Tasks;namespace EchoServer&#123;    public class Program    &#123;        static async Task RunServerAsync()        &#123;            IEventLoopGroup eventLoop;            eventLoop = new MultithreadEventLoopGroup();            try            &#123;                // 服务器引导程序                var bootstrap = new ServerBootstrap();                bootstrap.Group(eventLoop);                bootstrap.Channel&lt;TcpServerSocketChannel&gt;();                bootstrap.ChildHandler(new ActionChannelInitializer&lt;IChannel&gt;(channel =&gt;                &#123;                    IChannelPipeline pipeline = channel.Pipeline;                    pipeline.AddLast(new EchoServerHandler());                &#125;));                IChannel boundChannel = await bootstrap.BindAsync(3000);                Console.ReadLine();                await boundChannel.CloseAsync();            &#125;            catch (Exception ex)            &#123;                Console.WriteLine(ex);            &#125;            finally            &#123;                await eventLoop.ShutdownGracefullyAsync();            &#125;        &#125;        static void Main(string[] args) =&gt; RunServerAsync().Wait();    &#125;&#125;\n\n这个程序中同样有很多需要解释的，但是对于初学者来说，先明白这些概念就好了：\n\nbootstrap是启动引导的意思，Netty中的bootstrap的意思就是启动一个网络应用程序，那在启动之前我们肯定需要设置很多参数，bootstrap可以接收参数，引导用户启动Netty应用。\nEventLoopGroup 是一系列EventLoop的集合\nEventLoop 就对应了一个选择器（选择器看上一节的图）\n一个Channel都需要绑定到一个选择器（EventLoop）上\n每一个选择器（EventLoop）和一个线程绑定\n我们可以把Handler串起来处理数据，这个我们后面再讲，这里的做法是把Handler串到pipeline上。\n\n\n再新建一个项目取名叫EchoClient\n\n新建一个类 EchoClientHandler\nusing DotNetty.Buffers;using DotNetty.Transport.Channels;using System;using System.Text;namespace EchoClient&#123;    public class EchoClientHandler : SimpleChannelInboundHandler&lt;IByteBuffer&gt;    &#123;        /// &lt;summary&gt;        /// Read0是DotNetty特有的对于Read方法的封装        /// 封装实现了：        /// 1. 返回的message的泛型实现        /// 2. 丢弃非该指定泛型的信息        /// &lt;/summary&gt;        /// &lt;param name=&quot;ctx&quot;&gt;&lt;/param&gt;        /// &lt;param name=&quot;msg&quot;&gt;&lt;/param&gt;        protected override void ChannelRead0(IChannelHandlerContext ctx, IByteBuffer msg)        &#123;            if (msg != null)            &#123;                Console.WriteLine(&quot;Receive From Server:&quot; + msg.ToString(Encoding.UTF8));            &#125;            ctx.WriteAsync(Unpooled.CopiedBuffer(msg));        &#125;        public override void ChannelReadComplete(IChannelHandlerContext context)        &#123;            context.Flush();        &#125;        public override void ChannelActive(IChannelHandlerContext context)        &#123;            Console.WriteLine(&quot;发送Hello World&quot;);            context.WriteAndFlushAsync(Unpooled.CopiedBuffer(Encoding.UTF8.GetBytes(&quot;Hello World!&quot;)));        &#125;        public override void ExceptionCaught(IChannelHandlerContext context, Exception exception)        &#123;            Console.WriteLine(exception);            context.CloseAsync();        &#125;    &#125;&#125;\n\nHandler的编写方法于上面服务器的Handler基本一致，这里我们还是需要解释一些问题：\n\nSimpleChannelInboundHandler 继承自 ChannelHandlerAdapter，前者更强大的地方是对于资源的自动释放（这是一个伏笔）\nRead0方法在代码的注释中已经解释过了，有兴趣的同学可以看一下源码。这里我就不贴出来了\nctx.WriteAsync(Unpooled.CopiedBuffer(msg));如果这里直接将msg发送出去，大家就会发现，实验失败了，这是为什么呢？简单解释就是因为引用计数器机制，IByteBuffer只能使用一次，而在我们使用Read0方法接收这个消息的时候，这个消息的引用计数就被归零了，这时候我们再次使用就会报出异常，所以这里需要将源消息再复制一份。当然，如果你使用的Read方法则不会有这样的问题。原则上来说，我们不应该存储指向任何消息的引用供未来使用，因为这些引用都会自动失效（意思就是消息收到了处理完就丢掉，消息不应该被长久保存）。\n\n\n编写客户端引导程序\nusing DotNetty.Transport.Bootstrapping;using DotNetty.Transport.Channels;using DotNetty.Transport.Channels.Sockets;using System;using System.Net;using System.Threading.Tasks;namespace EchoClient&#123;    class Program    &#123;        static async Task RunClientAsync()        &#123;            var group = new MultithreadEventLoopGroup();            try            &#123;                var bootstrap = new Bootstrap();                bootstrap                    .Group(group)                    .Channel&lt;TcpSocketChannel&gt;()                    .Handler(new ActionChannelInitializer&lt;ISocketChannel&gt;(channel =&gt;                    &#123;                        IChannelPipeline pipeline = channel.Pipeline;                        pipeline.AddLast(new EchoClientHandler());                    &#125;));                IChannel clientChannel = await bootstrap.ConnectAsync(new IPEndPoint(IPAddress.Parse(&quot;10.10.10.158&quot;), 3000));                Console.ReadLine();                await clientChannel.CloseAsync();            &#125;            catch (Exception ex)            &#123;                Console.WriteLine(ex);            &#125;            finally            &#123;                await group.ShutdownGracefullyAsync();            &#125;        &#125;        static void Main(string[] args) =&gt; RunClientAsync().Wait();    &#125;&#125;\n\n写在最后项目的完整代码我放在了码云上，你可以点击这里可以下载。我相信很多完全没有接触过Netty的同学在跟着写完了第一个项目之后还是很懵，虽然解释了很多，但是还是感觉似懂非懂，这很正常。就如同我们写完HelloWorld之后，仍然会纠结一下static void Main(string[] args)为什么要这么写。我要说的是，只要坚持写完了第一个应用程序，你就是好样的，关于Netty我们还有很多很多要讲，相信你学了之后的知识以后，回过头来再看这个实例，会有恍然大悟的感觉。如果你坚持看完了文章并且敲了程序并且试验成功了，恭喜你，晚饭加个鸡腿，我们还有很多东西要学。\n","categories":["编程技术","DotNet","DotNetty教程"],"tags":["DotNetty"]},{"title":"DotNetty完全教程（五）","url":"/2019/10/31/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/DotNetty%E6%95%99%E7%A8%8B/DotNetty%E5%AE%8C%E5%85%A8%E6%95%99%E7%A8%8B%EF%BC%88%E4%BA%94%EF%BC%89/","content":"DotNetty完全教程（五）\nExcerptChannelHandler本篇文章着重介绍ChannelHandlerChannel的生命周期我们复习一下，Channel是Socket的抽象，可以被注册到一个EventLoop上，EventLoop相当于Selector，每一个EventLoop又有自己的处理线程。复习了这部分的知识，我们就知道在Channel的生命中，有以下这么几个关键的时间节点。ChannelHandler的生…\n\n版权声明：本文为博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。\nChannelHandler本篇文章着重介绍ChannelHandler\nChannel的生命周期我们复习一下，Channel是Socket的抽象，可以被注册到一个EventLoop上，EventLoop相当于Selector，每一个EventLoop又有自己的处理线程。复习了这部分的知识，我们就知道在Channel的生命中，有以下这么几个关键的时间节点。\nChannelHandler的生命周期我们复习一下，ChannelHandler是定义了如何处理数据的处理器，被串在ChannelPipeline中用于入站或者出站数据的处理。既然是处理Channel中的数据，就需要关注很多的时间节点，比如Channel被激活，比如，读取到了数据，所以，ChannelHandler不仅需要关心数据何时来，还需要关注Channel处于一个什么样的状态，所以ChannelHandler的生命周期如下：\n使用适配器类创建自己的Handler你可以使用 ChannelInboundHandlerAdapter 和 ChannelOutboundHandlerAdapter类作为自己的 ChannelHandler 的起始点。使用的时候我们只需要扩展使用这些适配器类，然后重新我们需要的方法即可。\n注意适配器类都有IsSharable属性，标识这个Hanlder能不能被添加到多个Pipeline中。\n","categories":["编程技术","DotNet","DotNetty教程"],"tags":["DotNetty"]},{"title":"DotNetty完全教程（八）","url":"/2019/10/31/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/DotNetty%E6%95%99%E7%A8%8B/DotNetty%E5%AE%8C%E5%85%A8%E6%95%99%E7%A8%8B%EF%BC%88%E5%85%AB%EF%BC%89/","content":"DotNetty完全教程（八）\nExcerptEventLoop介绍我们先回顾一下，EventLoop就是我们在最开始的示意图中的Selector，每个EventLoop和一个线程绑定，用于处理多个Channel。任务调度如果我们想实现延时任务的调度，比如连接成功5s之后发送一包数据，就可以用到EventLoop的计划任务ctx.Channel.EventLoop.Schedule(() &#x3D;&gt;{    Console.Wr…\n\n\n版权声明：本文为博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。\nEventLoop介绍我们先回顾一下，EventLoop就是我们在最开始的示意图中的Selector，每个EventLoop和一个线程绑定，用于处理多个Channel。\n任务调度\n如果我们想实现延时任务的调度，比如连接成功5s之后发送一包数据，就可以用到EventLoop的计划任务\nctx.Channel.EventLoop.Schedule(() =&gt;&#123;    Console.WriteLine(&quot;delay 1s&quot;);&#125;, new TimeSpan(1000));// 如果需要提前取消，可以调用Cancel方法IScheduledTask task = ctx.Channel.EventLoop.Schedule(() =&gt;&#123;    Console.WriteLine(&quot;delay 1s&quot;);&#125;, new TimeSpan(1000));tsak.Cancel();\n\n一个任务引发后，会判断当前是否在需要处理这个任务的EventLoop中（程序知道自己目前在执行哪个线程，线程又跟EventLoop对应），如果在就直接执行该任务，如果不在该任务中，则任务入队稍后处理\n\n永远不要把一个需要耗费长时间的任务放到EventLoop执行队列来执行，需要使用我们前面介绍的EventExecutor的方法。\n\n\nGroup许多Channel对应一个EventLoop，但是EventLoop能分配给她的Channel个数是有限的，要处理可以扩展的无数个Channel就需要EventLoopGroup。他们的结构关系如下图：我们之前讲过，Netty不仅能够完成NIO系统的搭建，也能通过一些简单的配置，变成OIO阻塞IO系统，阻塞IO的话，就不能多个Channel共享一个EventLoop了，就需要一个Channel分配一个EventLoop。总的来说，EventLoop跟线程的关系是不会改变的。\n需要注意的是：\n\n给Channel分配EventLoop的是EventLoopGroup。而他将尽量均衡的将Channel进行分配。\n\n","categories":["编程技术","DotNet","DotNetty教程"],"tags":["DotNetty"]},{"title":"DotNetty完全教程（六）","url":"/2019/10/31/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/DotNetty%E6%95%99%E7%A8%8B/DotNetty%E5%AE%8C%E5%85%A8%E6%95%99%E7%A8%8B%EF%BC%88%E5%85%AD%EF%BC%89/","content":"DotNetty完全教程（六）\nExcerpt资源管理目的在处理数据的过程中，我们需要确保没有任何的资源泄漏。这时候我们就得很关心资源管理。引用计数的处理使用完ByteBuf之后，需要调整其引用计数以确保资源的释放内存内漏探测Netty提供了ResourceLeakDetector来检测内存泄漏，因为其是采样检测的，所以相关开销并不大。泄露日志检测级别手动释放消息ReferenceCountUtil.SafeRelea…\n\n版权声明：本文为博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。\n资源管理目的在处理数据的过程中，我们需要确保没有任何的资源泄漏。这时候我们就得很关心资源管理。\n引用计数的处理使用完ByteBuf之后，需要调整其引用计数以确保资源的释放\n内存内漏探测Netty提供了ResourceLeakDetector来检测内存泄漏，因为其是采样检测的，所以相关开销并不大。\n\n泄露日志\n\n检测级别\n\n手动释放消息\nReferenceCountUtil.SafeRelease(this.Message);\n\n分析SimpleChannelInboundHandler\npublic override void ChannelRead(IChannelHandlerContext ctx, object msg)&#123;    bool release = true;    try    &#123;        if (this.AcceptInboundMessage(msg))        &#123;            I imsg = (I)msg;            this.ChannelRead0(ctx, imsg);        &#125;        else        &#123;            release = false;            ctx.FireChannelRead(msg);        &#125;    &#125;    finally    &#123;        if (autoRelease &amp;&amp; release)        &#123;            ReferenceCountUtil.Release(msg);        &#125;    &#125;&#125;\n\n由上面的源码可以看出，Read0事实上是Read的封装，区别就是Read0方法在调用的时候，消息一定是被释放了，这就是手动释放的例子。\n","categories":["编程技术","DotNet","DotNetty教程"],"tags":["DotNetty"]},{"title":"DotNetty完全教程（十一）","url":"/2019/10/31/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/DotNetty%E6%95%99%E7%A8%8B/DotNetty%E5%AE%8C%E5%85%A8%E6%95%99%E7%A8%8B%EF%BC%88%E5%8D%81%E4%B8%80%EF%BC%89/","content":"DotNetty完全教程（十一）\nExcerpt编码器和解码器定义编码器负责将应用程序可以识别的数据结构转化为可传输的数据流，解码器反之。对于应用程序来说，编码器操作出站数据，解码器操作入站数据。解码器和Handler解码器因为是处理入站数据的，所以继承了ChannelInBoundHandler.我们理解的时候可以认为解码器就是一种特殊的Handler，用于处理信息。解码器的类型ByteToMessageDecoderRepl…\n\n版权声明：本文为博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。\n编码器和解码器定义编码器负责将应用程序可以识别的数据结构转化为可传输的数据流，解码器反之。对于应用程序来说，编码器操作出站数据，解码器操作入站数据。\n解码器和Handler解码器因为是处理入站数据的，所以继承了ChannelInBoundHandler.我们理解的时候可以认为解码器就是一种特殊的Handler，用于处理信息。\n解码器的类型\nByteToMessageDecoder\nReplayingDecoder\nMessageToMessageDecoder\n\n解码器实例ByteToMessageDecoder\n// ByteToMessageDecoderpublic class ToIntDecoder : ByteToMessageDecoder&#123;    protected override void Decode(IChannelHandlerContext context, IByteBuffer input, List&lt;object&gt; output)    &#123;        if (input.ReadableBytes &gt;= 4) output.Add(input.ReadInt());    &#125;&#125;// 测试代码[Fact]public void TestIntDecoder()&#123;    IByteBuffer buf = Unpooled.Buffer();    for (int i = 0; i &lt; 8; i++)    &#123;        buf.WriteByte(i);    &#125;    // 构建Channel    EmbeddedChannel channel = new EmbeddedChannel(new ToIntDecoder());    // 测试    Assert.True(channel.WriteInbound(buf));    Assert.True(channel.Finish());    // 比如 0 1 2 3    // 3*2^0+2*2^8+1*2^16+0*2^24    Assert.Equal(66051, channel.ReadInbound&lt;int&gt;());&#125;\n\nReplayingDecoder\n// 不需要判断ReadableBytes的ReplayingDecoderpublic class ToIntDecoder2 : ReplayingDecoder&lt;int&gt;&#123;    public ToIntDecoder2(int initialState) : base(initialState)    &#123;    &#125;    protected override void Decode(IChannelHandlerContext context, IByteBuffer input, List&lt;object&gt; output)    &#123;        output.Add(input.ReadInt());    &#125;&#125;\n\nMessageToMessageDecoder\npublic class IntToStringDecoder : MessageToMessageDecoder&lt;int&gt;&#123;    protected override void Decode(IChannelHandlerContext context, int message, List&lt;object&gt; output)    &#123;        output.Add(message.ToString());    &#125;&#125;\n\n更多解码器\nLineBaseFrameDecoder 使用行尾控制符解析数据，可以把数据一行一行解析出来\nHttpObjectDecoder HTTP解码器\n\n编码器根据我们之前的知识可以轻易的推导出，Encoder继承了ChannelOutBoundHandler\n\nMessageToByteEncoder\nMessageToMessageEncoder\n\n编码器实例MessageToByteEncoder\npublic class ShortToByteEncoder : MessageToByteEncoder&lt;short&gt;&#123;    protected override void Encode(IChannelHandlerContext context, short message, IByteBuffer output)    &#123;        output.WriteShort(message);    &#125;&#125;\n\nMessageToMessageEncoder\npublic class IntToStringEncoder : MessageToMessageEncoder&lt;int&gt;&#123;    protected override void Encode(IChannelHandlerContext context, int message, List&lt;object&gt; output)    &#123;        output.Add(message.ToString());    &#125;&#125;\n\n编解码器MessageToMessageCodec,它拥有encode和decode两个方法，用于实现来回的转换数据，这种编解码器我们在后面实例的时候再举例说明。这种编解码器可以把数据的转换，逆转换过程封装，但是同时他的缺点是，不如分开写重用方便。那我们就会想了，既然如此的话，为什么我们不能把一个编码器，一个解码器结合起来，作为一个编解码器呢？这样的话，编码器解码器分别可以重用，结合出来的编解码器也可以方便的使用 CombinedChannelDuplexHandler 就可以实现这样的作用。\n// 提供结合的编解码器public class CombinedCodec : CombinedChannelDuplexHandler&lt;ToIntDecoder, ShortToByteEncoder&gt;&#123;&#125;\n","categories":["编程技术","DotNet","DotNetty教程"],"tags":["DotNetty"]},{"title":"DotNetty完全教程（十）","url":"/2019/10/31/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/DotNetty%E6%95%99%E7%A8%8B/DotNetty%E5%AE%8C%E5%85%A8%E6%95%99%E7%A8%8B%EF%BC%88%E5%8D%81%EF%BC%89/","content":"DotNetty完全教程（十）\nExcerpt单元测试EmbeddedChannel介绍EmbeddedChannel是专门为了测试ChannelHandler的传输。我们先看一下他的API用一张图来描述这样的一个模拟过程编写基于xUnit的单元测试新建一个xUnit工程 UnitTest新建一个用于测试EmbededChannel的工程 EmbededChannelTestEmbededChannelTest工程需要引用…\n\n版权声明：本文为博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。\n单元测试EmbeddedChannel介绍EmbeddedChannel是专门为了测试ChannelHandler的传输。我们先看一下他的API用一张图来描述这样的一个模拟过程\n编写基于xUnit的单元测试\n新建一个xUnit工程 UnitTest\n新建一个用于测试EmbededChannel的工程 EmbededChannelTest\nEmbededChannelTest工程需要引用DotNetty的类库，这里因为我们需要测试一个解码器，所以除了原先的Buffer Common Transport之外我们还需要引用Codecs\nxUnit工程需要引用EmbededChannelTest工程\n在EmbededChannelTest工程之下新建FixedLengthFrameDecoder待测试类\n\nusing DotNetty.Buffers;using DotNetty.Codecs;using DotNetty.Transport.Channels;using System;using System.Collections.Generic;using System.Text;namespace EmbededChannelTest&#123;    public class FixedLengthFrameDecoder : ByteToMessageDecoder    &#123;        private int _frameLength;        public FixedLengthFrameDecoder(int frameLength)        &#123;            if (frameLength &lt;= 0)            &#123;                throw new Exception(&quot;不合法的参数。&quot;);            &#125;            _frameLength = frameLength;        &#125;        protected override void Decode(IChannelHandlerContext context, IByteBuffer input, List&lt;object&gt; output)        &#123;            // 解码器实现固定的帧长度            while (input.ReadableBytes &gt;= _frameLength)            &#123;                IByteBuffer buf = input.ReadBytes(_frameLength);                output.Add(buf);            &#125;        &#125;    &#125;&#125;\n\n我们可以看到这个解码器将buffer中的字节流转化为每3个一帧。接下来我们需要编写测试类，我们在UnitTest工程下新建一个类，名字叫做UnitTester，编写如下代码：\nusing DotNetty.Buffers;using DotNetty.Transport.Channels.Embedded;using EmbededChannelTest;using System;using System.Collections.Generic;using System.Text;using Xunit;namespace UnitTest&#123;    public class UnitTester    &#123;        [Fact]        public void testFrameDecoder()        &#123;            IByteBuffer buf = Unpooled.Buffer();            for (int i = 0; i &lt; 9; i++)            &#123;                buf.WriteByte(i);            &#125;            IByteBuffer input = buf.Duplicate();            EmbeddedChannel channel = new EmbeddedChannel(new FixedLengthFrameDecoder(3));            // 写数据            // retain能够将buffer的引用计数加1，并且返回这个buffer本身            Assert.True(channel.WriteInbound(input.Retain()));            Assert.True(channel.Finish());            // 读数据            IByteBuffer read = channel.ReadInbound&lt;IByteBuffer&gt;();            Assert.Equal(buf.ReadSlice(3), read);            read.Release();            read = channel.ReadInbound&lt;IByteBuffer&gt;();            Assert.Equal(buf.ReadSlice(3), read);            read.Release();            read = channel.ReadInbound&lt;IByteBuffer&gt;();            Assert.Equal(buf.ReadSlice(3), read);            read.Release();            Assert.Null(channel.ReadInbound&lt;object&gt;());            buf.Release();        &#125;    &#125;&#125;\n\n编写完成之后直接右键点击运行测试即可。同理我们可以测试用于出站数据的Encoder，这里不贴代码了，感兴趣的可以去工程中自己看源码进行学习。\n","categories":["编程技术","DotNet","DotNetty教程"],"tags":["DotNetty"]},{"title":"DotNetty完全教程（四）","url":"/2019/10/31/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/DotNetty%E6%95%99%E7%A8%8B/DotNetty%E5%AE%8C%E5%85%A8%E6%95%99%E7%A8%8B%EF%BC%88%E5%9B%9B%EF%BC%89/","content":"DotNetty完全教程（四）\nExcerptByteBufferNetty中ByteBuffer的介绍Netty 的数据处理 API 通过两个组件暴露——abstract class ByteBuf 和 interfaceByteBufHolderDotNetty中有AbstractByteBuffer  IByteBuffer IByteBufferHolder优点：它可以被用户自定义的缓冲区类型扩展；通过内置的复合缓冲区…\n\n\nByteBufferNetty中ByteBuffer的介绍Netty 的数据处理 API 通过两个组件暴露——abstract class ByteBuf 和 interfaceByteBufHolder\nDotNetty中有AbstractByteBuffer IByteBuffer IByteBufferHolder\n优点：\n\n它可以被用户自定义的缓冲区类型扩展；\n通过内置的复合缓冲区类型实现了透明的零拷贝；\n容量可以按需增长（类似于 JDK 的 StringBuilder）；\n在读和写这两种模式之间切换不需要调用 ByteBuffer 的 flip()方法；\n读和写使用了不同的索引；\n支持方法的链式调用；\n支持引用计数；\n支持池化\n\n原理：每一个ByteBuf都有两个索引，读索引和写索引，read和write会移动索引，set和get不会引动索引。\n使用ByteBuf\n堆缓冲区(使用数组的方式展示和操作数据)\n\n使用支撑数组给ByteBuf提供快速的分配和释放的能力。适用于有遗留数据需要处理的情况。\npublic override void ChannelRead(IChannelHandlerContext ctx, object msg)&#123;    IByteBuffer message = msg as IByteBuffer;    // 检查是否有支撑数组    if (message.HasArray)    &#123;        // 获取数组        byte[] array = message.Array;        // 计算第一个字节的偏移        int offset = message.ArrayOffset + message.ReaderIndex;        // 获取可读字节数        int length = message.ReadableBytes;        // 调用方法，处理数据        HandleArray(array, offset, length);    &#125;    Console.WriteLine(&quot;收到信息：&quot; + message.ToString(Encoding.UTF8));    ctx.WriteAsync(message);&#125;\n\n\n直接缓冲区\n\npublic override void ChannelRead(IChannelHandlerContext ctx, object msg)&#123;    IByteBuffer message = msg as IByteBuffer;    if (message.HasArray)    &#123;        int length = message.ReadableBytes;        byte[] array = new byte[length];        message.GetBytes(message.ReaderIndex, array);        HandleArray(array, 0, length);    &#125;    Console.WriteLine(&quot;收到信息：&quot; + message.ToString(Encoding.UTF8));    ctx.WriteAsync(message);&#125;\n\n\nCompositeByteBuffer 复合缓冲区\n\n如果要发送的命令是由两个ByteBuf拼接构成的，那么就需要复合缓冲区，比如Http协议中一个数据流由头跟内容构成这样的逻辑。\npublic override void ChannelRead(IChannelHandlerContext ctx, object msg)&#123;    IByteBuffer message = msg as IByteBuffer;    // 创建一个复合缓冲区    CompositeByteBuffer messageBuf = Unpooled.CompositeBuffer();    // 创建两个ByteBuffer    IByteBuffer headBuf = Unpooled.CopiedBuffer(message);    IByteBuffer bodyBuf = Unpooled.CopiedBuffer(message);    // 添加到符合缓冲区中    messageBuf.AddComponents(headBuf, bodyBuf);    // 删除    messageBuf.RemoveComponent(0);    Console.WriteLine(&quot;收到信息：&quot; + message.ToString(Encoding.UTF8));    ctx.WriteAsync(message);&#125;\n\n字节级操作\n读取(不移动索引)\n\npublic override void ChannelRead(IChannelHandlerContext ctx, object msg)&#123;    IByteBuffer message = msg as IByteBuffer;    for (int i = 0; i &lt; message.Capacity; i++)    &#123;        // 如此使用索引访问不会改变读索引也不会改变写索引        byte b = message.GetByte(i);        Console.WriteLine(b);    &#125;    Console.WriteLine(&quot;收到信息：&quot; + message.ToString(Encoding.UTF8));    ctx.WriteAsync(message);&#125;\n\n\n丢弃可丢弃字节所谓可丢弃字节就是调用read方法之后，readindex已经移动过了的区域，这段区域的字节称为可丢弃字节。\n\nmessage.DiscardReadBytes();\n\n只有在内存十分宝贵需要清理的时候再调用这个方法，随便调用有可能会造成内存的复制，降低效率。3. 读取所有可读字节（移动读索引）\nwhile (message.IsReadable())&#123;    Console.WriteLine(message.ReadByte());&#125;\n\n\n写入数据\n\n// 使用随机数填充可写区域while (message.WritableBytes &gt; 4)&#123;    message.WriteInt(new Random().Next(0, 100));&#125;\n\n\n管理索引\n\n\nMarkReaderIndex ResetReaderIndex 标记和恢复读索引\nMarkWriterIndex ResetWriterIndex 标记和恢复写索引\nSetReaderIndex(int) SetWriterIndex(int) 直接移动索引\nclear() 重置两个索引都为0，但是不会清除内容\n\n\n查找\n\n\nIndexOf()\n使用Processor\n\n// 查找\\rmessage.ForEachByte(ByteProcessor.FindCR);\n\n\n派生\n\n派生的意思是创建一个新的ByteBuffer，这个ByteBuf派生于其他的ByteBuf，派生出来的子ByteBuf具有自己的读写索引，但是本质上指向同一个对象，这样就导致了改变一个，另一个也会改变。\n\nduplicate()；\nslice()；\nslice(int, int)；\nUnpooled.unmodifiableBuffer(…)；\norder(ByteOrder)；\nreadSlice(int)。\n\n\n复制复制不同于派生，会复制出一个独立的ByteBuf，修改其中一个不会改变另一个。\n\n\ncopy\n\n\n释放\n\n// 显式丢弃消息ReferenceCountUtil.release(msg);\n\n\n增加引用计数防止释放\n\nReferenceCountUtil.retain(message)\n\n\n其他api\n\nByteBufHolder\n目的再数据处理的过程中不仅仅有字节数据内容本身，还会有一些附加信息，比如HTTP响应的状态码，Cookie等。给ByteBuf附加信息就要用到ByteBufHolder.\nAPI\n\n管理ByteBuffer\n按需分配 ByteBufAllocator注意分配是池化的，最大程度上降低分配和释放内存的开销。\n// 获取Allocator// 1IChannelHandlerContext ctx = null;IByteBufferAllocator allocator = ctx.Allocator;// 2IChannel channel = null;allocator = channel.Allocator;\n\n有两种ByteBufAllocator的实现：PooledByteBufAllocator和UnpooledByteBufAllocator，前者池化了ByteBuf的实例，极大限度的提升了性能减少了内存碎片。2. Unpooled缓冲区获取不到 ByteBufAllocator的引用的时候我们可以使用Unpooled工具类来操作ByteBuf。\n\nByteBufUtil这个类提供了一些通用的API，都是静态的辅助方法，例如hexdump方法可以以十六进制的方式打印ByteBuf的内容。还有equal方法判断bytebuf是否相等。\n\n引用计数\n目的\nByteBuf和ByteBufHolder都有计数的机制。引用计数都从1开始，如果计数大于0则不被释放，如果等于0就会被释放。它的目的是为了支持池化的实现，降低了内存分配的开销。\n\n异常\n如果访问一个计数为0的对象就会引发IllegalReferenceCountException。\n\n\n","categories":["编程技术","DotNet","DotNetty教程"],"tags":["DotNetty"]},{"title":"DotNetty系列三：编码解码器,IdleStateHandler心跳机制","url":"/2019/10/31/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/DotNetty%E6%95%99%E7%A8%8B/DotNetty%E7%B3%BB%E5%88%97%E4%B8%89%EF%BC%9A%E7%BC%96%E7%A0%81%E8%A7%A3%E7%A0%81%E5%99%A8,IdleStateHandler%E5%BF%83%E8%B7%B3%E6%9C%BA%E5%88%B6/","content":"DotNetty系列三：编码解码器,IdleStateHandler心跳机制\nExcerpt在上一节基础上，实现编码解码器。1.创建一个类库项目。用于实现编码解码器。编码器：    public class CommonServerEncoder : MessageToByteEncoder&lt;string&gt;    {        protected override void Encode(IChannelHandlerContext context, s…\n\n\n在上一节基础上，实现编码解码器。\n1.创建一个类库项目。用于实现编码解码器。\n编码器：\npublic class CommonServerEncoder : MessageToByteEncoder&lt;string&gt;    &#123;    protected override void Encode(IChannelHandlerContext context, string message, IByteBuffer output)            &#123;        byte[] messageBytes = Encoding.UTF8.GetBytes(message);                    IByteBuffer initialMessage = Unpooled.Buffer(messageBytes.Length);                    initialMessage.WriteBytes(messageBytes);                    output.WriteBytes(initialMessage);            &#125;    &#125;public class CommonClientEncoder : MessageToByteEncoder&lt;string&gt;    &#123;    protected override void Encode(IChannelHandlerContext context, string message, IByteBuffer output)            &#123;        byte[] messageBytes = Encoding.UTF8.GetBytes(message);                    IByteBuffer initialMessage = Unpooled.Buffer(messageBytes.Length);                    initialMessage.WriteBytes(messageBytes);                    output.WriteBytes(initialMessage);            &#125;    &#125;\n\n解码器：\npublic class CommonServerDecoder : ByteToMessageDecoder    &#123;    protected override void Decode(IChannelHandlerContext context, IByteBuffer input, List&lt;object&gt; output)            &#123;        byte[] array = new byte[input.ReadableBytes];                    input.GetBytes(input.ReaderIndex, array, 0, input.ReadableBytes);                    input.Clear();                    output.Add(array);            &#125;    &#125;public class CommonClientDecoder : ByteToMessageDecoder    &#123;    protected override void Decode(IChannelHandlerContext context, IByteBuffer input, List&lt;object&gt; output)            &#123;        byte[] array = new byte[input.ReadableBytes];                    input.GetBytes(input.ReaderIndex, array, 0, input.ReadableBytes);                    input.Clear();                    output.Add(array);            &#125;    &#125;\n\n2.服务端里添加：\n                        &#x2F;&#x2F;配置编码解码器                        pipeline.AddLast(new CommonServerEncoder());                        pipeline.AddLast(new CommonServerDecoder());\n客户端里添加：\n                        &#x2F;&#x2F;配置编码解码器                        pipeline.AddLast(new CommonClientEncoder());                        pipeline.AddLast(new CommonClientDecoder());\n3.服务端接收和发送：\npublic override void ChannelRead(IChannelHandlerContext context, object message)        &#123;    if (message is byte[] o)                &#123;                        Console.WriteLine($&quot;解码器方式，从客户端接收:&#123;Encoding.UTF8.GetString(o)&#125;:&#123;DateTime.Now&#125;&quot;);               &#125;    string msg = &quot;服务端从客户端接收到内容后返回，我是服务端&quot;;                context.WriteAsync(msg);        &#125;\n\n客户端接收和发送：\npublic override void ChannelActive(IChannelHandlerContext context)        &#123;               Console.WriteLine(&quot;我是客户端.&quot;);               Console.WriteLine($&quot;连接至服务端&#123;context&#125;.&quot;);    string message = &quot;客户端1&quot;;                context.WriteAndFlushAsync(message);        &#125;public override void ChannelRead(IChannelHandlerContext context, object message)        &#123;    if (message is byte[] o)                &#123;                        Console.WriteLine($&quot;解码器方式，从服务端接收:&#123;Encoding.UTF8.GetString(o)&#125;:&#123;DateTime.Now&#125;&quot;);                &#125;        &#125;\n\n实现了上一节一样的效果。\n4.IdleStateHandler心跳机制:\n4.1服务端添加IdleStateHandler心跳检测处理器,添加自定义处理Handler类实现userEventTriggered()方法作为超时事件的逻辑处理.\nIdleStateHandler心跳检测每十五秒进行一次读检测，如果十五秒内ChannelRead()方法未被调用则触发一次userEventTrigger()方法.\n                        &#x2F;&#x2F; IdleStateHandler 心跳                        &#x2F;&#x2F;服务端为读IDLE                        pipeline.AddLast(new IdleStateHandler(15, 0, 0));&#x2F;&#x2F;第一个参数为读，第二个为写，第三个为读写全部\n4.2服务端Handler重载UserEventTriggered：\nprivate int lossConnectCount = 0;public override void UserEventTriggered(IChannelHandlerContext context, object evt)        &#123;                Console.WriteLine(&quot;已经15秒未收到客户端的消息了！&quot;);    if (evt is IdleStateEvent eventState)                &#123;        if (eventState.State == IdleState.ReaderIdle)                       &#123;                               lossConnectCount++;if (lossConnectCount &gt; 2)                                &#123;                                        Console.WriteLine(&quot;关闭这个不活跃通道！&quot;);                                        context.CloseAsync();                               &#125;                &#125;                &#125;    else                &#123;        base.UserEventTriggered(context, evt);                &#125;        &#125;\n\n接收部分改为判断心跳：\npublic override void ChannelRead(IChannelHandlerContext context, object message)        &#123;    if (message is byte[] o)                &#123;                        Console.WriteLine($&quot;解码器方式，从客户端接收:&#123;Encoding.UTF8.GetString(o)&#125;:&#123;DateTime.Now&#125;&quot;);        if (Encoding.UTF8.GetString(o).Contains(&quot;biubiu:&quot;))                        &#123;            string temp = &quot;服务端接收到心跳连接&quot;;                                context.WriteAsync(temp);return;                        &#125;                &#125;    string msg = &quot;服务端从客户端接收到内容后返回，我是服务端&quot;;                context.WriteAsync(msg);       &#125;\n\n4.3客户端添加IdleStateHandler心跳检测处理器，并添加自定义处理Handler类实现userEventTriggered()方法作为超时事件的逻辑处理；\n设定IdleStateHandler心跳检测每十秒进行一次写检测，如果十秒内write()方法未被调用则触发一次userEventTrigger()方法，实现客户端每十秒向服务端发送一次消息；\n                        &#x2F;&#x2F; IdleStateHandler 心跳                        &#x2F;&#x2F;客户端为写IDLE                        pipeline.AddLast(new IdleStateHandler(0, 10, 0));&#x2F;&#x2F;第一个参数为读，第二个为写，第三个为读写全部\n4.4客户端Handler重载UserEventTriggered：\npublic override void UserEventTriggered(IChannelHandlerContext context, object evt)        &#123;               Console.WriteLine(&quot;客户端循环心跳监测发送: &quot; + DateTime.Now);    if (evt is IdleStateEvent eventState)                &#123;        if (eventState.State == IdleState.WriterIdle)                        &#123;                                context.WriteAndFlushAsync($&quot;biubiu:&#123;DateTime.Now&#125;&quot;);                 &#125;               &#125;       &#125;\n\n4.5实现效果：\n5.群发：将客户端上下线通知，群发至所有客户端。只在服务端修改\nstatic volatile IChannelGroup groups;public override void HandlerAdded(IChannelHandlerContext context)        &#123;                Console.WriteLine($&quot;客户端&#123;context&#125;上线.&quot;);                                                                              base.HandlerAdded(context);                IChannelGroup g = groups;if (g == null)                &#123;        lock (this)         &#123;            if (groups == null)                                &#123;                                        g = groups = new DefaultChannelGroup(context.Executor);            &#125;                       &#125;                &#125;               g.Add(context.Channel);                groups.WriteAndFlushAsync($&quot;欢迎&#123;context.Channel.RemoteAddress&#125;加入.&quot;);        &#125;public override void HandlerRemoved(IChannelHandlerContext context)        &#123;                Console.WriteLine($&quot;客户端&#123;context&#125;下线.&quot;);    base.HandlerRemoved(context);                groups.Remove(context.Channel);                groups.WriteAndFlushAsync($&quot;恭送&#123;context.Channel.RemoteAddress&#125;离开.&quot;);       &#125;\n\n实现效果：\n\n项目下载地址：项目下载\n","categories":["编程技术","DotNet","DotNetty教程"],"tags":["DotNetty"]},{"title":"WPF中Binding使用StringFormat格式化字符串","url":"/2025/02/11/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/WPF/WPF%E4%B8%ADBinding%E4%BD%BF%E7%94%A8StringFormat%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%AD%97%E7%AC%A6%E4%B8%B2/","content":"货币格式&lt;!-- 默认保留两位小数 输出： $12.34 --&gt;&lt;TextBlock Text=&quot;&#123;Binding Price, StringFormat=&#123;&#125;&#123;0:C&#125;&#125;&quot; /&gt;&lt;!-- 保留一位小数 输出: $123.4 --&gt;&lt;TextBlock Text=&quot;&#123;Binding Price, StringFormat=&#123;&#125;&#123;0:C1&#125;&#125;&quot; /&gt;\n\n\n固定文字&lt;!-- 固定前缀 输出: 单价：$12.34 --&gt;&lt;TextBlock Text=&quot;&#123;Binding Price, StringFormat=单价: &#123;0:C&#125;&#125;&quot; /&gt;&lt;!-- 固定后缀 输出： 12.345元 --&gt;&lt;TextBlock Text=&quot;&#123;Binding Price, StringFormat=&#123;&#125;&#123;0&#125;元&#125;&quot; /&gt;\n\n数字格式化&lt;!-- 固定位数，仅支持整形 输出: 086723 --&gt;&lt;TextBlock Text=&quot;&#123;Binding Total, StringFormat=&#123;&#125;&#123;0:D6&#125;&#125;&quot; /&gt;&lt;!-- 固定小数点后位数 输出: 8234.9354 --&gt;&lt;TextBlock Text=&quot;&#123;Binding Total, StringFormat=&#123;&#125;&#123;0:F4&#125;&#125;&quot; /&gt;&lt;!-- 使用用分割符并指定小数点后位数 输出: 8234.933 --&gt;&lt;TextBlock Text=&quot;&#123;Binding Total, StringFormat=&#123;&#125;&#123;0:N3&#125;&#125;&quot; /&gt;&lt;!-- 格式化百分比 输出: 78.9%--&gt;&lt;TextBlock Text=&quot;&#123;Binding Persent, StringFormat=&#123;&#125;&#123;0:P1&#125;&#125;&quot; /&gt;\n\n占位符&lt;!-- 输出: 0123.46 --&gt;&lt;TextBox Text=&quot;&#123;Binding Price, StringFormat=&#123;&#125;&#123;0:0000.00&#125;&#125;&quot; /&gt; &lt;!-- 输出: 123.46 --&gt;&lt;TextBox Text=&quot;&#123;Binding Price, StringFormat=&#123;&#125;&#123;0:####.##&#125;&#125;&quot; /&gt; \n\n时间日期&lt;!-- 输出: 5/4/2015 --&gt;&lt;TextBox Text=&quot;&#123;Binding DateTimeNow, StringFormat=&#123;&#125;&#123;0:d&#125;&#125;&quot; /&gt; &lt;!-- 输出: Monday, May 04, 2015 --&gt;&lt;TextBox Text=&quot;&#123;Binding DateTimeNow, StringFormat=&#123;&#125;&#123;0:D&#125;&#125;&quot; /&gt;&lt;!-- 输出: Monday, May 04, 2015 5:46 PM --&gt;&lt;TextBox Text=&quot;&#123;Binding DateTimeNow, StringFormat=&#123;&#125;&#123;0:f&#125;&#125;&quot; /&gt;&lt;!-- 输出: Monday, May 04, 2015 5:46:56 PM --&gt;&lt;TextBox Text=&quot;&#123;Binding DateTimeNow, StringFormat=&#123;&#125;&#123;0:F&#125;&#125;&quot; /&gt;&lt;!-- 输出: 5/4/2015 5:46 PM --&gt;&lt;TextBox Text=&quot;&#123;Binding DateTimeNow, StringFormat=&#123;&#125;&#123;0:g&#125;&#125;&quot; /&gt;&lt;!-- 输出: 5/4/2015 5:46:56 PM --&gt;&lt;TextBox Text=&quot;&#123;Binding DateTimeNow, StringFormat=&#123;&#125;&#123;0:G&#125;&#125;&quot; /&gt;&lt;!-- 输出: May 04 --&gt;&lt;TextBox Text=&quot;&#123;Binding DateTimeNow, StringFormat=&#123;&#125;&#123;0:m&#125;&#125;&quot; /&gt;&lt;!-- 输出: May 04 --&gt;&lt;TextBox Text=&quot;&#123;Binding DateTimeNow, StringFormat=&#123;&#125;&#123;0:M&#125;&#125;&quot; /&gt;&lt;!-- 输出: 5:46 PM --&gt;&lt;TextBox Text=&quot;&#123;Binding DateTimeNow, StringFormat=&#123;&#125;&#123;0:t&#125;&#125;&quot; /&gt;&lt;!-- 输出: 5:46:56 PM --&gt;&lt;TextBox Text=&quot;&#123;Binding DateTimeNow, StringFormat=&#123;&#125;&#123;0:T&#125;&#125;&quot; /&gt;&lt;!-- 输出: 2015年05月04日 --&gt;&lt;TextBox Text=&quot;&#123;Binding DateTimeNow, StringFormat=&#123;&#125;&#123;0:yyyy年MM月dd日&#125;&#125;&quot; /&gt;&lt;!-- 输出: 2015-05-04 --&gt;&lt;TextBox Text=&quot;&#123;Binding DateTimeNow, StringFormat=&#123;&#125;&#123;0:yyyy-MM-dd&#125;&#125;&quot; /&gt;&lt;!-- 输出: 2015-05-04 17:46 --&gt;&lt;TextBox Text=&quot;&#123;Binding DateTimeNow, StringFormat=&#123;&#125;&#123;0:yyyy-MM-dd HH:mm&#125;&#125;&quot; /&gt;&lt;!-- 输出: 2015-05-04 17:46:56 --&gt;&lt;TextBox Text=&quot;&#123;Binding DateTimeNow, StringFormat=&#123;&#125;&#123;0:yyyy-MM-dd HH:mm:ss&#125;&#125;&quot; /&gt;\n\n多重绑定&lt;!--\\a  &amp;#x07;  BEL\\b  &amp;#x08;  BS - Backspace\\f  &amp;#x0c;  FF - Formfeed\\n  &amp;#x0a;  LF, NL - Linefeed, New Line\\r  &amp;#x0d;  CR - Carriage return\\t  &amp;#x09;  HT - Tab, Horizontal Tabelator\\v  &amp;#x0b;  VT - Vertical Tabelator --&gt;&lt;TextBlock.Text&gt;\t&lt;MultiBinding StringFormat=&quot;姓名: &#123;0&#125;&amp;#x09;&#123;1&#125;&quot;&gt;\t\t&lt;Binding Path=&quot;FirstName&quot; /&gt;\t\t&lt;Binding Path=&quot;LastName&quot; /&gt; \t&lt;/MultiBinding&gt;&lt;/TextBlock.Text&gt;","categories":["编程技术","DotNet","WPF"],"tags":["WPF","StringFormat"]},{"title":"WPF 数据校验","url":"/2017/02/12/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/WPF/WPF%E6%95%B0%E6%8D%AE%E6%A0%A1%E9%AA%8C/","content":"只要是有表单存在，那么就有可能有对数据的校验需求。如：判断是否为整数、判断电子邮件格式等等。\nWPF采用一种全新的方式 - Binding，来实现前台显示与后台数据进行交互，当然数据校验方式也不一样了。\n本专题全面介绍一下WPF中4种Validate方法，帮助你了解如何在WPF中对binding的数据进行校验，并处理错误显示。\n一、简介正常情况下，只要是绑定过程中出现异常或者在converter中出现异常，都会造成绑定失败。\n但是WPF不会出现任何异常，只会显示一片空白（当然有些Converter中的异常会造成程序崩溃）。\n这是因为默认情况下，Binding.ValidatesOnException为false，所以WPF忽视了这些绑定错误。\n但是如果我们把Binding.ValidatesOnException为true，那么WPF会对错误做出以下反应：\n\n设置绑定元素的附加属性 Validation.HasError为true（如TextBox，如果Text被绑定，并出现错误）。\n创建一个包含错误详细信息（如抛出的Exception对象）的ValidationError对象。\n将上面产生的对象添加到绑定对象的Validation.Errors附加属性当中。\n如果Binding.NotifyOnValidationError是true，那么绑定元素的附加属性中的Validation.Error附加事件将被触发。（这是一个冒泡事件）\n\n我们的Binding对象，维护着一个ValidationRule的集合，当设置ValidatesOnException为true时，\n默认会添加一个ExceptionValidationRule到这个集合当中。\nPS：对于绑定的校验只在Binding.Mode 为TwoWay和OneWayToSource才有效，\n即当需要从target控件将值传到source属性时，很容易理解，当你的值不需要被别人使用时，就很可能校验也没必要。\n二、四种实现方法1、在Setter方法中进行判断直接在Setter方法中，对value进行校验，如果不符合规则，那么就抛出异常。然后修改XAML不忽视异常。\npublic class PersonValidateInSetter : ObservableObject    &#123; private string name; private int age; public string Name        &#123; get   &#123;  return this.name;   &#125; set &#123; if (string.IsNullOrWhiteSpace(value))                &#123; throw new ArgumentException(&quot;Name cannot be empty!&quot;);                &#125; if (value.Length &lt; 4)                &#123; throw new ArgumentException(&quot;Name must have more than 4 char!&quot;);                &#125; this.name = value; this.OnPropertyChanged(() =&gt; this.Name);            &#125;        &#125; public int Age        &#123; get &#123; return this.age;  &#125; set &#123; if (value &lt; 18)                &#123; throw new ArgumentException(&quot;You must be an adult!&quot;);                &#125; this.age = value; this.OnPropertyChanged(() =&gt; this.Age);            &#125;        &#125;    &#125;\n\n&lt;Grid DataContext=&quot;&#123;Binding PersonValidateInSetter&#125;&quot;&gt;               &lt;Grid.RowDefinitions&gt;                   &lt;RowDefinition /&gt;                   &lt;RowDefinition /&gt;               &lt;/Grid.RowDefinitions&gt;               &lt;Grid.ColumnDefinitions&gt;                   &lt;ColumnDefinition Width\\=&quot;Auto&quot; /&gt;                   &lt;ColumnDefinition /&gt;               &lt;/Grid.ColumnDefinitions&gt;               &lt;TextBlock Text=&quot;Name:&quot; /&gt;               &lt;TextBox Grid.Column=&quot;1&quot; Margin=&quot;1&quot; Text=&quot;&#123;Binding Name,                                       ValidatesOnExceptions=True,                                       UpdateSourceTrigger=PropertyChanged&#125;&quot; /&gt;               &lt;TextBlock Grid.Row=&quot;1&quot; Text=&quot;Age:&quot; /&gt;               &lt;TextBox Grid.Row=&quot;1&quot; Grid.Column=&quot;1&quot; Margin=&quot;1&quot; Text\\=&quot;&#123;Binding Age,                                       ValidatesOnExceptions=True,                                       UpdateSourceTrigger=PropertyChanged&#125;&quot; /&gt;           &lt;/Grid&gt;           \n\n当输入的值，在setter方法中校验时出现错误，就会出现一个红色的错误框。\n关键代码：ValidatesOnExceptions=True, UpdateSourceTrigger=PropertyChanged。\n注意: 这种方式有一个BUG，首次加载时不会对默认数据进行检验。\n2、继承IDataErrorInfo接口使Model对象继承IDataErrorInfo接口，并实现一个索引进行校验。如果索引返回空表示没有错误，如果返回不为空，\n表示有错误。另外一个Erro属性，但是在WPF中没有被用到。\npublic class PersonDerivedFromIDataErrorInfo : ObservableObject, IDataErrorInfo    &#123; private string name; private int age; public string Name        &#123; get &#123; return this.name;            &#125; set &#123; this.name = value; this.OnPropertyChanged(() =&gt; this.Name);            &#125;        &#125; public int Age        &#123; get &#123; return this.age;            &#125; set &#123; this.age = value; this.OnPropertyChanged(() =&gt; this.Age);            &#125;        &#125; // never called by WPF        public string Error        &#123; get &#123; return null;            &#125;        &#125; public string this\\[string propertyName\\]        &#123; get &#123; switch (propertyName)                &#123; case &quot;Name&quot;: if (string.IsNullOrWhiteSpace(this.Name))                        &#123; return &quot;Name cannot be empty!&quot;;                        &#125; if (this.Name.Length &lt; 4)                        &#123; return &quot;Name must have more than 4 char!&quot;;                        &#125; break; case &quot;Age&quot;: if (this.Age &lt; 18)                        &#123; return &quot;You must be an adult!&quot;;                        &#125; break;                &#125; return null;            &#125;        &#125;    &#125;\n\n&lt;Grid  DataContext=&quot;&#123;Binding PersonDerivedFromIDataErrorInfo&#125;&quot;\\&gt;                &lt;Grid.RowDefinitions\\&gt;                    &lt;RowDefinition /&gt;                    &lt;RowDefinition /&gt;                &lt;/Grid.RowDefinitions\\&gt;                &lt;Grid.ColumnDefinitions\\&gt;                    &lt;ColumnDefinition Width\\=&quot;Auto&quot; /&gt;                    &lt;ColumnDefinition /&gt;                &lt;/Grid.ColumnDefinitions\\&gt;                &lt;TextBlock Text\\=&quot;Name:&quot; /&gt;                &lt;TextBox Grid.Column\\=&quot;1&quot; Margin\\=&quot;1&quot; Text\\=&quot;&#123;Binding Name,                                        NotifyOnValidationError=True,                                        ValidatesOnDataErrors=True,                                        UpdateSourceTrigger=PropertyChanged&#125;&quot; /&gt;                &lt;TextBlock Grid.Row\\=&quot;1&quot; Text\\=&quot;Age:&quot; /&gt;                &lt;TextBox Grid.Row\\=&quot;1&quot; Grid.Column\\=&quot;1&quot; Margin\\=&quot;1&quot; Text\\=&quot;&#123;Binding Age,                                        NotifyOnValidationError=True,                                        ValidatesOnDataErrors=True,                                        UpdateSourceTrigger=PropertyChanged&#125;&quot; /&gt;\n\n\nPS：这种方式，没有了第一种方法的BUG，但是相对很麻烦，既需要继承接口，又需要添加一个索引，如果遗留代码，那么这种方式就不太好。\n3、自定义校验规则一个数据对象或许不能包含一个应用要求的所有不同验证规则，但是通过自定义验证规则就可以解决这个问题。\n在需要的地方，添加我们创建的规则，并进行检测。\n通过继承ValidationRule抽象类，并实现Validate方法，并添加到绑定元素的Binding.ValidationRules中。\npublic class MinAgeValidation : ValidationRule    &#123; public int MinAge &#123; get; set; &#125; public override ValidationResult Validate(object value, CultureInfo cultureInfo)        &#123;            ValidationResult result \\= null; if (value != null)            &#123; int age; if (int.TryParse(value.ToString(), out age))                &#123; if (age &lt; this.MinAge)                    &#123;                        result \\= new ValidationResult(false, &quot;Age must large than &quot; + this.MinAge.ToString(CultureInfo.InvariantCulture));                    &#125;                &#125; else &#123;                    result \\= new ValidationResult(false, &quot;Age must be a number!&quot;);                &#125;            &#125; else &#123;                result \\= new ValidationResult(false, &quot;Age must not be null!&quot;);            &#125; return new ValidationResult(true, null);        &#125;    &#125;\n\n&lt;Grid\\&gt;                &lt;Grid.RowDefinitions\\&gt;                    &lt;RowDefinition /&gt;                    &lt;RowDefinition /&gt;                &lt;/Grid.RowDefinitions\\&gt;                &lt;Grid.ColumnDefinitions\\&gt;                    &lt;ColumnDefinition Width\\=&quot;Auto&quot; /&gt;                    &lt;ColumnDefinition /&gt;                &lt;/Grid.ColumnDefinitions\\&gt;                &lt;TextBlock Text\\=&quot;Name:&quot; /&gt;                &lt;TextBox Grid.Column\\=&quot;1&quot; Margin\\=&quot;1&quot; Text\\=&quot;&#123;Binding Name&#125;&quot;\\&gt;                &lt;/TextBox\\&gt;                &lt;TextBlock Grid.Row\\=&quot;1&quot; Text\\=&quot;Age:&quot; /&gt;                &lt;TextBox Grid.Row\\=&quot;1&quot; Grid.Column\\=&quot;1&quot; Margin\\=&quot;1&quot;\\&gt;                    &lt;TextBox.Text\\&gt;                        &lt;Binding Path\\=&quot;Age&quot; UpdateSourceTrigger\\=&quot;PropertyChanged&quot; ValidatesOnDataErrors\\=&quot;True&quot;\\&gt;                            &lt;Binding.ValidationRules\\&gt;                                &lt;validations:MinAgeValidation MinAge\\=&quot;18&quot; /&gt;                            &lt;/Binding.ValidationRules\\&gt;                        &lt;/Binding\\&gt;                    &lt;/TextBox.Text\\&gt;                &lt;/TextBox\\&gt;            &lt;/Grid\\&gt;\n\n这种方式，也会有第一种方法的BUG，暂时还不知道如何解决，但是这个能够灵活的实现校验，并且能传参数。\n效果图：![[WPF数据校验&#x2F;IMG-20250804110742687.png]]\n4、使用数据注解(特性方式)在System.ComponentModel.DataAnnotaions命名空间中定义了很多特性，\n它们可以被放置在属性前面，显示验证的具体需要。放置了这些特性之后，\n属性中的Setter方法就可以使用Validator静态类了，来用于验证数据。\npublic class PersonUseDataAnnotation : ObservableObject    &#123; private int age; private string name;        \\[Range(18, 120, ErrorMessage = &quot;Age must be a positive integer&quot;)\\] public int Age        &#123; get &#123; return this.age;            &#125; set &#123; this.ValidateProperty(value, &quot;Age&quot;); this.SetProperty(ref this.age, value, () =&gt; this.Age);            &#125;        &#125;        \\[Required(ErrorMessage \\= &quot;A name is required&quot;)\\]        \\[StringLength(100, MinimumLength = 3, ErrorMessage = &quot;Name must have at least 3 characters&quot;)\\] public string Name        &#123; get &#123; return this.name;            &#125; set &#123; this.ValidateProperty(value, &quot;Name&quot;); this.SetProperty(ref this.name, value, () =&gt; this.Name);            &#125;        &#125; protected void ValidateProperty&lt;T&gt;(T value, string propertyName)        &#123;            Validator.ValidateProperty(value,                new ValidationContext(this, null, null) &#123; MemberName = propertyName &#125;); &#125; ___&#125;___\n\n&lt;Grid\\&gt;                &lt;Grid.RowDefinitions\\&gt;                    &lt;RowDefinition /&gt;                    &lt;RowDefinition /&gt;                &lt;/Grid.RowDefinitions\\&gt;                &lt;Grid.ColumnDefinitions\\&gt;                    &lt;ColumnDefinition Width\\=&quot;Auto&quot; /&gt;                    &lt;ColumnDefinition /&gt;                &lt;/Grid.ColumnDefinitions\\&gt;                &lt;TextBlock Text\\=&quot;Name:&quot; /&gt;                &lt;TextBox Grid.Column\\=&quot;1&quot; Margin\\=&quot;1&quot; Text\\=&quot;&#123;Binding Name,                                        ValidatesOnExceptions=True,                                        UpdateSourceTrigger=PropertyChanged&#125;&quot; /&gt;                &lt;TextBlock Grid.Row\\=&quot;1&quot; Text\\=&quot;Age:&quot; /&gt;                &lt;TextBox Grid.Row\\=&quot;1&quot; Grid.Column\\=&quot;1&quot; Margin\\=&quot;1&quot; Text\\=&quot;&#123;Binding Age,                                        ValidatesOnExceptions=True,                                        UpdateSourceTrigger=PropertyChanged&#125;&quot; /&gt;            &lt;/Grid\\&gt;\n\n使用特性的方式，能够很自由的使用自定义的规则，而且在.Net4.5中新增了很多特性，可以很方便的对数据进行校验。\n例如：EmailAddress, Phone, and Url等。\n三、自定义错误显示模板在上面的例子中，我们可以看到当出现验证不正确时，绑定控件会被一圈红色错误线包裹住。\n这种方式一般不能够正确的展示出，错误的原因等信息，所以有可能需要自己的错误显示方式。\n前面，我们已经讲过了。当在检测过程中，出现错误时，WPF会把错误信息封装为一个ValidationError对象，\n并添加到Validation.Errors中，所以我们可以取出错误详细信息，并显示出来。\n1、为控件创建ErrorTemplate下面就是一个简单的例子，每次都把错误信息以红色展示在空间上面。这里的AdornedElementPlaceholder相当于\n控件的占位符，表示控件的真实位置。这个例子是在书上直接拿过来的，只能做基本展示用。\n&lt;ControlTemplate x:Key\\=&quot;ErrorTemplate&quot;\\&gt;            &lt;Border BorderBrush\\=&quot;Red&quot; BorderThickness\\=&quot;2&quot;\\&gt;                &lt;Grid\\&gt;                    &lt;AdornedElementPlaceholder x:Name\\=&quot;\\_el&quot; /&gt;                    &lt;TextBlock Margin\\=&quot;0,0,6,0&quot; HorizontalAlignment\\=&quot;Right&quot; VerticalAlignment\\=&quot;Center&quot; Foreground\\=&quot;Red&quot; Text\\=&quot;&#123;Binding \\[0\\].ErrorContent&#125;&quot; /&gt;                &lt;/Grid\\&gt;            &lt;/Border\\&gt;        &lt;/ControlTemplate\\&gt;\n\n&lt;TextBox x:Name\\=&quot;AgeTextBox&quot; Grid.Row\\=&quot;1&quot; Grid.Column\\=&quot;1&quot; Margin\\=&quot;1&quot; Validation.ErrorTemplate\\=&quot;&#123;StaticResource ErrorTemplate&#125;&quot; \\&gt;\n使用方式非常简单，将上面的模板作为逻辑资源加入项目中，然后像上面一样引用即可。\n效果图：\n![[WPF数据校验&#x2F;IMG-20250804110742879.png]]\n","categories":["编程技术","DotNet","WPF"],"tags":["WPF","数据校验"]},{"title":"WPF自定义行为Behavior，实现双击控件复制文本","url":"/2017/08/04/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/WPF/WPF%E8%87%AA%E5%AE%9A%E4%B9%89%E8%A1%8C%E4%B8%BABehavior%EF%BC%8C%E5%AE%9E%E7%8E%B0%E5%8F%8C%E5%87%BB%E6%8E%A7%E4%BB%B6%E5%A4%8D%E5%88%B6%E6%96%87%E6%9C%AC/","content":"WPF引用xmlns:i&#x3D;”clr-namespace:System.Windows.Interactivity;assembly&#x3D;System.Windows.Interactivity”后可以设置很多自定义的行为：\n       &lt;i:Interaction.Triggers\\&gt;\n            &lt;i:EventTrigger EventName\\=&quot;ValueChanged&quot;\\&gt;\n                &lt;i:InvokeCommandAction Command\\=&quot;&#123;Binding ValueChangedCommand&#125;&quot; /&gt;\n            &lt;/i:EventTrigger\\&gt;\n        &lt;/i:Interaction.Triggers\\&gt;\n\n&lt;UserControl.Resources&gt;        &lt;ControlTemplate x:Key=“trackThumb” TargetType=“{x:Type Slider}”&gt;            &lt;Border Background=“{TemplateBinding Background}” BorderBrush=“{TemplateBinding BorderBrush}” BorderThickness=“{TemplateBinding BorderThickness}”&gt;                &lt;Grid&gt;                    &lt;Track x:Name=“PART_Track”&gt;                        &lt;Track.Thumb&gt;                            &lt;Thumb Width=“10”&gt;                                &lt;i:Interaction.Triggers&gt;                                    &lt;i:EventTrigger EventName=“DragCompleted”&gt;                                        &lt;i:InvokeCommandAction Command=“{Binding ValueChangedCommand}” &#x2F;&gt;                                    &lt;&#x2F;i:EventTrigger&gt;                                &lt;&#x2F;i:Interaction.Triggers&gt;                            &lt;&#x2F;Thumb&gt;                        &lt;&#x2F;Track.Thumb&gt;                    &lt;&#x2F;Track&gt;                &lt;&#x2F;Grid&gt;            &lt;&#x2F;Border&gt;        &lt;&#x2F;ControlTemplate&gt;    &lt;&#x2F;UserControl.Resources&gt;\n当时当我们有一些自定义的需求时，需要自定义行为，例如给每个控件添加一个双击复制文本的行为。\n1. 定义行为\npublic class MouseDoubleClickCopyTextBehavior : Behavior {        &#x2F;&#x2F;&#x2F;         &#x2F;&#x2F;&#x2F; 需要复制的内容        &#x2F;&#x2F;&#x2F;         public string CopyText        { get { return (string)GetValue(CopyTextProperty); } set { SetValue(CopyTextProperty, value); }        } public static readonly DependencyProperty CopyTextProperty &#x3D; DependencyProperty.Register(“CopyText”, typeof(string), typeof(MouseDoubleClickCopyTextBehavior), new PropertyMetadata(null)); protected override void OnAttached()        { base.OnAttached();            AssociatedObject.PreviewMouseLeftButtonDown +&#x3D; AssociatedObject_PreviewMouseLeftButtonDown;        } protected override void OnDetaching()        { base.OnDetaching();            AssociatedObject.PreviewMouseLeftButtonDown -&#x3D; AssociatedObject_PreviewMouseLeftButtonDown;        } void AssociatedObject_PreviewMouseLeftButtonDown(object sender, MouseButtonEventArgs e)        { if (e.ClickCount &gt;&#x3D; 2)                Clipboard.SetDataObject(CopyText);        } \n\n控件绑定行为\n\n\n                \n                \n                    \n                        \n                            \n                                \n                                    \n                                      \n \n                                    \n                                \n                            \n                            \n                                \n                                    \n                                            \n                                        \n                                    \n                                \n                            \n                        \n                \n            \n","categories":["编程技术","DotNet","WPF"],"tags":["WPF","Behavior","行为"]},{"title":"Qt使用ONNX调用YOLOv8模型","url":"/2024/09/04/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Python/YOLOv8/Qt%E4%BD%BF%E7%94%A8ONNX%E8%B0%83%E7%94%A8YOLOv8%E6%A8%A1%E5%9E%8B/","content":"Qt配置onnx_runtime首先，onnx_runtime官方也给编译好的release版本，下载即可。但是在qt中配置有一个坑。在Qt Creator中正常添加外部库，但是你会发现构建会找不到onnxruntime.lib，这是如果你替换成全路径，即把注释的部分换成下面的lib路径，直接指明onnxruntime.lib。这时构建成功，可以include &lt;onnxruntime_cxx_api.h&gt;，但是在运行你会遇到应用程序无法启动。根据百度把onnxruntime.dll复制到.exe目录下。OK，启动成功。\nopencv读取视频流居中显示，随意拉伸。实现居中的逻辑：\n// 调整QImage的大小以匹配QLabel的大小 QPixmap scaledPixmap = QPixmap::fromImage(qimg).scaled(ui-&gt;Origin_Video-&gt;size(), Qt::KeepAspectRatio, Qt::FastTransformation);\n\n而在界面当中需要对窗口随意拉伸，这是就需要界面允许缩放。修改QLabel的属性：修改成minimum，并给定最小宽度和高度。（还不知道原因，等有空学习一下）\n最后opencv读取视频流并拉取每一帧显示在QLabel中，这里采用的是用一个Qtimer，定时去获取视频帧。\n// 创建定时器，每隔一定时间显示下一帧 timer = new QTimer(this); connect(timer, &amp;QTimer::timeout, this, &amp;MainWindow::showNextFrame); timer-&gt;start(33); // 设置帧率为30FPS，即每隔33毫秒显示一帧\n\n完整代码如下：\n// 在槽函数中处理视频的加载和显示 void MainWindow::on_actionvideo_triggered() &#123; camera-&gt;stop(); viewfinder-&gt;close(); QString curPath = QDir::homePath(); QString dlgTitle = &quot;选择视频文件&quot;; QString filter = &quot;视频文件(*.wmv *.mp4);;所有文件(*.*)&quot;; QString aFile = QFileDialog::getOpenFileName(this, dlgTitle, curPath, filter); if (aFile.isEmpty()) &#123; return; &#125; ui-&gt;dir_Edit-&gt;setText(aFile); currentSource = File; // 更新当前视频源为视频文件 displayVideo(); // 显示视频 &#125; // 根据当前视频源显示视频的函数 void MainWindow::displayVideo() &#123; if (currentSource == File) &#123; std::string video_path = ui-&gt;dir_Edit-&gt;text().toLocal8Bit().constData(); cap.open(video_path); if (!cap.isOpened()) &#123; qDebug() &lt;&lt; &quot;Error: Unable to open the video file&quot;; return; &#125; // 创建定时器，每隔一定时间显示下一帧 timer = new QTimer(this); connect(timer, &amp;QTimer::timeout, this, &amp;MainWindow::showNextFrame); timer-&gt;start(33); // 设置帧率为30FPS，即每隔33毫秒显示一帧 &#125; else if (currentSource == Camera) &#123; // 创建定时器，每隔一定时间显示下一帧 timer = new QTimer(this); connect(timer, &amp;QTimer::timeout, this, &amp;MainWindow::viewfinderchange); timer-&gt;start(33); // 设置帧率为30FPS，即每隔33毫秒显示一帧 // cameras = QCameraInfo::availableCameras(); //获取所有相机的列表 // camera = new QCamera(cameras[0]); //camera指向指定的摄像头 camera-&gt;setCaptureMode(QCamera::CaptureStillImage); //设定捕获模式 camera-&gt;setViewfinder(viewfinder); //设置取景器 camera-&gt;start(); &#125; &#125; // 显示下一帧的槽函数 void MainWindow::showNextFrame() &#123; cv::Mat frame; cap &gt;&gt; frame; // 从视频流中获取一帧 if (frame.empty()) &#123; cap.set(cv::CAP_PROP_POS_FRAMES, 0); // 如果视频结束，重新开始播放 cap &gt;&gt; frame; &#125; currentFrame = frame; // 保存当前帧 displayCurrentFrame(); // 显示当前帧 &#125; void MainWindow::displayCurrentFrame() &#123; // 将OpenCV帧转换为QImage QImage qimg(currentFrame.data, currentFrame.cols, currentFrame.rows, currentFrame.step, QImage::Format_RGB888); qimg = qimg.rgbSwapped(); // 将格式从BGR转换为RGB // 调整QImage的大小以匹配QLabel的大小 QPixmap scaledPixmap = QPixmap::fromImage(qimg).scaled(ui-&gt;Origin_Video-&gt;size(), Qt::KeepAspectRatio, Qt::FastTransformation); // 将调整大小后的图像居中显示在QLabel中 centerImageInLabel(ui-&gt;Origin_Video, scaledPixmap); &#125;\n\nQCamra居中显示，随意拉伸QCamera其实同理，中间拉伸也用了一个QTimer定时获取QLabel的size。QCamera的使用包括初始化一个camera和设置取景器viewfinder，viewfinder的作用就是控制图像在空间中的展示。\nvoid MainWindow::on_actioncamera_triggered() &#123; cameras = QCameraInfo::availableCameras(); //获取所有相机的列表 //qDebug() &lt;&lt; &quot;this is camera: &quot;; if (cameras.count() &gt; 0) &#123; for(const QCameraInfo &amp;cameraInfo:cameras) &#123; qDebug() &lt;&lt; cameraInfo.description(); &#125; camera = new QCamera(cameras.at(0)); //初始化实例化一个相机对象 &#125; //设置取景器 viewfinder = new QCameraViewfinder(ui-&gt;Origin_Video); camera-&gt;setViewfinder(viewfinder); centerCameraViewfinderInLabel(viewfinder, ui-&gt;Origin_Video); camera-&gt;start(); //开启相机 //设置默认摄像头参数 QCameraViewfinderSettings set; // set.setResolution(640, 480); //设置显示分辨率 set.setMaximumFrameRate(30); //设置帧率 camera-&gt;setViewfinderSettings(set); stopVideo(); ui-&gt;Origin_Video-&gt;setPixmap(QPixmap(&quot;&quot;)); currentSource = Camera; // 更新当前视频源为摄像头 viewfinder-&gt;show(); displayVideo(); // 显示视频 &#125;\n\nyolov8 onnx 推理void MainWindow::on_actionTest_triggered() &#123; // std::string projectBasePath = &quot;./&quot;; // Set your ultralytics base path QString qs = QCoreApplication::applicationDirPath(); std::string projectBasePath = qs.toLocal8Bit().constData(); bool runOnGPU = false; // Note that in this example the classes are hard-coded and &#x27;classes.txt&#x27; is a place holder. Inference inf(projectBasePath + &quot;/moust_best.onnx&quot;, cv::Size(640, 640), &quot;mouse.txt&quot;, runOnGPU); std::string video_path = ui-&gt;dir_Edit-&gt;text().toLocal8Bit().constData(); // 读取视频文件 // cv::VideoCapture cap(projectBasePath + &quot;/video/video.mp4&quot;); cv::VideoCapture cap(video_path); if (!cap.isOpened()) &#123; std::cout &lt;&lt; &quot;Error opening video file&quot; &lt;&lt; std::endl; return ; &#125; cv::Mat frame; while (cap.read(frame)) &#123; // 推断开始... std::vector&lt;Detection&gt; output = inf.runInference(frame); int detections = output.size(); std::cout &lt;&lt; &quot;Number of detections:&quot; &lt;&lt; detections &lt;&lt; std::endl; for (int i = 0; i &lt; detections; ++i) &#123; Detection detection = output[i]; cv::Rect box = detection.box; cv::Scalar color = detection.color; // Detection box cv::rectangle(frame, box, color, 2); // Detection box text std::string classString = detection.className + &#x27; &#x27; + std::to_string(detection.confidence).substr(0, 4); cv::Size textSize = cv::getTextSize(classString, cv::FONT_HERSHEY_DUPLEX, 1, 2, 0); cv::Rect textBox(box.x, box.y - 40, textSize.width + 10, textSize.height + 20); cv::rectangle(frame, textBox, color, cv::FILLED); cv::putText(frame, classString, cv::Point(box.x + 5, box.y - 10), cv::FONT_HERSHEY_DUPLEX, 1, cv::Scalar(0, 0, 0), 2, 0); &#125; // 推断结束... // 仅用于预览 float scale = 0.8; cv::resize(frame, frame, cv::Size(frame.cols*scale, frame.rows*scale)); cv::imshow(&quot;Inference&quot;, frame); if (cv::waitKey(1) == 27) &#123; break; &#125; &#125; cap.release(); cv::destroyAllWindows(); &#125;\n\n多线程（onnx推理线程和界面主线程）摄像头与onnx互不干扰，说明主界面线程与onnx推理是分开线程进行的，ok！\n######################### 2024 05 09 更新 ##############################################\n","categories":["编程技术","Python","YOLOv8"],"tags":["yolov8","onnx","qt"]},{"title":"YOLOv8目标检测：使用ONNX模型进行推理","url":"/2024/09/04/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Python/YOLOv8/YOLOv8%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9A%E4%BD%BF%E7%94%A8ONNX%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E6%8E%A8%E7%90%86_onnx%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86-CSDN%E5%8D%9A%E5%AE%A2/","content":"YOLOv8目标检测：使用ONNX模型进行推理_onnx模型推理-CSDN博客\nExcerpt文章浏览阅读8.2k次，点赞46次，收藏119次。本文详细介绍了如何在COCO数据集上使用YOLOv8目标检测模型进行推理，涉及环境配置、代码实现（包括图像、视频和摄像头检测），以及展示ONNX模型在不同大小版本（YOLOv8n,YOLOv8s,YOLOv8m,YOLOv8l,YOLOv8x）上的实验结果。\n\n\n基于COCO数据集的YOLOv8目标检测onnx模型推理在本博客中，我们将探讨如何使用YOLOv8目标检测模型进行推理，包括图片，视频文件，摄像头实时检测，特别是ONNX在不同大小（YOLOv8n, YOLOv8s, YOLOv8m, YOLOv8l, YOLOv8x）的模型上进行的实验。我们还将讨论所需的环境配置，代码实现，以及如何展示推理结果。\n环境配置在详细描述环境配置和安装步骤之前，请确保您的系统已经安装了Python和pip。下面是详细的环境配置步骤，适用于基于YOLOv8模型进行目标检测的项目。\n1. 安装必要的Python库pip install onnxruntime-gpu==1.13.1 opencv-python==4.7.0.68 numpy==1.24.1 Pillow==9.4.0 -i https://pypi.tuna.tsinghua.edu.cn/simple/\n\n如果您没有GPU或者不打算使用GPU，可以安装onnxruntime而不是onnxruntime-gpu：\npip install onnxruntime==1.13.1 opencv-python==4.7.0.68 numpy==1.24.1 Pillow==9.4.0 -i https://pypi.tuna.tsinghua.edu.cn/simple/\n\n2. 验证安装安装完成后，您可以通过运行Python并尝试导入安装的包来验证是否成功安装了所有必要的库：\nimport onnxruntime import cv2 import numpy import PIL\n\n如果上述命令没有引发任何错误，那么恭喜您，您已成功配置了运行环境。\n小贴士\n如果您在安装过程中遇到任何问题，可能需要更新pip到最新版本：pip install --upgrade pip。\n对于使用NVIDIA GPU的用户，确保您的系统已安装CUDA和cuDNN。onnxruntime-gpu要求系统预装这些NVIDIA库以利用GPU加速。\n\n按照这些步骤，您应该能够成功配置环境并运行基于YOLOv8的目标检测项目了。\n权重下载YOLOv8模型的权重可以通过以下百度网盘链接下载：\n\n链接：https://pan.baidu.com/s/1xpAdN7C9CS-L4XBLgBG8Kw\n提取码：8dm8\n\n请确保下载适合您需求的模型版本。\n代码实现以下是进行目标检测的整体代码流程，包括模型加载、图像预处理、推理执行、后处理及结果展示的步骤。\nimport cv2 import onnxruntime as ort from PIL import Image import numpy as np # 置信度 confidence_thres = 0.35 # iou阈值 iou_thres = 0.5 # 类别 classes = &#123;0: &#x27;person&#x27;, 1: &#x27;bicycle&#x27;, 2: &#x27;car&#x27;, 3: &#x27;motorcycle&#x27;, 4: &#x27;airplane&#x27;, 5: &#x27;bus&#x27;, 6: &#x27;train&#x27;, 7: &#x27;truck&#x27;, 8: &#x27;boat&#x27;, 9: &#x27;traffic light&#x27;, 10: &#x27;fire hydrant&#x27;, 11: &#x27;stop sign&#x27;, 12: &#x27;parking meter&#x27;, 13: &#x27;bench&#x27;, 14: &#x27;bird&#x27;, 15: &#x27;cat&#x27;, 16: &#x27;dog&#x27;, 17: &#x27;horse&#x27;, 18: &#x27;sheep&#x27;, 19: &#x27;cow&#x27;, 20: &#x27;elephant&#x27;, 21: &#x27;bear&#x27;, 22: &#x27;zebra&#x27;, 23: &#x27;giraffe&#x27;, 24: &#x27;backpack&#x27;, 25: &#x27;umbrella&#x27;, 26: &#x27;handbag&#x27;, 27: &#x27;tie&#x27;, 28: &#x27;suitcase&#x27;, 29: &#x27;frisbee&#x27;, 30: &#x27;skis&#x27;, 31: &#x27;snowboard&#x27;, 32: &#x27;sports ball&#x27;, 33: &#x27;kite&#x27;, 34: &#x27;baseball bat&#x27;, 35: &#x27;baseball glove&#x27;, 36: &#x27;skateboard&#x27;, 37: &#x27;surfboard&#x27;, 38: &#x27;tennis racket&#x27;, 39: &#x27;bottle&#x27;, 40: &#x27;wine glass&#x27;, 41: &#x27;cup&#x27;, 42: &#x27;fork&#x27;, 43: &#x27;knife&#x27;, 44: &#x27;spoon&#x27;, 45: &#x27;bowl&#x27;, 46: &#x27;banana&#x27;, 47: &#x27;apple&#x27;, 48: &#x27;sandwich&#x27;, 49: &#x27;orange&#x27;, 50: &#x27;broccoli&#x27;, 51: &#x27;carrot&#x27;, 52: &#x27;hot dog&#x27;, 53: &#x27;pizza&#x27;, 54: &#x27;donut&#x27;, 55: &#x27;cake&#x27;, 56: &#x27;chair&#x27;, 57: &#x27;couch&#x27;, 58: &#x27;potted plant&#x27;, 59: &#x27;bed&#x27;, 60: &#x27;dining table&#x27;, 61: &#x27;toilet&#x27;, 62: &#x27;tv&#x27;, 63: &#x27;laptop&#x27;, 64: &#x27;mouse&#x27;, 65: &#x27;remote&#x27;, 66: &#x27;keyboard&#x27;, 67: &#x27;cell phone&#x27;, 68: &#x27;microwave&#x27;, 69: &#x27;oven&#x27;, 70: &#x27;toaster&#x27;, 71: &#x27;sink&#x27;, 72: &#x27;refrigerator&#x27;, 73: &#x27;book&#x27;, 74: &#x27;clock&#x27;, 75: &#x27;vase&#x27;, 76: &#x27;scissors&#x27;, 77: &#x27;teddy bear&#x27;, 78: &#x27;hair drier&#x27;, 79: &#x27;toothbrush&#x27;&#125; # 随机颜色 color_palette = np.random.uniform(100, 255, size=(len(classes), 3)) # 判断是使用GPU或CPU providers = [ (&#x27;CUDAExecutionProvider&#x27;, &#123; &#x27;device_id&#x27;: 0, # 可以选择GPU设备ID，如果你有多个GPU &#125;), &#x27;CPUExecutionProvider&#x27;, # 也可以设置CPU作为备选 ] def calculate_iou(box, other_boxes): &quot;&quot;&quot; 计算给定边界框与一组其他边界框之间的交并比（IoU）。 参数： - box: 单个边界框，格式为 [x1, y1, width, height]。 - other_boxes: 其他边界框的数组，每个边界框的格式也为 [x1, y1, width, height]。 返回值： - iou: 一个数组，包含给定边界框与每个其他边界框的IoU值。 &quot;&quot;&quot; # 计算交集的左上角坐标 x1 = np.maximum(box[0], np.array(other_boxes)[:, 0]) y1 = np.maximum(box[1], np.array(other_boxes)[:, 1]) # 计算交集的右下角坐标 x2 = np.minimum(box[0] + box[2], np.array(other_boxes)[:, 0] + np.array(other_boxes)[:, 2]) y2 = np.minimum(box[1] + box[3], np.array(other_boxes)[:, 1] + np.array(other_boxes)[:, 3]) # 计算交集区域的面积 intersection_area = np.maximum(0, x2 - x1) * np.maximum(0, y2 - y1) # 计算给定边界框的面积 box_area = box[2] * box[3] # 计算其他边界框的面积 other_boxes_area = np.array(other_boxes)[:, 2] * np.array(other_boxes)[:, 3] # 计算IoU值 iou = intersection_area / (box_area + other_boxes_area - intersection_area) return iou def custom_NMSBoxes(boxes, scores, confidence_threshold, iou_threshold): # 如果没有边界框，则直接返回空列表 if len(boxes) == 0: return [] # 将得分和边界框转换为NumPy数组 scores = np.array(scores) boxes = np.array(boxes) # 根据置信度阈值过滤边界框 mask = scores &gt; confidence_threshold filtered_boxes = boxes[mask] filtered_scores = scores[mask] # 如果过滤后没有边界框，则返回空列表 if len(filtered_boxes) == 0: return [] # 根据置信度得分对边界框进行排序 sorted_indices = np.argsort(filtered_scores)[::-1] # 初始化一个空列表来存储选择的边界框索引 indices = [] # 当还有未处理的边界框时，循环继续 while len(sorted_indices) &gt; 0: # 选择得分最高的边界框索引 current_index = sorted_indices[0] indices.append(current_index) # 如果只剩一个边界框，则结束循环 if len(sorted_indices) == 1: break # 获取当前边界框和其他边界框 current_box = filtered_boxes[current_index] other_boxes = filtered_boxes[sorted_indices[1:]] # 计算当前边界框与其他边界框的IoU iou = calculate_iou(current_box, other_boxes) # 找到IoU低于阈值的边界框，即与当前边界框不重叠的边界框 non_overlapping_indices = np.where(iou &lt;= iou_threshold)[0] # 更新sorted_indices以仅包含不重叠的边界框 sorted_indices = sorted_indices[non_overlapping_indices + 1] # 返回选择的边界框索引 return indices def draw_detections(img, box, score, class_id): &quot;&quot;&quot; 在输入图像上绘制检测到的对象的边界框和标签。 参数: img: 要在其上绘制检测结果的输入图像。 box: 检测到的边界框。 score: 对应的检测得分。 class_id: 检测到的对象的类别ID。 返回: 无 &quot;&quot;&quot; # 提取边界框的坐标 x1, y1, w, h = box # 根据类别ID检索颜色 color = color_palette[class_id] # 在图像上绘制边界框 cv2.rectangle(img, (int(x1), int(y1)), (int(x1 + w), int(y1 + h)), color, 2) # 创建标签文本，包括类名和得分 label = f&#x27;&#123;classes[class_id]&#125;: &#123;score:.2f&#125;&#x27; # 计算标签文本的尺寸 (label_width, label_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1) # 计算标签文本的位置 label_x = x1 label_y = y1 - 10 if y1 - 10 &gt; label_height else y1 + 10 # 绘制填充的矩形作为标签文本的背景 cv2.rectangle(img, (label_x, label_y - label_height), (label_x + label_width, label_y + label_height), color, cv2.FILLED) # 在图像上绘制标签文本 cv2.putText(img, label, (label_x, label_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA) def preprocess(img, input_width, input_height): &quot;&quot;&quot; 在执行推理之前预处理输入图像。 返回: image_data: 为推理准备好的预处理后的图像数据。 &quot;&quot;&quot; # 获取输入图像的高度和宽度 img_height, img_width = img.shape[:2] # 将图像颜色空间从BGR转换为RGB img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # 将图像大小调整为匹配输入形状 img = cv2.resize(img, (input_width, input_height)) # 通过除以255.0来归一化图像数据 image_data = np.array(img) / 255.0 # 转置图像，使通道维度为第一维 image_data = np.transpose(image_data, (2, 0, 1)) # 通道首 # 扩展图像数据的维度以匹配预期的输入形状 image_data = np.expand_dims(image_data, axis=0).astype(np.float32) # 返回预处理后的图像数据 return image_data, img_height, img_width def postprocess(input_image, output, input_width, input_height, img_width, img_height): &quot;&quot;&quot; 对模型输出进行后处理，提取边界框、得分和类别ID。 参数: input_image (numpy.ndarray): 输入图像。 output (numpy.ndarray): 模型的输出。 input_width (int): 模型输入宽度。 input_height (int): 模型输入高度。 img_width (int): 原始图像宽度。 img_height (int): 原始图像高度。 返回: numpy.ndarray: 绘制了检测结果的输入图像。 &quot;&quot;&quot; # 转置和压缩输出以匹配预期的形状 outputs = np.transpose(np.squeeze(output[0])) # 获取输出数组的行数 rows = outputs.shape[0] # 用于存储检测的边界框、得分和类别ID的列表 boxes = [] scores = [] class_ids = [] # 计算边界框坐标的缩放因子 x_factor = img_width / input_width y_factor = img_height / input_height # 遍历输出数组的每一行 for i in range(rows): # 从当前行提取类别得分 classes_scores = outputs[i][4:] # 找到类别得分中的最大得分 max_score = np.amax(classes_scores) # 如果最大得分高于置信度阈值 if max_score &gt;= confidence_thres: # 获取得分最高的类别ID class_id = np.argmax(classes_scores) # 从当前行提取边界框坐标 x, y, w, h = outputs[i][0], outputs[i][1], outputs[i][2], outputs[i][3] # 计算边界框的缩放坐标 left = int((x - w / 2) * x_factor) top = int((y - h / 2) * y_factor) width = int(w * x_factor) height = int(h * y_factor) # 将类别ID、得分和框坐标添加到各自的列表中 class_ids.append(class_id) scores.append(max_score) boxes.append([left, top, width, height]) # 应用非最大抑制过滤重叠的边界框 indices = custom_NMSBoxes(boxes, scores, confidence_thres, iou_thres) # 遍历非最大抑制后的选定索引 for i in indices: # 根据索引获取框、得分和类别ID box = boxes[i] score = scores[i] class_id = class_ids[i] # 在输入图像上绘制检测结果 draw_detections(input_image, box, score, class_id) # 返回修改后的输入图像 return input_image def init_detect_model(model_path): # 使用ONNX模型文件创建一个推理会话，并指定执行提供者 session = ort.InferenceSession(model_path, providers=providers) # 获取模型的输入信息 model_inputs = session.get_inputs() # 获取输入的形状，用于后续使用 input_shape = model_inputs[0].shape # 从输入形状中提取输入宽度 input_width = input_shape[2] # 从输入形状中提取输入高度 input_height = input_shape[3] # 返回会话、模型输入信息、输入宽度和输入高度 return session, model_inputs, input_width, input_height def detect_object(image, session, model_inputs, input_width, input_height): # 如果输入的图像是PIL图像对象，将其转换为NumPy数组 if isinstance(image, Image.Image): result_image = np.array(image) else: # 否则，直接使用输入的图像（假定已经是NumPy数组） result_image = image # 预处理图像数据，调整图像大小并可能进行归一化等操作 img_data, img_height, img_width = preprocess(result_image, input_width, input_height) # 使用预处理后的图像数据进行推理 outputs = session.run(None, &#123;model_inputs[0].name: img_data&#125;) # 对推理结果进行后处理，例如解码检测框，过滤低置信度的检测等 output_image = postprocess(result_image, outputs, input_width, input_height, img_width, img_height) # 返回处理后的图像 return output_image if __name__ == &#x27;__main__&#x27;: # 模型文件的路径 model_path = &quot;yolov8n.onnx&quot; # 初始化检测模型，加载模型并获取模型输入节点信息和输入图像的宽度、高度 session, model_inputs, input_width, input_height = init_detect_model(model_path) # 三种模式 1为图片预测，并显示结果图片；2为摄像头检测，并实时显示FPS； 3为视频检测，并保存结果视频 mode = 1 if mode == 1: # 读取图像文件 image_data = cv2.imread(&quot;street.jpg&quot;) # 使用检测模型对读入的图像进行对象检测 result_image = detect_object(image_data, session, model_inputs, input_width, input_height) # 将检测后的图像保存到文件 cv2.imwrite(&quot;output_image.jpg&quot;, result_image) # 在窗口中显示检测后的图像 cv2.imshow(&#x27;Output&#x27;, result_image) # 等待用户按键，然后关闭显示窗口 cv2.waitKey(0) elif mode == 2: # 打开摄像头 cap = cv2.VideoCapture() # 0表示默认摄像头，如果有多个摄像头可以尝试使用1、2等 # 检查摄像头是否成功打开 if not cap.isOpened(): print(&quot;Error: Could not open camera.&quot;) exit() # 初始化帧数计数器和起始时间 frame_count = 0 start_time = time.time() # 循环读取摄像头视频流 while True: # 读取一帧 ret, frame = cap.read() # 检查帧是否成功读取 if not ret: print(&quot;Error: Could not read frame.&quot;) break # 使用检测模型对读入的帧进行对象检测 output_image = detect_object(frame, session, model_inputs, input_width, input_height) # 计算帧速率 frame_count += 1 end_time = time.time() elapsed_time = end_time - start_time fps = frame_count / elapsed_time print(f&quot;FPS: &#123;fps:.2f&#125;&quot;) # 将FPS绘制在图像上 cv2.putText(output_image, f&quot;FPS: &#123;fps:.2f&#125;&quot;, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA) # 在窗口中显示当前帧 cv2.imshow(&quot;Video&quot;, output_image) # 按下 &#x27;q&#x27; 键退出循环 if cv2.waitKey(1) &amp; 0xFF == ord(&#x27;q&#x27;): break # 释放摄像头资源 cap.release() # 关闭窗口 cv2.destroyAllWindows() elif mode == 3: # 输入视频路径 input_video_path = &#x27;kun.mp4&#x27; # 输出视频路径 output_video_path = &#x27;kun_det.mp4&#x27; # 打开视频文件 cap = cv2.VideoCapture(input_video_path) # 检查视频是否成功打开 if not cap.isOpened(): print(&quot;Error: Could not open video.&quot;) exit() # 读取视频的基本信息 frame_width = int(cap.get(3)) frame_height = int(cap.get(4)) fps = cap.get(cv2.CAP_PROP_FPS) # 定义视频编码器和创建VideoWriter对象 fourcc = cv2.VideoWriter_fourcc(*&#x27;mp4v&#x27;) # 根据文件名后缀使用合适的编码器 out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height)) # 初始化帧数计数器和起始时间 frame_count = 0 start_time = time.time() while True: ret, frame = cap.read() if not ret: print(&quot;Info: End of video file.&quot;) break # 对读入的帧进行对象检测 output_image = detect_object(frame, session, model_inputs, input_width, input_height) # 计算并打印帧速率 frame_count += 1 end_time = time.time() elapsed_time = end_time - start_time if elapsed_time &gt; 0: fps = frame_count / elapsed_time print(f&quot;FPS: &#123;fps:.2f&#125;&quot;) # 将处理后的帧写入输出视频 out.write(output_image) #（可选）实时显示处理后的视频帧 cv2.imshow(&quot;Output Video&quot;, output_image) if cv2.waitKey(1) &amp; 0xFF == ord(&#x27;q&#x27;): break # 释放资源 cap.release() out.release() cv2.destroyAllWindows() else: print(&quot;输入错误，请检查mode的赋值&quot;)\n\n请根据您的需求调整置信度阈值、IOU阈值以及模型和mode的值（1为图片预测；2为摄像头检测； 3为视频检测）。\n结果展示推理完成后，您可以查看处理后的图像，如下所示：\n\n原始图片：\n\n检测后的图片：\n\n\n请替换为您自己的图像路径来查看效果；或者其他两种模式（摄像头实时检测、视频文件检测）进行尝试。\n总结通过以上步骤，我们展示了如何使用YOLOv8进行目标检测的完整流程，从环境配置到代码实现和结果展示。此过程适用于YOLOv8目标检测任意模型进行检测任务。\n\n希望这篇博客能够帮助您理解和实现基于YOLOv8的目标检测项目。如果有任何问题或需要进一步的帮助，请随时留言讨论。\n","categories":["编程技术","Python","YOLOv8"],"tags":["onnx模型推理"]},{"title":"YOLOv8训练并测试VisDrone数据集","url":"/2024/09/04/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Python/YOLOv8/YOLOv8%E8%AE%AD%E7%BB%83%E5%B9%B6%E6%B5%8B%E8%AF%95VisDrone%E6%95%B0%E6%8D%AE%E9%9B%86/","content":"1.环境准备在这之前，需要先准备主机的环境，环境如下：\nUbuntu18.04cuda11.3pytorch:1.11.0torchvision:0.12.0在服务器上执行以下命令，\n创建yolov8虚拟环境conda create -n yolov8 python=3.8\n\n进入虚拟环境conda activate yolov8\n\n安装pytorch v1.11.0pytorch v1.11.0（torch1.11.0+cu1113 ，torchvision0.12.0+cu113）\n# CUDA 11.3 pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113\n\n下载yolov8的代码先创建yolov8文件夹，存放等会要下载的yolov8代码mkdir yolov8进入yolov8文件夹，cd yolov8下载yolov8代码git clone https://github.com/ultralytics/ultralytics.git\n其他配置pip install ultralytics\n\n2.VisDrone数据集准备数据集下载github链接上下载：官方链接下载Task1：Object Detectino in Images下面的四个VisDrone-DET dataset数据集下载好zip文件后，使用winscp将zip文件传输到远程服务器上。在服务器上进入到zip文件所在的文件夹中使用unzip命令解压zip文件。如： unzip VisDrone2019-DET-val.zip\n数据集处理和yolov5所需要的格式一致。参考yolov5数据处理方法。主要是labels的生成，可以在yolov8下面新建一个visdrone2yolov.py文件。\nfrom utils.general import download, os, Path def visdrone2yolo(dir): from PIL import Image from tqdm import tqdm def convert_box(size, box): # Convert VisDrone box to YOLO xywh box dw = 1. / size[0] dh = 1. / size[1] return (box[0] + box[2] / 2) * dw, (box[1] + box[3] / 2) * dh, box[2] * dw, box[3] * dh (dir / &#x27;labels&#x27;).mkdir(parents=True, exist_ok=True) # make labels directory pbar = tqdm((dir / &#x27;annotations&#x27;).glob(&#x27;*.txt&#x27;), desc=f&#x27;Converting &#123;dir&#125;&#x27;) for f in pbar: img_size = Image.open((dir / &#x27;images&#x27; / f.name).with_suffix(&#x27;.jpg&#x27;)).size lines = [] with open(f, &#x27;r&#x27;) as file: # read annotation.txt for row in [x.split(&#x27;,&#x27;) for x in file.read().strip().splitlines()]: if row[4] == &#x27;0&#x27;: # VisDrone &#x27;ignored regions&#x27; class 0 continue cls = int(row[5]) - 1 # 类别号-1 box = convert_box(img_size, tuple(map(int, row[:4]))) lines.append(f&quot;&#123;cls&#125; &#123;&#x27; &#x27;.join(f&#x27;&#123;x:.6f&#125;&#x27; for x in box)&#125;\\n&quot;) with open(str(f).replace(os.sep + &#x27;annotations&#x27; + os.sep, os.sep + &#x27;labels&#x27; + os.sep), &#x27;w&#x27;) as fl: fl.writelines(lines) # write label.txt dir = Path(&#x27;/home/yolov5/datasets/VisDrone2019&#x27;) # datasets文件夹下Visdrone2019文件夹目录 # Convert for d in &#x27;VisDrone2019-DET-train&#x27;, &#x27;VisDrone2019-DET-val&#x27;, &#x27;VisDrone2019-DET-test-dev&#x27;: visdrone2yolo(dir / d) # convert VisDrone annotations to YOLO labels\n\n正确执行代码后，会在’VisDrone2019-DET-train’, ‘VisDrone2019-DET-val’, ‘VisDrone2019-DET-test-dev三个文件夹内新生成labels文件夹，用以存放将VisDrone数据集处理成YoloV8格式后的数据标\n修改数据配置文件记事本或notepad++打开ultralytics-main\\ultralytics\\datasets\\文件夹下的VisDrone.yaml文件，将其中path参数修改为VisDrone2019文件夹所在的路径。\n3.训练&#x2F;验证&#x2F;导出训练打开终端（或者pycharm等IDE），进入虚拟环境，随后进入yolov8文件夹，在终端中输入下面命令，即可开始训练。\nyolo task=detect mode=train model=yolov8s.pt data=datasets/VisDrone.yaml batch=16 epochs=100 imgsz=640 workers=0 device=0\n\n验证\nval数据集上验证激活yolov8虚拟环境conda activate yolov8进入yolov8文件夹cd pyCode/yolov8/ultralytics/ultralytics/使用如下命令，即可完成对验证数据的评估。开始验证\n\nyolo task=detect mode=val model=runs/detect/train4/weights/best.pt data=datasets/VisDrone.yaml device=0\n\n验证结果如下。\n\n在test数据集上验证将datasets&#x2F;VisDrone.yaml文件中的val路径修改为：VisDrone2019-DET-test-dev&#x2F;images\n\n# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..] # path: ../datasets/VisDrone # dataset root dir path: /home/xxx/yolov5/datasets/VisDrone # dataset root dir train: VisDrone2019-DET-train/images # train images (relative to &#x27;path&#x27;) 6471 images val: VisDrone2019-DET-test-dev/images # val images (relative to &#x27;path&#x27;) 548 images VisDrone2019-DET-val/images test: VisDrone2019-DET-test-dev/images # test images (optional) 1610 images\n\n\n使用如下命令，即可完成在VisDrone2019-DET-test-dev数据集上的评估。开始验证\nyolo task=detect mode=val model=runs/detect/train4/weights/best.pt data=datasets/VisDrone.yaml device=0\n\n结果如下\n导出使用如下命令即可导出\nyolo task=detect mode=export model=runs/detect/train4/weights/best.pt\n","categories":["编程技术","Python","YOLOv8"],"tags":["yolov8","虚拟环境","pytorch"]},{"title":"YOLO数据处理界面程序","url":"/2024/09/04/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Python/YOLOv8/YOLO%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%95%8C%E9%9D%A2%E7%A8%8B%E5%BA%8F/","content":"点击这里，观看项目说明视频讲解\n本案例 使用 YOLOv8 结合 Python Qt ，开发一个图形界面的 AI实时物品监测程序。\n注意\n如果你使用其它版本YOLO（比如YOLOv5）训练的模型，请修改相应的导入和检测代码。\n您需要高效学习，找工作？ 点击咨询 报名实战班点击查看学员就业情况示例代码下面示例代码实现了摄像头实时视频流的YOLO检测。\n如果还需要 包含 视频文件实时检测 的功能代码, 请将这个YOLO+Qt视频分享到朋友圈（点击打开），截屏发微给 byhy44\n&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span id=&quot;__span-0-1&quot;&gt;&lt;span&gt;from&lt;/span&gt; &lt;span&gt;PySide6&lt;/span&gt; &lt;span&gt;import&lt;/span&gt; &lt;span&gt;QtWidgets&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;QtCore&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;QtGui&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-2&quot;&gt;&lt;span&gt;import&lt;/span&gt; &lt;span&gt;cv2&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;os&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;time&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-3&quot;&gt;&lt;span&gt;from&lt;/span&gt; &lt;span&gt;threading&lt;/span&gt; &lt;span&gt;import&lt;/span&gt; &lt;span&gt;Thread&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-4&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-5&quot;&gt;&lt;span&gt;# 不然每次YOLO处理都会输出调试信息&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-6&quot;&gt;&lt;span&gt;os&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;environ&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;&#x27;YOLO_VERBOSE&#x27;&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;&#x27;False&#x27;&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-7&quot;&gt;&lt;span&gt;from&lt;/span&gt; &lt;span&gt;ultralytics&lt;/span&gt; &lt;span&gt;import&lt;/span&gt; &lt;span&gt;YOLO&lt;/span&gt; &lt;/span&gt;&lt;span id=&quot;__span-0-8&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-9&quot;&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;MWindow&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;QtWidgets&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;QMainWindow&lt;/span&gt;&lt;span&gt;):&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-10&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-11&quot;&gt;    &lt;span&gt;def&lt;/span&gt; &lt;span&gt;__init__&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;):&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-12&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-13&quot;&gt;        &lt;span&gt;super&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;__init__&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-14&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-15&quot;&gt;        &lt;span&gt;# 设置界面&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-16&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;setupUI&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-17&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-18&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;camBtn&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;clicked&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;connect&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;startCamera&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-19&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;stopBtn&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;clicked&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;connect&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;stop&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-20&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-21&quot;&gt;        &lt;span&gt;# 定义定时器，用于控制显示视频的帧率&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-22&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;timer_camera&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;QtCore&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;QTimer&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-23&quot;&gt;        &lt;span&gt;# 定时到了，回调 self.show_camera&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-24&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;timer_camera&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;timeout&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;connect&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;show_camera&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-25&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-26&quot;&gt;        &lt;span&gt;# 加载 YOLO nano 模型，第一次比较耗时，要20秒左右&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-27&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;model&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;YOLO&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&#x27;yolov8n.pt&#x27;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-28&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-29&quot;&gt;        &lt;span&gt;# 要处理的视频帧图片队列，目前就放1帧图片&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-30&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;frameToAnalyze&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;[]&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-31&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-32&quot;&gt;        &lt;span&gt;# 启动处理视频帧独立线程&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-33&quot;&gt;        &lt;span&gt;Thread&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;target&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;frameAnalyzeThreadFunc&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;daemon&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;True&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;start&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-34&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-35&quot;&gt;    &lt;span&gt;def&lt;/span&gt; &lt;span&gt;setupUI&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;):&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-36&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-37&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;resize&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;1200&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;800&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-38&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-39&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;setWindowTitle&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&#x27;白月黑羽 YOLO-Qt 演示&#x27;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-40&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-41&quot;&gt;        &lt;span&gt;# central Widget&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-42&quot;&gt;        &lt;span&gt;centralWidget&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;QtWidgets&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;QWidget&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-43&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;setCentralWidget&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;centralWidget&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-44&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-45&quot;&gt;        &lt;span&gt;# central Widget 里面的 主 layout&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-46&quot;&gt;        &lt;span&gt;mainLayout&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;QtWidgets&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;QVBoxLayout&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;centralWidget&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-47&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-48&quot;&gt;        &lt;span&gt;# 界面的上半部分 : 图形展示部分&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-49&quot;&gt;        &lt;span&gt;topLayout&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;QtWidgets&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;QHBoxLayout&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-50&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;label_ori_video&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;QtWidgets&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;QLabel&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-51&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;label_treated&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;QtWidgets&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;QLabel&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-52&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;label_ori_video&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;setMinimumSize&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;520&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;400&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-53&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;label_treated&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;setMinimumSize&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;520&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;400&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-54&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;label_ori_video&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;setStyleSheet&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&#x27;border:1px solid #D7E2F9;&#x27;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-55&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;label_treated&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;setStyleSheet&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&#x27;border:1px solid #D7E2F9;&#x27;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-56&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-57&quot;&gt;        &lt;span&gt;topLayout&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;addWidget&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;label_ori_video&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-58&quot;&gt;        &lt;span&gt;topLayout&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;addWidget&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;label_treated&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-59&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-60&quot;&gt;        &lt;span&gt;mainLayout&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;addLayout&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;topLayout&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-61&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-62&quot;&gt;        &lt;span&gt;# 界面下半部分： 输出框 和 按钮&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-63&quot;&gt;        &lt;span&gt;groupBox&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;QtWidgets&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;QGroupBox&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-64&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-65&quot;&gt;        &lt;span&gt;bottomLayout&lt;/span&gt; &lt;span&gt;=&lt;/span&gt;  &lt;span&gt;QtWidgets&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;QHBoxLayout&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;groupBox&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-66&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;textLog&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;QtWidgets&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;QTextBrowser&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-67&quot;&gt;        &lt;span&gt;bottomLayout&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;addWidget&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;textLog&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-68&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-69&quot;&gt;        &lt;span&gt;mainLayout&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;addWidget&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;groupBox&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-70&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-71&quot;&gt;        &lt;span&gt;btnLayout&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;QtWidgets&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;QVBoxLayout&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-72&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;videoBtn&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;QtWidgets&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;QPushButton&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&#x27;🎞️视频文件&#x27;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-73&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;camBtn&lt;/span&gt;   &lt;span&gt;=&lt;/span&gt; &lt;span&gt;QtWidgets&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;QPushButton&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&#x27;📹摄像头&#x27;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-74&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;stopBtn&lt;/span&gt;  &lt;span&gt;=&lt;/span&gt; &lt;span&gt;QtWidgets&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;QPushButton&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&#x27;🛑停止&#x27;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-75&quot;&gt;        &lt;span&gt;btnLayout&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;addWidget&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;videoBtn&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-76&quot;&gt;        &lt;span&gt;btnLayout&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;addWidget&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;camBtn&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-77&quot;&gt;        &lt;span&gt;btnLayout&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;addWidget&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;stopBtn&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-78&quot;&gt;        &lt;span&gt;bottomLayout&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;addLayout&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;btnLayout&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-79&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-80&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-81&quot;&gt;    &lt;span&gt;def&lt;/span&gt; &lt;span&gt;startCamera&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;):&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-82&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-83&quot;&gt;        &lt;span&gt;# 参考 https://docs.opencv.org/3.4/dd/d43/tutorial_py_video_display.html&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-84&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-85&quot;&gt;        &lt;span&gt;# 在 windows上指定使用 cv2.CAP_DSHOW 会让打开摄像头快很多， &lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-86&quot;&gt;        &lt;span&gt;# 在 Linux/Mac上 指定 V4L, FFMPEG 或者 GSTREAMER&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-87&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;cap&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;cv2&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;VideoCapture&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;cv2&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;CAP_DSHOW&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-88&quot;&gt;        &lt;span&gt;if&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;cap&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;isOpened&lt;/span&gt;&lt;span&gt;():&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-89&quot;&gt;            &lt;span&gt;print&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&quot;1号摄像头不能打开&quot;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-90&quot;&gt;            &lt;span&gt;return&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-91&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-92&quot;&gt;        &lt;span&gt;if&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;timer_camera&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;isActive&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;==&lt;/span&gt; &lt;span&gt;False&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;  &lt;span&gt;# 若定时器未启动&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-93&quot;&gt;            &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;timer_camera&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;start&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;50&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-94&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-95&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-96&quot;&gt;    &lt;span&gt;def&lt;/span&gt; &lt;span&gt;show_camera&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;):&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-97&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-98&quot;&gt;        &lt;span&gt;ret&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;frame&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;cap&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;read&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;  &lt;span&gt;# 从视频流中读取&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-99&quot;&gt;        &lt;span&gt;if&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; &lt;span&gt;ret&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-100&quot;&gt;            &lt;span&gt;return&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-101&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-102&quot;&gt;        &lt;span&gt;# 把读到的16:10帧的大小重新设置 &lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-103&quot;&gt;        &lt;span&gt;frame&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;cv2&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;resize&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;frame&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;520&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;400&lt;/span&gt;&lt;span&gt;))&lt;/span&gt;          &lt;/span&gt;&lt;span id=&quot;__span-0-104&quot;&gt;        &lt;span&gt;# 视频色彩转换回RGB，OpenCV images as BGR&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-105&quot;&gt;        &lt;span&gt;frame&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;cv2&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;cvtColor&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;frame&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;cv2&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;COLOR_BGR2RGB&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;  &lt;/span&gt;&lt;span id=&quot;__span-0-106&quot;&gt;        &lt;span&gt;qImage&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;QtGui&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;QImage&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;frame&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;data&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;frame&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;shape&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;],&lt;/span&gt; &lt;span&gt;frame&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;shape&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;],&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-107&quot;&gt;                                 &lt;span&gt;QtGui&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;QImage&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Format_RGB888&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;  &lt;span&gt;# 变成QImage形式&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-108&quot;&gt;        &lt;span&gt;# 往显示视频的Label里 显示QImage&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-109&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;label_ori_video&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;setPixmap&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;QtGui&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;QPixmap&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;fromImage&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;qImage&lt;/span&gt;&lt;span&gt;))&lt;/span&gt; &lt;/span&gt;&lt;span id=&quot;__span-0-110&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-111&quot;&gt;        &lt;span&gt;# 如果当前没有处理任务&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-112&quot;&gt;        &lt;span&gt;if&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;frameToAnalyze&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-113&quot;&gt;            &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;frameToAnalyze&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;append&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;frame&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-114&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-115&quot;&gt;    &lt;span&gt;def&lt;/span&gt; &lt;span&gt;frameAnalyzeThreadFunc&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;):&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-116&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-117&quot;&gt;        &lt;span&gt;while&lt;/span&gt; &lt;span&gt;True&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-118&quot;&gt;            &lt;span&gt;if&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;frameToAnalyze&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-119&quot;&gt;                &lt;span&gt;time&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;sleep&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;0.01&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-120&quot;&gt;                &lt;span&gt;continue&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-121&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-122&quot;&gt;            &lt;span&gt;frame&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;frameToAnalyze&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;pop&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-123&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-124&quot;&gt;            &lt;span&gt;results&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;model&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;frame&lt;/span&gt;&lt;span&gt;)[&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;]&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-125&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-126&quot;&gt;            &lt;span&gt;img&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;results&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;plot&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;line_width&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;    &lt;/span&gt;&lt;span id=&quot;__span-0-127&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-128&quot;&gt;            &lt;span&gt;qImage&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;QtGui&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;QImage&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;img&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;data&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;img&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;shape&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;],&lt;/span&gt; &lt;span&gt;img&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;shape&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;],&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-129&quot;&gt;                                    &lt;span&gt;QtGui&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;QImage&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Format_RGB888&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;  &lt;span&gt;# 变成QImage形式&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-130&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-131&quot;&gt;            &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;label_treated&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;setPixmap&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;QtGui&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;QPixmap&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;fromImage&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;qImage&lt;/span&gt;&lt;span&gt;))&lt;/span&gt;  &lt;span&gt;# 往显示Label里 显示QImage&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-132&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-133&quot;&gt;            &lt;span&gt;time&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;sleep&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;0.5&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-134&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-135&quot;&gt;    &lt;span&gt;def&lt;/span&gt; &lt;span&gt;stop&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;self&lt;/span&gt;&lt;span&gt;):&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-136&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;timer_camera&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;stop&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;  &lt;span&gt;# 关闭定时器&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-137&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;cap&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;release&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;  &lt;span&gt;# 释放视频流&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-138&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;label_ori_video&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;clear&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;  &lt;span&gt;# 清空视频显示区域        &lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-139&quot;&gt;        &lt;span&gt;self&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;label_treated&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;clear&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;  &lt;span&gt;# 清空视频显示区域&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-140&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-141&quot;&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-142&quot;&gt;&lt;span&gt;app&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;QtWidgets&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;QApplication&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-143&quot;&gt;&lt;span&gt;window&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;MWindow&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-144&quot;&gt;&lt;span&gt;window&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;show&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;__span-0-145&quot;&gt;&lt;span&gt;app&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;exec&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;\n","categories":["编程技术","Python","YOLOv8"],"tags":["yolov8"]},{"title":"YOLOv8训练自己的数据集","url":"/2024/09/04/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/Python/YOLOv8/Yolov8%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86/","content":"一、Yolov8简介1、yolov8 源码地址：工程链接：https://github.com/ultralytics/ultralytics\n2、官方文档：CLI - Ultralytics YOLOv8 Docs\n3、预训练模型百度网盘地址：训练时需要用到，下载的网址较慢：\n如果模型下载不了，加QQ：187100248.\n链接: https://pan.baidu.com/s/1YfMxRPGk8LF75a4cbgYxGg 提取码: rd7b\n二、模型训练1、标定红绿灯数据：         类别为23类，分别为：\n红绿灯类别red_lightgreen_lightyellow_lightoff_lightpart_ry_lightpart_rg_lightpart_yg_lightryg_lightcountdown_off_lightcountdown_on_lightshade_lightzeroonetwothreefourfivesixseveneightninebrokeNumberbrokenLight\n\n        标注工具地址：AI标注工具Labelme和LabelImage Labelme和LabelImage集成工具_labelimage与labelme-CSDN博客\n\n标注后图像格式\n2、训练环境：1）、Ubuntu18.04；\n2）、Cuda11.7 + CUDNN8.0.6；\n3）、opencv4.5.5；\n4）、PyTorch1.8.1-GPU；\n5）、python3.9\n3、数据转化： 1）、需要把上面标定的数据集中的.xml文件转换为.txt，转换代码为：\nimport osimport shutilimport xml.etree.ElementTree as ETfrom xml.etree.ElementTree import Element, SubElementfrom PIL import Imageimport cv2classes = [&#x27;red_light&#x27;, &#x27;green_light&#x27;, &#x27;yellow_light&#x27;, &#x27;off_light&#x27;, &#x27;part_ry_light&#x27;, &#x27;part_rg_light&#x27;, &#x27;part_yg_light&#x27;, &#x27;ryg_light&#x27;,&#x27;countdown_off_light&#x27;, &#x27;countdown_on_light&#x27;,&#x27;shade_light&#x27;,&#x27;zero&#x27;,&#x27;one&#x27;,&#x27;two&#x27;,&#x27;three&#x27;,&#x27;four&#x27;,&#x27;five&#x27;,&#x27;six&#x27;,&#x27;seven&#x27;,&#x27;eight&#x27;,&#x27;nine&#x27;,&#x27;brokeNumber&#x27;,&#x27;brokenLight&#x27;]class Xml_make(object):def __init__(self):super().__init__()def __indent(self, elem, level=0):i = &quot;\\n&quot; + level * &quot;\\t&quot;if len(elem):if not elem.text or not elem.text.strip():elem.text = i + &quot;\\t&quot;if not elem.tail or not elem.tail.strip():elem.tail = ifor elem in elem:self.__indent(elem, level + 1)if not elem.tail or not elem.tail.strip():elem.tail = ielse:if level and (not elem.tail or not elem.tail.strip()):elem.tail = idef _imageinfo(self, list_top):annotation_root = ET.Element(&#x27;annotation&#x27;)annotation_root.set(&#x27;verified&#x27;, &#x27;no&#x27;)tree = ET.ElementTree(annotation_root)&#x27;&#x27;&#x27;0:xml_savepath 1:folder,2:filename,3:path4:checked,5:width,6:height,7:depth&#x27;&#x27;&#x27;folder_element = ET.Element(&#x27;folder&#x27;)folder_element.text = list_top[1]annotation_root.append(folder_element)filename_element = ET.Element(&#x27;filename&#x27;)filename_element.text = list_top[2]annotation_root.append(filename_element)path_element = ET.Element(&#x27;path&#x27;)path_element.text = list_top[3]annotation_root.append(path_element)# checked_element = ET.Element(&#x27;checked&#x27;)# checked_element.text = list_top[4]# annotation_root.append(checked_element)source_element = ET.Element(&#x27;source&#x27;)database_element = SubElement(source_element, &#x27;database&#x27;)database_element.text = &#x27;Unknown&#x27;annotation_root.append(source_element)size_element = ET.Element(&#x27;size&#x27;)width_element = SubElement(size_element, &#x27;width&#x27;)width_element.text = str(list_top[5])height_element = SubElement(size_element, &#x27;height&#x27;)height_element.text = str(list_top[6])depth_element = SubElement(size_element, &#x27;depth&#x27;)depth_element.text = str(list_top[7])annotation_root.append(size_element)segmented_person_element = ET.Element(&#x27;segmented&#x27;)segmented_person_element.text = &#x27;0&#x27;annotation_root.append(segmented_person_element)return tree, annotation_rootdef _bndbox(self, annotation_root, list_bndbox):for i in range(0, len(list_bndbox), 9):object_element = ET.Element(&#x27;object&#x27;)name_element = SubElement(object_element, &#x27;name&#x27;)name_element.text = list_bndbox[i]# flag_element = SubElement(object_element, &#x27;flag&#x27;)# flag_element.text = list_bndbox[i + 1]pose_element = SubElement(object_element, &#x27;pose&#x27;)pose_element.text = list_bndbox[i + 2]truncated_element = SubElement(object_element, &#x27;truncated&#x27;)truncated_element.text = list_bndbox[i + 3]difficult_element = SubElement(object_element, &#x27;difficult&#x27;)difficult_element.text = list_bndbox[i + 4]bndbox_element = SubElement(object_element, &#x27;bndbox&#x27;)xmin_element = SubElement(bndbox_element, &#x27;xmin&#x27;)xmin_element.text = str(list_bndbox[i + 5])ymin_element = SubElement(bndbox_element, &#x27;ymin&#x27;)ymin_element.text = str(list_bndbox[i + 6])xmax_element = SubElement(bndbox_element, &#x27;xmax&#x27;)xmax_element.text = str(list_bndbox[i + 7])ymax_element = SubElement(bndbox_element, &#x27;ymax&#x27;)ymax_element.text = str(list_bndbox[i + 8])annotation_root.append(object_element)return annotation_rootdef txt_to_xml(self, list_top, list_bndbox):tree, annotation_root = self._imageinfo(list_top)annotation_root = self._bndbox(annotation_root, list_bndbox)self.__indent(annotation_root)tree.write(list_top[0], encoding=&#x27;utf-8&#x27;, xml_declaration=True)def txt_2_xml(source_path, xml_save_dir, jpg_save_dir,txt_dir):COUNT = 0for folder_path_tuple, folder_name_list, file_name_list in os.walk(source_path):for file_name in file_name_list:file_suffix = os.path.splitext(file_name)[-1]if file_suffix != &#x27;.jpg&#x27;:continuelist_top = []list_bndbox = []path = os.path.join(folder_path_tuple, file_name)xml_save_path = os.path.join(xml_save_dir, file_name.replace(file_suffix, &#x27;.xml&#x27;))txt_path = os.path.join(txt_dir, file_name.replace(file_suffix, &#x27;.txt&#x27;))filename = file_name#os.path.splitext(file_name)[0]checked = &#x27;NO&#x27;#print(file_name)im = Image.open(path)im_w = im.size[0]im_h = im.size[1]shutil.copy(path, jpg_save_dir)if im_w*im_h &gt; 34434015:print(file_name)if im_w &lt; 100:print(file_name)width = str(im_w)height = str(im_h)depth = &#x27;3&#x27;flag = &#x27;rectangle&#x27;pose = &#x27;Unspecified&#x27;truncated = &#x27;0&#x27;difficult = &#x27;0&#x27;list_top.extend([xml_save_path, folder_path_tuple, filename, path, checked, width, height, depth])for line in open(txt_path, &#x27;r&#x27;):line = line.strip()info = line.split(&#x27; &#x27;)name = classes[int(info[0])]x_cen = float(info[1]) * im_wy_cen = float(info[2]) * im_hw = float(info[3]) * im_wh = float(info[4]) * im_hxmin = int(x_cen - w / 2) - 1ymin = int(y_cen - h / 2) - 1xmax = int(x_cen + w / 2) + 3ymax = int(y_cen + h / 2) + 3if xmin &lt; 0:xmin = 0if ymin &lt; 0:ymin = 0if xmax &gt; im_w - 1:xmax = im_w - 1if ymax &gt; im_h - 1:ymax = im_h - 1if w &gt; 5 and h &gt; 5:list_bndbox.extend([name, flag, pose, truncated, difficult,str(xmin), str(ymin), str(xmax), str(ymax)])if xmin &lt; 0 or xmax &gt; im_w - 1 or ymin &lt; 0 or ymax &gt; im_h - 1:print(xml_save_path)Xml_make().txt_to_xml(list_top, list_bndbox)COUNT += 1#print(COUNT, xml_save_path)if __name__ == &quot;__main__&quot;:out_xml_path = &quot;/home/TL_TrainData/&quot; # .xml输出文件存放地址out_jpg_path = &quot;/home/TL_TrainData/&quot; # .jpg输出文件存放地址txt_path = &quot;/home/Data/TrafficLight/trainData&quot; # yolov3标注.txt和图片文件夹images_path = &quot;/home/TrafficLight/trainData&quot; # image文件存放地址txt_2_xml(images_path, out_xml_path, out_jpg_path, txt_path)\n\n4、构造训练数据：2）、训练样本数据构造，需要把分成images和labels，images下面放入图片，labels下面放入.txt文件:\n\n分成images和labels\n\nimages\n\nlabels\n5、训练样本： 1）、首先安装训练包：\npip install ultralytics\n\n2）、修改训练数据参数coco128_light.yaml文件，这个是自己修改的。\n# Ultralytics YOLO 🚀, AGPL-3.0 license# COCO128 dataset https://www.kaggle.com/ultralytics/coco128 (first 128 images from COCO train2017) by Ultralytics# Example usage: yolo train data=coco128.yaml# parent# ├── ultralytics# └── datasets# └── coco128 ← downloads here (7 MB)# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]path: /home/Data/TrafficLight/datasets # dataset root dirtrain: images # train images (relative to &#x27;path&#x27;) 128 imagesval: images # val images (relative to &#x27;path&#x27;) 128 imagestest: # test images (optional)# Parametersnc: 23 # number of classes# Classesnames:0: red_light1: green_light2: yellow_light3: off_light4: part_ry_light5: part_rg_light6: part_yg_light7: ryg_light8: countdown_off_light9: countdown_on_light10: shade_light11: zero12: one13: two14: three15: four16: five17: six18: seven19: eight20: nine21: brokeNumber22: brokenLight# Download script/URL (optional)#download: https://ultralytics.com/assets/coco128.zip\n\n3）、执行 train_yolov8x_light.sh，内容为：\nyolo detect train data=coco128_light.yaml model=./runs/last.pt epochs=100 imgsz=640 workers=16 batch=32\n\n        开始启动训练：\n\n模型训练启动\n三、验证模型：1、图像测试：from ultralytics import YOLOmodel = YOLO(&#x27;best.pt&#x27;)results = model(&#x27;bus.jpg&#x27;)for r in results:print(r.boxes)\n\n2、视频测试：import cv2from ultralytics import YOLO# Load the YOLOv8 modelmodel = YOLO(&#x27;best.pt&#x27;)# Open the video filevideo_path = &quot;test_car_person_1080P.mp4&quot;cap = cv2.VideoCapture(video_path)# Loop through the video frameswhile cap.isOpened():# Read a frame from the videosuccess, frame = cap.read()if success:# Run YOLOv8 inference on the frameresults = model(frame)# Visualize the results on the frameannotated_frame = results[0].plot()# Display the annotated framecv2.imshow(&quot;YOLOv8 Inference&quot;, annotated_frame)cv2.waitKey(10)\n\n四、导出ONNX1、训练输出，经过上面的训练后，得到训练生成文件，weights下生成了best.pt和last.pt：\n\n训练数据生成文件\n2、等训练完毕后，利用best.pt生成best.onnx，执行命令如下：\nyolo export model=best.pt imgsz=640 format=onnx opset=12\n\n五、Opencv实现Yolov8 C++ 识别1、开发环境：1）、win7&#x2F;win10；\n2）、vs2019；\n3）、opencv4.7.0；\n2、main函数代码：#include &lt;iostream&gt;#include &lt;vector&gt;#include &quot;opencv2/opencv.hpp&quot;#include &quot;inference.h&quot;#include &lt;io.h&gt;#include &lt;thread&gt;#define socklen_t int#pragma comment (lib, &quot;ws2_32.lib&quot;)using namespace std;using namespace cv;int getFiles(std::string path, std::vector&lt;std::string&gt;&amp; files, std::vector&lt;std::string&gt;&amp; names)&#123;int i = 0;intptr_t hFile = 0;struct _finddata_t c_file;std::string imageFile = path + &quot;*.*&quot;;if ((hFile = _findfirst(imageFile.c_str(), &amp;c_file)) == -1L)&#123;_findclose(hFile);return -1;&#125;else&#123;while (true)&#123;std::string strname(c_file.name);if (std::string::npos != strname.find(&quot;.jpg&quot;) || std::string::npos != strname.find(&quot;.png&quot;) || std::string::npos != strname.find(&quot;.bmp&quot;))&#123;std::string fullName = path + c_file.name;files.push_back(fullName);std::string cutname = strname.substr(0, strname.rfind(&quot;.&quot;));names.push_back(cutname);&#125;if (_findnext(hFile, &amp;c_file) != 0)&#123;_findclose(hFile);break;&#125;&#125;&#125;return 0;&#125;int main()&#123;std::string projectBasePath = &quot;./&quot;; // Set your ultralytics base pathbool runOnGPU = true;//// Pass in either://// &quot;yolov8s.onnx&quot; or &quot;yolov5s.onnx&quot;//// To run Inference with yolov8/yolov5 (ONNX)//// Note that in this example the classes are hard-coded and &#x27;classes.txt&#x27; is a place holder.Inference inf(projectBasePath + &quot;/best.onnx&quot;, cv::Size(640, 640), &quot;classes.txt&quot;, runOnGPU);std::vector&lt;std::string&gt; files;std::vector&lt;std::string&gt; names;getFiles(&quot;./test/&quot;, files, names);//std::vector&lt;std::string&gt; imageNames;//imageNames.push_back(projectBasePath + &quot;/test/20221104_8336.jpg&quot;);//imageNames.push_back(projectBasePath + &quot;/test/20221104_8339.jpg&quot;);for (int i = 0; i &lt; files.size(); ++i)&#123;cv::Mat frame = cv::imread(files[i]);// Inference starts here...clock_t start, end;float time;start = clock();std::vector&lt;Detection&gt; output = inf.runInference(frame);end = clock();time = (float)(end - start);//CLOCKS_PER_SEC;printf(&quot;timeCount = %f\\n&quot;, time);int detections = output.size();std::cout &lt;&lt; &quot;Number of detections:&quot; &lt;&lt; detections &lt;&lt; std::endl;for (int i = 0; i &lt; detections; ++i)&#123;Detection detection = output[i];cv::Rect box = detection.box;cv::Scalar color = detection.color;// Detection boxcv::rectangle(frame, box, color, 2);// Detection box textstd::string classString = detection.className + &#x27; &#x27; + std::to_string(detection.confidence).substr(0, 4);cv::Size textSize = cv::getTextSize(classString, cv::FONT_HERSHEY_DUPLEX, 1, 2, 0);cv::Rect textBox(box.x, box.y - 40, textSize.width + 10, textSize.height + 20);cv::rectangle(frame, textBox, color, cv::FILLED);cv::putText(frame, classString, cv::Point(box.x + 5, box.y - 10), cv::FONT_HERSHEY_DUPLEX, 1, cv::Scalar(0, 0, 0), 2, 0);&#125;// Inference ends here...// This is only for preview purposesfloat scale = 0.8;cv::resize(frame, frame, cv::Size(frame.cols * scale, frame.rows * scale));cv::imshow(&quot;Inference&quot;, frame);cv::waitKey(10);&#125;&#125;\n\n3、yolov8 头文件inference.h代码：#ifndef INFERENCE_H#define INFERENCE_H// Cpp native#include &lt;fstream&gt;#include &lt;vector&gt;#include &lt;string&gt;#include &lt;random&gt;// OpenCV / DNN / Inference#include &lt;opencv2/imgproc.hpp&gt;#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/dnn.hpp&gt;struct Detection&#123;int class_id&#123;0&#125;;std::string className&#123;&#125;;float confidence&#123;0.0&#125;;cv::Scalar color&#123;&#125;;cv::Rect box&#123;&#125;;&#125;;class Inference&#123;public:Inference(const std::string &amp;onnxModelPath, const cv::Size &amp;modelInputShape = &#123;640, 640&#125;, const std::string &amp;classesTxtFile = &quot;&quot;, const bool &amp;runWithCuda = true);std::vector&lt;Detection&gt; runInference(const cv::Mat &amp;input);private:void loadClassesFromFile();void loadOnnxNetwork();cv::Mat formatToSquare(const cv::Mat &amp;source);std::string modelPath&#123;&#125;;std::string classesPath&#123;&#125;;bool cudaEnabled&#123;&#125;;std::vector&lt;std::string&gt; classes&#123; &quot;red_light&quot;, &quot;green_light&quot;, &quot;yellow_light&quot;, &quot;off_light&quot;, &quot;part_ry_light&quot;, &quot;part_rg_light&quot;, &quot;part_yg_light&quot;, &quot;ryg_light&quot;,&quot;countdown_off_light&quot;, &quot;countdown_on_light&quot;,&quot;shade_light&quot;,&quot;zero&quot;,&quot;one&quot;,&quot;two&quot;,&quot;three&quot;,&quot;four&quot;,&quot;five&quot;,&quot;six&quot;,&quot;seven&quot;,&quot;eight&quot;,&quot;nine&quot;,&quot;brokeNumber&quot;,&quot;brokenLight&quot; &#125;;cv::Size2f modelShape&#123;&#125;;float modelConfidenceThreshold &#123;0.25&#125;;float modelScoreThreshold &#123;0.45&#125;;float modelNMSThreshold &#123;0.50&#125;;bool letterBoxForSquare = true;cv::dnn::Net net;&#125;;#endif // INFERENCE_H\n\n4、yolov8 cpp文件inference.cpp代码：#include &quot;inference.h&quot;Inference::Inference(const std::string &amp;onnxModelPath, const cv::Size &amp;modelInputShape, const std::string &amp;classesTxtFile, const bool &amp;runWithCuda)&#123;modelPath = onnxModelPath;modelShape = modelInputShape;classesPath = classesTxtFile;cudaEnabled = runWithCuda;loadOnnxNetwork();// loadClassesFromFile(); The classes are hard-coded for this example&#125;std::vector&lt;Detection&gt; Inference::runInference(const cv::Mat &amp;input)&#123;cv::Mat modelInput = input;if (letterBoxForSquare &amp;&amp; modelShape.width == modelShape.height)modelInput = formatToSquare(modelInput);cv::Mat blob;cv::dnn::blobFromImage(modelInput, blob, 1.0/255.0, modelShape, cv::Scalar(), true, false);net.setInput(blob);std::vector&lt;cv::Mat&gt; outputs;net.forward(outputs, net.getUnconnectedOutLayersNames());int rows = outputs[0].size[1];int dimensions = outputs[0].size[2];bool yolov8 = false;// yolov5 has an output of shape (batchSize, 25200, 85) (Num classes + box[x,y,w,h] + confidence[c])// yolov8 has an output of shape (batchSize, 84, 8400) (Num classes + box[x,y,w,h])if (dimensions &gt; rows) // Check if the shape[2] is more than shape[1] (yolov8)&#123;yolov8 = true;rows = outputs[0].size[2];dimensions = outputs[0].size[1];outputs[0] = outputs[0].reshape(1, dimensions);cv::transpose(outputs[0], outputs[0]);&#125;float *data = (float *)outputs[0].data;float x_factor = modelInput.cols / modelShape.width;float y_factor = modelInput.rows / modelShape.height;std::vector&lt;int&gt; class_ids;std::vector&lt;float&gt; confidences;std::vector&lt;cv::Rect&gt; boxes;for (int i = 0; i &lt; rows; ++i)&#123;if (yolov8)&#123;float *classes_scores = data+4;cv::Mat scores(1, classes.size(), CV_32FC1, classes_scores);cv::Point class_id;double maxClassScore;minMaxLoc(scores, 0, &amp;maxClassScore, 0, &amp;class_id);if (maxClassScore &gt; modelScoreThreshold)&#123;confidences.push_back(maxClassScore);class_ids.push_back(class_id.x);float x = data[0];float y = data[1];float w = data[2];float h = data[3];int left = int((x - 0.5 * w) * x_factor);int top = int((y - 0.5 * h) * y_factor);int width = int(w * x_factor);int height = int(h * y_factor);boxes.push_back(cv::Rect(left, top, width, height));&#125;&#125;else // yolov5&#123;float confidence = data[4];if (confidence &gt;= modelConfidenceThreshold)&#123;float *classes_scores = data+5;cv::Mat scores(1, classes.size(), CV_32FC1, classes_scores);cv::Point class_id;double max_class_score;minMaxLoc(scores, 0, &amp;max_class_score, 0, &amp;class_id);if (max_class_score &gt; modelScoreThreshold)&#123;confidences.push_back(confidence);class_ids.push_back(class_id.x);float x = data[0];float y = data[1];float w = data[2];float h = data[3];int left = int((x - 0.5 * w) * x_factor);int top = int((y - 0.5 * h) * y_factor);int width = int(w * x_factor);int height = int(h * y_factor);boxes.push_back(cv::Rect(left, top, width, height));&#125;&#125;&#125;data += dimensions;&#125;std::vector&lt;int&gt; nms_result;cv::dnn::NMSBoxes(boxes, confidences, modelScoreThreshold, modelNMSThreshold, nms_result);std::vector&lt;Detection&gt; detections&#123;&#125;;for (unsigned long i = 0; i &lt; nms_result.size(); ++i)&#123;int idx = nms_result[i];Detection result;result.class_id = class_ids[idx];result.confidence = confidences[idx];std::random_device rd;std::mt19937 gen(rd());std::uniform_int_distribution&lt;int&gt; dis(100, 255);result.color = cv::Scalar(dis(gen),dis(gen),dis(gen));result.className = classes[result.class_id];result.box = boxes[idx];detections.push_back(result);&#125;return detections;&#125;void Inference::loadClassesFromFile()&#123;std::ifstream inputFile(classesPath);if (inputFile.is_open())&#123;std::string classLine;while (std::getline(inputFile, classLine))classes.push_back(classLine);inputFile.close();&#125;&#125;void Inference::loadOnnxNetwork()&#123;net = cv::dnn::readNetFromONNX(modelPath);if (cudaEnabled)&#123;std::cout &lt;&lt; &quot;\\nRunning on CUDA&quot; &lt;&lt; std::endl;net.setPreferableBackend(cv::dnn::DNN_BACKEND_CUDA);net.setPreferableTarget(cv::dnn::DNN_TARGET_CUDA);&#125;else&#123;std::cout &lt;&lt; &quot;\\nRunning on CPU&quot; &lt;&lt; std::endl;net.setPreferableBackend(cv::dnn::DNN_BACKEND_OPENCV);net.setPreferableTarget(cv::dnn::DNN_TARGET_CPU);&#125;&#125;cv::Mat Inference::formatToSquare(const cv::Mat &amp;source)&#123;int col = source.cols;int row = source.rows;int _max = MAX(col, row);cv::Mat result = cv::Mat::zeros(_max, _max, CV_8UC3);source.copyTo(result(cv::Rect(0, 0, col, row)));return result;&#125;\n\n4、效果图：\n\nvs2019工程运行结果\n\n红绿灯识别结果\n","categories":["编程技术","Python","YOLOv8"],"tags":["yolov8"]},{"title":"WPF控件库汇总","url":"/2024/12/10/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/DotNet/WPF/%E6%8E%A7%E4%BB%B6%E5%BA%93/WPF%E6%8E%A7%E4%BB%B6%E5%BA%93%E6%B1%87%E6%80%BB/","content":"XamlFlairXamlFlair库的目标是简化常见动画的实现，并允许开发人员使用几行Xaml轻松地添加单个或组合的动画集。\n\n","categories":["编程技术","DotNet","WPF","控件库"],"tags":["WPF","控件库"]}]